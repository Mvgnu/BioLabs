 (cd "$(git rev-parse --show-toplevel)" && git apply --3way <<'EOF'
diff --git a/.dockerignore b/.dockerignore
new file mode 100644
index 0000000000000000000000000000000000000000..3e76b6e72b10fdf069d0d20374a785e8856ffbe2
--- /dev/null
+++ b/.dockerignore
@@ -0,0 +1,5 @@
+**/__pycache__/
+**/*.pyc
+.git
+frontend/node_modules
+frontend/.next
diff --git a/.env.example b/.env.example
new file mode 100644
index 0000000000000000000000000000000000000000..cd60fa329f6ea318eca08db752f9e516efe1459c
--- /dev/null
+++ b/.env.example
@@ -0,0 +1,10 @@
+# Replace with a secure random string. The app will fail to start if unset.
+SECRET_KEY=change-me
+DATABASE_URL=sqlite:///./test.db
+UPLOAD_DIR=uploaded_files
+MINIO_ENDPOINT=
+MINIO_ACCESS_KEY=
+MINIO_SECRET_KEY=
+MINIO_BUCKET=uploads
+CELERY_BROKER_URL=memory://
+INVENTORY_WARNING_DAYS=7
diff --git a/.github/workflows/ci.yml b/.github/workflows/ci.yml
new file mode 100644
index 0000000000000000000000000000000000000000..684b23eb630242ee28b4a9b777fb372ba9172ff4
--- /dev/null
+++ b/.github/workflows/ci.yml
@@ -0,0 +1,37 @@
+name: CI
+on:
+  push:
+    branches: [ work ]
+  pull_request:
+    branches: [ work ]
+jobs:
+  test:
+    runs-on: ubuntu-latest
+    services:
+      postgres:
+        image: postgres:15
+        env:
+          POSTGRES_DB: labdb
+          POSTGRES_USER: postgres
+          POSTGRES_PASSWORD: postgres
+        ports: ['5432:5432']
+        options: >-
+          --health-cmd pg_isready
+          --health-interval 10s
+          --health-timeout 5s
+          --health-retries 5
+      redis:
+        image: redis:7-alpine
+        ports: ['6379:6379']
+    steps:
+      - uses: actions/checkout@v3
+      - name: Set up Python
+        uses: actions/setup-python@v4
+        with:
+          python-version: '3.11'
+      - name: Install dependencies
+        run: |
+          pip install -r backend/requirements.txt
+      - name: Run tests
+        run: |
+          pytest -q backend/app/tests
diff --git a/.gitignore b/.gitignore
new file mode 100644
index 0000000000000000000000000000000000000000..9b185e8a51db4fe6d6ce8fc0320044174ac39bb9
--- /dev/null
+++ b/.gitignore
@@ -0,0 +1,9 @@
+__pycache__/
+*.pyc
+*.db
+uploaded_files/
+.env
+frontend/node_modules/
+frontend/.next/
+__pycache__/
+alembic/versions/__pycache__/
diff --git a/PLAN.md b/PLAN.md
new file mode 100644
index 0000000000000000000000000000000000000000..bad746558d274e66ba55255d5f7d086e5f514c5c
--- /dev/null
+++ b/PLAN.md
@@ -0,0 +1,122 @@
+# Project Plan
+
+## Completed
+- Set up FastAPI backend with SQLAlchemy models
+- Implemented authentication endpoints for registering and logging in
+- Created inventory item CRUD endpoints
+- Added dynamic field definitions API
+- Added basic team management endpoints
+- Implemented item relationship endpoints
+- Added file upload endpoints and tests
+- Implemented relationship graph endpoint
+- Integrated MinIO for file storage
+- Added item update/delete endpoints and filtering options
+- Implemented advanced inventory filtering by custom fields
+- Bootstrapped a Next.js frontend using shadcn/ui
+- Added login and register pages with auth token handling
+- Built inventory listing and creation UI
+- Field definition management UI
+
+- Improve validation in dynamic forms and implement item editing
+- Integrated file uploads and relationship graphs in the frontend
+- Add real-time updates and websocket support
+- Implement protocol template engine
+- Build protocol execution tracking
+- Implement troubleshooting system
+- Integrate troubleshooting UI
+- Expand protocol UI
+- Implement lab notebook module
+- Build lab notebook frontend
+- Implement collaboration comment system
+- Implement resource scheduling system
+- Integrate scheduling with notification system
+
+- Add notification preferences center
+
+- Expand notification channels (email/SMS)
+
+- Implement daily notification digest
+- Add user profile management endpoints
+- Basic sequence analysis utilities
+- Asynchronous sequence analysis jobs
+- Sequence alignment endpoint
+- Primer design endpoint
+- Restriction mapping endpoint
+- Sequence annotation tools
+- Sanger chromatogram parsing endpoint
+- Build chromatogram viewer UI and integrate file previews
+- Integrate chromatogram viewer with inventory file previews
+
+- Add FASTA/FASTQ file preview support
+
+- Implement BLAST sequence search
+- Integrate BLAST search in frontend
+- Add job status page for sequence analysis
+- Implement project management module
+
+- Calendar events and analysis tools
+- Lab buddy assistant integration
+- Full-text search endpoint
+- Inventory CSV export endpoint
+- Barcode generation endpoint
+- Inventory CSV import endpoint
+- Two-factor authentication
+- Password reset flow
+
+- Implement audit logging system
+- Basic analytics endpoint
+- Equipment integration API
+- External service connectors
+- Compliance dashboard
+- Audit report generator
+- Notebook PDF export endpoint
+- Docker containerization and CI pipeline
+- E2E tests with Playwright
+- Performance benchmarking with Locust
+- UI/UX refinements
+- DevOps & Monitoring
+- Data analysis toolkit with Pandas integration
+- Knowledge base module
+- Workflow engine for chaining tools and protocols
+- Notebook entries linked to projects and multiple items
+- Calendar UI integration
+- Project task tracking and timeline management
+- Lab network system
+- Resource sharing framework
+- Global marketplace infrastructure
+- Marketplace interface
+- Community feed module
+- Community moderation tools
+- Database migrations with Alembic
+- Basic authorization checks for inventory actions
+- Granular RBAC for teams and projects
+- Route security audit enforcing authentication
+- Unique constraint on field definitions
+- Hierarchical location management
+- Notebook entry signing and versioning
+- Equipment operations module (maintenance, SOPs, training)
+- Inventory faceted search
+- Protocol variables and conditional workflows
+- Structured notebook blocks
+- Service marketplace for CRO offerings
+- Public protocol sharing
+- Protocol merge request system
+- Intelligent assistant inventory forecasting
+- Predictive inventory alerts
+- Assistant protocol suggestions
+- Assistant experiment design helper
+- Service result delivery & payment tracking
+- Trending protocol analytics
+- Trending knowledge article analytics
+- Trending item analytics
+- Trending thread analytics
+- Trending analytics UI integration
+- Analytics timeframe filter
+- Knowledge article comments & public sharing
+- Protocol diff viewer page
+- Community forum module
+- Post like system and trending posts analytics
+- Trending ranking improvements
+- Protocol star system and analytics
+- Knowledge article star system and analytics
+- Article comment analytics
diff --git a/README.md b/README.md
index cfa54cc480d3868505efe1c26598bbbbd45df3ae..2326e59d4a32916553eef35b513b2515d3510106 100644
--- a/README.md
+++ b/README.md
@@ -87,50 +87,61 @@ CREATE TABLE item_relationships (

 ## Phase 1: Core Foundation (Months 1-3)

 ### Sprint 1-2: Authentication & User Management

 **Goals:** Establish secure user authentication and team management

 **Implementation:**

 1. **User Authentication System**
 - JWT-based auth with refresh tokens
 - OAuth2 integration (Google, ORCID)
 - Two-factor authentication
 - Password policies and recovery
 1. **Team & Permission Management**
 - Hierarchical team structure
 - Role-based permissions (Admin, Manager, Researcher, Viewer)
 - Custom permission sets
 - Audit logging system
 1. **User Profile System**
 - Professional profiles with ORCID integration
 - Expertise tags
 - Publication links
 - Availability calendar

+### Authorization
+
+The API enforces role-based access control. Users belong to teams with a role of
+`owner`, `manager`, or `member`. Owners can manage team membership, while
+managers may edit team resources. Members have read/write access only to items
+they own. Global administrators (`is_admin` flag) bypass these checks. Helpers in
+`rbac.py` verify the current user has the required role before mutating data.
+Every API route is audited at startup to ensure it requires authentication unless
+explicitly listed as public (login, registration, metrics). A test verifies this
+policy so new endpoints cannot accidentally bypass the RBAC layer.
+
 **Deliverables:**

 - Complete auth API endpoints
 - User dashboard with profile management
 - Team invitation and management system
 - Permission matrix configuration UI

 ### Sprint 3-4: Dynamic Inventory System Foundation

 **Goals:** Build flexible inventory management with custom fields

 **Implementation:**

 1. **Dynamic Field System**
 - Field definition API
 - UI for creating custom fields per inventory type
 - Field types: text, number, date, select, multi-select, file, relation
 - Validation rules engine
 - Inheritance system for field definitions
 1. **Core Inventory Management**
 - CRUD operations for all inventory types
 - Barcode/QR code generation and scanning
 - Location management with hierarchical storage
 - Batch operations support
 - Import/Export functionality (CSV, Excel)
@@ -430,50 +441,53 @@ CREATE TABLE item_relationships (
 - ETL processes
 - Data warehouse
 - Feature engineering
 - Model training pipeline
 - A/B testing framework

 **Deliverables:**

 - Analytics dashboard
 - ML prediction interfaces
 - Data export tools
 - Performance reports

 ### Sprint 23-24: Advanced Integrations

 **Goals:** Connect with external systems and equipment

 **Implementation:**

 1. **Equipment Integration**
 - API for lab equipment
 - Data collection agents
 - Real-time monitoring
 - Automated logging
 - Maintenance alerts
+  - Schedule tasks with `/api/equipment/maintenance`
+  - Upload SOPs via `/api/equipment/sops`
+  - Record training with `/api/equipment/training`
 1. **External Services**
 - NCBI integration
 - PubMed linking
 - Patent database search
 - Vendor catalogs
 - Shipping providers
 1. **Compliance & Reporting**
 - Regulatory compliance tools
 - Audit trail generation
 - Report templates
 - Data retention policies
 - Export for audits

 **Deliverables:**

 - Equipment integration SDK
 - External service connectors
 - Compliance dashboard
 - Audit report generator

 ## Implementation Guidelines

 ### Development Best Practices

 1. **Code Quality**
@@ -541,25 +555,193 @@ CREATE TABLE item_relationships (
 - Compliance updates

 ## Budget Considerations

 - Development team: 8-12 engineers
 - Infrastructure: $5-15k/month
 - Third-party services: $2-5k/month
 - Security audits: $20-30k/year
 - Marketing: $50-100k/year

 ## Timeline Summary

 - Phase 1: Months 1-4 (Core Foundation)
 - Phase 2: Months 5-7 (Enhanced Features)
 - Phase 3: Months 8-10 (Collaboration)
 - Phase 4: Months 11-12 (Advanced Features)
 - Total MVP to Full Platform: 12 months

 ## Next Steps

 1. Finalize technical architecture
 1. Hire core development team
 1. Set up development environment
 1. Begin Phase 1 Sprint 1
 1. Establish user advisory board
+
+## Development with Docker
+
+Run `docker-compose up --build` to start all services including Postgres, Redis, MinIO, the FastAPI backend, and Next.js frontend.
+
+### Environment variables
+
+Copy `.env.example` to `.env` and adjust values for your deployment. `SECRET_KEY` **must** be set to a random value or the server will refuse to start. Other variables configure database access, file storage, and Celery broker settings. `INVENTORY_WARNING_DAYS` controls when inventory alerts are sent based on forecasted depletion (default `7`).
+
+### Database migrations
+
+The project uses Alembic for managing database schema changes. After modifying
+models, create a new migration and apply it:
+
+```bash
+alembic revision --autogenerate -m "description"
+alembic upgrade head
+```
+
+Make sure `DATABASE_URL` is set to your database before running these commands.
+
+## End-to-end tests
+
+The frontend uses Playwright for E2E tests. From the `frontend` directory run:
+
+```bash
+npm install
+npm run test:e2e
+```
+
+This starts the Next.js dev server and executes the tests.
+
+
+## Performance benchmarking
+
+Basic load tests are provided using [Locust](https://locust.io). From the `backend` directory run:
+
+```bash
+pip install -r requirements.txt
+locust -f benchmarks/locustfile.py --host http://localhost:8000
+```
+
+Then open http://localhost:8089 in your browser to start the test.
+
+## Data analysis tools
+
+The backend includes a simple Pandas-based endpoint for summarizing CSV files. Upload a CSV to `/api/data/summary` to receive descriptive statistics for numeric columns.
+
+## Analytics
+
+Use `/api/analytics/summary` to see counts of inventory items by type. The
+`/api/analytics/trending-protocols` endpoint lists the most frequently executed
+protocol templates and weights results by how recently each template was run.
+`/api/analytics/trending-protocol-stars` ranks public templates by how many users have starred them, weighted by how recent the stars are.
+`/api/analytics/trending-articles` returns the most viewed knowledge articles,
+also weighting recent views more heavily, while `/api/analytics/trending-article-stars` ranks articles by star count with a similar recency weighting. `/api/analytics/trending-article-comments` lists articles with the most comment activity. `/api/analytics/trending-items` shows
+which inventory items appear most often in notebook entries with a similar
+recency weighting. `/api/analytics/trending-threads` lists forum threads by a
+weighted score of post count and recent activity, and
+`/api/analytics/trending-posts` ranks community posts using likes adjusted for
+how recently the post was created. Each trending endpoint accepts an optional
+`days` query parameter (default `30`) to control how far back the data should be
+aggregated.
+
+The frontend Analytics page visualizes these trends, displaying item counts and
+lists of top protocols, knowledge articles, inventory items, and forum threads.
+
+## Knowledge base
+
+Users can contribute articles to a collaborative knowledge base. Use the `/api/knowledge/articles` endpoints to create, list, update, and delete articles tagged by topic.
+Set `is_public` to make an article visible to all users. Articles can be commented on via `/api/comments` using the `knowledge_article_id` field.
+Readers may star helpful articles with `POST /api/knowledge/articles/{id}/star` and remove their star via `DELETE` to the same path. Retrieve the current count from `/api/knowledge/articles/{id}/stars`.
+
+## Forum
+
+Use `/api/forum/threads` to start discussion threads and `/api/forum/threads/{thread_id}/posts` to reply. The forum allows labs to collaborate and troubleshoot together.
+
+## Protocol diffs
+
+Compare two protocol templates using `/api/protocols/diff?old_id=...&new_id=...` to see a unified diff of their contents.
+The frontend exposes a diff viewer at `/protocols/diff` where you can select two templates and view the differences.
+
+## Calendar events
+
+Schedule meetings or equipment usage with the `/api/calendar` endpoints. The frontend Calendar page allows creating events and viewing them in a list.
+
+## Project management
+
+Create and organize projects using `/api/projects`. Each project can have multiple tasks managed via `/api/projects/{project_id}/tasks`. The Projects page allows creating projects and tracking task status.
+
+## Lab network
+
+Labs can create public profiles and connect with other labs to collaborate. Use `/api/labs` to create and list lab profiles. Request connections with `/api/labs/{lab_id}/connections` and accept them via `/api/labs/connections/{connection_id}/accept`.
+
+
+## Locations
+
+Manage hierarchical storage locations via the `/api/locations` endpoints. Locations can be nested (e.g. `Building > Room > Freezer > Shelf`). When creating or updating an inventory item, set `location_id` to link it to a specific location.
+
+## Faceted inventory search
+
+The `/api/inventory/facets` endpoint returns counts of items grouped by type, status and team, along with available custom fields. The `/api/inventory/items` list API accepts `status`, `team_id`, `created_from`, and `created_to` query parameters to filter results. The frontend inventory page uses these facets to provide sidebar filters and shareable URLs.
+
+## Resource sharing
+
+Connected labs can share equipment with each other. Submit a request to `/api/resource-shares` with a resource ID and the target lab. Lab owners view requests at `/api/resource-shares` and may accept or reject them via `/api/resource-shares/{share_id}/accept` or `/reject`.
+
+## Marketplace
+
+Labs may list inventory items for exchange or sale. Create a listing via `/api/marketplace/listings` with the item ID and optional price. Anyone can view open listings at `/api/marketplace/listings`. Interested labs submit a request to `/api/marketplace/listings/{listing_id}/requests` and the listing owner may accept or reject it using `/api/marketplace/requests/{request_id}/accept` or `/reject`.
+The frontend includes a Marketplace page where labs can browse listings, create their own, and manage incoming requests.
+
+Labs may also offer **services** such as sequencing runs. Create a service listing via `/api/services/listings` and request it with `/api/services/listings/{listing_id}/requests`. Providers respond using `/api/services/requests/{request_id}/accept` or `/reject`.
+After completing a request, providers upload result files with `/api/services/requests/{request_id}/deliver`. Requesters confirm payment via `/api/services/requests/{request_id}/confirm-payment` which marks the request as paid.
+
+## Workflows and enhanced notebook
+
+Workflows combine analysis tools and protocol templates into reusable pipelines. Create workflows via `/api/workflows` with a list of steps referencing tool or protocol IDs. Run a workflow on an inventory item by calling `/api/workflows/run`.
+
+Protocol templates may define **variables** that must be provided when executing. Include a `variables` array when creating a template. When starting an execution, all required parameters must be supplied in the `params` object.
+Templates can be shared with the community by setting `is_public` to `true`. Public templates are listed at `/api/protocols/public`. Use `/api/protocols/templates/{id}/fork` to copy a public template into your own team for customization.
+Anyone may propose improvements via **merge requests** using `/api/protocols/merge-requests`. Template authors can review requests, accept them to update their template, or reject them.
+Users may also **star** interesting public templates. Add a star with `POST /api/protocols/templates/{id}/star` and remove it with `DELETE` to the same path. Retrieve the current star count via `/api/protocols/templates/{id}/stars`.
+
+Workflow steps accept an optional `condition` expression. If the expression evaluates to false using the current `item` and accumulated `results`, the step is skipped. This allows simple branching logic without a full workflow engine.
+
+Notebook entries now support linking to projects, multiple items, protocols, and uploaded images. Include `project_id`, `items`, `protocols`, and `images` fields when creating or updating entries.
+
+Entries may include **structured blocks** representing rich text, tables, images, and materials used. The API accepts a `blocks` array when creating or updating entries, storing each block as JSON so the frontend's TipTap editor can reconstruct the content.
+
+Entries can be **signed** by their author and subsequently **witnessed** by another user. Signing locks the entry from further edits. Every save automatically records a new version in `notebook_entry_versions`, which can be retrieved via `/api/notebook/entries/{entry_id}/versions`.
+Use `/api/notebook/entries/{entry_id}/sign` to sign an entry and `/witness` to witness it.
+
+## Lab buddy assistant
+
+The `/api/assistant` endpoints provide a lightweight chat assistant. Ask
+questions with `/api/assistant/ask` and view history via `/api/assistant`.
+The assistant can forecast inventory depletion based on recent notebook
+usage with `/api/assistant/forecast`.
+It can also suggest relevant protocols and matching materials from your
+inventory using `/api/assistant/suggest?goal=...`.
+The design helper at `/api/assistant/design?goal=...` returns a suggested
+protocol, matching materials, and relevant knowledge articles to kick start
+an experiment.
+Each day a background task reviews the forecast and sends an in-app or
+email notification if any item is projected to run out within
+`INVENTORY_WARNING_DAYS`.
+
+## Community feed
+
+Users can follow other researchers and share short posts. Create posts with `/api/community/posts` and follow a user via `/api/community/follow/{user_id}`. Your feed of followed users is available at `/api/community/feed`. The frontend provides a simple feed page to browse recent posts.
+Posts can be liked using `/api/community/posts/{post_id}/like` and unliked via `DELETE` to the same path. Retrieve the like count with `/api/community/posts/{post_id}/likes`. Posts can also be reported for moderation using `/api/community/posts/{post_id}/report`. Reports are listed at `/api/community/reports` and may be resolved via `/api/community/reports/{report_id}/resolve`.
+
+## UI/UX improvements
+
+Recent frontend updates focus on accessibility and usability:
+
+- Responsive navigation menu with mobile toggle
+- Skip link for keyboard users
+- Loading and error states on inventory pages
+- Simple onboarding tour displayed on first visit
+
+## Monitoring
+
+The backend exposes Prometheus metrics at `/metrics`. Running `docker-compose up`
+also starts Prometheus and Grafana. Visit `http://localhost:3001` to view
+metrics dashboards. Set `SENTRY_DSN` in the backend environment to enable
+Sentry error reporting.
diff --git a/alembic.ini b/alembic.ini
new file mode 100644
index 0000000000000000000000000000000000000000..b9d142fe752a6fbe4cc8423a313e4a3ab3e961a7
--- /dev/null
+++ b/alembic.ini
@@ -0,0 +1,141 @@
+# A generic, single database configuration.
+
+[alembic]
+# path to migration scripts.
+# this is typically a path given in POSIX (e.g. forward slashes)
+# format, relative to the token %(here)s which refers to the location of this
+# ini file
+script_location = %(here)s/alembic
+
+# template used to generate migration file names; The default value is %%(rev)s_%%(slug)s
+# Uncomment the line below if you want the files to be prepended with date and time
+# see https://alembic.sqlalchemy.org/en/latest/tutorial.html#editing-the-ini-file
+# for all available tokens
+# file_template = %%(year)d_%%(month).2d_%%(day).2d_%%(hour).2d%%(minute).2d-%%(rev)s_%%(slug)s
+
+# sys.path path, will be prepended to sys.path if present.
+# defaults to the current working directory.  for multiple paths, the path separator
+# is defined by "path_separator" below.
+prepend_sys_path = .
+
+
+# timezone to use when rendering the date within the migration file
+# as well as the filename.
+# If specified, requires the python>=3.9 or backports.zoneinfo library and tzdata library.
+# Any required deps can installed by adding `alembic[tz]` to the pip requirements
+# string value is passed to ZoneInfo()
+# leave blank for localtime
+# timezone =
+
+# max length of characters to apply to the "slug" field
+# truncate_slug_length = 40
+
+# set to 'true' to run the environment during
+# the 'revision' command, regardless of autogenerate
+# revision_environment = false
+
+# set to 'true' to allow .pyc and .pyo files without
+# a source .py file to be detected as revisions in the
+# versions/ directory
+# sourceless = false
+
+# version location specification; This defaults
+# to <script_location>/versions.  When using multiple version
+# directories, initial revisions must be specified with --version-path.
+# The path separator used here should be the separator specified by "path_separator"
+# below.
+# version_locations = %(here)s/bar:%(here)s/bat:%(here)s/alembic/versions
+
+# path_separator; This indicates what character is used to split lists of file
+# paths, including version_locations and prepend_sys_path within configparser
+# files such as alembic.ini.
+# The default rendered in new alembic.ini files is "os", which uses os.pathsep
+# to provide os-dependent path splitting.
+#
+# Note that in order to support legacy alembic.ini files, this default does NOT
+# take place if path_separator is not present in alembic.ini.  If this
+# option is omitted entirely, fallback logic is as follows:
+#
+# 1. Parsing of the version_locations option falls back to using the legacy
+#    "version_path_separator" key, which if absent then falls back to the legacy
+#    behavior of splitting on spaces and/or commas.
+# 2. Parsing of the prepend_sys_path option falls back to the legacy
+#    behavior of splitting on spaces, commas, or colons.
+#
+# Valid values for path_separator are:
+#
+# path_separator = :
+# path_separator = ;
+# path_separator = space
+# path_separator = newline
+#
+# Use os.pathsep. Default configuration used for new projects.
+path_separator = os
+
+# set to 'true' to search source files recursively
+# in each "version_locations" directory
+# new in Alembic version 1.10
+# recursive_version_locations = false
+
+# the output encoding used when revision files
+# are written from script.py.mako
+# output_encoding = utf-8
+
+# database URL.  This is consumed by the user-maintained env.py script only.
+# other means of configuring database URLs may be customized within the env.py
+# file.
+sqlalchemy.url =
+
+
+[post_write_hooks]
+# post_write_hooks defines scripts or Python functions that are run
+# on newly generated revision scripts.  See the documentation for further
+# detail and examples
+
+# format using "black" - use the console_scripts runner, against the "black" entrypoint
+# hooks = black
+# black.type = console_scripts
+# black.entrypoint = black
+# black.options = -l 79 REVISION_SCRIPT_FILENAME
+
+# lint with attempts to fix using "ruff" - use the exec runner, execute a binary
+# hooks = ruff
+# ruff.type = exec
+# ruff.executable = %(here)s/.venv/bin/ruff
+# ruff.options = check --fix REVISION_SCRIPT_FILENAME
+
+# Logging configuration.  This is also consumed by the user-maintained
+# env.py script only.
+[loggers]
+keys = root,sqlalchemy,alembic
+
+[handlers]
+keys = console
+
+[formatters]
+keys = generic
+
+[logger_root]
+level = WARNING
+handlers = console
+qualname =
+
+[logger_sqlalchemy]
+level = WARNING
+handlers =
+qualname = sqlalchemy.engine
+
+[logger_alembic]
+level = INFO
+handlers =
+qualname = alembic
+
+[handler_console]
+class = StreamHandler
+args = (sys.stderr,)
+level = NOTSET
+formatter = generic
+
+[formatter_generic]
+format = %(levelname)-5.5s [%(name)s] %(message)s
+datefmt = %H:%M:%S
diff --git a/alembic/README b/alembic/README
new file mode 100644
index 0000000000000000000000000000000000000000..98e4f9c44effe479ed38c66ba922e7bcc672916f
--- /dev/null
+++ b/alembic/README
@@ -0,0 +1 @@
+Generic single-database configuration.
\ No newline at end of file
diff --git a/alembic/env.py b/alembic/env.py
new file mode 100644
index 0000000000000000000000000000000000000000..4595bddb3e8ea1f80dece379e0c00dee1d171f04
--- /dev/null
+++ b/alembic/env.py
@@ -0,0 +1,86 @@
+from logging.config import fileConfig
+
+from sqlalchemy import engine_from_config
+from sqlalchemy import pool
+from logging.config import fileConfig
+import os
+
+from backend.app import models
+
+from alembic import context
+
+# this is the Alembic Config object, which provides
+# access to the values within the .ini file in use.
+config = context.config
+
+# Interpret the config file for Python logging.
+# This line sets up loggers basically.
+if config.config_file_name is not None:
+    fileConfig(config.config_file_name)
+
+# add your model's MetaData object here
+# for 'autogenerate' support
+# from myapp import mymodel
+# target_metadata = mymodel.Base.metadata
+target_metadata = models.Base.metadata
+
+# other values from the config, defined by the needs of env.py,
+# can be acquired:
+# my_important_option = config.get_main_option("my_important_option")
+# ... etc.
+
+
+def run_migrations_offline() -> None:
+    """Run migrations in 'offline' mode.
+
+    This configures the context with just a URL
+    and not an Engine, though an Engine is acceptable
+    here as well.  By skipping the Engine creation
+    we don't even need a DBAPI to be available.
+
+    Calls to context.execute() here emit the given string to the
+    script output.
+
+    """
+    url = os.getenv("DATABASE_URL", config.get_main_option("sqlalchemy.url"))
+    context.configure(
+        url=url,
+        target_metadata=target_metadata,
+        literal_binds=True,
+        dialect_opts={"paramstyle": "named"},
+    )
+
+    with context.begin_transaction():
+        context.run_migrations()
+
+
+def run_migrations_online() -> None:
+    """Run migrations in 'online' mode.
+
+    In this scenario we need to create an Engine
+    and associate a connection with the context.
+
+    """
+    configuration = config.get_section(config.config_ini_section)
+    if not configuration:
+        configuration = {}
+    configuration["sqlalchemy.url"] = os.getenv("DATABASE_URL", configuration.get("sqlalchemy.url"))
+    connectable = engine_from_config(
+        configuration,
+        prefix="sqlalchemy.",
+        poolclass=pool.NullPool,
+    )
+
+    with connectable.connect() as connection:
+        context.configure(
+            connection=connection, target_metadata=target_metadata
+        )
+
+        with context.begin_transaction():
+            context.run_migrations()
+
+
+if context.is_offline_mode():
+    run_migrations_offline()
+else:
+    run_migrations_online()
diff --git a/alembic/script.py.mako b/alembic/script.py.mako
new file mode 100644
index 0000000000000000000000000000000000000000..11016301e749297acb67822efc7974ee53c905c6
--- /dev/null
+++ b/alembic/script.py.mako
@@ -0,0 +1,28 @@
+"""${message}
+
+Revision ID: ${up_revision}
+Revises: ${down_revision | comma,n}
+Create Date: ${create_date}
+
+"""
+from typing import Sequence, Union
+
+from alembic import op
+import sqlalchemy as sa
+${imports if imports else ""}
+
+# revision identifiers, used by Alembic.
+revision: str = ${repr(up_revision)}
+down_revision: Union[str, Sequence[str], None] = ${repr(down_revision)}
+branch_labels: Union[str, Sequence[str], None] = ${repr(branch_labels)}
+depends_on: Union[str, Sequence[str], None] = ${repr(depends_on)}
+
+
+def upgrade() -> None:
+    """Upgrade schema."""
+    ${upgrades if upgrades else "pass"}
+
+
+def downgrade() -> None:
+    """Downgrade schema."""
+    ${downgrades if downgrades else "pass"}
diff --git a/alembic/versions/12345abcde01_post_likes.py b/alembic/versions/12345abcde01_post_likes.py
new file mode 100644
index 0000000000000000000000000000000000000000..663d2deb90a30c8f9ee23e60c6a4c177ebca754b
--- /dev/null
+++ b/alembic/versions/12345abcde01_post_likes.py
@@ -0,0 +1,23 @@
+"""add post likes table"""
+
+from alembic import op
+import sqlalchemy as sa
+from typing import Sequence, Union
+
+revision: str = '12345abcde01'
+down_revision: Union[str, Sequence[str], None] = '420fcd2743f2'
+branch_labels: Union[str, Sequence[str], None] = None
+depends_on: Union[str, Sequence[str], None] = None
+
+
+def upgrade() -> None:
+    op.create_table(
+        'post_likes',
+        sa.Column('post_id', sa.UUID(as_uuid=True), sa.ForeignKey('posts.id'), primary_key=True),
+        sa.Column('user_id', sa.UUID(as_uuid=True), sa.ForeignKey('users.id'), primary_key=True),
+        sa.Column('created_at', sa.DateTime(), nullable=False, server_default=sa.text('CURRENT_TIMESTAMP')),
+    )
+
+
+def downgrade() -> None:
+    op.drop_table('post_likes')
diff --git a/alembic/versions/1a2b3c4d5ef0_article_views.py b/alembic/versions/1a2b3c4d5ef0_article_views.py
new file mode 100644
index 0000000000000000000000000000000000000000..990dd8bf935dc301854febf90022cc4e800f3a15
--- /dev/null
+++ b/alembic/versions/1a2b3c4d5ef0_article_views.py
@@ -0,0 +1,24 @@
+"""add knowledge article views table"""
+
+from alembic import op
+import sqlalchemy as sa
+from typing import Sequence, Union
+
+revision: str = '1a2b3c4d5ef0'
+down_revision: Union[str, Sequence[str], None] = '5e3d29cf5af1'
+branch_labels: Union[str, Sequence[str], None] = None
+depends_on: Union[str, Sequence[str], None] = None
+
+
+def upgrade() -> None:
+    op.create_table(
+        'knowledge_article_views',
+        sa.Column('id', sa.UUID(as_uuid=True), primary_key=True),
+        sa.Column('article_id', sa.UUID(as_uuid=True), sa.ForeignKey('knowledge_articles.id')),
+        sa.Column('user_id', sa.UUID(as_uuid=True), sa.ForeignKey('users.id')),
+        sa.Column('viewed_at', sa.DateTime(), nullable=False, server_default=sa.text('CURRENT_TIMESTAMP')),
+    )
+
+
+def downgrade() -> None:
+    op.drop_table('knowledge_article_views')
diff --git a/alembic/versions/2345b6789abc_article_stars.py b/alembic/versions/2345b6789abc_article_stars.py
new file mode 100644
index 0000000000000000000000000000000000000000..25b8fab3d1b6c8d0484f7d16204cbc52c372fa9b
--- /dev/null
+++ b/alembic/versions/2345b6789abc_article_stars.py
@@ -0,0 +1,23 @@
+"""add knowledge article stars table"""
+
+from alembic import op
+import sqlalchemy as sa
+from typing import Sequence, Union
+
+revision: str = '2345b6789abc'
+down_revision: Union[str, Sequence[str], None] = 'abcdef123456'
+branch_labels: Union[str, Sequence[str], None] = None
+depends_on: Union[str, Sequence[str], None] = None
+
+
+def upgrade() -> None:
+    op.create_table(
+        'knowledge_article_stars',
+        sa.Column('article_id', sa.UUID(as_uuid=True), sa.ForeignKey('knowledge_articles.id'), primary_key=True),
+        sa.Column('user_id', sa.UUID(as_uuid=True), sa.ForeignKey('users.id'), primary_key=True),
+        sa.Column('created_at', sa.DateTime(), nullable=False, server_default=sa.text('CURRENT_TIMESTAMP')),
+    )
+
+
+def downgrade() -> None:
+    op.drop_table('knowledge_article_stars')
diff --git a/alembic/versions/420fcd2743f2_protocol_merge_requests.py b/alembic/versions/420fcd2743f2_protocol_merge_requests.py
new file mode 100644
index 0000000000000000000000000000000000000000..8afca3ca01815fabd6b6a6ce5236e343b4d90677
--- /dev/null
+++ b/alembic/versions/420fcd2743f2_protocol_merge_requests.py
@@ -0,0 +1,28 @@
+"""add protocol merge request table"""
+
+from alembic import op
+import sqlalchemy as sa
+from typing import Sequence, Union
+
+revision: str = '420fcd2743f2'
+down_revision: Union[str, Sequence[str], None] = '476a303c6afe'
+branch_labels: Union[str, Sequence[str], None] = None
+depends_on: Union[str, Sequence[str], None] = None
+
+
+def upgrade() -> None:
+    op.create_table(
+        'protocol_merge_requests',
+        sa.Column('id', sa.UUID(), primary_key=True),
+        sa.Column('template_id', sa.UUID(), sa.ForeignKey('protocol_templates.id')),
+        sa.Column('proposer_id', sa.UUID(), sa.ForeignKey('users.id')),
+        sa.Column('content', sa.String(), nullable=False),
+        sa.Column('variables', sa.JSON(), nullable=True),
+        sa.Column('status', sa.String(), nullable=True, server_default='open'),
+        sa.Column('created_at', sa.DateTime(), nullable=True),
+        sa.Column('updated_at', sa.DateTime(), nullable=True),
+    )
+
+
+def downgrade() -> None:
+    op.drop_table('protocol_merge_requests')
diff --git a/alembic/versions/476a303c6afe_public_protocols.py b/alembic/versions/476a303c6afe_public_protocols.py
new file mode 100644
index 0000000000000000000000000000000000000000..f63c5ed43a3af9d76a30ead901e3b200a4d7feb6
--- /dev/null
+++ b/alembic/versions/476a303c6afe_public_protocols.py
@@ -0,0 +1,20 @@
+"""add public and fork fields to protocol templates"""
+
+from alembic import op
+import sqlalchemy as sa
+from typing import Sequence, Union
+
+revision: str = '476a303c6afe'
+down_revision: Union[str, Sequence[str], None] = 'ff4b75d7cabc'
+branch_labels: Union[str, Sequence[str], None] = None
+depends_on: Union[str, Sequence[str], None] = None
+
+
+def upgrade() -> None:
+    op.add_column('protocol_templates', sa.Column('is_public', sa.Boolean(), nullable=True, server_default=sa.false()))
+    op.add_column('protocol_templates', sa.Column('forked_from', sa.UUID(), sa.ForeignKey('protocol_templates.id'), nullable=True))
+
+
+def downgrade() -> None:
+    op.drop_column('protocol_templates', 'forked_from')
+    op.drop_column('protocol_templates', 'is_public')
diff --git a/alembic/versions/5e3d29cf5af1_service_request_delivery.py b/alembic/versions/5e3d29cf5af1_service_request_delivery.py
new file mode 100644
index 0000000000000000000000000000000000000000..4b0df8da5774d18a7b79ecc30a186610dad0711d
--- /dev/null
+++ b/alembic/versions/5e3d29cf5af1_service_request_delivery.py
@@ -0,0 +1,22 @@
+"""add service request delivery
+
+Revision ID: 5e3d29cf5af1
+Revises: ff4b75d7cabc_add_equipment_ops
+Create Date: 2025-07-26 00:00:00.000000
+"""
+from alembic import op
+import sqlalchemy as sa
+
+revision = '5e3d29cf5af1'
+down_revision = 'ff4b75d7cabc'
+branch_labels = None
+depends_on = None
+
+def upgrade() -> None:
+    op.add_column('service_requests', sa.Column('result_file_id', sa.UUID(as_uuid=True), nullable=True))
+    op.add_column('service_requests', sa.Column('payment_status', sa.String(), nullable=True, server_default='pending'))
+
+
+def downgrade() -> None:
+    op.drop_column('service_requests', 'payment_status')
+    op.drop_column('service_requests', 'result_file_id')
diff --git a/alembic/versions/74cfc64cc205_add_rbac_roles.py b/alembic/versions/74cfc64cc205_add_rbac_roles.py
new file mode 100644
index 0000000000000000000000000000000000000000..b87c18c467443337b509ff269c172c4cbda45510
--- /dev/null
+++ b/alembic/versions/74cfc64cc205_add_rbac_roles.py
@@ -0,0 +1,23 @@
+"""add is_admin and project member role
+
+Revision ID: 74cfc64cc205
+Revises: fee2a4743cf3
+Create Date: 2025-07-03 18:10:42.610284
+"""
+from alembic import op
+import sqlalchemy as sa
+
+revision = '74cfc64cc205'
+down_revision = 'fee2a4743cf3'
+branch_labels = None
+depends_on = None
+
+
+def upgrade():
+    op.add_column('users', sa.Column('is_admin', sa.Boolean(), server_default='0', nullable=False))
+    op.add_column('project_members', sa.Column('role', sa.String(), server_default='member', nullable=False))
+
+
+def downgrade():
+    op.drop_column('project_members', 'role')
+    op.drop_column('users', 'is_admin')
diff --git a/alembic/versions/77a76f367d0f_forum_and_article_comments.py b/alembic/versions/77a76f367d0f_forum_and_article_comments.py
new file mode 100644
index 0000000000000000000000000000000000000000..392deaf9ffbc784ad81704535b049695edf9baaf
--- /dev/null
+++ b/alembic/versions/77a76f367d0f_forum_and_article_comments.py
@@ -0,0 +1,39 @@
+"""add forum and article comments
+
+Revision ID: 77a76f367d0f
+Revises: 1a2b3c4d5ef0
+Create Date: 2025-08-01
+"""
+from typing import Sequence, Union
+from alembic import op
+import sqlalchemy as sa
+
+revision: str = '77a76f367d0f'
+down_revision: Union[str, Sequence[str], None] = '1a2b3c4d5ef0'
+branch_labels: Union[str, Sequence[str], None] = None
+depends_on: Union[str, Sequence[str], None] = None
+
+
+def upgrade() -> None:
+    op.add_column('knowledge_articles', sa.Column('is_public', sa.Boolean(), nullable=True, server_default='0'))
+    op.add_column('comments', sa.Column('knowledge_article_id', sa.Uuid(as_uuid=True), nullable=True))
+    op.create_table('forum_threads',
+        sa.Column('id', sa.Uuid(as_uuid=True), primary_key=True),
+        sa.Column('title', sa.String(), nullable=False),
+        sa.Column('created_by', sa.Uuid(as_uuid=True), sa.ForeignKey('users.id')),
+        sa.Column('created_at', sa.DateTime(), nullable=False, server_default=sa.text('CURRENT_TIMESTAMP'))
+    )
+    op.create_table('forum_posts',
+        sa.Column('id', sa.Uuid(as_uuid=True), primary_key=True),
+        sa.Column('thread_id', sa.Uuid(as_uuid=True), sa.ForeignKey('forum_threads.id')),
+        sa.Column('user_id', sa.Uuid(as_uuid=True), sa.ForeignKey('users.id')),
+        sa.Column('content', sa.String(), nullable=False),
+        sa.Column('created_at', sa.DateTime(), nullable=False, server_default=sa.text('CURRENT_TIMESTAMP'))
+    )
+
+
+def downgrade() -> None:
+    op.drop_table('forum_posts')
+    op.drop_table('forum_threads')
+    op.drop_column('comments', 'knowledge_article_id')
+    op.drop_column('knowledge_articles', 'is_public')
diff --git a/alembic/versions/9b1c3d8fc4a7_add_locations.py b/alembic/versions/9b1c3d8fc4a7_add_locations.py
new file mode 100644
index 0000000000000000000000000000000000000000..ba90a847a2210ddf6cd3aa6265e0a9567216de77
--- /dev/null
+++ b/alembic/versions/9b1c3d8fc4a7_add_locations.py
@@ -0,0 +1,32 @@
+"""add locations table
+
+Revision ID: 9b1c3d8fc4a7
+Revises: d69c2eb94812
+Create Date: 2025-07-13 00:00:00.000000
+"""
+
+from alembic import op
+import sqlalchemy as sa
+from typing import Sequence, Union
+
+revision: str = '9b1c3d8fc4a7'
+down_revision: Union[str, Sequence[str], None] = 'd69c2eb94812'
+branch_labels: Union[str, Sequence[str], None] = None
+depends_on: Union[str, Sequence[str], None] = None
+
+
+def upgrade() -> None:
+    op.create_table(
+        'locations',
+        sa.Column('id', sa.UUID(), primary_key=True),
+        sa.Column('name', sa.String(), nullable=False),
+        sa.Column('parent_id', sa.UUID(), sa.ForeignKey('locations.id')),
+        sa.Column('team_id', sa.UUID(), sa.ForeignKey('teams.id')),
+        sa.Column('created_at', sa.DateTime(), nullable=True),
+    )
+    op.add_column('inventory_items', sa.Column('location_id', sa.UUID(), sa.ForeignKey('locations.id')))
+
+
+def downgrade() -> None:
+    op.drop_column('inventory_items', 'location_id')
+    op.drop_table('locations')
diff --git a/alembic/versions/a1e430d0e9d9_add_notebook_signing.py b/alembic/versions/a1e430d0e9d9_add_notebook_signing.py
new file mode 100644
index 0000000000000000000000000000000000000000..a3bbefd1c4352cb1b4093c017940b0c275f6c9fc
--- /dev/null
+++ b/alembic/versions/a1e430d0e9d9_add_notebook_signing.py
@@ -0,0 +1,42 @@
+"""add notebook signing fields and version table
+
+Revision ID: a1e430d0e9d9
+Revises: 9b1c3d8fc4a7
+Create Date: 2025-07-14 00:00:00.000000
+"""
+
+from alembic import op
+import sqlalchemy as sa
+from typing import Sequence, Union
+
+revision: str = 'a1e430d0e9d9'
+down_revision: Union[str, Sequence[str], None] = '9b1c3d8fc4a7'
+branch_labels: Union[str, Sequence[str], None] = None
+depends_on: Union[str, Sequence[str], None] = None
+
+
+def upgrade() -> None:
+    op.add_column('notebook_entries', sa.Column('is_locked', sa.Boolean(), server_default=sa.false(), nullable=False))
+    op.add_column('notebook_entries', sa.Column('signed_by', sa.UUID(), sa.ForeignKey('users.id'), nullable=True))
+    op.add_column('notebook_entries', sa.Column('signed_at', sa.DateTime(), nullable=True))
+    op.add_column('notebook_entries', sa.Column('witness_id', sa.UUID(), sa.ForeignKey('users.id'), nullable=True))
+    op.add_column('notebook_entries', sa.Column('witnessed_at', sa.DateTime(), nullable=True))
+
+    op.create_table(
+        'notebook_entry_versions',
+        sa.Column('id', sa.UUID(), primary_key=True),
+        sa.Column('entry_id', sa.UUID(), sa.ForeignKey('notebook_entries.id')),
+        sa.Column('title', sa.String(), nullable=False),
+        sa.Column('content', sa.String(), nullable=False),
+        sa.Column('created_by', sa.UUID(), sa.ForeignKey('users.id')),
+        sa.Column('created_at', sa.DateTime(), nullable=True),
+    )
+
+
+def downgrade() -> None:
+    op.drop_table('notebook_entry_versions')
+    op.drop_column('notebook_entries', 'witnessed_at')
+    op.drop_column('notebook_entries', 'witness_id')
+    op.drop_column('notebook_entries', 'signed_at')
+    op.drop_column('notebook_entries', 'signed_by')
+    op.drop_column('notebook_entries', 'is_locked')
diff --git a/alembic/versions/abcdef123456_protocol_stars.py b/alembic/versions/abcdef123456_protocol_stars.py
new file mode 100644
index 0000000000000000000000000000000000000000..eb68f46081aa2e9216ecd54644382c509e36164c
--- /dev/null
+++ b/alembic/versions/abcdef123456_protocol_stars.py
@@ -0,0 +1,23 @@
+"""add protocol stars table"""
+
+from alembic import op
+import sqlalchemy as sa
+from typing import Sequence, Union
+
+revision: str = 'abcdef123456'
+down_revision: Union[str, Sequence[str], None] = '12345abcde01'
+branch_labels: Union[str, Sequence[str], None] = None
+depends_on: Union[str, Sequence[str], None] = None
+
+
+def upgrade() -> None:
+    op.create_table(
+        'protocol_stars',
+        sa.Column('protocol_id', sa.UUID(as_uuid=True), sa.ForeignKey('protocol_templates.id'), primary_key=True),
+        sa.Column('user_id', sa.UUID(as_uuid=True), sa.ForeignKey('users.id'), primary_key=True),
+        sa.Column('created_at', sa.DateTime(), nullable=False, server_default=sa.text('CURRENT_TIMESTAMP')),
+    )
+
+
+def downgrade() -> None:
+    op.drop_table('protocol_stars')
diff --git a/alembic/versions/b3efabc12345_add_structured_notebook_blocks.py b/alembic/versions/b3efabc12345_add_structured_notebook_blocks.py
new file mode 100644
index 0000000000000000000000000000000000000000..a1d9261f082c7a81430bae35c6504285f2b8cdd1
--- /dev/null
+++ b/alembic/versions/b3efabc12345_add_structured_notebook_blocks.py
@@ -0,0 +1,20 @@
+"""add structured blocks to notebook entries"""
+
+from alembic import op
+import sqlalchemy as sa
+from typing import Sequence, Union
+
+revision: str = 'b3efabc12345'
+down_revision: Union[str, Sequence[str], None] = 'e83f0e889a1c'
+branch_labels: Union[str, Sequence[str], None] = None
+depends_on: Union[str, Sequence[str], None] = None
+
+
+def upgrade() -> None:
+    op.add_column('notebook_entries', sa.Column('blocks', sa.JSON(), nullable=True))
+    op.add_column('notebook_entry_versions', sa.Column('blocks', sa.JSON(), nullable=True))
+
+
+def downgrade() -> None:
+    op.drop_column('notebook_entry_versions', 'blocks')
+    op.drop_column('notebook_entries', 'blocks')
diff --git a/alembic/versions/c1a2b3c4d5e6_add_service_marketplace.py b/alembic/versions/c1a2b3c4d5e6_add_service_marketplace.py
new file mode 100644
index 0000000000000000000000000000000000000000..757877ba1b73612504f9f8ecdb24794e747fef6f
--- /dev/null
+++ b/alembic/versions/c1a2b3c4d5e6_add_service_marketplace.py
@@ -0,0 +1,36 @@
+"""add service marketplace tables"""
+from alembic import op
+import sqlalchemy as sa
+import uuid
+from sqlalchemy.dialects import postgresql
+
+revision = 'c1a2b3c4d5e6'
+down_revision = 'b3efabc12345'
+branch_labels = None
+depends_on = None
+
+def upgrade():
+    op.create_table(
+        'service_listings',
+        sa.Column('id', postgresql.UUID(as_uuid=True), primary_key=True, default=sa.text('uuid_generate_v4()')),
+        sa.Column('provider_id', postgresql.UUID(as_uuid=True), sa.ForeignKey('users.id')),
+        sa.Column('name', sa.String(), nullable=False),
+        sa.Column('description', sa.String()),
+        sa.Column('price', sa.Integer(), nullable=True),
+        sa.Column('status', sa.String(), nullable=False, server_default='open'),
+        sa.Column('created_at', sa.DateTime(), nullable=False, server_default=sa.text('now()')),
+    )
+    op.create_table(
+        'service_requests',
+        sa.Column('id', postgresql.UUID(as_uuid=True), primary_key=True, default=sa.text('uuid_generate_v4()')),
+        sa.Column('listing_id', postgresql.UUID(as_uuid=True), sa.ForeignKey('service_listings.id')),
+        sa.Column('requester_id', postgresql.UUID(as_uuid=True), sa.ForeignKey('users.id')),
+        sa.Column('item_id', postgresql.UUID(as_uuid=True), sa.ForeignKey('inventory_items.id'), nullable=True),
+        sa.Column('message', sa.String()),
+        sa.Column('status', sa.String(), nullable=False, server_default='pending'),
+        sa.Column('created_at', sa.DateTime(), nullable=False, server_default=sa.text('now()')),
+    )
+
+def downgrade():
+    op.drop_table('service_requests')
+    op.drop_table('service_listings')
diff --git a/alembic/versions/d69c2eb94812_add_field_definition_constraint.py b/alembic/versions/d69c2eb94812_add_field_definition_constraint.py
new file mode 100644
index 0000000000000000000000000000000000000000..029a1327acf3d86e69a6d5207c41054305c7d768
--- /dev/null
+++ b/alembic/versions/d69c2eb94812_add_field_definition_constraint.py
@@ -0,0 +1,36 @@
+"""add field definition constraint
+
+Revision ID: d69c2eb94812
+Revises: 74cfc64cc205
+Create Date: 2025-07-03 20:08:07.466069
+
+"""
+from typing import Sequence, Union
+
+from alembic import op
+import sqlalchemy as sa
+
+
+# revision identifiers, used by Alembic.
+revision: str = 'd69c2eb94812'
+down_revision: Union[str, Sequence[str], None] = '74cfc64cc205'
+branch_labels: Union[str, Sequence[str], None] = None
+depends_on: Union[str, Sequence[str], None] = None
+
+
+def upgrade() -> None:
+    """Upgrade schema."""
+    op.create_unique_constraint(
+        "uq_field_def",
+        "field_definitions",
+        ["entity_type", "field_key", "team_id"],
+    )
+
+
+def downgrade() -> None:
+    """Downgrade schema."""
+    op.drop_constraint(
+        "uq_field_def",
+        "field_definitions",
+        type_="unique",
+    )
diff --git a/alembic/versions/e83f0e889a1c_add_protocol_variables.py b/alembic/versions/e83f0e889a1c_add_protocol_variables.py
new file mode 100644
index 0000000000000000000000000000000000000000..0393b80f6c698baf9baae2e24420833d191d328c
--- /dev/null
+++ b/alembic/versions/e83f0e889a1c_add_protocol_variables.py
@@ -0,0 +1,18 @@
+"""add protocol variables and workflow conditions"""
+
+from alembic import op
+import sqlalchemy as sa
+from typing import Sequence, Union
+
+revision: str = 'e83f0e889a1c'
+down_revision: Union[str, Sequence[str], None] = 'ff4b75d7cabc'
+branch_labels: Union[str, Sequence[str], None] = None
+depends_on: Union[str, Sequence[str], None] = None
+
+
+def upgrade() -> None:
+    op.add_column('protocol_templates', sa.Column('variables', sa.JSON(), nullable=True))
+
+
+def downgrade() -> None:
+    op.drop_column('protocol_templates', 'variables')
diff --git a/alembic/versions/fee2a4743cf3_baseline.py b/alembic/versions/fee2a4743cf3_baseline.py
new file mode 100644
index 0000000000000000000000000000000000000000..9cf695e030a5a095c719ef45302c56b7a0d0c2bb
--- /dev/null
+++ b/alembic/versions/fee2a4743cf3_baseline.py
@@ -0,0 +1,538 @@
+"""baseline
+
+Revision ID: fee2a4743cf3
+Revises:
+Create Date: 2025-07-03 17:40:35.484727
+
+"""
+from typing import Sequence, Union
+
+from alembic import op
+import sqlalchemy as sa
+
+
+# revision identifiers, used by Alembic.
+revision: str = 'fee2a4743cf3'
+down_revision: Union[str, Sequence[str], None] = None
+branch_labels: Union[str, Sequence[str], None] = None
+depends_on: Union[str, Sequence[str], None] = None
+
+
+def upgrade() -> None:
+    """Upgrade schema."""
+    # ### commands auto generated by Alembic - please adjust! ###
+    op.create_table('users',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('email', sa.String(), nullable=False),
+    sa.Column('hashed_password', sa.String(), nullable=False),
+    sa.Column('full_name', sa.String(), nullable=True),
+    sa.Column('phone_number', sa.String(), nullable=True),
+    sa.Column('orcid_id', sa.String(), nullable=True),
+    sa.Column('two_factor_secret', sa.String(), nullable=True),
+    sa.Column('two_factor_enabled', sa.Boolean(), nullable=True),
+    sa.Column('is_active', sa.Boolean(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.Column('last_digest', sa.DateTime(), nullable=True),
+    sa.PrimaryKeyConstraint('id'),
+    sa.UniqueConstraint('email')
+    )
+    op.create_table('analysis_tools',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('name', sa.String(), nullable=False),
+    sa.Column('description', sa.String(), nullable=True),
+    sa.Column('code', sa.String(), nullable=False),
+    sa.Column('supported_types', sa.JSON(), nullable=True),
+    sa.Column('created_by', sa.UUID(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['created_by'], ['users.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('assistant_messages',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('user_id', sa.UUID(), nullable=True),
+    sa.Column('is_user', sa.Boolean(), nullable=True),
+    sa.Column('message', sa.String(), nullable=False),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('audit_logs',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('user_id', sa.UUID(), nullable=True),
+    sa.Column('action', sa.String(), nullable=False),
+    sa.Column('target_type', sa.String(), nullable=True),
+    sa.Column('target_id', sa.UUID(), nullable=True),
+    sa.Column('details', sa.JSON(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('follows',
+    sa.Column('follower_id', sa.UUID(), nullable=False),
+    sa.Column('followed_id', sa.UUID(), nullable=False),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['followed_id'], ['users.id'], ),
+    sa.ForeignKeyConstraint(['follower_id'], ['users.id'], ),
+    sa.PrimaryKeyConstraint('follower_id', 'followed_id')
+    )
+    op.create_table('knowledge_articles',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('title', sa.String(), nullable=False),
+    sa.Column('content', sa.String(), nullable=False),
+    sa.Column('tags', sa.JSON(), nullable=True),
+    sa.Column('created_by', sa.UUID(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.Column('updated_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['created_by'], ['users.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('labs',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('name', sa.String(), nullable=False),
+    sa.Column('description', sa.String(), nullable=True),
+    sa.Column('owner_id', sa.UUID(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['owner_id'], ['users.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('notification_preferences',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('user_id', sa.UUID(), nullable=True),
+    sa.Column('pref_type', sa.String(), nullable=False),
+    sa.Column('channel', sa.String(), nullable=False),
+    sa.Column('enabled', sa.Boolean(), nullable=True),
+    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
+    sa.PrimaryKeyConstraint('id'),
+    sa.UniqueConstraint('user_id', 'pref_type', 'channel')
+    )
+    op.create_table('notifications',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('user_id', sa.UUID(), nullable=True),
+    sa.Column('message', sa.String(), nullable=False),
+    sa.Column('is_read', sa.Boolean(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('password_reset_tokens',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('user_id', sa.UUID(), nullable=True),
+    sa.Column('token', sa.String(), nullable=False),
+    sa.Column('expires_at', sa.DateTime(), nullable=False),
+    sa.Column('used', sa.Boolean(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_index(op.f('ix_password_reset_tokens_token'), 'password_reset_tokens', ['token'], unique=True)
+    op.create_table('posts',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('user_id', sa.UUID(), nullable=True),
+    sa.Column('content', sa.String(), nullable=False),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('sequence_jobs',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('user_id', sa.UUID(), nullable=True),
+    sa.Column('status', sa.String(), nullable=True),
+    sa.Column('format', sa.String(), nullable=True),
+    sa.Column('result', sa.JSON(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.Column('updated_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('teams',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('name', sa.String(), nullable=False),
+    sa.Column('created_by', sa.UUID(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['created_by'], ['users.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('troubleshooting_articles',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('title', sa.String(), nullable=False),
+    sa.Column('category', sa.String(), nullable=False),
+    sa.Column('content', sa.String(), nullable=False),
+    sa.Column('created_by', sa.UUID(), nullable=True),
+    sa.Column('success_count', sa.Integer(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.Column('updated_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['created_by'], ['users.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('workflows',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('name', sa.String(), nullable=False),
+    sa.Column('description', sa.String(), nullable=True),
+    sa.Column('steps', sa.JSON(), nullable=True),
+    sa.Column('created_by', sa.UUID(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['created_by'], ['users.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('calendar_events',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('title', sa.String(), nullable=False),
+    sa.Column('description', sa.String(), nullable=True),
+    sa.Column('start_time', sa.DateTime(), nullable=False),
+    sa.Column('end_time', sa.DateTime(), nullable=False),
+    sa.Column('team_id', sa.UUID(), nullable=True),
+    sa.Column('user_id', sa.UUID(), nullable=True),
+    sa.Column('created_by', sa.UUID(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['created_by'], ['users.id'], ),
+    sa.ForeignKeyConstraint(['team_id'], ['teams.id'], ),
+    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('equipment',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('name', sa.String(), nullable=False),
+    sa.Column('eq_type', sa.String(), nullable=True),
+    sa.Column('connection_info', sa.JSON(), nullable=True),
+    sa.Column('status', sa.String(), nullable=True),
+    sa.Column('team_id', sa.UUID(), nullable=True),
+    sa.Column('created_by', sa.UUID(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['created_by'], ['users.id'], ),
+    sa.ForeignKeyConstraint(['team_id'], ['teams.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('field_definitions',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('entity_type', sa.String(), nullable=False),
+    sa.Column('field_key', sa.String(), nullable=False),
+    sa.Column('field_label', sa.String(), nullable=False),
+    sa.Column('field_type', sa.String(), nullable=False),
+    sa.Column('is_required', sa.Boolean(), nullable=True),
+    sa.Column('options', sa.JSON(), nullable=True),
+    sa.Column('validation', sa.JSON(), nullable=True),
+    sa.Column('team_id', sa.UUID(), nullable=True),
+    sa.ForeignKeyConstraint(['team_id'], ['teams.id'], ),
+    sa.PrimaryKeyConstraint('id'),
+    sqlite_autoincrement=True
+    )
+    op.create_table('inventory_items',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('item_type', sa.String(), nullable=False),
+    sa.Column('name', sa.String(), nullable=False),
+    sa.Column('barcode', sa.String(), nullable=True),
+    sa.Column('team_id', sa.UUID(), nullable=True),
+    sa.Column('owner_id', sa.UUID(), nullable=True),
+    sa.Column('location', sa.JSON(), nullable=True),
+    sa.Column('status', sa.String(), nullable=True),
+    sa.Column('custom_data', sa.JSON(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.Column('updated_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['owner_id'], ['users.id'], ),
+    sa.ForeignKeyConstraint(['team_id'], ['teams.id'], ),
+    sa.PrimaryKeyConstraint('id'),
+    sa.UniqueConstraint('barcode')
+    )
+    op.create_table('lab_connections',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('from_lab', sa.UUID(), nullable=True),
+    sa.Column('to_lab', sa.UUID(), nullable=True),
+    sa.Column('status', sa.String(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['from_lab'], ['labs.id'], ),
+    sa.ForeignKeyConstraint(['to_lab'], ['labs.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('post_reports',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('post_id', sa.UUID(), nullable=True),
+    sa.Column('reporter_id', sa.UUID(), nullable=True),
+    sa.Column('reason', sa.String(), nullable=False),
+    sa.Column('status', sa.String(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['post_id'], ['posts.id'], ),
+    sa.ForeignKeyConstraint(['reporter_id'], ['users.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('projects',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('name', sa.String(), nullable=False),
+    sa.Column('description', sa.String(), nullable=True),
+    sa.Column('start_date', sa.DateTime(), nullable=True),
+    sa.Column('end_date', sa.DateTime(), nullable=True),
+    sa.Column('team_id', sa.UUID(), nullable=True),
+    sa.Column('created_by', sa.UUID(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.Column('updated_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['created_by'], ['users.id'], ),
+    sa.ForeignKeyConstraint(['team_id'], ['teams.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('protocol_templates',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('name', sa.String(), nullable=False),
+    sa.Column('version', sa.String(), nullable=True),
+    sa.Column('content', sa.String(), nullable=False),
+    sa.Column('team_id', sa.UUID(), nullable=True),
+    sa.Column('created_by', sa.UUID(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.Column('updated_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['created_by'], ['users.id'], ),
+    sa.ForeignKeyConstraint(['team_id'], ['teams.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('resources',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('name', sa.String(), nullable=False),
+    sa.Column('description', sa.String(), nullable=True),
+    sa.Column('team_id', sa.UUID(), nullable=True),
+    sa.Column('created_by', sa.UUID(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['created_by'], ['users.id'], ),
+    sa.ForeignKeyConstraint(['team_id'], ['teams.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('team_members',
+    sa.Column('team_id', sa.UUID(), nullable=False),
+    sa.Column('user_id', sa.UUID(), nullable=False),
+    sa.Column('role', sa.String(), nullable=True),
+    sa.ForeignKeyConstraint(['team_id'], ['teams.id'], ),
+    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
+    sa.PrimaryKeyConstraint('team_id', 'user_id')
+    )
+    op.create_table('bookings',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('resource_id', sa.UUID(), nullable=True),
+    sa.Column('user_id', sa.UUID(), nullable=True),
+    sa.Column('start_time', sa.DateTime(), nullable=False),
+    sa.Column('end_time', sa.DateTime(), nullable=False),
+    sa.Column('notes', sa.String(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['resource_id'], ['resources.id'], ),
+    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('compliance_records',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('item_id', sa.UUID(), nullable=True),
+    sa.Column('user_id', sa.UUID(), nullable=True),
+    sa.Column('record_type', sa.String(), nullable=False),
+    sa.Column('status', sa.String(), nullable=True),
+    sa.Column('notes', sa.String(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['item_id'], ['inventory_items.id'], ),
+    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('equipment_readings',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('equipment_id', sa.UUID(), nullable=True),
+    sa.Column('timestamp', sa.DateTime(), nullable=True),
+    sa.Column('data', sa.JSON(), nullable=True),
+    sa.ForeignKeyConstraint(['equipment_id'], ['equipment.id'], ondelete='CASCADE'),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('files',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('item_id', sa.UUID(), nullable=True),
+    sa.Column('filename', sa.String(), nullable=True),
+    sa.Column('file_type', sa.String(), nullable=True),
+    sa.Column('file_size', sa.String(), nullable=True),
+    sa.Column('storage_path', sa.String(), nullable=True),
+    sa.Column('metadata', sa.JSON(), nullable=True),
+    sa.Column('uploaded_by', sa.UUID(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['item_id'], ['inventory_items.id'], ondelete='CASCADE'),
+    sa.ForeignKeyConstraint(['uploaded_by'], ['users.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('item_relationships',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('from_item', sa.UUID(), nullable=True),
+    sa.Column('to_item', sa.UUID(), nullable=True),
+    sa.Column('relationship_type', sa.String(), nullable=True),
+    sa.Column('metadata', sa.JSON(), nullable=True),
+    sa.ForeignKeyConstraint(['from_item'], ['inventory_items.id'], ondelete='CASCADE'),
+    sa.ForeignKeyConstraint(['to_item'], ['inventory_items.id'], ondelete='CASCADE'),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('marketplace_listings',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('item_id', sa.UUID(), nullable=True),
+    sa.Column('seller_id', sa.UUID(), nullable=True),
+    sa.Column('price', sa.Integer(), nullable=True),
+    sa.Column('description', sa.String(), nullable=True),
+    sa.Column('status', sa.String(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['item_id'], ['inventory_items.id'], ),
+    sa.ForeignKeyConstraint(['seller_id'], ['users.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('project_items',
+    sa.Column('project_id', sa.UUID(), nullable=False),
+    sa.Column('item_id', sa.UUID(), nullable=False),
+    sa.ForeignKeyConstraint(['item_id'], ['inventory_items.id'], ),
+    sa.ForeignKeyConstraint(['project_id'], ['projects.id'], ),
+    sa.PrimaryKeyConstraint('project_id', 'item_id')
+    )
+    op.create_table('project_members',
+    sa.Column('project_id', sa.UUID(), nullable=False),
+    sa.Column('user_id', sa.UUID(), nullable=False),
+    sa.ForeignKeyConstraint(['project_id'], ['projects.id'], ),
+    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
+    sa.PrimaryKeyConstraint('project_id', 'user_id')
+    )
+    op.create_table('project_protocols',
+    sa.Column('project_id', sa.UUID(), nullable=False),
+    sa.Column('template_id', sa.UUID(), nullable=False),
+    sa.ForeignKeyConstraint(['project_id'], ['projects.id'], ),
+    sa.ForeignKeyConstraint(['template_id'], ['protocol_templates.id'], ),
+    sa.PrimaryKeyConstraint('project_id', 'template_id')
+    )
+    op.create_table('project_tasks',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('project_id', sa.UUID(), nullable=True),
+    sa.Column('name', sa.String(), nullable=False),
+    sa.Column('description', sa.String(), nullable=True),
+    sa.Column('due_date', sa.DateTime(), nullable=True),
+    sa.Column('status', sa.String(), nullable=True),
+    sa.Column('created_by', sa.UUID(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.Column('updated_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['created_by'], ['users.id'], ),
+    sa.ForeignKeyConstraint(['project_id'], ['projects.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('protocol_executions',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('template_id', sa.UUID(), nullable=True),
+    sa.Column('run_by', sa.UUID(), nullable=True),
+    sa.Column('status', sa.String(), nullable=True),
+    sa.Column('params', sa.JSON(), nullable=True),
+    sa.Column('result', sa.JSON(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.Column('updated_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['run_by'], ['users.id'], ),
+    sa.ForeignKeyConstraint(['template_id'], ['protocol_templates.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('resource_shares',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('resource_id', sa.UUID(), nullable=True),
+    sa.Column('from_lab', sa.UUID(), nullable=True),
+    sa.Column('to_lab', sa.UUID(), nullable=True),
+    sa.Column('status', sa.String(), nullable=True),
+    sa.Column('start_date', sa.DateTime(), nullable=True),
+    sa.Column('end_date', sa.DateTime(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['from_lab'], ['labs.id'], ),
+    sa.ForeignKeyConstraint(['resource_id'], ['resources.id'], ),
+    sa.ForeignKeyConstraint(['to_lab'], ['labs.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('workflow_executions',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('workflow_id', sa.UUID(), nullable=True),
+    sa.Column('item_id', sa.UUID(), nullable=True),
+    sa.Column('run_by', sa.UUID(), nullable=True),
+    sa.Column('status', sa.String(), nullable=True),
+    sa.Column('result', sa.JSON(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.Column('updated_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['item_id'], ['inventory_items.id'], ),
+    sa.ForeignKeyConstraint(['run_by'], ['users.id'], ),
+    sa.ForeignKeyConstraint(['workflow_id'], ['workflows.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('marketplace_requests',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('listing_id', sa.UUID(), nullable=True),
+    sa.Column('buyer_id', sa.UUID(), nullable=True),
+    sa.Column('message', sa.String(), nullable=True),
+    sa.Column('status', sa.String(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['buyer_id'], ['users.id'], ),
+    sa.ForeignKeyConstraint(['listing_id'], ['marketplace_listings.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('notebook_entries',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('title', sa.String(), nullable=False),
+    sa.Column('content', sa.String(), nullable=False),
+    sa.Column('item_id', sa.UUID(), nullable=True),
+    sa.Column('execution_id', sa.UUID(), nullable=True),
+    sa.Column('project_id', sa.UUID(), nullable=True),
+    sa.Column('items', sa.JSON(), nullable=True),
+    sa.Column('protocols', sa.JSON(), nullable=True),
+    sa.Column('images', sa.JSON(), nullable=True),
+    sa.Column('created_by', sa.UUID(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.Column('updated_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['created_by'], ['users.id'], ),
+    sa.ForeignKeyConstraint(['execution_id'], ['protocol_executions.id'], ),
+    sa.ForeignKeyConstraint(['item_id'], ['inventory_items.id'], ),
+    sa.ForeignKeyConstraint(['project_id'], ['projects.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('comments',
+    sa.Column('id', sa.UUID(), nullable=False),
+    sa.Column('content', sa.String(), nullable=False),
+    sa.Column('item_id', sa.UUID(), nullable=True),
+    sa.Column('entry_id', sa.UUID(), nullable=True),
+    sa.Column('created_by', sa.UUID(), nullable=True),
+    sa.Column('created_at', sa.DateTime(), nullable=True),
+    sa.Column('updated_at', sa.DateTime(), nullable=True),
+    sa.ForeignKeyConstraint(['created_by'], ['users.id'], ),
+    sa.ForeignKeyConstraint(['entry_id'], ['notebook_entries.id'], ),
+    sa.ForeignKeyConstraint(['item_id'], ['inventory_items.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    # ### end Alembic commands ###
+
+
+def downgrade() -> None:
+    """Downgrade schema."""
+    # ### commands auto generated by Alembic - please adjust! ###
+    op.drop_table('comments')
+    op.drop_table('notebook_entries')
+    op.drop_table('marketplace_requests')
+    op.drop_table('workflow_executions')
+    op.drop_table('resource_shares')
+    op.drop_table('protocol_executions')
+    op.drop_table('project_tasks')
+    op.drop_table('project_protocols')
+    op.drop_table('project_members')
+    op.drop_table('project_items')
+    op.drop_table('marketplace_listings')
+    op.drop_table('item_relationships')
+    op.drop_table('files')
+    op.drop_table('equipment_readings')
+    op.drop_table('compliance_records')
+    op.drop_table('bookings')
+    op.drop_table('team_members')
+    op.drop_table('resources')
+    op.drop_table('protocol_templates')
+    op.drop_table('projects')
+    op.drop_table('post_reports')
+    op.drop_table('lab_connections')
+    op.drop_table('inventory_items')
+    op.drop_table('field_definitions')
+    op.drop_table('equipment')
+    op.drop_table('calendar_events')
+    op.drop_table('workflows')
+    op.drop_table('troubleshooting_articles')
+    op.drop_table('teams')
+    op.drop_table('sequence_jobs')
+    op.drop_table('posts')
+    op.drop_index(op.f('ix_password_reset_tokens_token'), table_name='password_reset_tokens')
+    op.drop_table('password_reset_tokens')
+    op.drop_table('notifications')
+    op.drop_table('notification_preferences')
+    op.drop_table('labs')
+    op.drop_table('knowledge_articles')
+    op.drop_table('follows')
+    op.drop_table('audit_logs')
+    op.drop_table('assistant_messages')
+    op.drop_table('analysis_tools')
+    op.drop_table('users')
+    # ### end Alembic commands ###
diff --git a/alembic/versions/ff4b75d7cabc_add_equipment_ops.py b/alembic/versions/ff4b75d7cabc_add_equipment_ops.py
new file mode 100644
index 0000000000000000000000000000000000000000..324fad6f966127bc87a71720796bc312020f5923
--- /dev/null
+++ b/alembic/versions/ff4b75d7cabc_add_equipment_ops.py
@@ -0,0 +1,51 @@
+"""add equipment ops
+
+Revision ID: ff4b75d7cabc
+Revises: d69c2eb94812
+Create Date: 2025-07-14 12:00:00
+"""
+
+from alembic import op
+import sqlalchemy as sa
+
+# revision identifiers, used by Alembic.
+revision = 'ff4b75d7cabc'
+down_revision = 'd69c2eb94812'
+branch_labels = None
+depends_on = None
+
+def upgrade():
+    op.create_table(
+        'equipment_maintenance',
+        sa.Column('id', sa.UUID(), primary_key=True),
+        sa.Column('equipment_id', sa.UUID(), sa.ForeignKey('equipment.id', ondelete='CASCADE')),
+        sa.Column('due_date', sa.DateTime(), nullable=False),
+        sa.Column('completed_at', sa.DateTime(), nullable=True),
+        sa.Column('task_type', sa.String(), nullable=True),
+        sa.Column('description', sa.String(), nullable=True),
+        sa.Column('created_at', sa.DateTime(), nullable=True),
+    )
+    op.create_table(
+        'sops',
+        sa.Column('id', sa.UUID(), primary_key=True),
+        sa.Column('title', sa.String(), nullable=False),
+        sa.Column('version', sa.Integer(), nullable=False),
+        sa.Column('content', sa.String(), nullable=False),
+        sa.Column('team_id', sa.UUID(), sa.ForeignKey('teams.id')),
+        sa.Column('created_by', sa.UUID(), sa.ForeignKey('users.id')),
+        sa.Column('created_at', sa.DateTime(), nullable=True),
+    )
+    op.create_table(
+        'training_records',
+        sa.Column('id', sa.UUID(), primary_key=True),
+        sa.Column('user_id', sa.UUID(), sa.ForeignKey('users.id')),
+        sa.Column('sop_id', sa.UUID(), sa.ForeignKey('sops.id')),
+        sa.Column('equipment_id', sa.UUID(), sa.ForeignKey('equipment.id')),
+        sa.Column('trained_by', sa.UUID(), sa.ForeignKey('users.id')),
+        sa.Column('trained_at', sa.DateTime(), nullable=True),
+    )
+
+def downgrade():
+    op.drop_table('training_records')
+    op.drop_table('sops')
+    op.drop_table('equipment_maintenance')
diff --git a/backend/Dockerfile b/backend/Dockerfile
new file mode 100644
index 0000000000000000000000000000000000000000..c459b65f91963a13466a5fdb359eb15da34d2373
--- /dev/null
+++ b/backend/Dockerfile
@@ -0,0 +1,6 @@
+FROM python:3.11-slim
+WORKDIR /app
+COPY requirements.txt ./
+RUN pip install --no-cache-dir -r requirements.txt
+COPY . .
+CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
diff --git a/backend/app/__init__.py b/backend/app/__init__.py
new file mode 100644
index 0000000000000000000000000000000000000000..e69de29bb2d1d6434b8b29ae775ad8c2e48c5391
diff --git a/backend/app/assistant.py b/backend/app/assistant.py
new file mode 100644
index 0000000000000000000000000000000000000000..7a008cfdf097335fb41b747db9b5b5120ee0b413
--- /dev/null
+++ b/backend/app/assistant.py
@@ -0,0 +1,116 @@
+from datetime import datetime, timezone, timedelta
+from sqlalchemy import or_
+from sqlalchemy.orm import Session
+from . import models
+
+
+def generate_response(question: str, user: models.User, db: Session) -> str:
+    q = question.lower()
+    if "project" in q:
+        projects = db.query(models.Project).all()
+        names = ", ".join(p.name for p in projects) or "no projects"
+        return f"Current projects: {names}."
+    if "inventory" in q or "item" in q:
+        items = db.query(models.InventoryItem).limit(5).all()
+        names = ", ".join(i.name for i in items) or "no items"
+        return f"Sample inventory items: {names}."
+    return "I'm your lab buddy assistant. Ask me about projects or inventory."
+
+
+def inventory_forecast(user: models.User, db: Session):
+    since = datetime.now(timezone.utc) - timedelta(days=30)
+    items = db.query(models.InventoryItem).filter(models.InventoryItem.owner_id == user.id).all()
+    results = []
+    for item in items:
+        stock = item.custom_data.get("stock") if isinstance(item.custom_data, dict) else None
+        if stock is None:
+            continue
+        usage = (
+            db.query(models.NotebookEntry)
+            .filter(
+                or_(
+                    models.NotebookEntry.item_id == item.id,
+                    models.NotebookEntry.items.contains([str(item.id)]),
+                ),
+                models.NotebookEntry.created_at >= since,
+            )
+            .count()
+        )
+        daily = usage / 30 if usage else 0
+        days_left = stock / daily if daily else None
+        results.append({"item_id": item.id, "name": item.name, "projected_days": days_left})
+    return results
+
+
+def suggest_protocols(goal: str, user: models.User, db: Session):
+    q = f"%{goal.lower()}%"
+    templates = (
+        db.query(models.ProtocolTemplate)
+        .filter(
+            or_(
+                models.ProtocolTemplate.name.ilike(q),
+                models.ProtocolTemplate.content.ilike(q),
+            )
+        )
+        .limit(3)
+        .all()
+    )
+    suggestions = []
+    for tpl in templates:
+        materials = []
+        for var in tpl.variables or []:
+            item = (
+                db.query(models.InventoryItem)
+                .filter(
+                    models.InventoryItem.owner_id == user.id,
+                    or_(
+                        models.InventoryItem.name.ilike(f"%{var}%"),
+                        models.InventoryItem.item_type.ilike(f"%{var}%"),
+                    ),
+                )
+                .first()
+            )
+            if item:
+                materials.append({"id": item.id, "name": item.name})
+        suggestions.append({
+            "protocol_id": tpl.id,
+            "protocol_name": tpl.name,
+            "materials": materials,
+        })
+    return suggestions
+
+
+def design_experiment(goal: str, user: models.User, db: Session):
+    protocol = None
+    suggestions = suggest_protocols(goal, user, db)
+    if suggestions:
+        protocol = suggestions[0]
+
+    art_q = f"%{goal.lower()}%"
+    articles = (
+        db.query(models.KnowledgeArticle)
+        .filter(
+            or_(
+                models.KnowledgeArticle.title.ilike(art_q),
+                models.KnowledgeArticle.tags.contains([goal.lower()]),
+            )
+        )
+        .limit(3)
+        .all()
+    )
+
+    articles_out = [
+        {
+            "id": a.id,
+            "title": a.title,
+            "content": a.content,
+            "tags": a.tags,
+            "created_by": a.created_by,
+            "created_at": a.created_at,
+            "updated_at": a.updated_at,
+        }
+        for a in articles
+    ]
+
+    msg = "Suggested protocol and articles generated." if protocol or articles else "No suggestions found."
+    return {"protocol": protocol, "articles": articles_out, "message": msg}
diff --git a/backend/app/audit.py b/backend/app/audit.py
new file mode 100644
index 0000000000000000000000000000000000000000..2b423ce26c48c7896572178a505cca70da59b143
--- /dev/null
+++ b/backend/app/audit.py
@@ -0,0 +1,47 @@
+from datetime import datetime, timezone
+from uuid import UUID
+from sqlalchemy.orm import Session
+from sqlalchemy import func
+from . import models
+
+
+def log_action(
+    db: Session,
+    user_id: str | UUID,
+    action: str,
+    target_type: str | None = None,
+    target_id: str | UUID | None = None,
+    details: dict | None = None,
+):
+    log = models.AuditLog(
+        user_id=UUID(str(user_id)),
+        action=action,
+        target_type=target_type,
+        target_id=UUID(str(target_id)) if target_id else None,
+        details=details or {},
+        created_at=datetime.now(timezone.utc),
+    )
+    db.add(log)
+    db.commit()
+    db.refresh(log)
+    return log
+
+
+def generate_report(
+    db: Session,
+    start: datetime,
+    end: datetime,
+    user_id: UUID | None = None,
+):
+    query = db.query(models.AuditLog).filter(
+        models.AuditLog.created_at >= start,
+        models.AuditLog.created_at <= end,
+    )
+    if user_id:
+        query = query.filter(models.AuditLog.user_id == user_id)
+    rows = (
+        query.with_entities(models.AuditLog.action, func.count(models.AuditLog.id))
+        .group_by(models.AuditLog.action)
+        .all()
+    )
+    return [{"action": r[0], "count": r[1]} for r in rows]
diff --git a/backend/app/auth.py b/backend/app/auth.py
new file mode 100644
index 0000000000000000000000000000000000000000..142d730de55977b60b55e5627753f5947a1a68d3
--- /dev/null
+++ b/backend/app/auth.py
@@ -0,0 +1,51 @@
+from datetime import datetime, timedelta, timezone
+from typing import Optional
+from jose import JWTError, jwt
+from passlib.context import CryptContext
+from fastapi import Depends, HTTPException, status
+from fastapi.security import OAuth2PasswordBearer
+from sqlalchemy.orm import Session
+
+from .database import get_db
+from . import models
+import os
+
+SECRET_KEY = os.getenv("SECRET_KEY")
+if not SECRET_KEY:
+    raise RuntimeError("SECRET_KEY environment variable is required")
+ALGORITHM = "HS256"
+ACCESS_TOKEN_EXPIRE_MINUTES = 30
+
+pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")
+oauth2_scheme = OAuth2PasswordBearer(tokenUrl="/api/auth/login")
+
+def verify_password(plain_password, hashed_password):
+    return pwd_context.verify(plain_password, hashed_password)
+
+def get_password_hash(password):
+    return pwd_context.hash(password)
+
+def create_access_token(data: dict, expires_delta: Optional[timedelta] = None):
+    to_encode = data.copy()
+    expire = datetime.now(timezone.utc) + (expires_delta or timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES))
+    to_encode.update({"exp": expire})
+    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
+    return encoded_jwt
+
+async def get_current_user(token: str = Depends(oauth2_scheme), db: Session = Depends(get_db)):
+    credentials_exception = HTTPException(
+        status_code=status.HTTP_401_UNAUTHORIZED,
+        detail="Could not validate credentials",
+        headers={"WWW-Authenticate": "Bearer"},
+    )
+    try:
+        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
+        email: str = payload.get("sub")
+        if email is None:
+            raise credentials_exception
+    except JWTError:
+        raise credentials_exception
+    user = db.query(models.User).filter(models.User.email == email).first()
+    if user is None:
+        raise credentials_exception
+    return user
diff --git a/backend/app/barcodes.py b/backend/app/barcodes.py
new file mode 100644
index 0000000000000000000000000000000000000000..d9cbbeb03ddd74ac2d32a5a26124adcf4c855502
--- /dev/null
+++ b/backend/app/barcodes.py
@@ -0,0 +1,16 @@
+import io
+import uuid
+import barcode
+from barcode.writer import ImageWriter
+
+
+def generate_barcode_png(data: str) -> bytes:
+    code = barcode.get('code128', data, writer=ImageWriter())
+    buf = io.BytesIO()
+    code.write(buf)
+    return buf.getvalue()
+
+
+def generate_unique_code() -> str:
+    num = uuid.uuid4().int % 10**12
+    return str(num).zfill(12)
diff --git a/backend/app/database.py b/backend/app/database.py
new file mode 100644
index 0000000000000000000000000000000000000000..8ef86b5f7b06d7491cd5abfdf01ff0106cdd5b77
--- /dev/null
+++ b/backend/app/database.py
@@ -0,0 +1,17 @@
+from sqlalchemy import create_engine
+from sqlalchemy.orm import sessionmaker, declarative_base
+import os
+
+DATABASE_URL = os.getenv("DATABASE_URL", "sqlite:///./test.db")
+
+engine = create_engine(DATABASE_URL, connect_args={"check_same_thread": False} if DATABASE_URL.startswith("sqlite") else {})
+SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
+
+Base = declarative_base()
+
+def get_db():
+    db = SessionLocal()
+    try:
+        yield db
+    finally:
+        db.close()
diff --git a/backend/app/external.py b/backend/app/external.py
new file mode 100644
index 0000000000000000000000000000000000000000..7140bee4953880ee80896944723442ffd7ffecf2
--- /dev/null
+++ b/backend/app/external.py
@@ -0,0 +1,22 @@
+import requests
+
+BASE_URL = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/"
+
+
+def search_pubmed(query: str, limit: int = 5):
+    params = {"db": "pubmed", "term": query, "retmode": "json", "retmax": limit}
+    r = requests.get(BASE_URL + "esearch.fcgi", params=params, timeout=10)
+    r.raise_for_status()
+    ids = r.json()["esearchresult"].get("idlist", [])
+    if not ids:
+        return []
+    r2 = requests.get(BASE_URL + "esummary.fcgi", params={"db": "pubmed", "id": ",".join(ids), "retmode": "json"}, timeout=10)
+    r2.raise_for_status()
+    data = r2.json()["result"]
+    articles = []
+    for _id in ids:
+        info = data.get(_id)
+        if not info:
+            continue
+        articles.append({"id": info["uid"], "title": info.get("title", "")})
+    return articles
diff --git a/backend/app/main.py b/backend/app/main.py
new file mode 100644
index 0000000000000000000000000000000000000000..bce427cfdca6d08fb3868b2f1d4a45b8827d9ec9
--- /dev/null
+++ b/backend/app/main.py
@@ -0,0 +1,154 @@
+from fastapi import FastAPI, WebSocket, Response, Request
+from slowapi import Limiter
+from slowapi.util import get_remote_address
+from slowapi.errors import RateLimitExceeded
+from slowapi.middleware import SlowAPIMiddleware
+import json
+import os
+import time
+from prometheus_client import Counter, Histogram, generate_latest, CONTENT_TYPE_LATEST
+import sentry_sdk
+from sentry_sdk.integrations.fastapi import FastApiIntegration
+from . import pubsub
+from .database import Base, engine
+from .routes import (
+    auth,
+    users,
+    inventory,
+    fields,
+    locations,
+    teams,
+    files,
+    protocols,
+    troubleshooting,
+    notebook,
+    comments,
+    notifications,
+    schedule,
+    sequence,
+    projects,
+    assistant,
+    calendar,
+    tools,
+    analytics,
+    search,
+    audit,
+    labs,
+    resource_shares,
+    marketplace,
+    services,
+    forum,
+    community,
+    compliance,
+    equipment,
+    external,
+    data_analysis,
+    knowledge,
+    workflows,
+)
+
+
+dsn = os.getenv("SENTRY_DSN")
+if dsn:
+    sentry_sdk.init(dsn=dsn, integrations=[FastApiIntegration()])
+
+REQUEST_COUNT = Counter("request_count", "Total requests", ["method", "endpoint"])
+REQUEST_LATENCY = Histogram(
+    "request_latency_seconds", "Request latency", ["endpoint"]
+)
+
+app = FastAPI(title="BioLabs API")
+limiter = Limiter(key_func=get_remote_address)
+app.state.limiter = limiter
+app.add_exception_handler(RateLimitExceeded, lambda r, e: Response("Too Many Requests", status_code=429))
+if os.getenv("TESTING") != "1":
+    app.add_middleware(SlowAPIMiddleware)
+
+
+@app.middleware("http")
+async def record_metrics(request: Request, call_next):
+    start = time.time()
+    response = await call_next(request)
+    endpoint = request.url.path
+    REQUEST_COUNT.labels(request.method, endpoint).inc()
+    REQUEST_LATENCY.labels(endpoint).observe(time.time() - start)
+    return response
+
+@app.get("/metrics")
+def metrics():
+    return Response(generate_latest(), media_type=CONTENT_TYPE_LATEST)
+
+app.include_router(auth.router)
+app.include_router(users.router)
+app.include_router(inventory.router)
+app.include_router(fields.router)
+app.include_router(locations.router)
+app.include_router(teams.router)
+app.include_router(files.router)
+app.include_router(protocols.router)
+app.include_router(troubleshooting.router)
+app.include_router(notebook.router)
+app.include_router(comments.router)
+app.include_router(notifications.router)
+app.include_router(schedule.router)
+app.include_router(sequence.router)
+app.include_router(projects.router)
+app.include_router(assistant.router)
+app.include_router(calendar.router)
+app.include_router(tools.router)
+app.include_router(analytics.router)
+app.include_router(search.router)
+app.include_router(audit.router)
+app.include_router(labs.router)
+app.include_router(resource_shares.router)
+app.include_router(marketplace.router)
+app.include_router(services.router)
+app.include_router(forum.router)
+app.include_router(community.router)
+app.include_router(compliance.router)
+app.include_router(equipment.router)
+app.include_router(external.router)
+app.include_router(data_analysis.router)
+app.include_router(knowledge.router)
+app.include_router(workflows.router)
+
+
+def audit_routes():
+    from fastapi.routing import APIRoute
+    from .auth import get_current_user
+
+    public_paths = {
+        "/api/auth/login",
+        "/api/auth/register",
+        "/api/auth/request-password-reset",
+        "/api/auth/reset-password",
+        "/metrics",
+        "/api/marketplace/listings",
+        "/api/services/listings",
+        "/api/protocols/public",
+    }
+    for route in app.routes:
+        if isinstance(route, APIRoute) and route.path.startswith("/api") and route.path not in public_paths:
+            calls = [dep.call for dep in route.dependant.dependencies]
+            if get_current_user not in calls:
+                raise RuntimeError(f"Route {route.path} missing authentication")
+
+
+audit_routes()
+
+
+@app.websocket("/ws/{team_id}")
+async def websocket_endpoint(websocket: WebSocket, team_id: str):
+    await websocket.accept()
+    r = await pubsub.get_redis()
+    pub = r.pubsub()
+    await pub.subscribe(f"team:{team_id}")
+    try:
+        async for message in pub.listen():
+            if message["type"] == "message":
+                data = message["data"]
+                if isinstance(data, bytes):
+                    data = data.decode()
+                await websocket.send_text(data)
+    finally:
+        await pub.unsubscribe(f"team:{team_id}")
diff --git a/backend/app/models.py b/backend/app/models.py
new file mode 100644
index 0000000000000000000000000000000000000000..250ff52bac7e54d4542b946d8ba0342cebc32f39
--- /dev/null
+++ b/backend/app/models.py
@@ -0,0 +1,608 @@
+import uuid
+import sqlalchemy as sa
+from sqlalchemy import Column, String, Boolean, DateTime, ForeignKey, JSON, Integer
+from sqlalchemy.dialects.postgresql import UUID
+from sqlalchemy.orm import relationship
+from datetime import datetime, timezone
+
+from .database import Base
+
+class User(Base):
+    __tablename__ = "users"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    email = Column(String, unique=True, nullable=False)
+    hashed_password = Column(String, nullable=False)
+    full_name = Column(String)
+    phone_number = Column(String)
+    orcid_id = Column(String)
+    two_factor_secret = Column(String)
+    two_factor_enabled = Column(Boolean, default=False)
+    is_admin = Column(Boolean, default=False)
+    is_active = Column(Boolean, default=True)
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+    last_digest = Column(DateTime, default=datetime.now(timezone.utc))
+
+    teams = relationship("TeamMember", back_populates="user")
+
+class Team(Base):
+    __tablename__ = "teams"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    name = Column(String, nullable=False)
+    created_by = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+    members = relationship("TeamMember", back_populates="team")
+
+class TeamMember(Base):
+    __tablename__ = "team_members"
+    team_id = Column(UUID(as_uuid=True), ForeignKey("teams.id"), primary_key=True)
+    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"), primary_key=True)
+    role = Column(String, default="member")
+
+    user = relationship("User", back_populates="teams")
+    team = relationship("Team", back_populates="members")
+
+
+class Location(Base):
+    __tablename__ = "locations"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    name = Column(String, nullable=False)
+    parent_id = Column(UUID(as_uuid=True), ForeignKey("locations.id"))
+    team_id = Column(UUID(as_uuid=True), ForeignKey("teams.id"))
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+    parent = relationship("Location", remote_side=[id])
+
+class InventoryItem(Base):
+    __tablename__ = "inventory_items"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    item_type = Column(String, nullable=False)
+    name = Column(String, nullable=False)
+    barcode = Column(String, unique=True)
+    team_id = Column(UUID(as_uuid=True), ForeignKey("teams.id"))
+    owner_id = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    location_id = Column(UUID(as_uuid=True), ForeignKey("locations.id"))
+    location = Column(JSON, default={})
+    status = Column(String, default="available")
+    custom_data = Column(JSON, default={})
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+    updated_at = Column(DateTime, default=datetime.now(timezone.utc), onupdate=datetime.now(timezone.utc))
+
+class FieldDefinition(Base):
+    __tablename__ = "field_definitions"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    entity_type = Column(String, nullable=False)
+    field_key = Column(String, nullable=False)
+    field_label = Column(String, nullable=False)
+    field_type = Column(String, nullable=False)
+    is_required = Column(Boolean, default=False)
+    options = Column(JSON)
+    validation = Column(JSON)
+    team_id = Column(UUID(as_uuid=True), ForeignKey("teams.id"))
+
+    __table_args__ = (
+        sa.UniqueConstraint("entity_type", "field_key", "team_id"),
+        {"sqlite_autoincrement": True},
+    )
+
+
+class ItemRelationship(Base):
+    __tablename__ = "item_relationships"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    from_item = Column(
+        UUID(as_uuid=True),
+        ForeignKey("inventory_items.id", ondelete="CASCADE"),
+    )
+    to_item = Column(
+        UUID(as_uuid=True),
+        ForeignKey("inventory_items.id", ondelete="CASCADE"),
+    )
+    relationship_type = Column(String)
+    meta = Column("metadata", JSON, default={})
+
+
+class File(Base):
+    __tablename__ = "files"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    item_id = Column(UUID(as_uuid=True), ForeignKey("inventory_items.id", ondelete="CASCADE"))
+    filename = Column(String)
+    file_type = Column(String)
+    file_size = Column(String)
+    storage_path = Column(String)
+    meta = Column("metadata", JSON, default={})
+    uploaded_by = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class ProtocolTemplate(Base):
+    __tablename__ = "protocol_templates"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    name = Column(String, nullable=False)
+    version = Column(String, default="1")
+    content = Column(String, nullable=False)
+    variables = Column(JSON, default=list)
+    is_public = Column(Boolean, default=False)
+    forked_from = Column(UUID(as_uuid=True), ForeignKey("protocol_templates.id"), nullable=True)
+    team_id = Column(UUID(as_uuid=True), ForeignKey("teams.id"))
+    created_by = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+    updated_at = Column(DateTime, default=datetime.now(timezone.utc), onupdate=datetime.now(timezone.utc))
+
+
+class ProtocolExecution(Base):
+    __tablename__ = "protocol_executions"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    template_id = Column(UUID(as_uuid=True), ForeignKey("protocol_templates.id"))
+    run_by = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    status = Column(String, default="pending")
+    params = Column(JSON, default={})
+    result = Column(JSON, default={})
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+    updated_at = Column(DateTime, default=datetime.now(timezone.utc), onupdate=datetime.now(timezone.utc))
+
+
+class ProtocolMergeRequest(Base):
+    __tablename__ = "protocol_merge_requests"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    template_id = Column(UUID(as_uuid=True), ForeignKey("protocol_templates.id"))
+    proposer_id = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    content = Column(String, nullable=False)
+    variables = Column(JSON, default=list)
+    status = Column(String, default="open")
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+    updated_at = Column(DateTime, default=datetime.now(timezone.utc), onupdate=datetime.now(timezone.utc))
+
+
+class TroubleshootingArticle(Base):
+    __tablename__ = "troubleshooting_articles"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    title = Column(String, nullable=False)
+    category = Column(String, nullable=False)
+    content = Column(String, nullable=False)
+    created_by = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    success_count = Column(Integer, default=0)
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+    updated_at = Column(DateTime, default=datetime.now(timezone.utc), onupdate=datetime.now(timezone.utc))
+
+
+class NotebookEntry(Base):
+    __tablename__ = "notebook_entries"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    title = Column(String, nullable=False)
+    content = Column(String, nullable=False)
+    item_id = Column(UUID(as_uuid=True), ForeignKey("inventory_items.id"), nullable=True)
+    execution_id = Column(UUID(as_uuid=True), ForeignKey("protocol_executions.id"), nullable=True)
+    project_id = Column(UUID(as_uuid=True), ForeignKey("projects.id"), nullable=True)
+    items = Column(JSON, default=list)
+    protocols = Column(JSON, default=list)
+    images = Column(JSON, default=list)
+    blocks = Column(JSON, default=list)
+    created_by = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+    updated_at = Column(DateTime, default=datetime.now(timezone.utc), onupdate=datetime.now(timezone.utc))
+    is_locked = Column(Boolean, default=False)
+    signed_by = Column(UUID(as_uuid=True), ForeignKey("users.id"), nullable=True)
+    signed_at = Column(DateTime, nullable=True)
+    witness_id = Column(UUID(as_uuid=True), ForeignKey("users.id"), nullable=True)
+    witnessed_at = Column(DateTime, nullable=True)
+
+
+class NotebookEntryVersion(Base):
+    __tablename__ = "notebook_entry_versions"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    entry_id = Column(UUID(as_uuid=True), ForeignKey("notebook_entries.id"))
+    title = Column(String, nullable=False)
+    content = Column(String, nullable=False)
+    blocks = Column(JSON, default=list)
+    created_by = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class Comment(Base):
+    __tablename__ = "comments"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    content = Column(String, nullable=False)
+    item_id = Column(UUID(as_uuid=True), ForeignKey("inventory_items.id"), nullable=True)
+    entry_id = Column(UUID(as_uuid=True), ForeignKey("notebook_entries.id"), nullable=True)
+    knowledge_article_id = Column(UUID(as_uuid=True), ForeignKey("knowledge_articles.id"), nullable=True)
+    created_by = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+    updated_at = Column(DateTime, default=datetime.now(timezone.utc), onupdate=datetime.now(timezone.utc))
+
+
+class Resource(Base):
+    __tablename__ = "resources"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    name = Column(String, nullable=False)
+    description = Column(String)
+    team_id = Column(UUID(as_uuid=True), ForeignKey("teams.id"), nullable=True)
+    created_by = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class Booking(Base):
+    __tablename__ = "bookings"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    resource_id = Column(UUID(as_uuid=True), ForeignKey("resources.id"))
+    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    start_time = Column(DateTime, nullable=False)
+    end_time = Column(DateTime, nullable=False)
+    notes = Column(String)
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class Notification(Base):
+    __tablename__ = "notifications"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    message = Column(String, nullable=False)
+    is_read = Column(Boolean, default=False)
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+class NotificationPreference(Base):
+    __tablename__ = "notification_preferences"
+    __table_args__ = (
+        sa.UniqueConstraint("user_id", "pref_type", "channel"),
+    )
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    pref_type = Column(String, nullable=False)
+    channel = Column(String, nullable=False, default="in_app")
+    enabled = Column(Boolean, default=True)
+
+
+class PasswordResetToken(Base):
+    __tablename__ = "password_reset_tokens"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    token = Column(String, unique=True, nullable=False, index=True)
+    expires_at = Column(DateTime, nullable=False)
+    used = Column(Boolean, default=False)
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class SequenceAnalysisJob(Base):
+    __tablename__ = "sequence_jobs"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    status = Column(String, default="pending")
+    format = Column(String)
+    result = Column(JSON, default={})
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+    updated_at = Column(DateTime, default=datetime.now(timezone.utc), onupdate=datetime.now(timezone.utc))
+
+
+class Project(Base):
+    __tablename__ = "projects"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    name = Column(String, nullable=False)
+    description = Column(String)
+    start_date = Column(DateTime)
+    end_date = Column(DateTime)
+    team_id = Column(UUID(as_uuid=True), ForeignKey("teams.id"), nullable=True)
+    created_by = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+    updated_at = Column(DateTime, default=datetime.now(timezone.utc), onupdate=datetime.now(timezone.utc))
+
+
+class ProjectMember(Base):
+    __tablename__ = "project_members"
+    project_id = Column(UUID(as_uuid=True), ForeignKey("projects.id"), primary_key=True)
+    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"), primary_key=True)
+    role = Column(String, default="member")
+
+
+class ProjectItem(Base):
+    __tablename__ = "project_items"
+    project_id = Column(UUID(as_uuid=True), ForeignKey("projects.id"), primary_key=True)
+    item_id = Column(UUID(as_uuid=True), ForeignKey("inventory_items.id"), primary_key=True)
+
+
+class ProjectProtocol(Base):
+    __tablename__ = "project_protocols"
+    project_id = Column(UUID(as_uuid=True), ForeignKey("projects.id"), primary_key=True)
+    template_id = Column(UUID(as_uuid=True), ForeignKey("protocol_templates.id"), primary_key=True)
+
+
+class ProjectTask(Base):
+    __tablename__ = "project_tasks"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    project_id = Column(UUID(as_uuid=True), ForeignKey("projects.id"))
+    name = Column(String, nullable=False)
+    description = Column(String)
+    due_date = Column(DateTime)
+    status = Column(String, default="pending")
+    created_by = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+    updated_at = Column(DateTime, default=datetime.now(timezone.utc), onupdate=datetime.now(timezone.utc))
+
+
+class CalendarEvent(Base):
+    __tablename__ = "calendar_events"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    title = Column(String, nullable=False)
+    description = Column(String)
+    start_time = Column(DateTime, nullable=False)
+    end_time = Column(DateTime, nullable=False)
+    team_id = Column(UUID(as_uuid=True), ForeignKey("teams.id"), nullable=True)
+    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"), nullable=True)
+    created_by = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class AnalysisTool(Base):
+    __tablename__ = "analysis_tools"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    name = Column(String, nullable=False)
+    description = Column(String)
+    code = Column(String, nullable=False)
+    supported_types = Column(JSON, default=list)
+    created_by = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+
+class AssistantMessage(Base):
+    __tablename__ = "assistant_messages"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    is_user = Column(Boolean, default=True)
+    message = Column(String, nullable=False)
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class AuditLog(Base):
+    __tablename__ = "audit_logs"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    action = Column(String, nullable=False)
+    target_type = Column(String)
+    target_id = Column(UUID(as_uuid=True))
+    details = Column(JSON, default={})
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class Equipment(Base):
+    __tablename__ = "equipment"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    name = Column(String, nullable=False)
+    eq_type = Column(String)
+    connection_info = Column(JSON, default={})
+    status = Column(String, default="offline")
+    team_id = Column(UUID(as_uuid=True), ForeignKey("teams.id"), nullable=True)
+    created_by = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class EquipmentReading(Base):
+    __tablename__ = "equipment_readings"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    equipment_id = Column(
+        UUID(as_uuid=True), ForeignKey("equipment.id", ondelete="CASCADE")
+    )
+    timestamp = Column(DateTime, default=datetime.now(timezone.utc))
+    data = Column(JSON, default={})
+
+
+class EquipmentMaintenance(Base):
+    __tablename__ = "equipment_maintenance"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    equipment_id = Column(
+        UUID(as_uuid=True), ForeignKey("equipment.id", ondelete="CASCADE")
+    )
+    due_date = Column(DateTime, nullable=False)
+    completed_at = Column(DateTime, nullable=True)
+    task_type = Column(String, default="maintenance")
+    description = Column(String, nullable=True)
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class SOP(Base):
+    __tablename__ = "sops"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    title = Column(String, nullable=False)
+    version = Column(Integer, default=1)
+    content = Column(String, nullable=False)
+    team_id = Column(UUID(as_uuid=True), ForeignKey("teams.id"))
+    created_by = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class TrainingRecord(Base):
+    __tablename__ = "training_records"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    sop_id = Column(UUID(as_uuid=True), ForeignKey("sops.id"))
+    equipment_id = Column(UUID(as_uuid=True), ForeignKey("equipment.id"))
+    trained_by = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    trained_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+class ComplianceRecord(Base):
+    __tablename__ = "compliance_records"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    item_id = Column(UUID(as_uuid=True), ForeignKey("inventory_items.id"), nullable=True)
+    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"), nullable=True)
+    record_type = Column(String, nullable=False)
+    status = Column(String, default="pending")
+    notes = Column(String)
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class KnowledgeArticle(Base):
+    __tablename__ = "knowledge_articles"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    title = Column(String, nullable=False)
+    content = Column(String, nullable=False)
+    tags = Column(JSON, default=list)
+    is_public = Column(Boolean, default=False)
+    created_by = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+    updated_at = Column(DateTime, default=datetime.now(timezone.utc), onupdate=datetime.now(timezone.utc))
+
+
+class KnowledgeArticleView(Base):
+    __tablename__ = "knowledge_article_views"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    article_id = Column(UUID(as_uuid=True), ForeignKey("knowledge_articles.id"))
+    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    viewed_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class KnowledgeArticleStar(Base):
+    __tablename__ = "knowledge_article_stars"
+    article_id = Column(UUID(as_uuid=True), ForeignKey("knowledge_articles.id"), primary_key=True)
+    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"), primary_key=True)
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class Workflow(Base):
+    __tablename__ = "workflows"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    name = Column(String, nullable=False)
+    description = Column(String)
+    steps = Column(JSON, default=list)
+    created_by = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class WorkflowExecution(Base):
+    __tablename__ = "workflow_executions"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    workflow_id = Column(UUID(as_uuid=True), ForeignKey("workflows.id"))
+    item_id = Column(UUID(as_uuid=True), ForeignKey("inventory_items.id"))
+    run_by = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    status = Column(String, default="pending")
+    result = Column(JSON, default=list)
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+    updated_at = Column(DateTime, default=datetime.now(timezone.utc), onupdate=datetime.now(timezone.utc))
+
+
+class Lab(Base):
+    __tablename__ = "labs"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    name = Column(String, nullable=False)
+    description = Column(String)
+    owner_id = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class LabConnection(Base):
+    __tablename__ = "lab_connections"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    from_lab = Column(UUID(as_uuid=True), ForeignKey("labs.id"))
+    to_lab = Column(UUID(as_uuid=True), ForeignKey("labs.id"))
+    status = Column(String, default="pending")
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class ResourceShare(Base):
+    __tablename__ = "resource_shares"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    resource_id = Column(UUID(as_uuid=True), ForeignKey("resources.id"))
+    from_lab = Column(UUID(as_uuid=True), ForeignKey("labs.id"))
+    to_lab = Column(UUID(as_uuid=True), ForeignKey("labs.id"))
+    status = Column(String, default="pending")
+    start_date = Column(DateTime, nullable=True)
+    end_date = Column(DateTime, nullable=True)
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class MarketplaceListing(Base):
+    __tablename__ = "marketplace_listings"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    item_id = Column(UUID(as_uuid=True), ForeignKey("inventory_items.id"))
+    seller_id = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    price = Column(Integer, nullable=True)
+    description = Column(String)
+    status = Column(String, default="open")
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class MarketplaceRequest(Base):
+    __tablename__ = "marketplace_requests"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    listing_id = Column(UUID(as_uuid=True), ForeignKey("marketplace_listings.id"))
+    buyer_id = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    message = Column(String)
+    status = Column(String, default="pending")
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class Post(Base):
+    __tablename__ = "posts"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    content = Column(String, nullable=False)
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class Follow(Base):
+    __tablename__ = "follows"
+    follower_id = Column(UUID(as_uuid=True), ForeignKey("users.id"), primary_key=True)
+    followed_id = Column(UUID(as_uuid=True), ForeignKey("users.id"), primary_key=True)
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class PostReport(Base):
+    __tablename__ = "post_reports"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    post_id = Column(UUID(as_uuid=True), ForeignKey("posts.id"))
+    reporter_id = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    reason = Column(String, nullable=False)
+    status = Column(String, default="pending")
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class ForumThread(Base):
+    __tablename__ = "forum_threads"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    title = Column(String, nullable=False)
+    created_by = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class ForumPost(Base):
+    __tablename__ = "forum_posts"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    thread_id = Column(UUID(as_uuid=True), ForeignKey("forum_threads.id"))
+    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    content = Column(String, nullable=False)
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class PostLike(Base):
+    __tablename__ = "post_likes"
+    post_id = Column(UUID(as_uuid=True), ForeignKey("posts.id"), primary_key=True)
+    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"), primary_key=True)
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class ProtocolStar(Base):
+    __tablename__ = "protocol_stars"
+    protocol_id = Column(UUID(as_uuid=True), ForeignKey("protocol_templates.id"), primary_key=True)
+    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"), primary_key=True)
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class ServiceListing(Base):
+    __tablename__ = "service_listings"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    provider_id = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    name = Column(String, nullable=False)
+    description = Column(String)
+    price = Column(Integer, nullable=True)
+    status = Column(String, default="open")
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
+
+
+class ServiceRequest(Base):
+    __tablename__ = "service_requests"
+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
+    listing_id = Column(UUID(as_uuid=True), ForeignKey("service_listings.id"))
+    requester_id = Column(UUID(as_uuid=True), ForeignKey("users.id"))
+    item_id = Column(UUID(as_uuid=True), ForeignKey("inventory_items.id"), nullable=True)
+    message = Column(String)
+    result_file_id = Column(UUID(as_uuid=True), ForeignKey("files.id"), nullable=True)
+    payment_status = Column(String, default="pending")
+    status = Column(String, default="pending")
+    created_at = Column(DateTime, default=datetime.now(timezone.utc))
diff --git a/backend/app/notify.py b/backend/app/notify.py
new file mode 100644
index 0000000000000000000000000000000000000000..063d93760f01c1eae33f2feb87e7516aef236c87
--- /dev/null
+++ b/backend/app/notify.py
@@ -0,0 +1,55 @@
+import os
+import smtplib
+from email.message import EmailMessage
+
+EMAIL_OUTBOX: list[tuple[str, str, str]] = []
+SMS_OUTBOX: list[tuple[str, str]] = []
+
+
+def send_email(to_email: str, subject: str, message: str):
+    if os.getenv("TESTING") == "1":
+        EMAIL_OUTBOX.append((to_email, subject, message))
+        return
+    server = os.getenv("SMTP_SERVER")
+    if not server:
+        return
+    from_addr = os.getenv("EMAIL_FROM", "noreply@example.com")
+    msg = EmailMessage()
+    msg["Subject"] = subject
+    msg["From"] = from_addr
+    msg["To"] = to_email
+    msg.set_content(message)
+    with smtplib.SMTP(server) as s:
+        s.send_message(msg)
+
+
+def send_sms(to_number: str, message: str):
+    if os.getenv("TESTING") == "1":
+        SMS_OUTBOX.append((to_number, message))
+        return
+    provider = os.getenv("SMS_PROVIDER")
+    if provider:
+        pass
+
+
+def send_daily_digest(db):
+    from datetime import datetime, timezone
+    from . import models
+
+    now = datetime.now(timezone.utc)
+    users = db.query(models.User).all()
+    for user in users:
+        if not user.email:
+            continue
+        since = user.last_digest
+        notifs = (
+            db.query(models.Notification)
+            .filter(models.Notification.user_id == user.id)
+            .filter(models.Notification.created_at > since)
+            .all()
+        )
+        if notifs:
+            content = "\n".join(n.message for n in notifs)
+            send_email(user.email, "Daily Notification Digest", content)
+            user.last_digest = now
+    db.commit()
diff --git a/backend/app/pubsub.py b/backend/app/pubsub.py
new file mode 100644
index 0000000000000000000000000000000000000000..b4036ec38452aa0412aa846e3ddeff93b9fd2151
--- /dev/null
+++ b/backend/app/pubsub.py
@@ -0,0 +1,20 @@
+import os
+import json
+import redis.asyncio as redis
+
+REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379/0")
+_redis = None
+
+async def get_redis():
+    global _redis
+    if _redis is None:
+        if os.getenv("TESTING") == "1":
+            from fakeredis import aioredis
+            _redis = aioredis.FakeRedis()
+        else:
+            _redis = redis.from_url(REDIS_URL)
+    return _redis
+
+async def publish_team_event(team_id: str, event: dict):
+    r = await get_redis()
+    await r.publish(f"team:{team_id}", json.dumps(event))
diff --git a/backend/app/rbac.py b/backend/app/rbac.py
new file mode 100644
index 0000000000000000000000000000000000000000..9e2a386f947d9e47c674b99801210581ec325899
--- /dev/null
+++ b/backend/app/rbac.py
@@ -0,0 +1,52 @@
+from uuid import UUID
+from sqlalchemy.orm import Session
+from fastapi import HTTPException
+
+from . import models
+
+
+def check_team_role(db: Session, user: models.User, team_id: UUID, roles: list[str] | tuple[str, ...]):
+    if user.is_admin:
+        return
+    membership = (
+        db.query(models.TeamMember)
+        .filter(models.TeamMember.team_id == team_id, models.TeamMember.user_id == user.id)
+        .first()
+    )
+    if not membership or membership.role not in roles:
+        raise HTTPException(status_code=403, detail="Not authorized")
+
+
+def ensure_project_member(db: Session, user: models.User, project_id: UUID, roles: list[str] | tuple[str, ...] = ("member", "owner")):
+    if user.is_admin:
+        return
+    membership = (
+        db.query(models.ProjectMember)
+        .filter(models.ProjectMember.project_id == project_id, models.ProjectMember.user_id == user.id)
+        .first()
+    )
+    if not membership or membership.role not in roles:
+        raise HTTPException(status_code=403, detail="Not authorized")
+
+
+def ensure_item_access(
+    db: Session,
+    user: models.User,
+    item_id: UUID,
+    roles: list[str] | tuple[str, ...] = ("member", "manager", "owner"),
+) -> models.InventoryItem:
+    """Return the item if the user has access, otherwise raise 403."""
+    item = db.query(models.InventoryItem).filter(models.InventoryItem.id == item_id).first()
+    if not item:
+        raise HTTPException(status_code=404, detail="Item not found")
+    if user.is_admin or item.owner_id == user.id:
+        return item
+    if item.team_id:
+        membership = (
+            db.query(models.TeamMember)
+            .filter(models.TeamMember.team_id == item.team_id, models.TeamMember.user_id == user.id)
+            .first()
+        )
+        if membership and membership.role in roles:
+            return item
+    raise HTTPException(status_code=403, detail="Not authorized")
diff --git a/backend/app/routes/__init__.py b/backend/app/routes/__init__.py
new file mode 100644
index 0000000000000000000000000000000000000000..59abe25030fa31eeda324b8f19fa8af220fc84f4
--- /dev/null
+++ b/backend/app/routes/__init__.py
@@ -0,0 +1,42 @@
+from importlib import import_module
+
+modules = [
+    'auth',
+    'users',
+    'inventory',
+    'fields',
+    'locations',
+    'teams',
+    'files',
+    'protocols',
+    'troubleshooting',
+    'notebook',
+    'comments',
+    'notifications',
+    'schedule',
+    'sequence',
+    'projects',
+    'assistant',
+    'calendar',
+    'tools',
+    'search',
+    'analytics',
+    'audit',
+    'equipment',
+    'compliance',
+    'external',
+    'data_analysis',
+    'labs',
+    'resource_shares',
+    'marketplace',
+    'services',
+    'knowledge',
+    'forum',
+    'community',
+    'workflows',
+]
+
+for m in modules:
+    import_module(f'.{m}', __name__)
+
+__all__ = modules
diff --git a/backend/app/routes/analytics.py b/backend/app/routes/analytics.py
new file mode 100644
index 0000000000000000000000000000000000000000..d6c0190ab6f7cf9ca85da88b227708843499af7d
--- /dev/null
+++ b/backend/app/routes/analytics.py
@@ -0,0 +1,408 @@
+from typing import List
+from fastapi import APIRouter, Depends
+from sqlalchemy.orm import Session
+from datetime import datetime, timezone, timedelta
+from sqlalchemy import func
+
+from ..database import get_db
+from ..auth import get_current_user
+from .. import models, schemas
+
+router = APIRouter(prefix="/api/analytics", tags=["analytics"])
+
+@router.get("/summary", response_model=List[schemas.ItemTypeCount])
+def analytics_summary(db: Session = Depends(get_db), user: models.User = Depends(get_current_user)):
+    rows = (
+        db.query(models.InventoryItem.item_type, func.count(models.InventoryItem.id))
+        .group_by(models.InventoryItem.item_type)
+        .all()
+    )
+    return [{"item_type": r[0], "count": r[1]} for r in rows]
+
+
+@router.get("/trending-protocols", response_model=List[schemas.TrendingProtocol])
+def analytics_trending_protocols(
+    days: int = 30,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    since = datetime.now(timezone.utc) - timedelta(days=days)
+    rows = (
+        db.query(
+            models.ProtocolExecution.template_id,
+            func.count(models.ProtocolExecution.id).label("cnt"),
+            func.max(models.ProtocolExecution.created_at).label("last"),
+        )
+        .filter(models.ProtocolExecution.created_at >= since)
+        .group_by(models.ProtocolExecution.template_id)
+        .all()
+    )
+    scored = [
+        (
+            r.template_id,
+            r.cnt,
+            r.cnt
+            / (
+                1
+                + (
+                    datetime.now(timezone.utc)
+                    - r.last.replace(tzinfo=timezone.utc)
+                ).days
+            ),
+        )
+        for r in rows
+    ]
+    scored.sort(key=lambda x: x[2], reverse=True)
+    template_ids = [r[0] for r in scored]
+    templates = {
+        t.id: t
+        for t in db.query(models.ProtocolTemplate).filter(models.ProtocolTemplate.id.in_(template_ids)).all()
+    }
+    return [
+        {
+            "template_id": tid,
+            "template_name": templates.get(tid).name if tid in templates else "",
+            "count": cnt,
+        }
+        for tid, cnt, _score in scored[:5]
+    ]
+
+
+@router.get("/trending-protocol-stars", response_model=List[schemas.TrendingProtocol])
+def analytics_trending_protocol_stars(
+    days: int = 30,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    since = datetime.now(timezone.utc) - timedelta(days=days)
+    rows = (
+        db.query(
+            models.ProtocolStar.protocol_id,
+            func.count(models.ProtocolStar.user_id).label("cnt"),
+            func.max(models.ProtocolStar.created_at).label("last"),
+        )
+        .filter(models.ProtocolStar.created_at >= since)
+        .group_by(models.ProtocolStar.protocol_id)
+        .all()
+    )
+    scored = [
+        (
+            r.protocol_id,
+            r.cnt,
+            r.cnt
+            / (
+                1
+                + (
+                    datetime.now(timezone.utc)
+                    - r.last.replace(tzinfo=timezone.utc)
+                ).days
+            ),
+        )
+        for r in rows
+    ]
+    scored.sort(key=lambda x: x[2], reverse=True)
+    ids = [r[0] for r in scored]
+    templates = {
+        t.id: t
+        for t in db.query(models.ProtocolTemplate).filter(models.ProtocolTemplate.id.in_(ids)).all()
+    }
+    return [
+        {
+            "template_id": tid,
+            "template_name": templates.get(tid).name if tid in templates else "",
+            "count": cnt,
+        }
+        for tid, cnt, _ in scored[:5]
+    ]
+
+
+@router.get("/trending-article-stars", response_model=List[schemas.TrendingArticle])
+def analytics_trending_article_stars(
+    days: int = 30,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    since = datetime.now(timezone.utc) - timedelta(days=days)
+    rows = (
+        db.query(
+            models.KnowledgeArticleStar.article_id,
+            func.count(models.KnowledgeArticleStar.user_id).label("cnt"),
+            func.max(models.KnowledgeArticleStar.created_at).label("last"),
+        )
+        .filter(models.KnowledgeArticleStar.created_at >= since)
+        .group_by(models.KnowledgeArticleStar.article_id)
+        .all()
+    )
+    scored = [
+        (
+            r.article_id,
+            r.cnt,
+            r.cnt
+            / (
+                1
+                + (
+                    datetime.now(timezone.utc)
+                    - r.last.replace(tzinfo=timezone.utc)
+                ).days
+            ),
+        )
+        for r in rows
+    ]
+    scored.sort(key=lambda x: x[2], reverse=True)
+    ids = [r[0] for r in scored]
+    arts = {
+        a.id: a
+        for a in db.query(models.KnowledgeArticle).filter(models.KnowledgeArticle.id.in_(ids)).all()
+    }
+    return [
+        {
+            "article_id": aid,
+            "title": arts.get(aid).title if aid in arts else "",
+            "count": cnt,
+        }
+        for aid, cnt, _ in scored[:5]
+    ]
+
+
+@router.get("/trending-article-comments", response_model=List[schemas.TrendingArticle])
+def analytics_trending_article_comments(
+    days: int = 30,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    since = datetime.now(timezone.utc) - timedelta(days=days)
+    rows = (
+        db.query(
+            models.Comment.knowledge_article_id,
+            func.count(models.Comment.id).label("cnt"),
+            func.max(models.Comment.created_at).label("last"),
+        )
+        .filter(
+            models.Comment.knowledge_article_id.isnot(None),
+            models.Comment.created_at >= since,
+        )
+        .group_by(models.Comment.knowledge_article_id)
+        .all()
+    )
+    scored = [
+        (
+            r.knowledge_article_id,
+            r.cnt,
+            r.cnt
+            / (
+                1
+                + (
+                    datetime.now(timezone.utc)
+                    - r.last.replace(tzinfo=timezone.utc)
+                ).days
+            ),
+        )
+        for r in rows
+    ]
+    scored.sort(key=lambda x: x[2], reverse=True)
+    ids = [r[0] for r in scored]
+    arts = {
+        a.id: a
+        for a in db.query(models.KnowledgeArticle).filter(models.KnowledgeArticle.id.in_(ids)).all()
+    }
+    return [
+        {
+            "article_id": aid,
+            "title": arts.get(aid).title if aid in arts else "",
+            "count": cnt,
+        }
+        for aid, cnt, _ in scored[:5]
+    ]
+
+
+@router.get("/trending-articles", response_model=List[schemas.TrendingArticle])
+def analytics_trending_articles(
+    days: int = 30,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    since = datetime.now(timezone.utc) - timedelta(days=days)
+    rows = (
+        db.query(
+            models.KnowledgeArticleView.article_id,
+            func.count(models.KnowledgeArticleView.id).label("cnt"),
+            func.max(models.KnowledgeArticleView.viewed_at).label("last"),
+        )
+        .filter(models.KnowledgeArticleView.viewed_at >= since)
+        .group_by(models.KnowledgeArticleView.article_id)
+        .all()
+    )
+    scored = [
+        (
+            r.article_id,
+            r.cnt,
+            r.cnt
+            / (
+                1
+                + (
+                    datetime.now(timezone.utc)
+                    - r.last.replace(tzinfo=timezone.utc)
+                ).days
+            ),
+        )
+        for r in rows
+    ]
+    scored.sort(key=lambda x: x[2], reverse=True)
+    ids = [r[0] for r in scored]
+    arts = {a.id: a for a in db.query(models.KnowledgeArticle).filter(models.KnowledgeArticle.id.in_(ids)).all()}
+    return [
+        {
+            "article_id": aid,
+            "title": arts.get(aid).title if aid in arts else "",
+            "count": cnt,
+        }
+        for aid, cnt, _score in scored[:5]
+    ]
+
+
+@router.get("/trending-items", response_model=List[schemas.TrendingItem])
+def analytics_trending_items(
+    days: int = 30,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    since = datetime.now(timezone.utc) - timedelta(days=days)
+    rows = (
+        db.query(
+            models.NotebookEntry.item_id,
+            func.count(models.NotebookEntry.id).label("cnt"),
+            func.max(models.NotebookEntry.created_at).label("last"),
+        )
+        .filter(
+            models.NotebookEntry.item_id.isnot(None),
+            models.NotebookEntry.created_at >= since,
+        )
+        .group_by(models.NotebookEntry.item_id)
+        .all()
+    )
+    scored = [
+        (
+            r.item_id,
+            r.cnt,
+            r.cnt
+            / (
+                1
+                + (
+                    datetime.now(timezone.utc)
+                    - r.last.replace(tzinfo=timezone.utc)
+                ).days
+            ),
+        )
+        for r in rows
+    ]
+    scored.sort(key=lambda x: x[2], reverse=True)
+    ids = [r[0] for r in scored]
+    items = {
+        i.id: i
+        for i in db.query(models.InventoryItem).filter(models.InventoryItem.id.in_(ids)).all()
+    }
+    return [
+        {
+            "item_id": iid,
+            "name": items.get(iid).name if iid in items else "",
+            "count": cnt,
+        }
+        for iid, cnt, _score in scored[:5]
+    ]
+
+
+@router.get("/trending-threads", response_model=List[schemas.TrendingThread])
+def analytics_trending_threads(
+    days: int = 30,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    since = datetime.now(timezone.utc) - timedelta(days=days)
+    rows = (
+        db.query(
+            models.ForumPost.thread_id,
+            func.count(models.ForumPost.id).label("cnt"),
+            func.max(models.ForumPost.created_at).label("last"),
+        )
+        .filter(models.ForumPost.created_at >= since)
+        .group_by(models.ForumPost.thread_id)
+        .all()
+    )
+    scored = [
+        (
+            r.thread_id,
+            r.cnt,
+            r.cnt
+            / (
+                1
+                + (
+                    datetime.now(timezone.utc)
+                    - r.last.replace(tzinfo=timezone.utc)
+                ).days
+            ),
+            r.last,
+        )
+        for r in rows
+    ]
+    scored.sort(key=lambda x: x[2], reverse=True)
+    ids = [r[0] for r in scored]
+    threads = {
+        t.id: t
+        for t in db.query(models.ForumThread).filter(models.ForumThread.id.in_(ids)).all()
+    }
+    return [
+        {
+            "thread_id": tid,
+            "title": threads.get(tid).title if tid in threads else "",
+            "count": cnt,
+        }
+        for tid, cnt, _score, _last in scored[:5]
+    ]
+
+
+@router.get("/trending-posts", response_model=List[schemas.TrendingPost])
+def analytics_trending_posts(
+    days: int = 30,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    since = datetime.now(timezone.utc) - timedelta(days=days)
+    likes = (
+        db.query(
+            models.PostLike.post_id,
+            func.count(models.PostLike.user_id).label("cnt"),
+        )
+        .filter(models.PostLike.created_at >= since)
+        .group_by(models.PostLike.post_id)
+        .all()
+    )
+    ids = [l.post_id for l in likes]
+    posts = {
+        p.id: p
+        for p in db.query(models.Post).filter(models.Post.id.in_(ids)).all()
+    }
+    scored = [
+        (
+            l.post_id,
+            l.cnt,
+            l.cnt
+            / (
+                1
+                + (
+                    datetime.now(timezone.utc)
+                    - posts[l.post_id].created_at.replace(tzinfo=timezone.utc)
+                ).days
+            ),
+        )
+        for l in likes
+        if l.post_id in posts
+    ]
+    scored.sort(key=lambda x: x[2], reverse=True)
+    return [
+        {
+            "post_id": pid,
+            "content": posts[pid].content,
+            "count": cnt,
+        }
+        for pid, cnt, _score in scored[:5]
+    ]
diff --git a/backend/app/routes/assistant.py b/backend/app/routes/assistant.py
new file mode 100644
index 0000000000000000000000000000000000000000..2434d5c2aa8e90b4c281f3435c436d9a3ffea26b
--- /dev/null
+++ b/backend/app/routes/assistant.py
@@ -0,0 +1,70 @@
+from fastapi import APIRouter, Depends
+from sqlalchemy.orm import Session
+
+from ..database import get_db
+from ..auth import get_current_user
+from .. import models, schemas
+from ..assistant import (
+    generate_response,
+    inventory_forecast,
+    suggest_protocols,
+    design_experiment,
+)
+
+router = APIRouter(prefix="/api/assistant", tags=["assistant"])
+
+@router.post("/ask", response_model=schemas.AssistantMessageOut)
+def ask_question(
+    question: schemas.AssistantQuestion,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    user_msg = models.AssistantMessage(user_id=user.id, is_user=True, message=question.question)
+    db.add(user_msg)
+    db.flush()
+    answer = generate_response(question.question, user, db)
+    bot_msg = models.AssistantMessage(user_id=user.id, is_user=False, message=answer)
+    db.add(bot_msg)
+    db.commit()
+    db.refresh(bot_msg)
+    return bot_msg
+
+
+@router.get("", response_model=list[schemas.AssistantMessageOut])
+def get_history(
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    msgs = (
+        db.query(models.AssistantMessage)
+        .filter(models.AssistantMessage.user_id == user.id)
+        .order_by(models.AssistantMessage.created_at)
+        .all()
+    )
+    return msgs
+
+
+@router.get("/forecast", response_model=list[schemas.InventoryForecastItem])
+def get_inventory_forecast(
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    return inventory_forecast(user, db)
+
+
+@router.get("/suggest", response_model=list[schemas.ProtocolSuggestion])
+def suggest_protocol(
+    goal: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    return suggest_protocols(goal, user, db)
+
+
+@router.get("/design", response_model=schemas.ExperimentDesignOut)
+def design_experiment_endpoint(
+    goal: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    return design_experiment(goal, user, db)
diff --git a/backend/app/routes/audit.py b/backend/app/routes/audit.py
new file mode 100644
index 0000000000000000000000000000000000000000..c3c62be16764019be0e522dac495b3b5af828fb8
--- /dev/null
+++ b/backend/app/routes/audit.py
@@ -0,0 +1,37 @@
+from uuid import UUID
+from datetime import datetime
+from sqlalchemy.orm import Session
+from fastapi import APIRouter, Depends
+from ..database import get_db
+from ..auth import get_current_user
+from .. import models, schemas, audit
+
+router = APIRouter(prefix="/api/audit", tags=["audit"])
+
+
+@router.get("/", response_model=list[schemas.AuditLogOut])
+async def list_logs(
+    user_id: UUID | None = None,
+    db: Session = Depends(get_db),
+    current_user: models.User = Depends(get_current_user),
+):
+    query = db.query(models.AuditLog)
+    if user_id:
+        query = query.filter(models.AuditLog.user_id == user_id)
+    else:
+        query = query.filter(models.AuditLog.user_id == current_user.id)
+    return query.order_by(models.AuditLog.created_at.desc()).all()
+
+
+@router.get("/report", response_model=list[schemas.AuditReportItem])
+async def audit_report(
+    start: datetime,
+    end: datetime,
+    user_id: UUID | None = None,
+    db: Session = Depends(get_db),
+    current_user: models.User = Depends(get_current_user),
+):
+    if user_id is None:
+        user_id = current_user.id
+    data = audit.generate_report(db, start, end, user_id)
+    return data
diff --git a/backend/app/routes/auth.py b/backend/app/routes/auth.py
new file mode 100644
index 0000000000000000000000000000000000000000..3a0e682ddaaa7fb19dfef05a93c31108147d34ba
--- /dev/null
+++ b/backend/app/routes/auth.py
@@ -0,0 +1,122 @@
+from fastapi import APIRouter, Depends, HTTPException, Request
+import os
+from sqlalchemy.orm import Session
+from datetime import datetime, timedelta, timezone
+import uuid
+import pyotp
+from ..database import get_db
+from .. import models, schemas, notify, audit
+from ..auth import get_password_hash, verify_password, create_access_token, get_current_user
+from slowapi import Limiter
+from slowapi.util import get_remote_address
+
+limiter = Limiter(key_func=get_remote_address)
+testing = os.getenv("TESTING") == "1"
+
+def rate_limit(limit: str):
+    if testing:
+        def wrapper(func):
+            return func
+        return wrapper
+    return limiter.limit(limit)
+
+router = APIRouter(prefix="/api/auth", tags=["auth"])
+
+@router.post("/register", response_model=schemas.Token)
+@rate_limit("5/minute")
+async def register(request: Request, user: schemas.UserCreate, db: Session = Depends(get_db)):
+    existing = db.query(models.User).filter(models.User.email == user.email).first()
+    if existing:
+        raise HTTPException(status_code=400, detail="Email already registered")
+    db_user = models.User(
+        email=user.email,
+        hashed_password=get_password_hash(user.password),
+        full_name=user.full_name,
+        phone_number=user.phone_number,
+        orcid_id=user.orcid_id,
+    )
+    db.add(db_user)
+    db.commit()
+    db.refresh(db_user)
+    audit.log_action(db, str(db_user.id), "register", "user", str(db_user.id))
+    token = create_access_token({"sub": db_user.email})
+    return schemas.Token(access_token=token)
+
+
+@router.post("/request-password-reset")
+async def request_password_reset(data: schemas.PasswordResetRequest, db: Session = Depends(get_db)):
+    user = db.query(models.User).filter(models.User.email == data.email).first()
+    if user:
+        token = uuid.uuid4().hex
+        expires = datetime.now(timezone.utc) + timedelta(hours=1)
+        db_token = models.PasswordResetToken(user_id=user.id, token=token, expires_at=expires)
+        db.add(db_token)
+        db.commit()
+        notify.send_email(user.email, "Password Reset", f"Use this code to reset: {token}")
+    return {"status": "sent"}
+
+
+@router.post("/reset-password")
+async def reset_password(data: schemas.PasswordResetConfirm, db: Session = Depends(get_db)):
+    record = (
+        db.query(models.PasswordResetToken)
+        .filter(models.PasswordResetToken.token == data.token, models.PasswordResetToken.used == False)
+        .first()
+    )
+    expires_at = record.expires_at
+    if expires_at.tzinfo is None:
+        expires_at = expires_at.replace(tzinfo=timezone.utc)
+    if not record or expires_at < datetime.now(timezone.utc):
+        raise HTTPException(status_code=400, detail="Invalid or expired token")
+    user = db.get(models.User, record.user_id)
+    user.hashed_password = get_password_hash(data.new_password)
+    record.used = True
+    db.add_all([user, record])
+    db.commit()
+    return {"status": "password updated"}
+
+
+@router.post("/enable-2fa", response_model=schemas.TwoFactorEnableOut)
+async def enable_two_factor(
+    db: Session = Depends(get_db),
+    current_user: models.User = Depends(get_current_user),
+):
+    secret = pyotp.random_base32()
+    current_user.two_factor_secret = secret
+    db.add(current_user)
+    db.commit()
+    url = pyotp.totp.TOTP(secret).provisioning_uri(name=current_user.email, issuer_name="BioLabs")
+    return schemas.TwoFactorEnableOut(secret=secret, otpauth_url=url)
+
+
+@router.post("/verify-2fa")
+async def verify_two_factor(
+    data: schemas.TwoFactorVerifyIn,
+    db: Session = Depends(get_db),
+    current_user: models.User = Depends(get_current_user),
+):
+    if not current_user.two_factor_secret:
+        raise HTTPException(status_code=400, detail="2FA not initiated")
+    totp = pyotp.TOTP(current_user.two_factor_secret)
+    if not totp.verify(data.code, valid_window=1):
+        raise HTTPException(status_code=400, detail="Invalid code")
+    current_user.two_factor_enabled = True
+    db.add(current_user)
+    db.commit()
+    return {"status": "enabled"}
+
+@router.post("/login", response_model=schemas.Token)
+@rate_limit("10/minute")
+async def login(request: Request, user: schemas.LoginRequest, db: Session = Depends(get_db)):
+    db_user = db.query(models.User).filter(models.User.email == user.email).first()
+    if not db_user or not verify_password(user.password, db_user.hashed_password):
+        raise HTTPException(status_code=401, detail="Invalid credentials")
+    if db_user.two_factor_enabled:
+        if not user.otp_code:
+            raise HTTPException(status_code=401, detail="Two-factor code required")
+        totp = pyotp.TOTP(db_user.two_factor_secret)
+        if not totp.verify(user.otp_code, valid_window=1):
+            raise HTTPException(status_code=401, detail="Invalid two-factor code")
+    token = create_access_token({"sub": db_user.email})
+    audit.log_action(db, str(db_user.id), "login", "user", str(db_user.id))
+    return schemas.Token(access_token=token)
diff --git a/backend/app/routes/calendar.py b/backend/app/routes/calendar.py
new file mode 100644
index 0000000000000000000000000000000000000000..04661350ae6ce209fd301b4a489c9464c4724a5d
--- /dev/null
+++ b/backend/app/routes/calendar.py
@@ -0,0 +1,51 @@
+from fastapi import APIRouter, Depends, HTTPException
+from sqlalchemy.orm import Session
+from uuid import UUID
+
+from ..database import get_db
+from ..models import CalendarEvent
+from ..schemas import CalendarEventCreate, CalendarEventOut, CalendarEventUpdate
+from ..auth import get_current_user
+
+router = APIRouter(prefix="/api/calendar", tags=["calendar"])
+
+
+@router.post("", response_model=CalendarEventOut)
+def create_event(event: CalendarEventCreate, db: Session = Depends(get_db), user=Depends(get_current_user)):
+    db_event = CalendarEvent(**event.model_dump(), created_by=user.id)
+    db.add(db_event)
+    db.commit()
+    db.refresh(db_event)
+    return db_event
+
+
+@router.get("", response_model=list[CalendarEventOut])
+def list_events(db: Session = Depends(get_db), user=Depends(get_current_user)):
+    return db.query(CalendarEvent).all()
+
+
+@router.put("/{event_id}", response_model=CalendarEventOut)
+def update_event(
+    event_id: UUID,
+    data: CalendarEventUpdate,
+    db: Session = Depends(get_db),
+    user=Depends(get_current_user),
+):
+    ev = db.get(CalendarEvent, event_id)
+    if not ev:
+        raise HTTPException(status_code=404)
+    for k, v in data.model_dump(exclude_unset=True).items():
+        setattr(ev, k, v)
+    db.commit()
+    db.refresh(ev)
+    return ev
+
+
+@router.delete("/{event_id}", status_code=204)
+def delete_event(event_id: UUID, db: Session = Depends(get_db), user=Depends(get_current_user)):
+    ev = db.get(CalendarEvent, event_id)
+    if not ev:
+        raise HTTPException(status_code=404)
+    db.delete(ev)
+    db.commit()
+    return
diff --git a/backend/app/routes/comments.py b/backend/app/routes/comments.py
new file mode 100644
index 0000000000000000000000000000000000000000..699156cecce162469b2dd40ba389e4ca4eb57b34
--- /dev/null
+++ b/backend/app/routes/comments.py
@@ -0,0 +1,78 @@
+from fastapi import APIRouter, Depends, HTTPException
+from sqlalchemy.orm import Session
+from uuid import UUID
+
+from ..database import get_db
+from ..auth import get_current_user
+from .. import models, schemas
+
+router = APIRouter(prefix="/api/comments", tags=["comments"])
+
+@router.post("/", response_model=schemas.CommentOut)
+async def create_comment(
+    comment: schemas.CommentCreate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    db_comment = models.Comment(**comment.model_dump(), created_by=user.id)
+    db.add(db_comment)
+    db.commit()
+    db.refresh(db_comment)
+    return db_comment
+
+
+@router.get("/", response_model=list[schemas.CommentOut])
+async def list_comments(
+    item_id: UUID | None = None,
+    entry_id: UUID | None = None,
+    article_id: UUID | None = None,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    q = db.query(models.Comment)
+    if item_id:
+        q = q.filter(models.Comment.item_id == item_id)
+    if entry_id:
+        q = q.filter(models.Comment.entry_id == entry_id)
+    if article_id:
+        q = q.filter(models.Comment.knowledge_article_id == article_id)
+    return q.all()
+
+
+@router.put("/{comment_id}", response_model=schemas.CommentOut)
+async def update_comment(
+    comment_id: str,
+    update: schemas.CommentUpdate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(comment_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid comment id")
+    comment = db.query(models.Comment).filter(models.Comment.id == uid).first()
+    if not comment:
+        raise HTTPException(status_code=404, detail="Comment not found")
+    for k, v in update.model_dump(exclude_unset=True).items():
+        setattr(comment, k, v)
+    db.commit()
+    db.refresh(comment)
+    return comment
+
+
+@router.delete("/{comment_id}")
+async def delete_comment(
+    comment_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(comment_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid comment id")
+    comment = db.query(models.Comment).filter(models.Comment.id == uid).first()
+    if not comment:
+        raise HTTPException(status_code=404, detail="Comment not found")
+    db.delete(comment)
+    db.commit()
+    return {"detail": "deleted"}
diff --git a/backend/app/routes/community.py b/backend/app/routes/community.py
new file mode 100644
index 0000000000000000000000000000000000000000..b501c8964577c8c9da5a976b28e30aa64c1e6d27
--- /dev/null
+++ b/backend/app/routes/community.py
@@ -0,0 +1,230 @@
+from typing import Optional
+from uuid import UUID
+
+from fastapi import APIRouter, Depends, HTTPException
+from sqlalchemy.orm import Session
+
+from ..database import get_db
+from ..auth import get_current_user
+from .. import models, schemas
+
+router = APIRouter(prefix="/api/community", tags=["community"])
+
+@router.post("/posts", response_model=schemas.PostOut)
+async def create_post(
+    post: schemas.PostCreate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    db_post = models.Post(content=post.content, user_id=user.id)
+    db.add(db_post)
+    db.commit()
+    db.refresh(db_post)
+    return db_post
+
+
+@router.delete("/posts/{post_id}")
+async def delete_post(
+    post_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        pid = UUID(post_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid post id")
+    post = db.query(models.Post).filter(models.Post.id == pid).first()
+    if not post:
+        raise HTTPException(status_code=404, detail="Post not found")
+    if post.user_id != user.id:
+        raise HTTPException(status_code=403, detail="Not allowed")
+    db.delete(post)
+    db.commit()
+    return {"detail": "deleted"}
+
+
+@router.get("/posts", response_model=list[schemas.PostOut])
+async def list_posts(
+    user_id: Optional[str] = None,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    query = db.query(models.Post)
+    if user_id:
+        try:
+            uid = UUID(user_id)
+        except ValueError:
+            raise HTTPException(status_code=400, detail="Invalid user id")
+        query = query.filter(models.Post.user_id == uid)
+    return query.order_by(models.Post.created_at.desc()).all()
+
+
+@router.post("/follow/{user_id}", response_model=schemas.FollowOut)
+async def follow_user(
+    user_id: str,
+    db: Session = Depends(get_db),
+    current_user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(user_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid user id")
+    if uid == current_user.id:
+        raise HTTPException(status_code=400, detail="Cannot follow yourself")
+    follow = db.query(models.Follow).filter(
+        models.Follow.follower_id == current_user.id,
+        models.Follow.followed_id == uid,
+    ).first()
+    if not follow:
+        follow = models.Follow(follower_id=current_user.id, followed_id=uid)
+        db.add(follow)
+        db.commit()
+    return follow
+
+
+@router.delete("/follow/{user_id}")
+async def unfollow_user(
+    user_id: str,
+    db: Session = Depends(get_db),
+    current_user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(user_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid user id")
+    follow = db.query(models.Follow).filter(
+        models.Follow.follower_id == current_user.id,
+        models.Follow.followed_id == uid,
+    ).first()
+    if follow:
+        db.delete(follow)
+        db.commit()
+    return {"detail": "unfollowed"}
+
+
+@router.get("/feed", response_model=list[schemas.PostOut])
+async def get_feed(
+    db: Session = Depends(get_db),
+    current_user: models.User = Depends(get_current_user),
+):
+    followed_ids = [
+        f.followed_id
+        for f in db.query(models.Follow).filter(models.Follow.follower_id == current_user.id)
+    ]
+    if not followed_ids:
+        return []
+    return (
+        db.query(models.Post)
+        .filter(models.Post.user_id.in_(followed_ids))
+        .order_by(models.Post.created_at.desc())
+        .all()
+    )
+
+
+@router.post("/posts/{post_id}/like", response_model=schemas.PostLikeOut)
+async def like_post(
+    post_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        pid = UUID(post_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid post id")
+    if not db.query(models.Post).filter(models.Post.id == pid).first():
+        raise HTTPException(status_code=404, detail="Post not found")
+    like = (
+        db.query(models.PostLike)
+        .filter(models.PostLike.post_id == pid, models.PostLike.user_id == user.id)
+        .first()
+    )
+    if not like:
+        like = models.PostLike(post_id=pid, user_id=user.id)
+        db.add(like)
+        db.commit()
+    return like
+
+
+@router.delete("/posts/{post_id}/like")
+async def unlike_post(
+    post_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        pid = UUID(post_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid post id")
+    like = (
+        db.query(models.PostLike)
+        .filter(models.PostLike.post_id == pid, models.PostLike.user_id == user.id)
+        .first()
+    )
+    if like:
+        db.delete(like)
+        db.commit()
+    return {"detail": "unliked"}
+
+
+@router.get("/posts/{post_id}/likes", response_model=int)
+async def count_likes(
+    post_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        pid = UUID(post_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid post id")
+    return (
+        db.query(models.PostLike)
+        .filter(models.PostLike.post_id == pid)
+        .count()
+    )
+
+
+@router.post("/posts/{post_id}/report", response_model=schemas.PostReportOut)
+async def report_post(
+    post_id: str,
+    report: schemas.PostReportCreate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        pid = UUID(post_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid post id")
+    post = db.query(models.Post).filter(models.Post.id == pid).first()
+    if not post:
+        raise HTTPException(status_code=404, detail="Post not found")
+    db_report = models.PostReport(post_id=pid, reporter_id=user.id, reason=report.reason)
+    db.add(db_report)
+    db.commit()
+    db.refresh(db_report)
+    return db_report
+
+
+@router.get("/reports", response_model=list[schemas.PostReportOut])
+async def list_reports(
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    return db.query(models.PostReport).order_by(models.PostReport.created_at.desc()).all()
+
+
+@router.post("/reports/{report_id}/resolve")
+async def resolve_report(
+    report_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        rid = UUID(report_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid report id")
+    rep = db.query(models.PostReport).filter(models.PostReport.id == rid).first()
+    if not rep:
+        raise HTTPException(status_code=404, detail="Report not found")
+    rep.status = "resolved"
+    db.commit()
+    return {"detail": "resolved"}
diff --git a/backend/app/routes/compliance.py b/backend/app/routes/compliance.py
new file mode 100644
index 0000000000000000000000000000000000000000..6fd15fd64c3d97ca68b4beb86fa2966f35ed37fa
--- /dev/null
+++ b/backend/app/routes/compliance.py
@@ -0,0 +1,61 @@
+from fastapi import APIRouter, Depends, HTTPException
+from sqlalchemy.orm import Session
+from sqlalchemy import func
+from uuid import UUID
+
+from ..database import get_db
+from ..auth import get_current_user
+from .. import models, schemas
+
+router = APIRouter(prefix="/api/compliance", tags=["compliance"])
+
+@router.post("/records", response_model=schemas.ComplianceRecordOut)
+async def create_record(
+    rec: schemas.ComplianceRecordCreate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    obj = models.ComplianceRecord(
+        item_id=rec.item_id,
+        record_type=rec.record_type,
+        status=rec.status,
+        notes=rec.notes,
+        user_id=user.id,
+    )
+    db.add(obj)
+    db.commit()
+    db.refresh(obj)
+    return obj
+
+
+@router.get("/records", response_model=list[schemas.ComplianceRecordOut])
+async def list_records(
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    return db.query(models.ComplianceRecord).all()
+
+
+@router.put("/records/{record_id}", response_model=schemas.ComplianceRecordOut)
+async def update_record(
+    record_id: UUID,
+    data: schemas.ComplianceRecordUpdate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    obj = db.query(models.ComplianceRecord).filter_by(id=record_id).first()
+    if not obj:
+        raise HTTPException(status_code=404, detail="Record not found")
+    if data.status is not None:
+        obj.status = data.status
+    if data.notes is not None:
+        obj.notes = data.notes
+    db.commit()
+    db.refresh(obj)
+    return obj
+
+
+@router.get("/summary")
+async def compliance_summary(db: Session = Depends(get_db), user: models.User = Depends(get_current_user)):
+    rows = db.query(models.ComplianceRecord.status, func.count(models.ComplianceRecord.id)).group_by(models.ComplianceRecord.status).all()
+    return [{"status": r[0], "count": r[1]} for r in rows]
diff --git a/backend/app/routes/data_analysis.py b/backend/app/routes/data_analysis.py
new file mode 100644
index 0000000000000000000000000000000000000000..50c85fe60c4884630a11cda0f8219012ddb7cef3
--- /dev/null
+++ b/backend/app/routes/data_analysis.py
@@ -0,0 +1,13 @@
+from fastapi import APIRouter, Depends, UploadFile, File
+import pandas as pd
+
+from ..auth import get_current_user
+
+router = APIRouter(prefix="/api/data", tags=["data"])
+
+@router.post("/summary")
+def csv_summary(upload: UploadFile = File(...), user=Depends(get_current_user)):
+    df = pd.read_csv(upload.file)
+    # return describe dictionary for numeric columns
+    summary = df.describe().to_dict()
+    return summary
diff --git a/backend/app/routes/equipment.py b/backend/app/routes/equipment.py
new file mode 100644
index 0000000000000000000000000000000000000000..bac01d9ba437bf8cc85ced2bd9b3db0ee5cb828f
--- /dev/null
+++ b/backend/app/routes/equipment.py
@@ -0,0 +1,144 @@
+from uuid import UUID
+from fastapi import APIRouter, Depends, HTTPException
+from sqlalchemy.orm import Session
+
+from ..database import get_db
+from ..auth import get_current_user
+from .. import models, schemas
+
+router = APIRouter(prefix="/api/equipment", tags=["equipment"])
+
+
+@router.post("/devices", response_model=schemas.EquipmentOut)
+def create_equipment(
+    equipment: schemas.EquipmentCreate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    db_eq = models.Equipment(**equipment.model_dump(), created_by=user.id)
+    db.add(db_eq)
+    db.commit()
+    db.refresh(db_eq)
+    return db_eq
+
+
+@router.get("/devices", response_model=list[schemas.EquipmentOut])
+def list_equipment(db: Session = Depends(get_db), user: models.User = Depends(get_current_user)):
+    return db.query(models.Equipment).all()
+
+
+@router.put("/devices/{equipment_id}", response_model=schemas.EquipmentOut)
+def update_equipment(
+    equipment_id: UUID,
+    data: schemas.EquipmentUpdate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    eq = db.get(models.Equipment, equipment_id)
+    if not eq:
+        raise HTTPException(status_code=404)
+    for k, v in data.model_dump(exclude_unset=True).items():
+        setattr(eq, k, v)
+    db.commit()
+    db.refresh(eq)
+    return eq
+
+
+@router.post("/devices/{equipment_id}/readings", response_model=schemas.EquipmentReadingOut)
+def add_reading(
+    equipment_id: UUID,
+    reading: schemas.EquipmentReadingCreate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    eq = db.get(models.Equipment, equipment_id)
+    if not eq:
+        raise HTTPException(status_code=404)
+    r = models.EquipmentReading(equipment_id=equipment_id, data=reading.data)
+    db.add(r)
+    db.commit()
+    db.refresh(r)
+    return r
+
+
+@router.get("/devices/{equipment_id}/readings", response_model=list[schemas.EquipmentReadingOut])
+def list_readings(
+    equipment_id: UUID,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    return db.query(models.EquipmentReading).filter_by(equipment_id=equipment_id).all()
+
+
+@router.post("/maintenance", response_model=schemas.EquipmentMaintenanceOut)
+def create_maintenance(
+    task: schemas.EquipmentMaintenanceCreate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    eq = db.get(models.Equipment, task.equipment_id)
+    if not eq:
+        raise HTTPException(status_code=404)
+    obj = models.EquipmentMaintenance(**task.model_dump())
+    db.add(obj)
+    db.commit()
+    db.refresh(obj)
+    return obj
+
+
+@router.get("/maintenance", response_model=list[schemas.EquipmentMaintenanceOut])
+def list_maintenance(db: Session = Depends(get_db), user: models.User = Depends(get_current_user)):
+    return db.query(models.EquipmentMaintenance).all()
+
+
+@router.put("/maintenance/{task_id}", response_model=schemas.EquipmentMaintenanceOut)
+def update_maintenance(
+    task_id: UUID,
+    data: schemas.EquipmentMaintenanceCreate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    obj = db.get(models.EquipmentMaintenance, task_id)
+    if not obj:
+        raise HTTPException(status_code=404)
+    for k, v in data.model_dump(exclude_unset=True).items():
+        setattr(obj, k, v)
+    db.commit()
+    db.refresh(obj)
+    return obj
+
+
+@router.post("/sops", response_model=schemas.SOPOut)
+def create_sop(
+    sop: schemas.SOPCreate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    obj = models.SOP(**sop.model_dump(), created_by=user.id)
+    db.add(obj)
+    db.commit()
+    db.refresh(obj)
+    return obj
+
+
+@router.get("/sops", response_model=list[schemas.SOPOut])
+def list_sops(db: Session = Depends(get_db), user: models.User = Depends(get_current_user)):
+    return db.query(models.SOP).all()
+
+
+@router.post("/training", response_model=schemas.TrainingRecordOut)
+def create_training(
+    rec: schemas.TrainingRecordCreate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    obj = models.TrainingRecord(**rec.model_dump())
+    db.add(obj)
+    db.commit()
+    db.refresh(obj)
+    return obj
+
+
+@router.get("/training", response_model=list[schemas.TrainingRecordOut])
+def list_training(db: Session = Depends(get_db), user: models.User = Depends(get_current_user)):
+    return db.query(models.TrainingRecord).all()
diff --git a/backend/app/routes/external.py b/backend/app/routes/external.py
new file mode 100644
index 0000000000000000000000000000000000000000..3a451b49d9f96ba5c3d1676df3d6c2cf0263680a
--- /dev/null
+++ b/backend/app/routes/external.py
@@ -0,0 +1,22 @@
+from fastapi import APIRouter, Depends, HTTPException
+from sqlalchemy.orm import Session
+
+from ..auth import get_current_user
+from ..database import get_db
+from .. import models, schemas
+from ..external import search_pubmed
+
+router = APIRouter(prefix="/api/external", tags=["external"])
+
+
+@router.post("/pubmed", response_model=list[schemas.PubMedArticle])
+async def pubmed_search(
+    payload: schemas.PubMedQuery,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        return search_pubmed(payload.query, payload.limit)
+    except Exception:
+        raise HTTPException(status_code=502, detail="Failed to reach PubMed")
+
diff --git a/backend/app/routes/fields.py b/backend/app/routes/fields.py
new file mode 100644
index 0000000000000000000000000000000000000000..965ece3d2625b46ade3147a6c0980a34ed2a9ba7
--- /dev/null
+++ b/backend/app/routes/fields.py
@@ -0,0 +1,78 @@
+from fastapi import APIRouter, Depends, HTTPException, Response
+from sqlalchemy.orm import Session
+from sqlalchemy.exc import IntegrityError
+from typing import List
+from uuid import UUID
+
+from ..database import get_db
+from ..auth import get_current_user
+from .. import models, schemas
+
+router = APIRouter(prefix="/api/fields", tags=["fields"])
+
+@router.post("/definitions", response_model=schemas.FieldDefinitionOut)
+async def create_field(field: schemas.FieldDefinitionCreate, db: Session = Depends(get_db), user: models.User = Depends(get_current_user)):
+    query = db.query(models.FieldDefinition).filter(
+        models.FieldDefinition.entity_type == field.entity_type,
+        models.FieldDefinition.field_key == field.field_key,
+    )
+    team_id = getattr(field, "team_id", None)
+    if team_id is None:
+        query = query.filter(models.FieldDefinition.team_id.is_(None))
+    else:
+        query = query.filter(models.FieldDefinition.team_id == team_id)
+    existing = query.first()
+    if existing:
+        raise HTTPException(status_code=400, detail="Field already exists")
+    db_field = models.FieldDefinition(**field.model_dump())
+    db.add(db_field)
+    try:
+        db.commit()
+    except IntegrityError:
+        db.rollback()
+        raise HTTPException(status_code=400, detail="Field already exists")
+    db.refresh(db_field)
+    return db_field
+
+@router.get("/definitions/{entity_type}", response_model=List[schemas.FieldDefinitionOut])
+async def list_fields(entity_type: str, db: Session = Depends(get_db), user: models.User = Depends(get_current_user)):
+    return db.query(models.FieldDefinition).filter(models.FieldDefinition.entity_type == entity_type).all()
+
+
+@router.put("/definitions/{field_id}", response_model=schemas.FieldDefinitionOut)
+async def update_field(
+    field_id: str,
+    field: schemas.FieldDefinitionCreate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(field_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid field id")
+    db_field = db.query(models.FieldDefinition).filter(models.FieldDefinition.id == uid).first()
+    if not db_field:
+        raise HTTPException(status_code=404, detail="Field not found")
+    for key, value in field.model_dump().items():
+        setattr(db_field, key, value)
+    db.commit()
+    db.refresh(db_field)
+    return db_field
+
+
+@router.delete("/definitions/{field_id}", status_code=204)
+async def delete_field(
+    field_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(field_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid field id")
+    db_field = db.query(models.FieldDefinition).filter(models.FieldDefinition.id == uid).first()
+    if not db_field:
+        raise HTTPException(status_code=404, detail="Field not found")
+    db.delete(db_field)
+    db.commit()
+    return Response(status_code=204)
diff --git a/backend/app/routes/files.py b/backend/app/routes/files.py
new file mode 100644
index 0000000000000000000000000000000000000000..02aecafe5b3ebe4e03ba0244c049d4bf3652dfe4
--- /dev/null
+++ b/backend/app/routes/files.py
@@ -0,0 +1,179 @@
+from fastapi import APIRouter, Depends, UploadFile, File, HTTPException, Form
+from sqlalchemy.orm import Session
+import os
+from uuid import uuid4, UUID
+import io
+
+from minio import Minio
+from fastapi.responses import StreamingResponse
+
+from ..sequence import parse_chromatogram, process_sequence_file
+
+from ..database import get_db
+from ..auth import get_current_user
+from ..rbac import ensure_item_access
+from .. import models, schemas
+
+UPLOAD_DIR = os.getenv("UPLOAD_DIR", "uploaded_files")
+MINIO_ENDPOINT = os.getenv("MINIO_ENDPOINT")
+MINIO_ACCESS_KEY = os.getenv("MINIO_ACCESS_KEY")
+MINIO_SECRET_KEY = os.getenv("MINIO_SECRET_KEY")
+MINIO_BUCKET = os.getenv("MINIO_BUCKET", "uploads")
+
+if MINIO_ENDPOINT:
+    minio_client = Minio(
+        MINIO_ENDPOINT,
+        access_key=MINIO_ACCESS_KEY,
+        secret_key=MINIO_SECRET_KEY,
+        secure=MINIO_ENDPOINT.startswith("https"),
+    )
+    if not minio_client.bucket_exists(MINIO_BUCKET):
+        minio_client.make_bucket(MINIO_BUCKET)
+else:
+    os.makedirs(UPLOAD_DIR, exist_ok=True)
+    minio_client = None
+
+router = APIRouter(prefix="/api/files", tags=["files"])
+
+
+@router.post("/upload", response_model=schemas.FileOut)
+async def upload_file(
+    item_id: str = Form(...),
+    upload: UploadFile = File(...),
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        item_uuid = UUID(item_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid item id")
+    item = ensure_item_access(db, user, item_uuid)
+
+    file_id = uuid4()
+    safe_name = os.path.basename(upload.filename)
+    object_name = f"{file_id}_{safe_name}"
+    data = await upload.read()
+    if MINIO_ENDPOINT:
+        minio_client.put_object(
+            MINIO_BUCKET,
+            object_name,
+            io.BytesIO(data),
+            length=len(data),
+            content_type=upload.content_type or "application/octet-stream",
+        )
+        storage_path = f"s3://{MINIO_BUCKET}/{object_name}"
+        file_size = len(data)
+    else:
+        save_path = os.path.join(UPLOAD_DIR, object_name)
+        with open(save_path, "wb") as f:
+            f.write(data)
+        storage_path = save_path
+        file_size = upload.size or 0
+
+    db_file = models.File(
+        id=file_id,
+        item_id=item_uuid,
+        filename=upload.filename,
+        file_type=upload.content_type or "application/octet-stream",
+        file_size=file_size,
+        storage_path=storage_path,
+        uploaded_by=user.id,
+    )
+    db.add(db_file)
+    db.commit()
+    db.refresh(db_file)
+    return db_file
+
+
+@router.get("/items/{item_id}", response_model=list[schemas.FileOut])
+async def list_files(
+    item_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        item_uuid = UUID(item_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid item id")
+    ensure_item_access(db, user, item_uuid)
+    return db.query(models.File).filter(models.File.item_id == item_uuid).all()
+
+
+@router.get("/{file_id}/download")
+async def download_file(
+    file_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        file_uuid = UUID(file_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid file id")
+    db_file = db.query(models.File).filter(models.File.id == file_uuid).first()
+    if not db_file:
+        raise HTTPException(status_code=404, detail="File not found")
+    ensure_item_access(db, user, db_file.item_id)
+    if MINIO_ENDPOINT:
+        data = minio_client.get_object(MINIO_BUCKET, db_file.storage_path.split("/")[-1]).read()
+    else:
+        with open(db_file.storage_path, "rb") as fh:
+            data = fh.read()
+    return StreamingResponse(io.BytesIO(data), media_type=db_file.file_type, headers={"Content-Disposition": f"attachment; filename={db_file.filename}"})
+
+
+@router.get("/{file_id}/chromatogram", response_model=schemas.ChromatogramOut)
+async def file_chromatogram(
+    file_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        file_uuid = UUID(file_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid file id")
+    db_file = db.query(models.File).filter(models.File.id == file_uuid).first()
+    if not db_file:
+        raise HTTPException(status_code=404, detail="File not found")
+    ensure_item_access(db, user, db_file.item_id)
+    if MINIO_ENDPOINT:
+        data = minio_client.get_object(MINIO_BUCKET, db_file.storage_path.split("/")[-1]).read()
+    else:
+        with open(db_file.storage_path, "rb") as fh:
+            data = fh.read()
+    try:
+        return parse_chromatogram(data)
+    except Exception:
+        raise HTTPException(status_code=400, detail="Invalid chromatogram file")
+
+
+@router.get("/{file_id}/sequence", response_model=list[schemas.SequenceRead])
+async def file_sequence(
+    file_id: str,
+    format: str | None = None,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        file_uuid = UUID(file_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid file id")
+    db_file = db.query(models.File).filter(models.File.id == file_uuid).first()
+    if not db_file:
+        raise HTTPException(status_code=404, detail="File not found")
+    ensure_item_access(db, user, db_file.item_id)
+    if MINIO_ENDPOINT:
+        data = minio_client.get_object(MINIO_BUCKET, db_file.storage_path.split("/")[-1]).read()
+    else:
+        with open(db_file.storage_path, "rb") as fh:
+            data = fh.read()
+    fmt = format
+    if not fmt:
+        ext = db_file.filename.rsplit(".", 1)[-1].lower()
+        if ext in {"fastq", "fq"}:
+            fmt = "fastq"
+        else:
+            fmt = "fasta"
+    try:
+        return process_sequence_file(data, fmt)
+    except Exception:
+        raise HTTPException(status_code=400, detail="Invalid sequence file")
diff --git a/backend/app/routes/forum.py b/backend/app/routes/forum.py
new file mode 100644
index 0000000000000000000000000000000000000000..b2df986d5ab92111decf843f6f22918727eece0b
--- /dev/null
+++ b/backend/app/routes/forum.py
@@ -0,0 +1,60 @@
+from uuid import UUID
+from fastapi import APIRouter, Depends, HTTPException
+from sqlalchemy.orm import Session
+
+from ..database import get_db
+from ..auth import get_current_user
+from .. import models, schemas
+
+router = APIRouter(prefix="/api/forum", tags=["forum"])
+
+
+@router.post("/threads", response_model=schemas.ForumThreadOut)
+async def create_thread(
+    thread: schemas.ForumThreadCreate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    db_thread = models.ForumThread(title=thread.title, created_by=user.id)
+    db.add(db_thread)
+    db.commit()
+    db.refresh(db_thread)
+    return db_thread
+
+
+@router.get("/threads", response_model=list[schemas.ForumThreadOut])
+async def list_threads(db: Session = Depends(get_db), user: models.User = Depends(get_current_user)):
+    return db.query(models.ForumThread).all()
+
+
+@router.post("/threads/{thread_id}/posts", response_model=schemas.ForumPostOut)
+async def create_post(
+    thread_id: str,
+    post: schemas.ForumPostCreate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        tid = UUID(thread_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid thread id")
+    if not db.query(models.ForumThread).filter(models.ForumThread.id == tid).first():
+        raise HTTPException(status_code=404, detail="Thread not found")
+    db_post = models.ForumPost(thread_id=tid, user_id=user.id, content=post.content)
+    db.add(db_post)
+    db.commit()
+    db.refresh(db_post)
+    return db_post
+
+
+@router.get("/threads/{thread_id}/posts", response_model=list[schemas.ForumPostOut])
+async def list_posts(
+    thread_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        tid = UUID(thread_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid thread id")
+    return db.query(models.ForumPost).filter(models.ForumPost.thread_id == tid).all()
diff --git a/backend/app/routes/inventory.py b/backend/app/routes/inventory.py
new file mode 100644
index 0000000000000000000000000000000000000000..d853343ed78358257456dfa60c3a2460a2d67ae0
--- /dev/null
+++ b/backend/app/routes/inventory.py
@@ -0,0 +1,400 @@
+from fastapi import APIRouter, Depends, HTTPException, Response, UploadFile, File
+import json
+from sqlalchemy.orm import Session
+import sqlalchemy as sa
+from typing import List, Optional
+import csv
+import io
+from uuid import UUID
+from datetime import datetime
+
+from ..database import get_db
+from ..auth import get_current_user
+from .. import models, schemas, pubsub, search, barcodes, audit
+from ..rbac import check_team_role, ensure_item_access
+
+
+async def get_item_and_check_permission(
+    item_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+) -> models.InventoryItem:
+    try:
+        uuid = UUID(item_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid item id")
+    item = db.query(models.InventoryItem).filter(models.InventoryItem.id == uuid).first()
+    if not item:
+        raise HTTPException(status_code=404, detail="Item not found")
+    if item.owner_id != user.id:
+        is_member = (
+            db.query(models.TeamMember)
+            .filter(
+                models.TeamMember.team_id == item.team_id,
+                models.TeamMember.user_id == user.id,
+            )
+            .first()
+        )
+        if not is_member:
+            raise HTTPException(status_code=403, detail="Not authorized")
+    return item
+
+router = APIRouter(prefix="/api/inventory", tags=["inventory"])
+
+
+@router.post("/items", response_model=schemas.InventoryItemOut)
+async def create_item(
+    item: schemas.InventoryItemCreate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    db_item = models.InventoryItem(**item.model_dump())
+    if db_item.team_id:
+        check_team_role(db, user, db_item.team_id, ["owner", "manager", "member"])
+    if not db_item.team_id:
+        # if team not specified, use user's first team if exists
+        membership = user.teams[0] if user.teams else None
+        if membership:
+            db_item.team_id = membership.team_id
+    if not db_item.owner_id:
+        db_item.owner_id = user.id
+    db.add(db_item)
+    db.commit()
+    db.refresh(db_item)
+    audit.log_action(db, str(user.id), "create_item", "inventory", str(db_item.id))
+    search.index_item(db_item)
+    if db_item.team_id:
+        await pubsub.publish_team_event(
+            str(db_item.team_id),
+            {"type": "item_created", "id": str(db_item.id)},
+        )
+    return db_item
+
+
+@router.get("/items", response_model=List[schemas.InventoryItemOut])
+async def list_items(
+    item_type: Optional[str] = None,
+    name: Optional[str] = None,
+    barcode: Optional[str] = None,
+    status: Optional[str] = None,
+    team_id: Optional[str] = None,
+    created_from: Optional[str] = None,
+    created_to: Optional[str] = None,
+    custom: Optional[str] = None,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    query = db.query(models.InventoryItem)
+    if not user.is_admin:
+        team_ids = [m.team_id for m in user.teams]
+        query = query.filter(
+            (models.InventoryItem.owner_id == user.id)
+            | (models.InventoryItem.team_id.in_(team_ids))
+        )
+    if item_type:
+        query = query.filter(models.InventoryItem.item_type == item_type)
+    if name:
+        query = query.filter(models.InventoryItem.name.ilike(f"%{name}%"))
+    if barcode:
+        query = query.filter(models.InventoryItem.barcode == barcode)
+    if status:
+        query = query.filter(models.InventoryItem.status == status)
+    if team_id:
+        try:
+            team_uuid = UUID(team_id)
+        except ValueError:
+            raise HTTPException(status_code=400, detail="Invalid team id")
+        query = query.filter(models.InventoryItem.team_id == team_uuid)
+    if created_from:
+        try:
+            dt_from = datetime.fromisoformat(created_from)
+        except ValueError:
+            raise HTTPException(status_code=400, detail="Invalid created_from")
+        query = query.filter(models.InventoryItem.created_at >= dt_from)
+    if created_to:
+        try:
+            dt_to = datetime.fromisoformat(created_to)
+        except ValueError:
+            raise HTTPException(status_code=400, detail="Invalid created_to")
+        query = query.filter(models.InventoryItem.created_at <= dt_to)
+    if custom:
+        try:
+            data = json.loads(custom)
+        except json.JSONDecodeError:
+            raise HTTPException(status_code=400, detail="Invalid custom filter")
+        query = query.filter(models.InventoryItem.custom_data.contains(data))
+    return query.all()
+
+
+@router.get("/facets", response_model=schemas.InventoryFacets)
+async def get_facets(
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    team_ids = [m.team_id for m in user.teams]
+    query = db.query(models.InventoryItem)
+    if not user.is_admin:
+        query = query.filter(
+            (models.InventoryItem.owner_id == user.id)
+            | (models.InventoryItem.team_id.in_(team_ids))
+        )
+    else:
+        # admin can access all teams
+        team_ids = [t.id for t in db.query(models.Team.id).all()]
+    item_types = (
+        query.with_entities(models.InventoryItem.item_type, sa.func.count())
+        .group_by(models.InventoryItem.item_type)
+        .all()
+    )
+    statuses = (
+        query.with_entities(models.InventoryItem.status, sa.func.count())
+        .group_by(models.InventoryItem.status)
+        .all()
+    )
+    teams = (
+        query.with_entities(models.InventoryItem.team_id, sa.func.count())
+        .group_by(models.InventoryItem.team_id)
+        .all()
+    )
+    team_names = {
+        str(t.id): t.name
+        for t in db.query(models.Team).filter(
+            models.Team.id.in_([t[0] for t in teams if t[0]])
+        ).all()
+    }
+    fields = (
+        db.query(models.FieldDefinition)
+        .filter(
+            (models.FieldDefinition.team_id.is_(None))
+            | (models.FieldDefinition.team_id.in_(team_ids))
+        )
+        .all()
+    )
+    return schemas.InventoryFacets(
+        item_types=[schemas.FacetCount(key=it[0], count=it[1]) for it in item_types],
+        statuses=[schemas.FacetCount(key=st[0], count=st[1]) for st in statuses],
+        teams=[
+            schemas.FacetCount(
+                key=team_names.get(str(t[0]), str(t[0])), count=t[1]
+            )
+            for t in teams
+            if t[0]
+        ],
+        fields=fields,
+    )
+
+
+@router.get("/export")
+async def export_items(
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    output = io.StringIO()
+    writer = csv.writer(output)
+    writer.writerow([
+        "id",
+        "item_type",
+        "name",
+        "barcode",
+        "status",
+    ])
+    query = db.query(models.InventoryItem)
+    if not user.is_admin:
+        team_ids = [m.team_id for m in user.teams]
+        query = query.filter(
+            (models.InventoryItem.owner_id == user.id)
+            | (models.InventoryItem.team_id.in_(team_ids))
+        )
+    for item in query.all():
+        writer.writerow(
+            [
+                str(item.id),
+                item.item_type,
+                item.name,
+                item.barcode or "",
+                item.status,
+            ]
+        )
+    output.seek(0)
+    headers = {
+        "Content-Disposition": "attachment; filename=inventory.csv"
+    }
+    return Response(content=output.read(), media_type="text/csv", headers=headers)
+
+
+@router.post("/import", response_model=List[schemas.InventoryItemOut])
+async def import_items(
+    file: UploadFile = File(...),
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    data = await file.read()
+    reader = csv.DictReader(io.StringIO(data.decode()))
+    items: list[models.InventoryItem] = []
+    for row in reader:
+        try:
+            custom = json.loads(row.get("custom_data", "{}"))
+        except json.JSONDecodeError:
+            custom = {}
+        item = models.InventoryItem(
+            item_type=row.get("item_type", "sample"),
+            name=row.get("name", ""),
+            barcode=row.get("barcode") or None,
+            status=row.get("status"),
+            custom_data=custom,
+            owner_id=user.id,
+        )
+        if user.teams:
+            item.team_id = user.teams[0].team_id
+        db.add(item)
+        items.append(item)
+    db.commit()
+    for it in items:
+        db.refresh(it)
+        search.index_item(it)
+    return items
+
+
+@router.put("/items/{item_id}", response_model=schemas.InventoryItemOut)
+async def update_item(
+    item: schemas.InventoryItemUpdate,
+    db_item: models.InventoryItem = Depends(get_item_and_check_permission),
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    for key, value in item.model_dump(exclude_unset=True).items():
+        setattr(db_item, key, value)
+    db.commit()
+    db.refresh(db_item)
+    audit.log_action(db, str(user.id), "update_item", "inventory", str(db_item.id))
+    if db_item.team_id:
+        await pubsub.publish_team_event(
+            str(db_item.team_id),
+            {"type": "item_updated", "id": str(db_item.id)},
+        )
+    return db_item
+
+
+@router.delete("/items/{item_id}", status_code=204)
+async def delete_item(
+    db_item: models.InventoryItem = Depends(get_item_and_check_permission),
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    db.delete(db_item)
+    db.commit()
+    audit.log_action(db, str(user.id), "delete_item", "inventory", str(db_item.id))
+    search.delete_item(str(db_item.id))
+    if db_item.team_id:
+        await pubsub.publish_team_event(
+            str(db_item.team_id),
+            {"type": "item_deleted", "id": str(db_item.id)},
+        )
+    return Response(status_code=204)
+
+
+@router.post("/relationships", response_model=schemas.ItemRelationshipOut)
+async def create_relationship(
+    rel: schemas.ItemRelationshipCreate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    ensure_item_access(db, user, rel.from_item, roles=("manager", "owner"))
+    ensure_item_access(db, user, rel.to_item, roles=("manager", "owner"))
+    db_rel = models.ItemRelationship(**rel.model_dump())
+    db.add(db_rel)
+    db.commit()
+    db.refresh(db_rel)
+    return db_rel
+
+
+@router.get(
+    "/items/{item_id}/relationships",
+    response_model=List[schemas.ItemRelationshipOut],
+)
+async def list_relationships(
+    item_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        item_uuid = UUID(item_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid item id")
+    ensure_item_access(db, user, item_uuid)
+    return (
+        db.query(models.ItemRelationship)
+        .filter(
+            (models.ItemRelationship.from_item == item_uuid)
+            | (models.ItemRelationship.to_item == item_uuid)
+        )
+        .all()
+    )
+
+
+@router.get("/items/{item_id}/graph", response_model=schemas.ItemGraphOut)
+async def relationship_graph(
+    item_id: str,
+    depth: int = 1,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        start_id = UUID(item_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid item id")
+    ensure_item_access(db, user, start_id)
+
+    visited = set()
+    nodes = []
+    edges = []
+    queue = [(start_id, 0)]
+    while queue:
+        current_id, level = queue.pop(0)
+        if current_id in visited or level > depth:
+            continue
+        visited.add(current_id)
+        item = (
+            db.query(models.InventoryItem)
+            .filter(models.InventoryItem.id == current_id)
+            .first()
+        )
+        if item:
+            nodes.append(item)
+        rels = (
+            db.query(models.ItemRelationship)
+            .filter(
+                (models.ItemRelationship.from_item == current_id)
+                | (models.ItemRelationship.to_item == current_id)
+            )
+            .all()
+        )
+        for rel in rels:
+            edges.append(rel)
+            other_id = rel.to_item if rel.from_item == current_id else rel.from_item
+            if other_id not in visited:
+                queue.append((other_id, level + 1))
+
+    return {"nodes": nodes, "edges": edges}
+
+
+@router.post("/items/{item_id}/barcode")
+async def generate_barcode(
+    item_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        item_uuid = UUID(item_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid item id")
+    item = ensure_item_access(db, user, item_uuid, roles=("manager", "owner"))
+    if not item.barcode:
+        code = barcodes.generate_unique_code()
+        while db.query(models.InventoryItem).filter(models.InventoryItem.barcode == code).first():
+            code = barcodes.generate_unique_code()
+        item.barcode = code
+        db.commit()
+        db.refresh(item)
+    img = barcodes.generate_barcode_png(item.barcode)
+    return Response(content=img, media_type="image/png")
diff --git a/backend/app/routes/knowledge.py b/backend/app/routes/knowledge.py
new file mode 100644
index 0000000000000000000000000000000000000000..a591aa9e18732f4e2abfad19b0294a6d89606754
--- /dev/null
+++ b/backend/app/routes/knowledge.py
@@ -0,0 +1,182 @@
+from uuid import UUID
+from fastapi import APIRouter, Depends, HTTPException
+from sqlalchemy.orm import Session
+
+from ..database import get_db
+from ..auth import get_current_user
+from .. import models, schemas
+
+router = APIRouter(prefix="/api/knowledge", tags=["knowledge"])
+
+
+@router.post("/articles", response_model=schemas.KnowledgeArticleOut)
+async def create_article(
+    article: schemas.KnowledgeArticleCreate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    db_article = models.KnowledgeArticle(
+        **article.model_dump(exclude_unset=True), created_by=user.id
+    )
+    db.add(db_article)
+    db.commit()
+    db.refresh(db_article)
+    return db_article
+
+
+@router.get("/articles", response_model=list[schemas.KnowledgeArticleOut])
+async def list_articles(
+    tag: str | None = None,
+    public_only: bool = False,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    query = db.query(models.KnowledgeArticle)
+    if tag:
+        query = query.filter(models.KnowledgeArticle.tags.contains([tag]))
+    if public_only:
+        query = query.filter(models.KnowledgeArticle.is_public == True)
+    return query.all()
+
+
+@router.get("/articles/{article_id}", response_model=schemas.KnowledgeArticleOut)
+async def get_article(
+    article_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(article_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid article id")
+    art = db.query(models.KnowledgeArticle).filter(models.KnowledgeArticle.id == uid).first()
+    if not art:
+        raise HTTPException(status_code=404, detail="Article not found")
+    if not art.is_public and art.created_by != user.id:
+        raise HTTPException(status_code=403, detail="Not authorized")
+    db.add(models.KnowledgeArticleView(article_id=uid, user_id=user.id))
+    db.commit()
+    return art
+
+
+@router.put("/articles/{article_id}", response_model=schemas.KnowledgeArticleOut)
+async def update_article(
+    article_id: str,
+    update: schemas.KnowledgeArticleUpdate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(article_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid article id")
+    art = db.query(models.KnowledgeArticle).filter(models.KnowledgeArticle.id == uid).first()
+    if not art:
+        raise HTTPException(status_code=404, detail="Article not found")
+    if art.created_by != user.id:
+        raise HTTPException(status_code=403, detail="Not authorized")
+    for key, value in update.model_dump(exclude_unset=True).items():
+        setattr(art, key, value)
+    db.commit()
+    db.refresh(art)
+    return art
+
+
+@router.delete("/articles/{article_id}")
+async def delete_article(
+    article_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(article_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid article id")
+    art = db.query(models.KnowledgeArticle).filter(models.KnowledgeArticle.id == uid).first()
+    if not art:
+        raise HTTPException(status_code=404, detail="Article not found")
+    if art.created_by != user.id:
+        raise HTTPException(status_code=403, detail="Not authorized")
+    db.delete(art)
+    db.commit()
+    return {"detail": "deleted"}
+
+
+@router.post("/articles/{article_id}/view")
+async def record_article_view(
+    article_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(article_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid article id")
+    article = db.query(models.KnowledgeArticle).filter(models.KnowledgeArticle.id == uid).first()
+    if not article:
+        raise HTTPException(status_code=404, detail="Article not found")
+    db.add(models.KnowledgeArticleView(article_id=uid, user_id=user.id))
+    db.commit()
+    return {"detail": "view recorded"}
+
+
+@router.post("/articles/{article_id}/star", response_model=schemas.KnowledgeArticleStarOut)
+async def star_article(
+    article_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(article_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid article id")
+    article = db.query(models.KnowledgeArticle).filter(models.KnowledgeArticle.id == uid).first()
+    if not article:
+        raise HTTPException(status_code=404, detail="Article not found")
+    existing = (
+        db.query(models.KnowledgeArticleStar)
+        .filter(models.KnowledgeArticleStar.article_id == uid, models.KnowledgeArticleStar.user_id == user.id)
+        .first()
+    )
+    if existing:
+        return existing
+    star = models.KnowledgeArticleStar(article_id=uid, user_id=user.id)
+    db.add(star)
+    db.commit()
+    db.refresh(star)
+    return star
+
+
+@router.delete("/articles/{article_id}/star")
+async def unstar_article(
+    article_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(article_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid article id")
+    star = (
+        db.query(models.KnowledgeArticleStar)
+        .filter(models.KnowledgeArticleStar.article_id == uid, models.KnowledgeArticleStar.user_id == user.id)
+        .first()
+    )
+    if star:
+        db.delete(star)
+        db.commit()
+    return {"detail": "ok"}
+
+
+@router.get("/articles/{article_id}/stars")
+async def get_article_stars(
+    article_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(article_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid article id")
+    count = db.query(models.KnowledgeArticleStar).filter(models.KnowledgeArticleStar.article_id == uid).count()
+    return {"count": count}
diff --git a/backend/app/routes/labs.py b/backend/app/routes/labs.py
new file mode 100644
index 0000000000000000000000000000000000000000..4736c790ed4fb18edbb7db64c66c8b305f671802
--- /dev/null
+++ b/backend/app/routes/labs.py
@@ -0,0 +1,77 @@
+from typing import List
+from uuid import UUID
+
+from fastapi import APIRouter, Depends, HTTPException
+from sqlalchemy.orm import Session
+
+from ..database import get_db
+from ..auth import get_current_user
+from .. import models, schemas
+
+router = APIRouter(prefix="/api/labs", tags=["labs"])
+
+
+@router.post("", response_model=schemas.LabOut)
+def create_lab(
+    lab: schemas.LabCreate,
+    db: Session = Depends(get_db),
+    user=Depends(get_current_user),
+):
+    db_lab = models.Lab(**lab.model_dump(), owner_id=user.id)
+    db.add(db_lab)
+    db.commit()
+    db.refresh(db_lab)
+    return db_lab
+
+
+@router.get("", response_model=List[schemas.LabOut])
+def list_labs(db: Session = Depends(get_db), user=Depends(get_current_user)):
+    return db.query(models.Lab).all()
+
+
+@router.post("/{lab_id}/connections", response_model=schemas.LabConnectionOut)
+def request_connection(
+    lab_id: UUID,
+    data: schemas.LabConnectionCreate,
+    db: Session = Depends(get_db),
+    user=Depends(get_current_user),
+):
+    lab = db.get(models.Lab, lab_id)
+    if not lab or lab.owner_id != user.id:
+        raise HTTPException(status_code=404)
+    conn = models.LabConnection(from_lab=lab_id, to_lab=data.target_lab)
+    db.add(conn)
+    db.commit()
+    db.refresh(conn)
+    return conn
+
+
+@router.post("/connections/{connection_id}/accept", response_model=schemas.LabConnectionOut)
+def accept_connection(
+    connection_id: UUID,
+    db: Session = Depends(get_db),
+    user=Depends(get_current_user),
+):
+    conn = db.get(models.LabConnection, connection_id)
+    if not conn:
+        raise HTTPException(status_code=404)
+    lab = db.get(models.Lab, conn.to_lab)
+    if not lab or lab.owner_id != user.id:
+        raise HTTPException(status_code=403)
+    conn.status = "accepted"
+    db.commit()
+    db.refresh(conn)
+    return conn
+
+
+@router.get("/connections", response_model=List[schemas.LabConnectionOut])
+def list_connections(db: Session = Depends(get_db), user=Depends(get_current_user)):
+    labs = db.query(models.Lab).filter(models.Lab.owner_id == user.id).all()
+    ids = [l.id for l in labs]
+    if not ids:
+        return []
+    return (
+        db.query(models.LabConnection)
+        .filter(models.LabConnection.from_lab.in_(ids) | models.LabConnection.to_lab.in_(ids))
+        .all()
+    )
diff --git a/backend/app/routes/locations.py b/backend/app/routes/locations.py
new file mode 100644
index 0000000000000000000000000000000000000000..c3334fa68734b388250178bfaa4d4002b8ad2202
--- /dev/null
+++ b/backend/app/routes/locations.py
@@ -0,0 +1,79 @@
+from fastapi import APIRouter, Depends, HTTPException
+from sqlalchemy.orm import Session
+from uuid import UUID
+
+from ..database import get_db
+from ..auth import get_current_user
+from .. import models, schemas
+from ..rbac import check_team_role
+
+router = APIRouter(prefix="/api/locations", tags=["locations"])
+
+@router.post("/", response_model=schemas.LocationOut)
+async def create_location(
+    loc: schemas.LocationCreate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    if loc.team_id:
+        check_team_role(db, user, loc.team_id, ["owner", "manager", "member"])
+    else:
+        membership = user.teams[0] if user.teams else None
+        if membership:
+            loc.team_id = membership.team_id
+    db_loc = models.Location(**loc.model_dump())
+    db.add(db_loc)
+    db.commit()
+    db.refresh(db_loc)
+    return db_loc
+
+
+@router.get("/", response_model=list[schemas.LocationOut])
+async def list_locations(
+    team_id: UUID | None = None,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    query = db.query(models.Location)
+    if team_id:
+        check_team_role(db, user, team_id, ["owner", "manager", "member"])
+        query = query.filter(models.Location.team_id == team_id)
+    else:
+        team_ids = [m.team_id for m in user.teams]
+        query = query.filter(models.Location.team_id.in_(team_ids))
+    return query.all()
+
+
+@router.put("/{loc_id}", response_model=schemas.LocationOut)
+async def update_location(
+    loc_id: UUID,
+    update: schemas.LocationUpdate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    loc = db.get(models.Location, loc_id)
+    if not loc:
+        raise HTTPException(status_code=404, detail="Location not found")
+    if loc.team_id:
+        check_team_role(db, user, loc.team_id, ["owner", "manager"])
+    for k, v in update.model_dump(exclude_unset=True).items():
+        setattr(loc, k, v)
+    db.commit()
+    db.refresh(loc)
+    return loc
+
+
+@router.delete("/{loc_id}", status_code=204)
+async def delete_location(
+    loc_id: UUID,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    loc = db.get(models.Location, loc_id)
+    if not loc:
+        raise HTTPException(status_code=404, detail="Location not found")
+    if loc.team_id:
+        check_team_role(db, user, loc.team_id, ["owner", "manager"])
+    db.delete(loc)
+    db.commit()
+    return
diff --git a/backend/app/routes/marketplace.py b/backend/app/routes/marketplace.py
new file mode 100644
index 0000000000000000000000000000000000000000..ed14fef5c2c70fe6331eaa701fd269e5c8f288e0
--- /dev/null
+++ b/backend/app/routes/marketplace.py
@@ -0,0 +1,125 @@
+from typing import List
+from uuid import UUID
+from fastapi import APIRouter, Depends, HTTPException
+from sqlalchemy.orm import Session
+
+from ..database import get_db
+from ..auth import get_current_user
+from .. import models, schemas
+
+router = APIRouter(prefix="/api/marketplace", tags=["marketplace"])
+
+@router.post("/listings", response_model=schemas.MarketplaceListingOut)
+def create_listing(
+    data: schemas.MarketplaceListingCreate,
+    db: Session = Depends(get_db),
+    user=Depends(get_current_user),
+):
+    item = db.get(models.InventoryItem, data.item_id)
+    if not item or (item.owner_id and item.owner_id != user.id):
+        raise HTTPException(status_code=403)
+    listing = models.MarketplaceListing(
+        item_id=item.id,
+        seller_id=user.id,
+        price=data.price,
+        description=data.description,
+    )
+    db.add(listing)
+    db.commit()
+    db.refresh(listing)
+    return listing
+
+
+@router.get("/listings", response_model=List[schemas.MarketplaceListingOut])
+def list_listings(db: Session = Depends(get_db)):
+    return (
+        db.query(models.MarketplaceListing)
+        .filter(models.MarketplaceListing.status == "open")
+        .all()
+    )
+
+
+@router.post(
+    "/listings/{listing_id}/requests",
+    response_model=schemas.MarketplaceRequestOut,
+)
+def create_request(
+    listing_id: UUID,
+    data: schemas.MarketplaceRequestCreate,
+    db: Session = Depends(get_db),
+    user=Depends(get_current_user),
+):
+    listing = db.get(models.MarketplaceListing, listing_id)
+    if not listing or listing.status != "open":
+        raise HTTPException(status_code=404)
+    req = models.MarketplaceRequest(
+        listing_id=listing_id,
+        buyer_id=user.id,
+        message=data.message,
+    )
+    db.add(req)
+    db.commit()
+    db.refresh(req)
+    return req
+
+
+@router.get(
+    "/listings/{listing_id}/requests",
+    response_model=List[schemas.MarketplaceRequestOut],
+)
+def list_requests(
+    listing_id: UUID,
+    db: Session = Depends(get_db),
+    user=Depends(get_current_user),
+):
+    listing = db.get(models.MarketplaceListing, listing_id)
+    if not listing or listing.seller_id != user.id:
+        raise HTTPException(status_code=403)
+    return (
+        db.query(models.MarketplaceRequest)
+        .filter_by(listing_id=listing_id)
+        .all()
+    )
+
+
+@router.post(
+    "/requests/{request_id}/accept",
+    response_model=schemas.MarketplaceRequestOut,
+)
+def accept_request(
+    request_id: UUID,
+    db: Session = Depends(get_db),
+    user=Depends(get_current_user),
+):
+    req = db.get(models.MarketplaceRequest, request_id)
+    if not req:
+        raise HTTPException(status_code=404)
+    listing = db.get(models.MarketplaceListing, req.listing_id)
+    if listing.seller_id != user.id:
+        raise HTTPException(status_code=403)
+    req.status = "accepted"
+    listing.status = "closed"
+    db.commit()
+    db.refresh(req)
+    return req
+
+
+@router.post(
+    "/requests/{request_id}/reject",
+    response_model=schemas.MarketplaceRequestOut,
+)
+def reject_request(
+    request_id: UUID,
+    db: Session = Depends(get_db),
+    user=Depends(get_current_user),
+):
+    req = db.get(models.MarketplaceRequest, request_id)
+    if not req:
+        raise HTTPException(status_code=404)
+    listing = db.get(models.MarketplaceListing, req.listing_id)
+    if listing.seller_id != user.id:
+        raise HTTPException(status_code=403)
+    req.status = "rejected"
+    db.commit()
+    db.refresh(req)
+    return req
diff --git a/backend/app/routes/notebook.py b/backend/app/routes/notebook.py
new file mode 100644
index 0000000000000000000000000000000000000000..fee9d0216ab36b34badb1c5b6785671e6debb5ae
--- /dev/null
+++ b/backend/app/routes/notebook.py
@@ -0,0 +1,223 @@
+from fastapi import APIRouter, Depends, HTTPException
+from fastapi.responses import Response
+from sqlalchemy.orm import Session
+from uuid import UUID
+from datetime import datetime, timezone
+from fpdf import FPDF
+
+from ..database import get_db
+from ..auth import get_current_user
+from .. import models, schemas
+
+router = APIRouter(prefix="/api/notebook", tags=["notebook"])
+
+@router.post("/entries", response_model=schemas.NotebookEntryOut)
+async def create_entry(
+    entry: schemas.NotebookEntryCreate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    data = entry.model_dump()
+    data["items"] = [str(i) for i in data.get("items", [])]
+    data["protocols"] = [str(p) for p in data.get("protocols", [])]
+    data["images"] = [str(img) for img in data.get("images", [])]
+    data["blocks"] = data.get("blocks", [])
+    db_entry = models.NotebookEntry(**data, created_by=user.id)
+    db.add(db_entry)
+    db.commit()
+    db.refresh(db_entry)
+    version = models.NotebookEntryVersion(
+        entry_id=db_entry.id,
+        title=db_entry.title,
+        content=db_entry.content,
+        blocks=db_entry.blocks,
+        created_by=user.id,
+    )
+    db.add(version)
+    db.commit()
+    return db_entry
+
+@router.get("/entries", response_model=list[schemas.NotebookEntryOut])
+async def list_entries(
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    return db.query(models.NotebookEntry).all()
+
+@router.get("/entries/{entry_id}", response_model=schemas.NotebookEntryOut)
+async def get_entry(
+    entry_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(entry_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid entry id")
+    entry = db.query(models.NotebookEntry).filter(models.NotebookEntry.id == uid).first()
+    if not entry:
+        raise HTTPException(status_code=404, detail="Entry not found")
+    return entry
+
+@router.get("/entries/{entry_id}/export")
+async def export_entry(
+    entry_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(entry_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid entry id")
+    entry = (
+        db.query(models.NotebookEntry)
+        .filter(models.NotebookEntry.id == uid)
+        .first()
+    )
+    if not entry:
+        raise HTTPException(status_code=404, detail="Entry not found")
+
+    pdf = FPDF()
+    pdf.add_page()
+    pdf.set_font("Arial", size=12)
+    pdf.cell(0, 10, txt=entry.title, ln=True)
+    pdf.multi_cell(0, 10, entry.content)
+    pdf_bytes = pdf.output(dest="S")
+    if isinstance(pdf_bytes, str):
+        pdf_bytes = pdf_bytes.encode("latin-1")
+    else:
+        pdf_bytes = bytes(pdf_bytes)
+    return Response(content=pdf_bytes, media_type="application/pdf")
+
+@router.put("/entries/{entry_id}", response_model=schemas.NotebookEntryOut)
+async def update_entry(
+    entry_id: str,
+    update: schemas.NotebookEntryUpdate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(entry_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid entry id")
+    entry = db.query(models.NotebookEntry).filter(models.NotebookEntry.id == uid).first()
+    if not entry:
+        raise HTTPException(status_code=404, detail="Entry not found")
+    if entry.is_locked:
+        raise HTTPException(status_code=400, detail="Entry is locked")
+    upd = update.model_dump(exclude_unset=True)
+    if "items" in upd:
+        upd["items"] = [str(i) for i in upd["items"]]
+    if "protocols" in upd:
+        upd["protocols"] = [str(p) for p in upd["protocols"]]
+    if "images" in upd:
+        upd["images"] = [str(img) for img in upd["images"]]
+    if "blocks" in upd:
+        upd["blocks"] = upd["blocks"]
+    for k, v in upd.items():
+        setattr(entry, k, v)
+    db.commit()
+    version = models.NotebookEntryVersion(
+        entry_id=entry.id,
+        title=entry.title,
+        content=entry.content,
+        blocks=entry.blocks,
+        created_by=user.id,
+    )
+    db.add(version)
+    db.commit()
+    db.refresh(entry)
+    return entry
+
+@router.delete("/entries/{entry_id}")
+async def delete_entry(
+    entry_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(entry_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid entry id")
+    entry = db.query(models.NotebookEntry).filter(models.NotebookEntry.id == uid).first()
+    if not entry:
+        raise HTTPException(status_code=404, detail="Entry not found")
+    db.delete(entry)
+    db.commit()
+    return {"detail": "deleted"}
+
+
+@router.post("/entries/{entry_id}/sign", response_model=schemas.NotebookEntryOut)
+async def sign_entry(
+    entry_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(entry_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid entry id")
+    entry = db.query(models.NotebookEntry).filter(models.NotebookEntry.id == uid).first()
+    if not entry:
+        raise HTTPException(status_code=404, detail="Entry not found")
+    if entry.is_locked:
+        raise HTTPException(status_code=400, detail="Entry already signed")
+    if entry.created_by != user.id:
+        raise HTTPException(status_code=403, detail="Only the author may sign")
+    entry.is_locked = True
+    entry.signed_by = user.id
+    entry.signed_at = datetime.now(timezone.utc)
+    db.commit()
+    db.refresh(entry)
+    return entry
+
+
+@router.post(
+    "/entries/{entry_id}/witness",
+    response_model=schemas.NotebookEntryOut,
+)
+async def witness_entry(
+    entry_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(entry_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid entry id")
+    entry = db.query(models.NotebookEntry).filter(models.NotebookEntry.id == uid).first()
+    if not entry:
+        raise HTTPException(status_code=404, detail="Entry not found")
+    if not entry.is_locked:
+        raise HTTPException(status_code=400, detail="Entry must be signed first")
+    if entry.witness_id is not None:
+        raise HTTPException(status_code=400, detail="Already witnessed")
+    if entry.created_by == user.id:
+        raise HTTPException(status_code=400, detail="Author cannot witness")
+    entry.witness_id = user.id
+    entry.witnessed_at = datetime.now(timezone.utc)
+    db.commit()
+    db.refresh(entry)
+    return entry
+
+
+@router.get(
+    "/entries/{entry_id}/versions",
+    response_model=list[schemas.NotebookEntryVersionOut],
+)
+async def list_versions(
+    entry_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(entry_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid entry id")
+    versions = (
+        db.query(models.NotebookEntryVersion)
+        .filter(models.NotebookEntryVersion.entry_id == uid)
+        .order_by(models.NotebookEntryVersion.created_at)
+        .all()
+    )
+    return versions
diff --git a/backend/app/routes/notifications.py b/backend/app/routes/notifications.py
new file mode 100644
index 0000000000000000000000000000000000000000..bee3143f227e16835e2fca71b65f1d8ad3c3cb27
--- /dev/null
+++ b/backend/app/routes/notifications.py
@@ -0,0 +1,77 @@
+from uuid import UUID
+from fastapi import APIRouter, Depends, HTTPException
+from sqlalchemy.orm import Session
+
+from ..database import get_db
+from ..auth import get_current_user
+from .. import models, schemas
+
+router = APIRouter(prefix="/api/notifications", tags=["notifications"])
+
+@router.get("/", response_model=list[schemas.NotificationOut])
+async def list_notifications(
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    return (
+        db.query(models.Notification)
+        .filter(models.Notification.user_id == user.id)
+        .order_by(models.Notification.created_at.desc())
+        .all()
+    )
+
+
+@router.post("/{notification_id}/read", response_model=schemas.NotificationOut)
+async def mark_read(
+    notification_id: UUID,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    notif = (
+        db.query(models.Notification)
+        .filter_by(id=notification_id, user_id=user.id)
+        .first()
+    )
+    if not notif:
+        raise HTTPException(status_code=404, detail="Notification not found")
+    notif.is_read = True
+    db.commit()
+    db.refresh(notif)
+    return notif
+@router.get("/preferences", response_model=list[schemas.NotificationPreferenceOut])
+async def list_preferences(
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    return db.query(models.NotificationPreference).filter_by(user_id=user.id).all()
+
+
+@router.put(
+    "/preferences/{pref_type}/{channel}",
+    response_model=schemas.NotificationPreferenceOut,
+)
+async def set_preference(
+    pref_type: str,
+    channel: str,
+    pref: schemas.NotificationPreferenceUpdate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    obj = (
+        db.query(models.NotificationPreference)
+        .filter_by(user_id=user.id, pref_type=pref_type, channel=channel)
+        .first()
+    )
+    if obj:
+        obj.enabled = pref.enabled
+    else:
+        obj = models.NotificationPreference(
+            user_id=user.id,
+            pref_type=pref_type,
+            channel=channel,
+            enabled=pref.enabled,
+        )
+        db.add(obj)
+    db.commit()
+    db.refresh(obj)
+    return obj
diff --git a/backend/app/routes/projects.py b/backend/app/routes/projects.py
new file mode 100644
index 0000000000000000000000000000000000000000..44a4a59fc246e2bd479e239044dbea478364d7ee
--- /dev/null
+++ b/backend/app/routes/projects.py
@@ -0,0 +1,161 @@
+from fastapi import APIRouter, Depends, HTTPException, Response
+from sqlalchemy.orm import Session
+from uuid import UUID
+
+from ..database import get_db
+from ..models import (
+    Project,
+    ProjectMember,
+    ProjectItem,
+    ProjectProtocol,
+    ProjectTask,
+)
+from ..schemas import (
+    ProjectCreate,
+    ProjectUpdate,
+    ProjectOut,
+    ProjectTaskCreate,
+    ProjectTaskUpdate,
+    ProjectTaskOut,
+)
+from ..auth import get_current_user
+from ..rbac import ensure_project_member
+
+router = APIRouter(prefix="/api/projects", tags=["projects"])
+
+
+@router.post("", response_model=ProjectOut)
+def create_project(
+    project: ProjectCreate,
+    db: Session = Depends(get_db),
+    user=Depends(get_current_user),
+):
+    db_proj = Project(**project.model_dump(), created_by=user.id)
+    db.add(db_proj)
+    db.flush()
+    db.add(ProjectMember(project_id=db_proj.id, user_id=user.id, role="owner"))
+    db.commit()
+    db.refresh(db_proj)
+    return db_proj
+
+
+@router.get("", response_model=list[ProjectOut])
+def list_projects(db: Session = Depends(get_db), user=Depends(get_current_user)):
+    return db.query(Project).all()
+
+
+@router.get("/{project_id}", response_model=ProjectOut)
+def get_project(project_id: UUID, db: Session = Depends(get_db), user=Depends(get_current_user)):
+    proj = db.get(Project, project_id)
+    if not proj:
+        raise HTTPException(status_code=404)
+    return proj
+
+
+@router.put("/{project_id}", response_model=ProjectOut)
+def update_project(
+    project_id: UUID,
+    project: ProjectUpdate,
+    db: Session = Depends(get_db),
+    user=Depends(get_current_user),
+):
+    proj = db.get(Project, project_id)
+    if not proj:
+        raise HTTPException(status_code=404)
+    ensure_project_member(db, user, project_id, ("owner",))
+    for k, v in project.model_dump(exclude_unset=True).items():
+        setattr(proj, k, v)
+    db.commit()
+    db.refresh(proj)
+    return proj
+
+
+@router.delete("/{project_id}", status_code=204)
+def delete_project(project_id: UUID, db: Session = Depends(get_db), user=Depends(get_current_user)):
+    proj = db.get(Project, project_id)
+    if not proj:
+        raise HTTPException(status_code=404)
+    ensure_project_member(db, user, project_id, ("owner",))
+    db.query(ProjectMember).filter_by(project_id=project_id).delete()
+    db.query(ProjectItem).filter_by(project_id=project_id).delete()
+    db.query(ProjectProtocol).filter_by(project_id=project_id).delete()
+    db.delete(proj)
+    db.commit()
+    return Response(status_code=204)
+
+
+@router.post("/{project_id}/items", status_code=204)
+def add_project_item(project_id: UUID, item_id: UUID, db: Session = Depends(get_db), user=Depends(get_current_user)):
+    ensure_project_member(db, user, project_id)
+    db.add(ProjectItem(project_id=project_id, item_id=item_id))
+    db.commit()
+    return Response(status_code=204)
+
+
+@router.post("/{project_id}/protocols", status_code=204)
+def add_project_protocol(project_id: UUID, template_id: UUID, db: Session = Depends(get_db), user=Depends(get_current_user)):
+    ensure_project_member(db, user, project_id)
+    db.add(ProjectProtocol(project_id=project_id, template_id=template_id))
+    db.commit()
+    return Response(status_code=204)
+
+
+@router.post("/{project_id}/members", status_code=204)
+def add_project_member(project_id: UUID, member_id: UUID, db: Session = Depends(get_db), user=Depends(get_current_user)):
+    ensure_project_member(db, user, project_id, ("owner",))
+    db.add(ProjectMember(project_id=project_id, user_id=member_id, role="member"))
+    db.commit()
+    return Response(status_code=204)
+
+
+@router.get("/{project_id}/tasks", response_model=list[ProjectTaskOut])
+def list_project_tasks(project_id: UUID, db: Session = Depends(get_db), user=Depends(get_current_user)):
+    ensure_project_member(db, user, project_id)
+    return db.query(ProjectTask).filter_by(project_id=project_id).all()
+
+
+@router.post("/{project_id}/tasks", response_model=ProjectTaskOut)
+def create_project_task(
+    project_id: UUID,
+    task: ProjectTaskCreate,
+    db: Session = Depends(get_db),
+    user=Depends(get_current_user),
+):
+    ensure_project_member(db, user, project_id)
+    db_task = ProjectTask(
+        **task.model_dump(), project_id=project_id, created_by=user.id
+    )
+    db.add(db_task)
+    db.commit()
+    db.refresh(db_task)
+    return db_task
+
+
+@router.put("/{project_id}/tasks/{task_id}", response_model=ProjectTaskOut)
+def update_project_task(
+    project_id: UUID,
+    task_id: UUID,
+    data: ProjectTaskUpdate,
+    db: Session = Depends(get_db),
+    user=Depends(get_current_user),
+):
+    task = db.get(ProjectTask, task_id)
+    if not task or task.project_id != project_id:
+        raise HTTPException(status_code=404)
+    ensure_project_member(db, user, project_id)
+    for k, v in data.model_dump(exclude_unset=True).items():
+        setattr(task, k, v)
+    db.commit()
+    db.refresh(task)
+    return task
+
+
+@router.delete("/{project_id}/tasks/{task_id}", status_code=204)
+def delete_project_task(project_id: UUID, task_id: UUID, db: Session = Depends(get_db), user=Depends(get_current_user)):
+    task = db.get(ProjectTask, task_id)
+    if not task or task.project_id != project_id:
+        raise HTTPException(status_code=404)
+    ensure_project_member(db, user, project_id)
+    db.delete(task)
+    db.commit()
+    return Response(status_code=204)
diff --git a/backend/app/routes/protocols.py b/backend/app/routes/protocols.py
new file mode 100644
index 0000000000000000000000000000000000000000..3ff9935b4c399d166fe4fa74bef1f34e9ab22625
--- /dev/null
+++ b/backend/app/routes/protocols.py
@@ -0,0 +1,397 @@
+from fastapi import APIRouter, Depends, HTTPException
+from sqlalchemy.orm import Session
+from uuid import UUID
+
+from ..database import get_db
+from ..auth import get_current_user
+from .. import models, schemas
+
+router = APIRouter(prefix="/api/protocols", tags=["protocols"])
+
+
+@router.post("/templates", response_model=schemas.ProtocolTemplateOut)
+async def create_template(
+    template: schemas.ProtocolTemplateCreate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    version = 1
+    existing = (
+        db.query(models.ProtocolTemplate)
+        .filter(models.ProtocolTemplate.name == template.name)
+        .order_by(models.ProtocolTemplate.version.desc())
+        .first()
+    )
+    if existing:
+        try:
+            version = int(existing.version) + 1
+        except ValueError:
+            version = 1
+    db_template = models.ProtocolTemplate(
+        **template.model_dump(), version=str(version), created_by=user.id
+    )
+    db.add(db_template)
+    db.commit()
+    db.refresh(db_template)
+    return db_template
+
+
+@router.get("/templates", response_model=list[schemas.ProtocolTemplateOut])
+async def list_templates(
+    db: Session = Depends(get_db), user: models.User = Depends(get_current_user)
+):
+    return db.query(models.ProtocolTemplate).all()
+
+
+@router.get("/public", response_model=list[schemas.ProtocolTemplateOut])
+async def list_public_templates(db: Session = Depends(get_db)):
+    return (
+        db.query(models.ProtocolTemplate)
+        .filter(models.ProtocolTemplate.is_public == True)
+        .all()
+    )
+
+
+@router.put("/templates/{template_id}", response_model=schemas.ProtocolTemplateOut)
+async def update_template(
+    template_id: str,
+    update: schemas.ProtocolTemplateUpdate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(template_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid template id")
+    tpl = db.query(models.ProtocolTemplate).filter(models.ProtocolTemplate.id == uid).first()
+    if not tpl:
+        raise HTTPException(status_code=404, detail="Template not found")
+    for key, value in update.model_dump(exclude_unset=True).items():
+        setattr(tpl, key, value)
+    db.commit()
+    db.refresh(tpl)
+    return tpl
+
+
+@router.delete("/templates/{template_id}")
+async def delete_template(
+    template_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(template_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid template id")
+    tpl = db.query(models.ProtocolTemplate).filter(models.ProtocolTemplate.id == uid).first()
+    if not tpl:
+        raise HTTPException(status_code=404, detail="Template not found")
+    db.delete(tpl)
+    db.commit()
+    return {"detail": "deleted"}
+
+
+@router.get(
+    "/templates/{template_id}", response_model=schemas.ProtocolTemplateOut
+)
+async def get_template(
+    template_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(template_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid template id")
+    tpl = db.query(models.ProtocolTemplate).filter(models.ProtocolTemplate.id == uid).first()
+    if not tpl:
+        raise HTTPException(status_code=404, detail="Template not found")
+    return tpl
+
+
+@router.post("/templates/{template_id}/star", response_model=schemas.ProtocolStarOut)
+async def star_template(
+    template_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        tid = UUID(template_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid template id")
+    tpl = db.query(models.ProtocolTemplate).filter(models.ProtocolTemplate.id == tid).first()
+    if not tpl:
+        raise HTTPException(status_code=404, detail="Template not found")
+    existing = (
+        db.query(models.ProtocolStar)
+        .filter(models.ProtocolStar.protocol_id == tid, models.ProtocolStar.user_id == user.id)
+        .first()
+    )
+    if existing:
+        return existing
+    star = models.ProtocolStar(protocol_id=tid, user_id=user.id)
+    db.add(star)
+    db.commit()
+    db.refresh(star)
+    return star
+
+
+@router.delete("/templates/{template_id}/star")
+async def unstar_template(
+    template_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        tid = UUID(template_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid template id")
+    star = (
+        db.query(models.ProtocolStar)
+        .filter(models.ProtocolStar.protocol_id == tid, models.ProtocolStar.user_id == user.id)
+        .first()
+    )
+    if star:
+        db.delete(star)
+        db.commit()
+    return {"detail": "ok"}
+
+
+@router.get("/templates/{template_id}/stars")
+async def get_template_stars(
+    template_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        tid = UUID(template_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid template id")
+    count = db.query(models.ProtocolStar).filter(models.ProtocolStar.protocol_id == tid).count()
+    return {"count": count}
+
+
+@router.post("/templates/{template_id}/fork", response_model=schemas.ProtocolTemplateOut)
+async def fork_template(
+    template_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(template_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid template id")
+    tpl = db.query(models.ProtocolTemplate).filter(models.ProtocolTemplate.id == uid).first()
+    if not tpl or not tpl.is_public:
+        raise HTTPException(status_code=404, detail="Template not found or not public")
+    member = db.query(models.TeamMember).filter(models.TeamMember.user_id == user.id).first()
+    new_tpl = models.ProtocolTemplate(
+        name=tpl.name,
+        content=tpl.content,
+        variables=tpl.variables,
+        is_public=False,
+        forked_from=tpl.id,
+        team_id=member.team_id if member else None,
+        created_by=user.id,
+    )
+    db.add(new_tpl)
+    db.commit()
+    db.refresh(new_tpl)
+    return new_tpl
+
+
+@router.post("/executions", response_model=schemas.ProtocolExecutionOut)
+async def create_execution(
+    execution: schemas.ProtocolExecutionCreate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        tpl_id = UUID(str(execution.template_id))
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid template id")
+    tpl = (
+        db.query(models.ProtocolTemplate)
+        .filter(models.ProtocolTemplate.id == tpl_id)
+        .first()
+    )
+    if not tpl:
+        raise HTTPException(status_code=404, detail="Template not found")
+    if tpl.variables:
+        missing = [v for v in tpl.variables if v not in execution.params]
+        if missing:
+            raise HTTPException(status_code=400, detail=f"Missing params: {', '.join(missing)}")
+    db_exec = models.ProtocolExecution(
+        template_id=tpl_id,
+        run_by=user.id,
+        params=execution.params,
+        status="pending",
+    )
+    db.add(db_exec)
+    db.commit()
+    db.refresh(db_exec)
+    return db_exec
+
+
+@router.get("/executions", response_model=list[schemas.ProtocolExecutionOut])
+async def list_executions(
+    db: Session = Depends(get_db), user: models.User = Depends(get_current_user)
+):
+    return db.query(models.ProtocolExecution).all()
+
+
+@router.get("/executions/{exec_id}", response_model=schemas.ProtocolExecutionOut)
+async def get_execution(
+    exec_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(exec_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid execution id")
+    exec_db = (
+        db.query(models.ProtocolExecution)
+        .filter(models.ProtocolExecution.id == uid)
+        .first()
+    )
+    if not exec_db:
+        raise HTTPException(status_code=404, detail="Execution not found")
+    return exec_db
+
+
+@router.put("/executions/{exec_id}", response_model=schemas.ProtocolExecutionOut)
+async def update_execution(
+    exec_id: str,
+    update: schemas.ProtocolExecutionUpdate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(exec_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid execution id")
+    exec_db = (
+        db.query(models.ProtocolExecution)
+        .filter(models.ProtocolExecution.id == uid)
+        .first()
+    )
+    if not exec_db:
+        raise HTTPException(status_code=404, detail="Execution not found")
+    for key, value in update.model_dump(exclude_unset=True).items():
+        setattr(exec_db, key, value)
+    db.commit()
+    db.refresh(exec_db)
+    return exec_db
+
+
+# ----- Merge Requests -----
+
+@router.post("/merge-requests", response_model=schemas.ProtocolMergeRequestOut)
+async def create_merge_request(
+    req: schemas.ProtocolMergeRequestCreate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    tpl = db.query(models.ProtocolTemplate).filter(models.ProtocolTemplate.id == req.template_id).first()
+    if not tpl or not tpl.is_public:
+        raise HTTPException(status_code=404, detail="Template not found or not public")
+    mr = models.ProtocolMergeRequest(
+        template_id=req.template_id,
+        proposer_id=user.id,
+        content=req.content,
+        variables=req.variables,
+    )
+    db.add(mr)
+    db.commit()
+    db.refresh(mr)
+    return mr
+
+
+@router.get("/diff")
+async def diff_templates(
+    old_id: str,
+    new_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        oid = UUID(old_id)
+        nid = UUID(new_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid id")
+    old = db.query(models.ProtocolTemplate).filter(models.ProtocolTemplate.id == oid).first()
+    new = db.query(models.ProtocolTemplate).filter(models.ProtocolTemplate.id == nid).first()
+    if not old or not new:
+        raise HTTPException(status_code=404, detail="Template not found")
+    import difflib
+    diff = "\n".join(
+        difflib.unified_diff(
+            old.content.splitlines(),
+            new.content.splitlines(),
+            fromfile=str(old.id),
+            tofile=str(new.id),
+        )
+    )
+    return {"diff": diff}
+
+
+@router.get("/merge-requests", response_model=list[schemas.ProtocolMergeRequestOut])
+async def list_merge_requests(
+    db: Session = Depends(get_db), user: models.User = Depends(get_current_user)
+):
+    return (
+        db.query(models.ProtocolMergeRequest)
+        .join(models.ProtocolTemplate, models.ProtocolMergeRequest.template_id == models.ProtocolTemplate.id)
+        .filter(models.ProtocolTemplate.created_by == user.id)
+        .all()
+    )
+
+
+def _get_merge_request(db: Session, mr_id: UUID) -> models.ProtocolMergeRequest:
+    mr = db.query(models.ProtocolMergeRequest).filter(models.ProtocolMergeRequest.id == mr_id).first()
+    if not mr:
+        raise HTTPException(status_code=404, detail="Merge request not found")
+    return mr
+
+
+@router.post("/merge-requests/{mr_id}/accept", response_model=schemas.ProtocolTemplateOut)
+async def accept_merge_request(
+    mr_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(mr_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid merge request id")
+    mr = _get_merge_request(db, uid)
+    tpl = db.query(models.ProtocolTemplate).filter(models.ProtocolTemplate.id == mr.template_id).first()
+    if tpl.created_by != user.id:
+        raise HTTPException(status_code=403, detail="Not authorized")
+    tpl.content = mr.content
+    tpl.variables = mr.variables
+    mr.status = "accepted"
+    db.commit()
+    db.refresh(tpl)
+    return tpl
+
+
+@router.post("/merge-requests/{mr_id}/reject", response_model=schemas.ProtocolMergeRequestOut)
+async def reject_merge_request(
+    mr_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(mr_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid merge request id")
+    mr = _get_merge_request(db, uid)
+    tpl = db.query(models.ProtocolTemplate).filter(models.ProtocolTemplate.id == mr.template_id).first()
+    if tpl.created_by != user.id:
+        raise HTTPException(status_code=403, detail="Not authorized")
+    mr.status = "rejected"
+    db.commit()
+    db.refresh(mr)
+    return mr
diff --git a/backend/app/routes/resource_shares.py b/backend/app/routes/resource_shares.py
new file mode 100644
index 0000000000000000000000000000000000000000..b65e6abcb23f825c9498b18da0951063fa57ebe3
--- /dev/null
+++ b/backend/app/routes/resource_shares.py
@@ -0,0 +1,71 @@
+from typing import List
+from uuid import UUID
+from datetime import datetime
+
+from fastapi import APIRouter, Depends, HTTPException
+from sqlalchemy.orm import Session
+
+from ..database import get_db
+from ..auth import get_current_user
+from .. import models, schemas
+
+router = APIRouter(prefix="/api/resource-shares", tags=["resource_shares"])
+
+@router.post("", response_model=schemas.ResourceShareOut)
+def request_share(
+    data: schemas.ResourceShareCreate,
+    db: Session = Depends(get_db),
+    user = Depends(get_current_user),
+):
+    lab = db.query(models.Lab).filter_by(owner_id=user.id).first()
+    if not lab:
+        raise HTTPException(status_code=400, detail="No lab owned by user")
+    share = models.ResourceShare(
+        resource_id=data.resource_id,
+        from_lab=lab.id,
+        to_lab=data.to_lab,
+        start_date=data.start_date,
+        end_date=data.end_date,
+    )
+    db.add(share)
+    db.commit()
+    db.refresh(share)
+    return share
+
+@router.get("", response_model=List[schemas.ResourceShareOut])
+def list_shares(db: Session = Depends(get_db), user = Depends(get_current_user)):
+    labs = db.query(models.Lab).filter(models.Lab.owner_id == user.id).all()
+    lab_ids = [l.id for l in labs]
+    if not lab_ids:
+        return []
+    return (
+        db.query(models.ResourceShare)
+        .filter(models.ResourceShare.from_lab.in_(lab_ids) | models.ResourceShare.to_lab.in_(lab_ids))
+        .all()
+    )
+
+@router.post("/{share_id}/accept", response_model=schemas.ResourceShareOut)
+def accept_share(share_id: UUID, db: Session = Depends(get_db), user = Depends(get_current_user)):
+    share = db.get(models.ResourceShare, share_id)
+    if not share:
+        raise HTTPException(status_code=404)
+    lab = db.get(models.Lab, share.to_lab)
+    if not lab or lab.owner_id != user.id:
+        raise HTTPException(status_code=403)
+    share.status = "accepted"
+    db.commit()
+    db.refresh(share)
+    return share
+
+@router.post("/{share_id}/reject", response_model=schemas.ResourceShareOut)
+def reject_share(share_id: UUID, db: Session = Depends(get_db), user = Depends(get_current_user)):
+    share = db.get(models.ResourceShare, share_id)
+    if not share:
+        raise HTTPException(status_code=404)
+    lab = db.get(models.Lab, share.to_lab)
+    if not lab or lab.owner_id != user.id:
+        raise HTTPException(status_code=403)
+    share.status = "rejected"
+    db.commit()
+    db.refresh(share)
+    return share
diff --git a/backend/app/routes/schedule.py b/backend/app/routes/schedule.py
new file mode 100644
index 0000000000000000000000000000000000000000..5b09a0d31b8da2e473110c80aa93af37ba8214f4
--- /dev/null
+++ b/backend/app/routes/schedule.py
@@ -0,0 +1,120 @@
+from datetime import datetime
+from uuid import UUID
+from sqlalchemy.orm import Session
+from fastapi import APIRouter, Depends, HTTPException
+
+from ..database import get_db
+from ..auth import get_current_user
+from .. import models, schemas, notify
+
+router = APIRouter(prefix="/api/schedule", tags=["schedule"])
+
+@router.post("/resources", response_model=schemas.ResourceOut)
+async def create_resource(
+    resource: schemas.ResourceCreate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    db_res = models.Resource(**resource.model_dump(), created_by=user.id)
+    db.add(db_res)
+    db.commit()
+    db.refresh(db_res)
+    return db_res
+
+
+@router.get("/resources", response_model=list[schemas.ResourceOut])
+async def list_resources(
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    return db.query(models.Resource).all()
+
+
+@router.post("/bookings", response_model=schemas.BookingOut)
+async def create_booking(
+    booking: schemas.BookingCreate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    if booking.start_time >= booking.end_time:
+        raise HTTPException(status_code=400, detail="Invalid time range")
+    overlaps = (
+        db.query(models.Booking)
+        .filter(models.Booking.resource_id == booking.resource_id)
+        .filter(models.Booking.end_time > booking.start_time)
+        .filter(models.Booking.start_time < booking.end_time)
+        .first()
+    )
+    if overlaps:
+        raise HTTPException(status_code=400, detail="Time slot unavailable")
+    db_booking = models.Booking(**booking.model_dump(), user_id=user.id)
+    resource = (
+        db.query(models.Resource)
+        .filter(models.Resource.id == booking.resource_id)
+        .first()
+    )
+    if resource:
+        message = (
+            f"{user.email} booked {resource.name} from {booking.start_time} to {booking.end_time}"
+        )
+        # in-app notification
+        pref_in_app = (
+            db.query(models.NotificationPreference)
+            .filter_by(
+                user_id=resource.created_by,
+                pref_type="booking",
+                channel="in_app",
+            )
+            .first()
+        )
+        if not pref_in_app or pref_in_app.enabled:
+            notif = models.Notification(
+                user_id=resource.created_by,
+                message=message,
+            )
+            db.add(notif)
+
+        owner = db.query(models.User).filter_by(id=resource.created_by).first()
+        if owner:
+            # email
+            pref_email = (
+                db.query(models.NotificationPreference)
+                .filter_by(
+                    user_id=resource.created_by,
+                    pref_type="booking",
+                    channel="email",
+                )
+                .first()
+            )
+            if (not pref_email or pref_email.enabled) and owner.email:
+                notify.send_email(owner.email, "Booking notification", message)
+
+            # sms
+            pref_sms = (
+                db.query(models.NotificationPreference)
+                .filter_by(
+                    user_id=resource.created_by,
+                    pref_type="booking",
+                    channel="sms",
+                )
+                .first()
+            )
+            if (not pref_sms or pref_sms.enabled) and owner.phone_number:
+                notify.send_sms(owner.phone_number, message)
+    db.add(db_booking)
+    db.commit()
+    db.refresh(db_booking)
+    return db_booking
+
+
+@router.get("/bookings", response_model=list[schemas.BookingOut])
+async def list_bookings(
+    resource_id: UUID | None = None,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    q = db.query(models.Booking)
+    if resource_id:
+        q = q.filter(models.Booking.resource_id == resource_id)
+    return q.all()
+
diff --git a/backend/app/routes/search.py b/backend/app/routes/search.py
new file mode 100644
index 0000000000000000000000000000000000000000..9ae943eb0cb32ad2043c3acb50961c889a0f698f
--- /dev/null
+++ b/backend/app/routes/search.py
@@ -0,0 +1,22 @@
+from fastapi import APIRouter, Depends, HTTPException
+from sqlalchemy.orm import Session
+from typing import List
+
+from ..database import get_db
+from ..auth import get_current_user
+from .. import models, schemas
+from .. import search as search_utils
+
+router = APIRouter(prefix="/api/search", tags=["search"])
+
+
+@router.get("/items", response_model=List[schemas.InventoryItemOut])
+async def search_items_route(
+    q: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    if not q:
+        raise HTTPException(status_code=400, detail="Query required")
+    return search_utils.search_items(q, db)
+
diff --git a/backend/app/routes/sequence.py b/backend/app/routes/sequence.py
new file mode 100644
index 0000000000000000000000000000000000000000..3f16887bf241371fcfea8573e3e5a3b65463e5a5
--- /dev/null
+++ b/backend/app/routes/sequence.py
@@ -0,0 +1,158 @@
+from fastapi import APIRouter, Depends, UploadFile, File, Form, HTTPException
+from sqlalchemy.orm import Session
+
+from ..auth import get_current_user
+from .. import models, schemas
+from ..database import get_db
+from ..sequence import (
+    process_sequence_file,
+    align_sequences,
+    design_primers,
+    restriction_map,
+    parse_genbank_features,
+    parse_chromatogram,
+    blast_search,
+)
+from ..tasks import enqueue_analyze_sequence_job
+from uuid import UUID
+
+router = APIRouter(prefix="/api/sequence", tags=["sequence"])
+
+@router.post("/analyze", response_model=list[schemas.SequenceRead])
+async def analyze_sequence(
+    format: str = Form("fasta"),
+    upload: UploadFile = File(...),
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    data = await upload.read()
+    try:
+        return process_sequence_file(data, format)
+    except Exception:
+        raise HTTPException(status_code=400, detail="Invalid sequence file")
+
+
+@router.post("/align", response_model=schemas.SequenceAlignmentOut)
+async def align(
+    payload: schemas.SequenceAlignmentIn,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    return align_sequences(payload.seq1, payload.seq2, payload.mode)
+
+
+@router.post("/blast", response_model=schemas.BlastSearchOut)
+async def blast(
+    payload: schemas.BlastSearchIn,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    return blast_search(payload.query, payload.subject)
+
+
+@router.post("/primers", response_model=schemas.PrimerDesignOut)
+async def primers(
+    payload: schemas.PrimerDesignIn,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        return design_primers(payload.sequence, payload.size)
+    except ValueError as e:
+        raise HTTPException(status_code=400, detail=str(e))
+
+
+@router.post("/restriction", response_model=schemas.RestrictionMapOut)
+async def restriction(
+    payload: schemas.RestrictionMapIn,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        mapping = restriction_map(payload.sequence, payload.enzymes)
+        return {"map": mapping}
+    except Exception:
+        raise HTTPException(status_code=400, detail="Invalid input")
+
+
+@router.post("/annotate", response_model=list[schemas.SequenceFeature])
+async def annotate(
+    format: str = Form("genbank"),
+    upload: UploadFile = File(...),
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    data = await upload.read()
+    try:
+        if format not in {"genbank", "gb"}:
+            raise ValueError("Unsupported format")
+        return parse_genbank_features(data)
+    except Exception:
+        raise HTTPException(status_code=400, detail="Invalid annotation file")
+
+
+@router.post("/chromatogram", response_model=schemas.ChromatogramOut)
+async def chromatogram(
+    upload: UploadFile = File(...),
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    data = await upload.read()
+    try:
+        return parse_chromatogram(data)
+    except Exception:
+        raise HTTPException(status_code=400, detail="Invalid chromatogram file")
+
+
+@router.post("/jobs", response_model=schemas.SequenceJobOut)
+async def create_analysis_job(
+    format: str = Form("fasta"),
+    upload: UploadFile = File(...),
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    data = await upload.read()
+    job = models.SequenceAnalysisJob(user_id=user.id, format=format)
+    db.add(job)
+    db.commit()
+    db.refresh(job)
+    enqueue_analyze_sequence_job(str(job.id), data, format)
+    db.refresh(job)
+    return job
+
+
+@router.get("/jobs", response_model=list[schemas.SequenceJobOut])
+async def list_analysis_jobs(
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    jobs = (
+        db.query(models.SequenceAnalysisJob)
+        .filter(models.SequenceAnalysisJob.user_id == user.id)
+        .order_by(models.SequenceAnalysisJob.created_at.desc())
+        .all()
+    )
+    return jobs
+
+
+@router.get("/jobs/{job_id}", response_model=schemas.SequenceJobOut)
+async def get_analysis_job(
+    job_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        job_uuid = UUID(job_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid job id")
+    job = (
+        db.query(models.SequenceAnalysisJob)
+        .filter(
+            models.SequenceAnalysisJob.id == job_uuid,
+            models.SequenceAnalysisJob.user_id == user.id,
+        )
+        .first()
+    )
+    if not job:
+        raise HTTPException(status_code=404, detail="Job not found")
+    return job
diff --git a/backend/app/routes/services.py b/backend/app/routes/services.py
new file mode 100644
index 0000000000000000000000000000000000000000..d9e034c1c83782d5bf4e631ee63623b010dec2a1
--- /dev/null
+++ b/backend/app/routes/services.py
@@ -0,0 +1,198 @@
+from typing import List
+from uuid import UUID
+from fastapi import APIRouter, Depends, HTTPException
+from sqlalchemy.orm import Session
+
+from ..database import get_db
+from ..auth import get_current_user
+from .. import models, schemas
+from .files import MINIO_ENDPOINT, minio_client, UPLOAD_DIR, MINIO_BUCKET
+import os, io
+from uuid import uuid4
+from fastapi import UploadFile, File
+
+router = APIRouter(prefix="/api/services", tags=["services"])
+
+
+@router.post("/listings", response_model=schemas.ServiceListingOut)
+def create_service_listing(
+    data: schemas.ServiceListingCreate,
+    db: Session = Depends(get_db),
+    user=Depends(get_current_user),
+):
+    listing = models.ServiceListing(
+        provider_id=user.id,
+        name=data.name,
+        description=data.description,
+        price=data.price,
+    )
+    db.add(listing)
+    db.commit()
+    db.refresh(listing)
+    return listing
+
+
+@router.get("/listings", response_model=List[schemas.ServiceListingOut])
+def list_service_listings(db: Session = Depends(get_db)):
+    return (
+        db.query(models.ServiceListing)
+        .filter(models.ServiceListing.status == "open")
+        .all()
+    )
+
+
+@router.post(
+    "/listings/{listing_id}/requests",
+    response_model=schemas.ServiceRequestOut,
+)
+def create_service_request(
+    listing_id: UUID,
+    data: schemas.ServiceRequestCreate,
+    db: Session = Depends(get_db),
+    user=Depends(get_current_user),
+):
+    listing = db.get(models.ServiceListing, listing_id)
+    if not listing or listing.status != "open":
+        raise HTTPException(status_code=404)
+    req = models.ServiceRequest(
+        listing_id=listing_id,
+        requester_id=user.id,
+        item_id=data.item_id,
+        message=data.message,
+    )
+    db.add(req)
+    db.commit()
+    db.refresh(req)
+    return req
+
+
+@router.get(
+    "/listings/{listing_id}/requests",
+    response_model=List[schemas.ServiceRequestOut],
+)
+def list_service_requests(
+    listing_id: UUID,
+    db: Session = Depends(get_db),
+    user=Depends(get_current_user),
+):
+    listing = db.get(models.ServiceListing, listing_id)
+    if not listing or listing.provider_id != user.id:
+        raise HTTPException(status_code=403)
+    return (
+        db.query(models.ServiceRequest)
+        .filter_by(listing_id=listing_id)
+        .all()
+    )
+
+
+@router.post(
+    "/requests/{request_id}/accept",
+    response_model=schemas.ServiceRequestOut,
+)
+def accept_service_request(
+    request_id: UUID,
+    db: Session = Depends(get_db),
+    user=Depends(get_current_user),
+):
+    req = db.get(models.ServiceRequest, request_id)
+    if not req:
+        raise HTTPException(status_code=404)
+    listing = db.get(models.ServiceListing, req.listing_id)
+    if listing.provider_id != user.id:
+        raise HTTPException(status_code=403)
+    req.status = "accepted"
+    listing.status = "closed"
+    db.commit()
+    db.refresh(req)
+    return req
+
+
+@router.post(
+    "/requests/{request_id}/reject",
+    response_model=schemas.ServiceRequestOut,
+)
+def reject_service_request(
+    request_id: UUID,
+    db: Session = Depends(get_db),
+    user=Depends(get_current_user),
+):
+    req = db.get(models.ServiceRequest, request_id)
+    if not req:
+        raise HTTPException(status_code=404)
+    listing = db.get(models.ServiceListing, req.listing_id)
+    if listing.provider_id != user.id:
+        raise HTTPException(status_code=403)
+    req.status = "rejected"
+    db.commit()
+    db.refresh(req)
+    return req
+
+
+@router.post("/requests/{request_id}/deliver", response_model=schemas.ServiceRequestOut)
+async def deliver_service_result(
+    request_id: UUID,
+    upload: UploadFile = File(...),
+    db: Session = Depends(get_db),
+    user=Depends(get_current_user),
+):
+    req = db.get(models.ServiceRequest, request_id)
+    if not req:
+        raise HTTPException(status_code=404)
+    listing = db.get(models.ServiceListing, req.listing_id)
+    if listing.provider_id != user.id:
+        raise HTTPException(status_code=403)
+
+    file_id = uuid4()
+    safe_name = os.path.basename(upload.filename)
+    object_name = f"{file_id}_{safe_name}"
+    data = await upload.read()
+    if MINIO_ENDPOINT:
+        minio_client.put_object(
+            MINIO_BUCKET,
+            object_name,
+            io.BytesIO(data),
+            length=len(data),
+            content_type=upload.content_type or "application/octet-stream",
+        )
+        storage_path = f"s3://{MINIO_BUCKET}/{object_name}"
+        file_size = len(data)
+    else:
+        os.makedirs(UPLOAD_DIR, exist_ok=True)
+        save_path = os.path.join(UPLOAD_DIR, object_name)
+        with open(save_path, "wb") as f:
+            f.write(data)
+        storage_path = save_path
+        file_size = upload.size or 0
+
+    db_file = models.File(
+        id=file_id,
+        item_id=req.item_id,
+        filename=upload.filename,
+        file_type=upload.content_type or "application/octet-stream",
+        file_size=file_size,
+        storage_path=storage_path,
+        uploaded_by=user.id,
+    )
+    db.add(db_file)
+    req.result_file_id = file_id
+    req.status = "completed"
+    db.commit()
+    db.refresh(req)
+    return req
+
+
+@router.post("/requests/{request_id}/confirm-payment", response_model=schemas.ServiceRequestOut)
+def confirm_payment(
+    request_id: UUID,
+    db: Session = Depends(get_db),
+    user=Depends(get_current_user),
+):
+    req = db.get(models.ServiceRequest, request_id)
+    if not req:
+        raise HTTPException(status_code=404)
+    if req.requester_id != user.id:
+        raise HTTPException(status_code=403)
+    req.payment_status = "paid"
+    db.commit()
+    db.refresh(req)
+    return req
diff --git a/backend/app/routes/teams.py b/backend/app/routes/teams.py
new file mode 100644
index 0000000000000000000000000000000000000000..a47bbe8fcb26c3f0b49a7d5f6ca7433f629e9d15
--- /dev/null
+++ b/backend/app/routes/teams.py
@@ -0,0 +1,83 @@
+from fastapi import APIRouter, Depends, HTTPException
+from sqlalchemy.orm import Session
+from typing import List
+from uuid import UUID
+
+from ..database import get_db
+from ..auth import get_current_user
+from .. import models, schemas
+from ..rbac import check_team_role
+
+router = APIRouter(prefix="/api/teams", tags=["teams"])
+
+
+@router.post("/", response_model=schemas.TeamOut)
+async def create_team(
+    team: schemas.TeamCreate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    db_team = models.Team(name=team.name, created_by=user.id)
+    db.add(db_team)
+    db.commit()
+    db.refresh(db_team)
+    membership = models.TeamMember(team_id=db_team.id, user_id=user.id, role="owner")
+    db.add(membership)
+    db.commit()
+    return db_team
+
+
+@router.get("/", response_model=List[schemas.TeamOut])
+async def list_teams(
+    db: Session = Depends(get_db), user: models.User = Depends(get_current_user)
+):
+    team_ids = [m.team_id for m in user.teams]
+    if not team_ids:
+        return []
+    return db.query(models.Team).filter(models.Team.id.in_(team_ids)).all()
+
+
+@router.post("/{team_id}/members", response_model=schemas.TeamMemberOut)
+async def add_member(
+    team_id: str,
+    member: schemas.TeamMemberAdd,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        team_uuid = UUID(team_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid team id")
+
+    team = db.query(models.Team).filter(models.Team.id == team_uuid).first()
+    if not team:
+        raise HTTPException(status_code=404, detail="Team not found")
+    check_team_role(db, user, team_uuid, ["owner"])  # only owner or admin may add members
+    if member.user_id:
+        db_user = db.query(models.User).filter(models.User.id == member.user_id).first()
+    elif member.email:
+        db_user = (
+            db.query(models.User).filter(models.User.email == member.email).first()
+        )
+    else:
+        raise HTTPException(status_code=400, detail="user_id or email required")
+    if not db_user:
+        raise HTTPException(status_code=404, detail="User not found")
+    existing = (
+        db.query(models.TeamMember)
+        .filter(
+            models.TeamMember.team_id == team_uuid,
+            models.TeamMember.user_id == db_user.id,
+        )
+        .first()
+    )
+    if existing:
+        raise HTTPException(status_code=400, detail="User already member")
+    membership = models.TeamMember(
+        team_id=team_uuid, user_id=db_user.id, role=member.role
+    )
+    db.add(membership)
+    db.commit()
+    db.refresh(membership)
+    user_data = schemas.UserOut.model_validate(db_user)
+    return schemas.TeamMemberOut(user=user_data, role=membership.role)
diff --git a/backend/app/routes/tools.py b/backend/app/routes/tools.py
new file mode 100644
index 0000000000000000000000000000000000000000..64c51bf18052a55f425a7d8b583c3b32cfd4664d
--- /dev/null
+++ b/backend/app/routes/tools.py
@@ -0,0 +1,37 @@
+from fastapi import APIRouter, Depends, HTTPException
+from sqlalchemy.orm import Session
+from uuid import UUID
+
+from ..database import get_db
+from ..models import AnalysisTool, InventoryItem
+from ..schemas import AnalysisToolCreate, AnalysisToolOut, ToolRunIn
+from ..tools import run_tool
+from ..auth import get_current_user
+
+router = APIRouter(prefix="/api/tools", tags=["tools"])
+
+
+@router.post("", response_model=AnalysisToolOut)
+def create_tool(tool: AnalysisToolCreate, db: Session = Depends(get_db), user=Depends(get_current_user)):
+    db_tool = AnalysisTool(**tool.model_dump(), created_by=user.id)
+    db.add(db_tool)
+    db.commit()
+    db.refresh(db_tool)
+    return db_tool
+
+
+@router.get("", response_model=list[AnalysisToolOut])
+def list_tools(db: Session = Depends(get_db), user=Depends(get_current_user)):
+    return db.query(AnalysisTool).all()
+
+
+@router.post("/{tool_id}/run")
+def run_tool_endpoint(tool_id: UUID, data: ToolRunIn, db: Session = Depends(get_db), user=Depends(get_current_user)):
+    tool = db.get(AnalysisTool, tool_id)
+    if not tool:
+        raise HTTPException(status_code=404)
+    item = db.get(InventoryItem, data.item_id)
+    if not item:
+        raise HTTPException(status_code=404)
+    result = run_tool(tool.code, {"id": str(item.id), "type": item.item_type, "name": item.name, "custom_data": item.custom_data})
+    return {"result": result}
diff --git a/backend/app/routes/troubleshooting.py b/backend/app/routes/troubleshooting.py
new file mode 100644
index 0000000000000000000000000000000000000000..6b00c1d43aa6c41324f81a34fd304d0d6f4f5f92
--- /dev/null
+++ b/backend/app/routes/troubleshooting.py
@@ -0,0 +1,90 @@
+from uuid import UUID
+from fastapi import APIRouter, Depends, HTTPException
+from sqlalchemy.orm import Session
+
+from ..database import get_db
+from ..auth import get_current_user
+from .. import models, schemas
+
+router = APIRouter(prefix="/api/troubleshooting", tags=["troubleshooting"])
+
+
+@router.post("/articles", response_model=schemas.TroubleshootingArticleOut)
+async def create_article(
+    article: schemas.TroubleshootingArticleCreate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    db_article = models.TroubleshootingArticle(**article.model_dump(), created_by=user.id)
+    db.add(db_article)
+    db.commit()
+    db.refresh(db_article)
+    return db_article
+
+
+@router.get("/articles", response_model=list[schemas.TroubleshootingArticleOut])
+async def list_articles(
+    category: str | None = None,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    query = db.query(models.TroubleshootingArticle)
+    if category:
+        query = query.filter(models.TroubleshootingArticle.category == category)
+    return query.all()
+
+
+@router.get("/articles/{article_id}", response_model=schemas.TroubleshootingArticleOut)
+async def get_article(
+    article_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(article_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid article id")
+    art = db.query(models.TroubleshootingArticle).filter(models.TroubleshootingArticle.id == uid).first()
+    if not art:
+        raise HTTPException(status_code=404, detail="Article not found")
+    return art
+
+
+@router.put("/articles/{article_id}", response_model=schemas.TroubleshootingArticleOut)
+async def update_article(
+    article_id: str,
+    update: schemas.TroubleshootingArticleUpdate,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(article_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid article id")
+    art = db.query(models.TroubleshootingArticle).filter(models.TroubleshootingArticle.id == uid).first()
+    if not art:
+        raise HTTPException(status_code=404, detail="Article not found")
+    for key, value in update.model_dump(exclude_unset=True).items():
+        setattr(art, key, value)
+    db.commit()
+    db.refresh(art)
+    return art
+
+
+@router.post("/articles/{article_id}/success", response_model=schemas.TroubleshootingArticleOut)
+async def mark_success(
+    article_id: str,
+    db: Session = Depends(get_db),
+    user: models.User = Depends(get_current_user),
+):
+    try:
+        uid = UUID(article_id)
+    except ValueError:
+        raise HTTPException(status_code=400, detail="Invalid article id")
+    art = db.query(models.TroubleshootingArticle).filter(models.TroubleshootingArticle.id == uid).first()
+    if not art:
+        raise HTTPException(status_code=404, detail="Article not found")
+    art.success_count += 1
+    db.commit()
+    db.refresh(art)
+    return art
diff --git a/backend/app/routes/users.py b/backend/app/routes/users.py
new file mode 100644
index 0000000000000000000000000000000000000000..2e4625b50a05a1b94741769bde3fc5e6abbbda82
--- /dev/null
+++ b/backend/app/routes/users.py
@@ -0,0 +1,30 @@
+from fastapi import APIRouter, Depends
+from sqlalchemy.orm import Session
+
+from ..database import get_db
+from .. import models, schemas, auth
+
+router = APIRouter(prefix="/api/users", tags=["users"])
+
+
+@router.get("/me", response_model=schemas.UserOut)
+async def read_profile(current_user: models.User = Depends(auth.get_current_user)):
+    return current_user
+
+
+@router.put("/me", response_model=schemas.UserOut)
+async def update_profile(
+    update: schemas.UserUpdate,
+    db: Session = Depends(get_db),
+    current_user: models.User = Depends(auth.get_current_user),
+):
+    if update.full_name is not None:
+        current_user.full_name = update.full_name
+    if update.phone_number is not None:
+        current_user.phone_number = update.phone_number
+    if update.orcid_id is not None:
+        current_user.orcid_id = update.orcid_id
+    db.add(current_user)
+    db.commit()
+    db.refresh(current_user)
+    return current_user
diff --git a/backend/app/routes/workflows.py b/backend/app/routes/workflows.py
new file mode 100644
index 0000000000000000000000000000000000000000..75ba1301a02683b49453db2a3801afc0489aef4a
--- /dev/null
+++ b/backend/app/routes/workflows.py
@@ -0,0 +1,81 @@
+from fastapi import APIRouter, Depends, HTTPException
+from sqlalchemy.orm import Session
+from uuid import UUID
+
+from ..database import get_db
+from ..auth import get_current_user
+from .. import models, schemas, tools
+
+router = APIRouter(prefix="/api/workflows", tags=["workflows"])
+
+
+@router.post("", response_model=schemas.WorkflowOut)
+def create_workflow(wf: schemas.WorkflowCreate, db: Session = Depends(get_db), user=Depends(get_current_user)):
+    data = wf.model_dump()
+    for step in data["steps"]:
+        step["id"] = str(step["id"])
+    db_wf = models.Workflow(**data, created_by=user.id)
+    db.add(db_wf)
+    db.commit()
+    db.refresh(db_wf)
+    return db_wf
+
+
+@router.get("", response_model=list[schemas.WorkflowOut])
+def list_workflows(db: Session = Depends(get_db), user=Depends(get_current_user)):
+    return db.query(models.Workflow).all()
+
+
+@router.post("/run", response_model=schemas.WorkflowExecutionOut)
+def run_workflow(exec_in: schemas.WorkflowExecutionCreate, db: Session = Depends(get_db), user=Depends(get_current_user)):
+    wf = db.get(models.Workflow, exec_in.workflow_id)
+    if not wf:
+        raise HTTPException(status_code=404, detail="Workflow not found")
+    item = db.get(models.InventoryItem, exec_in.item_id)
+    if not item:
+        raise HTTPException(status_code=404, detail="Item not found")
+    results = []
+    context = {"item": item, "results": results}
+    for step in wf.steps:
+        cond = step.get("condition")
+        if cond:
+            try:
+                if not eval(cond, {}, context):
+                    continue
+            except Exception:
+                continue
+        if step.get("type") == "tool":
+            tool_obj = db.get(models.AnalysisTool, UUID(step["id"]))
+            if tool_obj:
+                res = tools.run_tool(tool_obj.code, {
+                    "id": str(item.id),
+                    "type": item.item_type,
+                    "name": item.name,
+                    "custom_data": item.custom_data,
+                })
+                results.append(res)
+                context["results"] = results
+        elif step.get("type") == "protocol":
+            tpl = db.get(models.ProtocolTemplate, UUID(step["id"]))
+            if tpl:
+                exec_db = models.ProtocolExecution(template_id=tpl.id, run_by=user.id, params={})
+                db.add(exec_db)
+                db.flush()
+                results.append({"execution_id": str(exec_db.id)})
+                context["results"] = results
+    wf_exec = models.WorkflowExecution(
+        workflow_id=wf.id,
+        item_id=item.id,
+        run_by=user.id,
+        status="completed",
+        result=results,
+    )
+    db.add(wf_exec)
+    db.commit()
+    db.refresh(wf_exec)
+    return wf_exec
+
+
+@router.get("/executions", response_model=list[schemas.WorkflowExecutionOut])
+def list_executions(db: Session = Depends(get_db), user=Depends(get_current_user)):
+    return db.query(models.WorkflowExecution).all()
diff --git a/backend/app/schemas.py b/backend/app/schemas.py
new file mode 100644
index 0000000000000000000000000000000000000000..05e333226cb104496683be9527af37ce4ffc58e9
--- /dev/null
+++ b/backend/app/schemas.py
@@ -0,0 +1,1085 @@
+from datetime import datetime
+from typing import Optional, Any, Dict
+from pydantic import BaseModel, EmailStr, ConfigDict
+from uuid import UUID
+
+
+class UserCreate(BaseModel):
+    email: EmailStr
+    password: str
+    full_name: Optional[str] = None
+    phone_number: Optional[str] = None
+    orcid_id: Optional[str] = None
+
+
+class UserOut(BaseModel):
+    id: UUID
+    email: EmailStr
+    full_name: Optional[str]
+    phone_number: Optional[str] = None
+    orcid_id: Optional[str] = None
+    is_admin: bool = False
+    model_config = ConfigDict(from_attributes=True)
+
+
+class UserUpdate(BaseModel):
+    full_name: Optional[str] = None
+    phone_number: Optional[str] = None
+    orcid_id: Optional[str] = None
+
+
+class Token(BaseModel):
+    access_token: str
+    token_type: str = "bearer"
+
+
+class LoginRequest(BaseModel):
+    email: EmailStr
+    password: str
+    otp_code: Optional[str] = None
+
+
+class TwoFactorEnableOut(BaseModel):
+    secret: str
+    otpauth_url: str
+
+
+class TwoFactorVerifyIn(BaseModel):
+    code: str
+
+
+class PasswordResetRequest(BaseModel):
+    email: EmailStr
+
+
+class PasswordResetConfirm(BaseModel):
+    token: str
+    new_password: str
+
+
+class TeamCreate(BaseModel):
+    name: str
+
+
+class TeamOut(BaseModel):
+    id: UUID
+    name: str
+    model_config = ConfigDict(from_attributes=True)
+
+
+class TeamMemberAdd(BaseModel):
+    user_id: Optional[UUID] = None
+    email: Optional[EmailStr] = None
+    role: str = "member"
+
+
+class TeamMemberOut(BaseModel):
+    user: UserOut
+    role: str
+    model_config = ConfigDict(from_attributes=True)
+
+
+class LocationBase(BaseModel):
+    name: str
+    parent_id: Optional[UUID] = None
+    team_id: Optional[UUID] = None
+
+
+class LocationCreate(LocationBase):
+    pass
+
+
+class LocationUpdate(BaseModel):
+    name: Optional[str] = None
+    parent_id: Optional[UUID] = None
+
+
+class LocationOut(LocationBase):
+    id: UUID
+    created_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class InventoryItemCreate(BaseModel):
+    item_type: str
+    name: str
+    barcode: Optional[str] = None
+    team_id: Optional[UUID] = None
+    owner_id: Optional[UUID] = None
+    location_id: Optional[UUID] = None
+    location: Dict[str, Any] = {}
+    status: Optional[str] = None
+    custom_data: Dict[str, Any] = {}
+
+
+class InventoryItemUpdate(BaseModel):
+    item_type: Optional[str] = None
+    name: Optional[str] = None
+    barcode: Optional[str] = None
+    team_id: Optional[UUID] = None
+    owner_id: Optional[UUID] = None
+    location_id: Optional[UUID] = None
+    location: Optional[Dict[str, Any]] = None
+    status: Optional[str] = None
+    custom_data: Optional[Dict[str, Any]] = None
+
+
+class InventoryItemOut(BaseModel):
+    id: UUID
+    item_type: str
+    name: str
+    barcode: Optional[str]
+    team_id: Optional[UUID]
+    owner_id: Optional[UUID]
+    location_id: Optional[UUID]
+    location: Dict[str, Any]
+    status: str
+    custom_data: Dict[str, Any]
+    created_at: datetime
+    updated_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class FieldDefinitionCreate(BaseModel):
+    entity_type: str
+    field_key: str
+    field_label: str
+    field_type: str
+    is_required: bool = False
+    options: Optional[list[Dict[str, Any]]] = None
+    validation: Optional[Dict[str, Any]] = None
+
+
+class FieldDefinitionOut(FieldDefinitionCreate):
+    id: UUID
+    model_config = ConfigDict(from_attributes=True)
+
+
+class ItemRelationshipCreate(BaseModel):
+    from_item: UUID
+    to_item: UUID
+    relationship_type: str
+    meta: Dict[str, Any] = {}
+
+
+class ItemRelationshipOut(ItemRelationshipCreate):
+    id: UUID
+    model_config = ConfigDict(from_attributes=True)
+
+
+class FileUpload(BaseModel):
+    filename: str
+    file_type: str
+    file_size: int
+    item_id: UUID
+    meta: Dict[str, Any] = {}
+
+
+class FileOut(FileUpload):
+    id: UUID
+    storage_path: str
+    uploaded_by: UUID
+    created_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class ItemGraphOut(BaseModel):
+    nodes: list[InventoryItemOut]
+    edges: list[ItemRelationshipOut]
+
+
+class FacetCount(BaseModel):
+    key: str
+    count: int
+
+
+class InventoryFacets(BaseModel):
+    item_types: list[FacetCount]
+    statuses: list[FacetCount]
+    teams: list[FacetCount]
+    fields: list[FieldDefinitionOut]
+
+
+class ProtocolTemplateCreate(BaseModel):
+    name: str
+    content: str
+    variables: list[str] = []
+    is_public: bool = False
+    forked_from: Optional[UUID] = None
+    team_id: Optional[UUID] = None
+
+
+class ProtocolTemplateUpdate(BaseModel):
+    name: Optional[str] = None
+    content: Optional[str] = None
+    variables: Optional[list[str]] = None
+    is_public: Optional[bool] = None
+    forked_from: Optional[UUID] = None
+    team_id: Optional[UUID] = None
+
+
+class ProtocolTemplateOut(ProtocolTemplateCreate):
+    id: UUID
+    version: str
+    created_by: Optional[UUID] = None
+    created_at: datetime
+    updated_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class ProtocolExecutionCreate(BaseModel):
+    template_id: UUID
+    params: Dict[str, Any] = {}
+
+
+class ProtocolExecutionUpdate(BaseModel):
+    status: Optional[str] = None
+    result: Optional[Dict[str, Any]] = None
+
+
+class ProtocolExecutionOut(BaseModel):
+    id: UUID
+    template_id: UUID
+    run_by: Optional[UUID] = None
+    status: str
+    params: Dict[str, Any]
+    result: Dict[str, Any]
+    created_at: datetime
+    updated_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class ProtocolMergeRequestCreate(BaseModel):
+    template_id: UUID
+    content: str
+    variables: list[str] = []
+
+
+class ProtocolMergeRequestUpdate(BaseModel):
+    status: Optional[str] = None
+
+
+class ProtocolMergeRequestOut(BaseModel):
+    id: UUID
+    template_id: UUID
+    proposer_id: Optional[UUID] = None
+    content: str
+    variables: list[str]
+    status: str
+    created_at: datetime
+    updated_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class TroubleshootingArticleCreate(BaseModel):
+    title: str
+    category: str
+    content: str
+
+
+class TroubleshootingArticleUpdate(BaseModel):
+    title: Optional[str] = None
+    category: Optional[str] = None
+    content: Optional[str] = None
+
+
+class TroubleshootingArticleOut(BaseModel):
+    id: UUID
+    title: str
+    category: str
+    content: str
+    created_by: Optional[UUID] = None
+    success_count: int
+    created_at: datetime
+    updated_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class NotebookEntryCreate(BaseModel):
+    title: str
+    content: str
+    item_id: Optional[UUID] = None
+    execution_id: Optional[UUID] = None
+    project_id: Optional[UUID] = None
+    items: list[UUID] = []
+    protocols: list[UUID] = []
+    images: list[UUID] = []
+    blocks: list[dict] = []
+
+
+class NotebookEntryUpdate(BaseModel):
+    title: Optional[str] = None
+    content: Optional[str] = None
+    item_id: Optional[UUID] = None
+    execution_id: Optional[UUID] = None
+    project_id: Optional[UUID] = None
+    items: Optional[list[UUID]] = None
+    protocols: Optional[list[UUID]] = None
+    images: Optional[list[UUID]] = None
+    blocks: Optional[list[dict]] = None
+
+
+class NotebookEntryOut(BaseModel):
+    id: UUID
+    title: str
+    content: str
+    item_id: Optional[UUID] = None
+    execution_id: Optional[UUID] = None
+    project_id: Optional[UUID] = None
+    items: list[UUID] = []
+    protocols: list[UUID] = []
+    images: list[UUID] = []
+    blocks: list[dict] = []
+    created_by: Optional[UUID] = None
+    created_at: datetime
+    updated_at: datetime
+    is_locked: bool
+    signed_by: Optional[UUID] = None
+    signed_at: Optional[datetime] = None
+    witness_id: Optional[UUID] = None
+    witnessed_at: Optional[datetime] = None
+    model_config = ConfigDict(from_attributes=True)
+
+
+class NotebookEntryVersionOut(BaseModel):
+    id: UUID
+    entry_id: UUID
+    title: str
+    content: str
+    blocks: list[dict] = []
+    created_by: Optional[UUID] = None
+    created_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class CommentBase(BaseModel):
+    content: str
+    item_id: Optional[UUID] = None
+    entry_id: Optional[UUID] = None
+    knowledge_article_id: Optional[UUID] = None
+
+
+class CommentCreate(CommentBase):
+    pass
+
+
+class CommentUpdate(BaseModel):
+    content: Optional[str] = None
+
+
+class CommentOut(CommentBase):
+    id: UUID
+    created_by: Optional[UUID] = None
+    created_at: datetime
+    updated_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class ResourceCreate(BaseModel):
+    name: str
+    description: Optional[str] = None
+    team_id: Optional[UUID] = None
+
+
+class ResourceUpdate(BaseModel):
+    name: Optional[str] = None
+    description: Optional[str] = None
+    team_id: Optional[UUID] = None
+
+
+class ResourceOut(BaseModel):
+    id: UUID
+    name: str
+    description: Optional[str] = None
+    team_id: Optional[UUID] = None
+    created_by: Optional[UUID] = None
+    created_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class BookingCreate(BaseModel):
+    resource_id: UUID
+    start_time: datetime
+    end_time: datetime
+    notes: Optional[str] = None
+
+
+class BookingUpdate(BaseModel):
+    start_time: Optional[datetime] = None
+    end_time: Optional[datetime] = None
+    notes: Optional[str] = None
+
+
+class BookingOut(BaseModel):
+    id: UUID
+    resource_id: UUID
+    user_id: UUID
+    start_time: datetime
+    end_time: datetime
+    notes: Optional[str] = None
+    created_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class NotificationCreate(BaseModel):
+    user_id: UUID
+    message: str
+
+
+class NotificationOut(BaseModel):
+    id: UUID
+    user_id: UUID
+    message: str
+    is_read: bool
+    created_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+class NotificationPreferenceUpdate(BaseModel):
+    enabled: bool
+
+
+class NotificationPreferenceOut(BaseModel):
+    id: UUID
+    user_id: UUID
+    pref_type: str
+    channel: str
+    enabled: bool
+    model_config = ConfigDict(from_attributes=True)
+
+
+class SequenceRead(BaseModel):
+    id: str
+    seq: str
+    length: int
+    gc_content: float
+
+
+class SequenceJobOut(BaseModel):
+    id: UUID
+    status: str
+    format: str
+    result: list[SequenceRead] | None = None
+    created_at: datetime
+    updated_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class SequenceAlignmentIn(BaseModel):
+    seq1: str
+    seq2: str
+    mode: str = "global"
+
+class SequenceAlignmentOut(BaseModel):
+    aligned_seq1: str
+    aligned_seq2: str
+    score: float
+
+
+class RestrictionMapIn(BaseModel):
+    sequence: str
+    enzymes: list[str]
+
+
+class RestrictionMapOut(BaseModel):
+    map: dict[str, list[int]]
+
+
+class PrimerDesignIn(BaseModel):
+    sequence: str
+    size: int = 20
+
+
+class PrimerInfo(BaseModel):
+    sequence: str
+    gc_content: float
+    tm: float
+
+
+class PrimerDesignOut(BaseModel):
+    forward: PrimerInfo
+    reverse: PrimerInfo
+
+
+class SequenceFeature(BaseModel):
+    record_id: str
+    type: str
+    start: int
+    end: int
+    strand: int | None
+    qualifiers: Dict[str, list[str]]
+
+
+class ChromatogramOut(BaseModel):
+    sequence: str
+    traces: Dict[str, list[int]]
+
+
+class BlastSearchIn(BaseModel):
+    query: str
+    subject: str
+    mode: str = "blastn"
+
+
+class BlastSearchOut(BaseModel):
+    query_aligned: str
+    subject_aligned: str
+    score: float
+    identity: float
+
+
+class ProjectCreate(BaseModel):
+    name: str
+    description: Optional[str] = None
+    start_date: Optional[datetime] = None
+    end_date: Optional[datetime] = None
+    team_id: Optional[UUID] = None
+
+
+class ProjectUpdate(BaseModel):
+    name: Optional[str] = None
+    description: Optional[str] = None
+    start_date: Optional[datetime] = None
+    end_date: Optional[datetime] = None
+    team_id: Optional[UUID] = None
+
+
+class ProjectOut(ProjectCreate):
+    id: UUID
+    created_by: Optional[UUID] = None
+    created_at: datetime
+    updated_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class ProjectTaskCreate(BaseModel):
+    name: str
+    description: Optional[str] = None
+    due_date: Optional[datetime] = None
+
+
+class ProjectTaskUpdate(BaseModel):
+    name: Optional[str] = None
+    description: Optional[str] = None
+    due_date: Optional[datetime] = None
+    status: Optional[str] = None
+
+
+class ProjectTaskOut(ProjectTaskCreate):
+    id: UUID
+    status: str
+    created_by: Optional[UUID] = None
+    created_at: datetime
+    updated_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class CalendarEventCreate(BaseModel):
+    title: str
+    start_time: datetime
+    end_time: datetime
+    description: Optional[str] = None
+    team_id: Optional[UUID] = None
+    user_id: Optional[UUID] = None
+
+
+class CalendarEventOut(CalendarEventCreate):
+    id: UUID
+    created_by: Optional[UUID] = None
+    created_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class CalendarEventUpdate(BaseModel):
+    title: Optional[str] = None
+    start_time: Optional[datetime] = None
+    end_time: Optional[datetime] = None
+    description: Optional[str] = None
+    team_id: Optional[UUID] = None
+    user_id: Optional[UUID] = None
+
+
+class AnalysisToolCreate(BaseModel):
+    name: str
+    description: Optional[str] = None
+    code: str
+    supported_types: list[str] = []
+
+
+class AnalysisToolOut(AnalysisToolCreate):
+    id: UUID
+    created_by: Optional[UUID] = None
+    created_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class ToolRunIn(BaseModel):
+    item_id: UUID
+
+
+class AssistantMessageOut(BaseModel):
+    id: UUID
+    is_user: bool
+    message: str
+    created_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class AuditLogOut(BaseModel):
+    id: UUID
+    user_id: UUID
+    action: str
+    target_type: str | None = None
+    target_id: UUID | None = None
+    details: Dict[str, Any] = {}
+    created_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class AuditReportItem(BaseModel):
+    action: str
+    count: int
+
+
+class EquipmentCreate(BaseModel):
+    name: str
+    eq_type: str
+    connection_info: Dict[str, Any] = {}
+    team_id: UUID | None = None
+
+
+class EquipmentUpdate(BaseModel):
+    name: str | None = None
+    eq_type: str | None = None
+    connection_info: Dict[str, Any] | None = None
+    status: str | None = None
+    team_id: UUID | None = None
+
+
+class EquipmentOut(BaseModel):
+    id: UUID
+    name: str
+    eq_type: str
+    connection_info: Dict[str, Any]
+    status: str
+    team_id: UUID | None = None
+    created_by: UUID | None = None
+    created_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class EquipmentReadingCreate(BaseModel):
+    data: Dict[str, Any]
+
+
+class EquipmentReadingOut(EquipmentReadingCreate):
+    id: UUID
+    timestamp: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class EquipmentMaintenanceCreate(BaseModel):
+    equipment_id: UUID
+    due_date: datetime
+    task_type: str = "maintenance"
+    description: str | None = None
+
+
+class EquipmentMaintenanceOut(EquipmentMaintenanceCreate):
+    id: UUID
+    completed_at: datetime | None = None
+    created_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class SOPCreate(BaseModel):
+    title: str
+    version: int = 1
+    content: str
+    team_id: UUID | None = None
+
+
+class SOPOut(SOPCreate):
+    id: UUID
+    created_by: UUID | None = None
+    created_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class TrainingRecordCreate(BaseModel):
+    user_id: UUID
+    sop_id: UUID
+    equipment_id: UUID
+    trained_by: UUID
+
+
+class TrainingRecordOut(TrainingRecordCreate):
+    id: UUID
+    trained_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class AssistantQuestion(BaseModel):
+    question: str
+
+
+class InventoryForecastItem(BaseModel):
+    item_id: UUID
+    name: str
+    projected_days: float | None = None
+
+
+class MaterialSuggestion(BaseModel):
+    id: UUID
+    name: str
+
+
+class ProtocolSuggestion(BaseModel):
+    protocol_id: UUID
+    protocol_name: str
+    materials: list[MaterialSuggestion]
+
+
+
+class ItemTypeCount(BaseModel):
+    item_type: str
+    count: int
+
+    model_config = ConfigDict(from_attributes=True)
+
+
+class TrendingProtocol(BaseModel):
+    template_id: UUID
+    template_name: str
+    count: int
+
+    model_config = ConfigDict(from_attributes=True)
+
+
+class TrendingArticle(BaseModel):
+    article_id: UUID
+    title: str
+    count: int
+
+    model_config = ConfigDict(from_attributes=True)
+
+
+class TrendingItem(BaseModel):
+    item_id: UUID
+    name: str
+    count: int
+
+    model_config = ConfigDict(from_attributes=True)
+
+
+class TrendingThread(BaseModel):
+    thread_id: UUID
+    title: str
+    count: int
+
+    model_config = ConfigDict(from_attributes=True)
+
+
+class TrendingPost(BaseModel):
+    post_id: UUID
+    content: str
+    count: int
+
+    model_config = ConfigDict(from_attributes=True)
+
+
+class PubMedQuery(BaseModel):
+    query: str
+    limit: int = 5
+
+
+class PubMedArticle(BaseModel):
+    id: str
+    title: str
+
+
+class ComplianceRecordCreate(BaseModel):
+    item_id: UUID | None = None
+    record_type: str
+    status: str = "pending"
+    notes: str | None = None
+
+
+class ComplianceRecordUpdate(BaseModel):
+    status: str | None = None
+    notes: str | None = None
+
+
+class ComplianceRecordOut(BaseModel):
+    id: UUID
+    item_id: UUID | None = None
+    user_id: UUID | None = None
+    record_type: str
+    status: str
+    notes: str | None = None
+    created_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class KnowledgeArticleCreate(BaseModel):
+    title: str
+    content: str
+    tags: list[str] | None = None
+    is_public: bool = False
+
+
+class KnowledgeArticleUpdate(BaseModel):
+    title: str | None = None
+    content: str | None = None
+    tags: list[str] | None = None
+    is_public: bool | None = None
+
+
+class KnowledgeArticleOut(BaseModel):
+    id: UUID
+    title: str
+    content: str
+    tags: list[str] | None = None
+    is_public: bool = False
+    created_by: UUID | None = None
+    created_at: datetime
+    updated_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class ExperimentDesignOut(BaseModel):
+    protocol: ProtocolSuggestion | None = None
+    articles: list[KnowledgeArticleOut] = []
+    message: str
+
+
+class WorkflowStep(BaseModel):
+    type: str
+    id: UUID
+    condition: str | None = None
+
+
+class WorkflowCreate(BaseModel):
+    name: str
+    description: str | None = None
+    steps: list[WorkflowStep]
+
+
+class WorkflowOut(WorkflowCreate):
+    id: UUID
+    created_by: UUID | None = None
+    created_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class WorkflowExecutionCreate(BaseModel):
+    workflow_id: UUID
+    item_id: UUID
+
+
+class WorkflowExecutionUpdate(BaseModel):
+    status: str | None = None
+    result: list[Any] | None = None
+
+
+class WorkflowExecutionOut(BaseModel):
+    id: UUID
+    workflow_id: UUID
+    item_id: UUID
+    run_by: UUID | None = None
+    status: str
+    result: list[Any]
+    created_at: datetime
+    updated_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class LabCreate(BaseModel):
+    name: str
+    description: str | None = None
+
+
+class LabOut(LabCreate):
+    id: UUID
+    owner_id: UUID | None = None
+    created_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class LabConnectionCreate(BaseModel):
+    target_lab: UUID
+
+
+class LabConnectionOut(BaseModel):
+    id: UUID
+    from_lab: UUID
+    to_lab: UUID
+    status: str
+    created_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class ResourceShareCreate(BaseModel):
+    resource_id: UUID
+    to_lab: UUID
+    start_date: datetime | None = None
+    end_date: datetime | None = None
+
+
+class ResourceShareOut(BaseModel):
+    id: UUID
+    resource_id: UUID
+    from_lab: UUID
+    to_lab: UUID
+    status: str
+    start_date: datetime | None = None
+    end_date: datetime | None = None
+    created_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class MarketplaceListingCreate(BaseModel):
+    item_id: UUID
+    price: int | None = None
+    description: str | None = None
+
+
+class MarketplaceListingOut(BaseModel):
+    id: UUID
+    item_id: UUID
+    seller_id: UUID
+    price: int | None = None
+    description: str | None = None
+    status: str
+    created_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class MarketplaceRequestCreate(BaseModel):
+    message: str | None = None
+
+
+class MarketplaceRequestOut(BaseModel):
+    id: UUID
+    listing_id: UUID
+    buyer_id: UUID
+    message: str | None = None
+    status: str
+    created_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class PostCreate(BaseModel):
+    content: str
+
+
+class PostOut(BaseModel):
+    id: UUID
+    user_id: UUID
+    content: str
+    created_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class FollowOut(BaseModel):
+    follower_id: UUID
+    followed_id: UUID
+    created_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class PostReportCreate(BaseModel):
+    reason: str
+
+
+class PostReportOut(BaseModel):
+    id: UUID
+    post_id: UUID
+    reporter_id: UUID
+    reason: str
+    status: str
+    created_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class PostLikeOut(BaseModel):
+    post_id: UUID
+    user_id: UUID
+    created_at: datetime
+
+    model_config = ConfigDict(from_attributes=True)
+
+
+class ProtocolStarOut(BaseModel):
+    protocol_id: UUID
+    user_id: UUID
+    created_at: datetime
+
+    model_config = ConfigDict(from_attributes=True)
+
+
+class KnowledgeArticleStarOut(BaseModel):
+    article_id: UUID
+    user_id: UUID
+    created_at: datetime
+
+    model_config = ConfigDict(from_attributes=True)
+
+
+class ForumThreadCreate(BaseModel):
+    title: str
+
+
+class ForumThreadOut(BaseModel):
+    id: UUID
+    title: str
+    created_by: UUID | None = None
+    created_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class ForumPostCreate(BaseModel):
+    content: str
+
+
+class ForumPostOut(BaseModel):
+    id: UUID
+    thread_id: UUID
+    user_id: UUID | None = None
+    content: str
+    created_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class ServiceListingCreate(BaseModel):
+    name: str
+    description: str | None = None
+    price: int | None = None
+
+
+class ServiceListingOut(BaseModel):
+    id: UUID
+    provider_id: UUID
+    name: str
+    description: str | None = None
+    price: int | None = None
+    status: str
+    created_at: datetime
+    model_config = ConfigDict(from_attributes=True)
+
+
+class ServiceRequestCreate(BaseModel):
+    item_id: UUID | None = None
+    message: str | None = None
+
+
+class ServiceRequestOut(BaseModel):
+    id: UUID
+    listing_id: UUID
+    requester_id: UUID
+    item_id: UUID | None = None
+    message: str | None = None
+    result_file_id: UUID | None = None
+    payment_status: str | None = None
+    status: str
+    created_at: datetime
+    model_config = ConfigDict(from_attributes=True)
diff --git a/backend/app/search.py b/backend/app/search.py
new file mode 100644
index 0000000000000000000000000000000000000000..b9a8f89c4618f47c802da37eafe63bec9bc60e98
--- /dev/null
+++ b/backend/app/search.py
@@ -0,0 +1,54 @@
+from typing import List, Optional
+from elasticsearch import Elasticsearch
+from elasticsearch.helpers import bulk
+import os
+
+from .models import InventoryItem
+
+ES_URL = os.environ.get("ELASTICSEARCH_URL")
+_es_client: Optional[Elasticsearch] = None
+
+if ES_URL:
+    _es_client = Elasticsearch(ES_URL)
+
+INDEX_NAME = "inventory_items"
+
+
+def index_item(item: InventoryItem):
+    if not _es_client:
+        return
+    doc = {
+        "id": str(item.id),
+        "name": item.name,
+        "item_type": item.item_type,
+        "custom_data": item.custom_data,
+        "status": item.status,
+    }
+    _es_client.index(index=INDEX_NAME, id=str(item.id), document=doc)
+
+
+def delete_item(item_id: str):
+    if not _es_client:
+        return
+    _es_client.delete(index=INDEX_NAME, id=item_id, ignore=[404])
+
+
+def search_items(query: str, db_session) -> List[InventoryItem]:
+    if _es_client:
+        res = _es_client.search(
+            index=INDEX_NAME,
+            query={
+                "multi_match": {
+                    "query": query,
+                    "fields": ["name", "item_type", "custom_data", "status"],
+                }
+            },
+        )
+        ids = [hit["_id"] for hit in res["hits"]["hits"]]
+        if not ids:
+            return []
+        return db_session.query(InventoryItem).filter(InventoryItem.id.in_(ids)).all()
+    else:
+        # fallback simple LIKE search
+        return db_session.query(InventoryItem).filter(InventoryItem.name.ilike(f"%{query}%")).all()
+
diff --git a/backend/app/sequence.py b/backend/app/sequence.py
new file mode 100644
index 0000000000000000000000000000000000000000..221cd371a1cccc2a274297af8891906ed51fa424
--- /dev/null
+++ b/backend/app/sequence.py
@@ -0,0 +1,110 @@
+from Bio import SeqIO
+import io
+
+def process_sequence_file(file_content: bytes, fmt: str):
+    with io.StringIO(file_content.decode()) as handle:
+        records = list(SeqIO.parse(handle, fmt))
+    result = []
+    for r in records:
+        seq_str = str(r.seq)
+        length = len(seq_str)
+        gc = 0
+        if length:
+            gc = (seq_str.count("G") + seq_str.count("C")) / length * 100
+        result.append({
+            "id": r.id,
+            "seq": seq_str,
+            "length": length,
+            "gc_content": gc,
+        })
+    return result
+
+from Bio import pairwise2
+from Bio.Seq import Seq
+from Bio.SeqUtils import MeltingTemp as mt
+from Bio.Restriction import RestrictionBatch
+
+def align_sequences(seq1: str, seq2: str, mode: str = "global"):
+    if mode == "local":
+        alignments = pairwise2.align.localms(seq1, seq2, 2, -1, -0.5, -0.1, one_alignment_only=True)
+    else:
+        alignments = pairwise2.align.globalms(seq1, seq2, 2, -1, -0.5, -0.1, one_alignment_only=True)
+    if not alignments:
+        return {"aligned_seq1": "", "aligned_seq2": "", "score": 0}
+    a = alignments[0]
+    return {"aligned_seq1": a.seqA, "aligned_seq2": a.seqB, "score": a.score}
+
+
+def design_primers(sequence: str, size: int = 20):
+    if len(sequence) < size * 2:
+        raise ValueError("Sequence too short for primer design")
+    fwd = sequence[:size]
+    rev = str(Seq(sequence[-size:]).reverse_complement())
+    def stats(seq: str):
+        length = len(seq)
+        gc = 0.0
+        if length:
+            gc = (seq.count("G") + seq.count("C")) / length * 100
+        tm = mt.Tm_Wallace(seq)
+        return {"sequence": seq, "gc_content": gc, "tm": tm}
+    return {"forward": stats(fwd), "reverse": stats(rev)}
+
+
+def restriction_map(sequence: str, enzymes: list[str]):
+    rb = RestrictionBatch(enzymes)
+    sites = rb.search(Seq(sequence))
+    # convert sets/lists to sorted lists for JSON serialization
+    return {enz.__name__: sorted(pos) for enz, pos in sites.items()}
+
+
+def parse_genbank_features(file_content: bytes):
+    """Parse GenBank file and return basic feature annotations."""
+    records = SeqIO.parse(io.StringIO(file_content.decode()), "genbank")
+    features = []
+    for record in records:
+        for f in record.features:
+            features.append(
+                {
+                    "record_id": record.id,
+                    "type": f.type,
+                    "start": int(f.location.start),
+                    "end": int(f.location.end),
+                    "strand": f.location.strand,
+                    "qualifiers": {k: list(v) for k, v in f.qualifiers.items()},
+                }
+            )
+    return features
+
+
+def parse_chromatogram(file_content: bytes):
+    """Parse ABI/AB1 chromatogram file and return sequence and trace data."""
+    record = SeqIO.read(io.BytesIO(file_content), "abi")
+    abif = record.annotations.get("abif_raw", {})
+    traces = {
+        "A": list(abif.get("DATA9", [])),
+        "C": list(abif.get("DATA10", [])),
+        "G": list(abif.get("DATA11", [])),
+        "T": list(abif.get("DATA12", [])),
+    }
+    return {"sequence": str(record.seq), "traces": traces}
+
+
+def blast_search(query: str, subject: str):
+    """Perform a simple local BLAST-like search using Smith-Waterman."""
+    alignments = pairwise2.align.localms(
+        query, subject, 2, -1, -0.5, -0.1, one_alignment_only=True
+    )
+    if not alignments:
+        return {"query_aligned": "", "subject_aligned": "", "score": 0, "identity": 0}
+    aln = alignments[0]
+    matches = sum(
+        1 for a, b in zip(aln.seqA, aln.seqB) if a == b and a != "-" and b != "-"
+    )
+    length = sum(1 for a, b in zip(aln.seqA, aln.seqB) if a != "-" and b != "-")
+    identity = (matches / length * 100) if length else 0
+    return {
+        "query_aligned": aln.seqA,
+        "subject_aligned": aln.seqB,
+        "score": aln.score,
+        "identity": identity,
+    }
diff --git a/backend/app/tasks.py b/backend/app/tasks.py
new file mode 100644
index 0000000000000000000000000000000000000000..8141d82d9279fe6985b8093fc277a3c206d0abe1
--- /dev/null
+++ b/backend/app/tasks.py
@@ -0,0 +1,117 @@
+import os
+import datetime
+from datetime import timezone
+from celery import Celery
+from celery.schedules import crontab
+from .database import SessionLocal
+from uuid import UUID
+from .sequence import process_sequence_file
+from . import models
+
+CELERY_BROKER_URL = os.getenv("CELERY_BROKER_URL", "memory://")
+celery_app = Celery("tasks", broker=CELERY_BROKER_URL)
+celery_app.conf.task_always_eager = (
+    CELERY_BROKER_URL == "memory://" or os.getenv("TESTING") == "1"
+)
+
+@celery_app.task
+def analyze_sequence_job(job_id: str, data: bytes, fmt: str):
+    db = SessionLocal()
+    job = db.get(models.SequenceAnalysisJob, UUID(job_id))
+    if not job:
+        db.close()
+        return
+    try:
+        result = process_sequence_file(data, fmt)
+        job.result = result
+        job.status = "completed"
+    except Exception:
+        job.status = "failed"
+        job.result = []
+    db.commit()
+    db.close()
+
+
+def enqueue_analyze_sequence_job(job_id: str, data: bytes, fmt: str):
+    if celery_app.conf.task_always_eager:
+        analyze_sequence_job(job_id, data, fmt)
+    else:
+        analyze_sequence_job.delay(job_id, data, fmt)
+
+
+celery_app.conf.beat_schedule = {
+    "daily-backup": {
+        "task": "app.tasks.backup_database",
+        "schedule": crontab(hour=0, minute=0),
+    },
+    "inventory-warning": {
+        "task": "app.tasks.check_inventory_levels",
+        "schedule": crontab(hour=7, minute=0),
+    },
+}
+
+
+@celery_app.task
+def backup_database():
+    dest = os.getenv("BACKUP_DIR", "/tmp/backups")
+    os.makedirs(dest, exist_ok=True)
+    fname = os.path.join(
+        dest,
+        f"backup_{datetime.datetime.now(timezone.utc).strftime('%Y%m%d%H%M%S')}" + ".txt",
+    )
+    with open(fname, "w") as f:
+        f.write("backup")
+    return fname
+
+
+@celery_app.task
+def check_inventory_levels():
+    from .assistant import inventory_forecast
+    from . import notify
+
+    db = SessionLocal()
+    threshold = int(os.getenv("INVENTORY_WARNING_DAYS", "7"))
+    since = datetime.datetime.now(timezone.utc) - datetime.timedelta(days=1)
+    users = db.query(models.User).all()
+    for user in users:
+        forecasts = inventory_forecast(user, db)
+        for f in forecasts:
+            days = f.get("projected_days")
+            if days is None or days > threshold:
+                continue
+            msg = f"{f['name']} may run out in {int(days)} days"
+            exists = (
+                db.query(models.Notification)
+                .filter(
+                    models.Notification.user_id == user.id,
+                    models.Notification.message == msg,
+                    models.Notification.created_at > since,
+                )
+                .first()
+            )
+            if exists:
+                continue
+            pref = (
+                db.query(models.NotificationPreference)
+                .filter_by(
+                    user_id=user.id,
+                    pref_type="inventory_alert",
+                    channel="in_app",
+                )
+                .first()
+            )
+            if not pref or pref.enabled:
+                db.add(models.Notification(user_id=user.id, message=msg))
+            pref_email = (
+                db.query(models.NotificationPreference)
+                .filter_by(
+                    user_id=user.id,
+                    pref_type="inventory_alert",
+                    channel="email",
+                )
+                .first()
+            )
+            if (not pref_email or pref_email.enabled) and user.email:
+                notify.send_email(user.email, "Inventory Alert", msg)
+    db.commit()
+    db.close()
diff --git a/backend/app/tests/__init__.py b/backend/app/tests/__init__.py
new file mode 100644
index 0000000000000000000000000000000000000000..e69de29bb2d1d6434b8b29ae775ad8c2e48c5391
diff --git a/backend/app/tests/conftest.py b/backend/app/tests/conftest.py
new file mode 100644
index 0000000000000000000000000000000000000000..1bf8628bbb33d4192b754b6a30ada4cf0961a0b6
--- /dev/null
+++ b/backend/app/tests/conftest.py
@@ -0,0 +1,48 @@
+import os
+os.environ["TESTING"] = "1"
+os.environ.setdefault("SECRET_KEY", "test-secret")
+import pytest
+from fastapi.testclient import TestClient
+from sqlalchemy import create_engine
+from sqlalchemy.orm import sessionmaker
+
+import sys
+from pathlib import Path
+import shutil
+
+import tempfile
+
+sys.path.append(str(Path(__file__).resolve().parents[2]))
+
+from app.main import app
+from app.database import Base, get_db
+
+SQLALCHEMY_DATABASE_URL = "sqlite:///./test.db"
+engine = create_engine(SQLALCHEMY_DATABASE_URL, connect_args={"check_same_thread": False})
+TestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
+
+Base.metadata.drop_all(bind=engine)
+Base.metadata.create_all(bind=engine)
+
+def override_get_db():
+    db = TestingSessionLocal()
+    try:
+        yield db
+    finally:
+        db.close()
+
+app.dependency_overrides[get_db] = override_get_db
+
+
+@pytest.fixture(autouse=True)
+def upload_dir(tmp_path):
+    d = tmp_path / "uploads"
+    d.mkdir()
+    os.environ["UPLOAD_DIR"] = str(d)
+    yield
+    shutil.rmtree(d, ignore_errors=True)
+
+@pytest.fixture
+def client():
+    with TestClient(app) as c:
+        yield c
diff --git a/backend/app/tests/data/sample.ab1.gz b/backend/app/tests/data/sample.ab1.gz
new file mode 100644
index 0000000000000000000000000000000000000000..f2c81f65480fff2f8bfc93c7f72509dbcb707cd3
GIT binary patch
literal 88965
zcmV(sK<&RDiwFpFOl4>Q12Zu&E@5IZ0POt-loeI*?~9+)VTLs1oO8}O=bUrSIisLp
zMlqnGf*>LY22>0nC<ai;N;07$Ip+)m3^M~m_<!ru4ZnNu|K0T7z3Z*@);+ztPxtN}
zYS*q^RlD}?+Kn2wY91N($k0&}Baukdy%))=|A!-y^pS|$ZBFEW`_F4ysZ#T}MvYq)
z?AW<gmv#lKRH~T&KYJ?JWWw07!-hOEYQp$}RmxW?UolAMtg&mhF2f!!*s(*$>IF+y
zDmbofse;YQj~iOm?>cDQ#6f9V4w^J+(D<^g#t+KWw5xKmcuzKN`gHkm69#+D@AZnL
zi@0}Ycn{zE;NInXEAI~Qy4)KODH_Rmw~1Fiqh;KzVCCu+D^;vme%vFErCXTq`0^RE
zKbiOTf805q<LZow-qXLs={ZrIshwCSMo+QCusG4^J;kzTUol)KqWAVL#&Iom^sd6~
z&f%S}BckU!r1gmDC@hsuFPf-ptU_X)bmS1DaF5b_{-fN*=o+j0^tz@ZP7I-T7lg#{
z-U;Cd;C9Ht&U{WzCzF%KiF4BEus3Nr(x}w?`J|$Z)H-~f>4=$DDf}@17)nZ`YkFN{
z!dj#yRgf~4+C{*YM?HMylPV048deNCFdP9J4mGv-slyt(VLoYf=Yy9hHHr;e!ZTb8
zmmb%s+Tt#dM99qtn||0*QKd*lOSxhG5mE-&j8T}u5Q*N6-cfi&clS6QFll*4gZ8Er
zl@PtHc1()i43E2t>k~`(j;0t@SQt4#6P7A^n_TZG{Fcr;y57?Dwyu^wO3BJUdP~<^
z(G*goSZ-Fj!f&gj+lu8FY@|-%KS-StqyXj!x!+a%8;X$}O(x$IE6r*N&Rwu@5BfBy
zla+TeW!xa;T}q0A5f`X$3x{`gBu5jYR}>>rM}nU23KKW<e+PJP>1w$oS$!!ph0q|s
zh;#oJ0S7nrpF%8Bg9W3Bi0H+$oD^~!$Zn~u8#+>W4)VSg;xHw8jU0lK?ofZjn^8iX
zVkVLPp5VQu9PBAs?~}Q|rL;-ZBFN34aKd{1M@???K7|^Bi?HqP5aXuOcxpGJJs<4d
z0q>$q@N$d1?!qtbQtxDFB$1L+$PEgh1(K+n(c(?grG&>Vo>RiQ+X+3;?g3@p4pTsP
z!mSU?x5()Z>Fqy}e`~|@(fH`)=v86hvYz5~cQJZN_ZRekS$CHddQ~y6>$G_B`nNW?
zs`S<xw{&+yVHXLF*O8!j@p?{xBCaY%yiQAdopcE*%W7?9TFzENg6{13y5e4<Y<o(k
z+ytFhDK$xVmubHQrMVX7mO!cm^1Y$^>-x8+ctS2w?!_?Yc!gX9!aLOOqRP5V%`XD;
zh3FYwt;U86EBgY_T~}?d5^^<!)!>UKjfGzUvJ0dP@MpEUp)(1r7<LUZt96p<at(@0
zpajFhC624g!AiE{64wjSbGp08(*^Kyg(oZZa`dcP?+j2}egN@hdSn9EBw$Yf=3CSu
ziB`KBwtq_4n^L$Yk;ZU%jdr#BAbkS3Pk`F4tMo)#Ac4M=MBHRr^crOb@hl`hEH9aw
zCsD@z_&2z_L22>iW%#*5Yuo_F8>CMJb2mwo%rymg?u5L@aG4U)M<Qh#)mf?cdqOhM
zr0{<mh%MedIIYDMjJitzwg4|lP+|gC>z&tt=Y9`K410sMUNZ4+hLo2~=-rS{+ydSt
z@=JlA-wpUEye*I-5hTt%U`;0Hpzg_VrJKN$00sjto)q@rl&~JjaHaq|0k^#g7raA%
zzXeP;!JoBHl1jZvJ>x@8ngFDUK!20`ZU9N}E}7g?Le6oW{(B4D-yzOjFcq9hz>vV3
zWa#M@@Fc5-qC?gD78H;OOt<wfSpc66Qv3(xK`RHbQYi0s$Y<|CU5WJQ>tH^f-gAR?
zk0&gktQ6{*NPi5t$7QJbTG(PYz;VDI;%QCmIe|P&3~4Db>;*xu4Y*GNRGR?zyGpCy
z0JGOaIhdqe?$c>vSl?S=`z3LI8yZXurAQ#};Oy}J6mS~!E0ZBffz(E;h@ds44fQS`
zt;G!wAMGNLR)G!?Xq--{gG7*oK1Vv~acR-B(xUaG3N=U5gaR!uMsd=iwWT%fjl9sb
z0!;uND$rD8LXFNe&_GYVuXS3iIGurB858PnPM}w#XS!(0{saBX57P$qjDn9_XfrXu
z;sCqpBPpf{qO(}N16}mK-t7dEP)}(nF%|k|pwr&hs8gefqq&E&^bYvHOLzp0FBRHg
zpxHaby%TC^KINNk8;fon2UgQa6Ati}D%7Jb55qu4UE`b#(z>%t>(1fia!NWSoYGEh
zr>WD;dDwZ{dDHpEIqW36h1_QD1b4Q($vxtw@iKb(bf$5yx%=F&-8bDnZgaP+Ti7k`
z7Io{nUEJR8aQA8V4flO_p*zQYU3W9wm)z%cPID)@54-)`Zf--jqMOP&<^1k^=e*;*
zsAG!rg!82HxXx#tsXR?_#yKOL&Q4pWu~S!2m3OKNx=K!2r=n9$XAP&a{;N6loqA3a
zr=8;UcSbpnI4?L0oiCK{56)(1gR{n2<$U10?aXkVQ@)SscwBeSIWIZSI8Qkfo#D;^
zr>pAQ+G*vqblNz*oPN$Ql{;D(nBa_e#wf;6r;qaP;dF93INhC&PJ10K6~B?LjrHGJ
zZ+a=tAYF$!eRXF~J(Y7mLWk*iNcDMArM}|427D_8+b$=`&EnQ}d$?2F>B7@&{kL*U
zxURF``N{dv`Pg~OnddBVmN_e&<<6(hC(Z)Z;}z$5)numLEO)j$hunzkxq00jZhGgc
zb5wbLtJpuN<$ib0yBXaE?m*%FdG~Fd{e|}&YSAy1_Ax<cb!n?QSY5g~L!80RSi$+E
zFgVwl=DaFM-x3V#oTF|Uwd@r42lt?RNyL1|J>-7tzUp>%E2z{I=eoLjW;dT(%&qCx
z*HOgHDp>YAKMLmAYR}1{rH7U8W5U5Jx_@5K&vfSK?JDP2=b-4|t{ZXgI*HCD=U?X^
zmAH}`|K$9vr)y4%o61e6{PVk6-Ry22J;l1d{xhlk4x*@8?t1r%=X({rYF<6BkeAB+
z$6eqKQQfmSNy`0{v(NcU)UZj^@SQNTMAsjkznu$i22pM&;b)$^%w6h!>b~bb;to>{
z3aJe)IY*om&M{}V((e(RYXs3eLH(-g^N8wW6#AGmUA<(MPHWc%P}M}|QPE*P+P=5W
z!Fn1a%udmDlIs4Fj_JzhJ?C?^)i2I!)pMhcFZKMcXk(W1vas`x+W#GAk@JyS{R3yd
z-h80vnJVW6wf>7L?M*$uFWUIYSugm`I@g7%JA(V38{=FS+}l*&uas`8D1L<Kx3}83
zqiDT@D7mNZ2Z}O>3Z~Jzj&Mfm9H^&JqW95)^GVfYhRT~k-Ch>lFRJ9%1<4}O#23y|
z=WDg!7pn7Yy?<QP)L*%F)j3dkJ+7E9DD6DK`I2a9vX0Th#X!aCCEQI_?yoC%!`_SF
zY`n@JtXzhZ(?I<{q_c;5Q#U<#QxEH?H@yYxP{n;z`8`E%epJ153edhFjD9NG`AyjP
zL)8D5vqSx0HJE!(c(hjkRd0_vhjg3}rEL`MRwzx-x4uw~K2wVrZG5AYOZD`zT49d!
zhG2a|^>|G+eM5a?HuU>Gt+G(9ut5KFbzLYty(ow#>3CH2d0enPLvLEB{6A7D%hbxt
z1<4Ynoul(}m9j<9UZd6Sx}I~#Iinu2Rd6g;S<fk_G3uEk)mDArE!}l=5?5@YKHElk
z=|ImNB-~9<iKB$I(Yg);(*xl`hQS`{;~m5!JHqE$z*8HF&l}%tp|h3VbX3ei@X#?j
z#*4;>>1hP~v6s@dRH>a+W_#si5Oh#TTOCGIU340~8|Uky7;Tkj6Q_YnXech(SaI7Z
zhpu|lM)6zezoX)HQ~a(fwKpa7=d}LPO;GpOe_z#LfM6M^It_s`hU&kkO1B#IQHg`}
zW&~6_TF{OM_NmabQSoTKAEKv+lvjVH9sn)b-8lN=^J>p$MWypar;F7xKZ@UM6Kz~|
zUGdYR;>@GmvF>A%T93Qq-4Sj_x2{{zx$Pu~cGin>7O4$qsePXiHBQknL3I3(Xz~$3
zGDRhf7o}V8GU&$X?PO8KIE6h1=XgT2@hlWPO~;FRepda#`r8}2&JyokAo}}QJaV0A
z<d}}j;<RbS?Q^&}#R0R6ALbPoEa6sln+mor?o;B0kGWHIj*|@TEpA`N&F%WmP0{=x
zk`=2&;mbsYA1T)*Q1^0C`WpD+M)jIqIxjlsMS<6y8*WtmHJ4jjJiVRU(jA~YpH$w{
z+{wbnL}8|bTUk;(gBx`&h*NHoJo`pCT&5mleQma|^P&3Pd&2A&aIz273+B^HW~wi}
zAvy4r`t4Jy`@^F0DZ<9%`hQws)|($wJKDeXA8RF(8c*y0dEsWddZNidljGBbzsH3;
zlj~D-Z#slspVph{O8c7HXqounTJ`+>l1ld^af_=RJGp~YkLTPcRI5pnjD6fTk{8t_
z56TLwncO(%o^wUVN#{?c+@jY0P&Jt&N-+-p0y>Lvg?EL;70&n0PG_$$cUSr6Q2vG7
za&9Hzu8FW$Q`%Eo$;wv3;TRncxxLg*<J_Ktp@nEHzZ<Lme@3Nj5~Rj4pAiKaO`AmS
z0l)4A|LaWO?<@MXe%()ZL+P)h;Mh;7&aa4W4F6xNMSoFy9#*~=Rf`*{O`?vAl4=LU
z7dMF37ppbiQfaTz52ot+y8ai6uPsHUY*DL<64VzWZj7idMzS<nIUN>%+N?T%u4A4!
z-c+^W6qP?24m4c7bsVsd2eQHR+)*4ufVr<~GgxO|)uFSvKzC$POWk!qi!-j$Mtq~0
z4&za#Wi{ZrrFd0Sag#<)a~&-e)?8esnL_Pd6W$spGJe!U`F0ln7$$f|sV_c>4l-Ms
z;FszL+l1{i>gT?jTAE9FwOJmwptK8LxJpn<{woZaH26sL`l_fm;Qg-(U$aF6uPfZR
z`De=MOC1a8Q;TT37m-TF2TbM;5d=e3&!KRthZX*e=+dZWnK=A9^~r70a1Kj9*`xnm
zg6e0r+-iD`<@Tyt<u&1Wx@5>qrTb8&eXX|pLv46kGXJ2?D{9p}qV2t+)L#YnGWEU%
z^pdHRI2=woK-e{Ww}OY8?C2nl+*%lHB<;GcQ%5*%Bu%=3j%L!f>*=hi&^o$nto!<K
z@;Z8F@r}Q?Q?A35`y`d~vhezeVEaZiyhD_;TX5}Fjkc-ZZInd)P*gQrz4aMjGG1*o
zJOC}Jui)z^44IZZ25vuCxekO+_tQC;elSe;hRd<S>kw$nu49zj7_`=hM17NVj#f)Q
zq`qLh<OQhObgg$){uh$z-wMNfg|%zYbvhkc)$%#T>$8Zn#z_k`E$Wnd^KXKC162N@
z+Sw%gTcQBtTbAQAQPb0Kno02eNl^D#K{P;6_LH3H3bxzpzlDzW!gzCCTO)tl3wJhV
z=qIXe&3K|SX9uLUwbd}u%b>7lk5Y}t^ZziEJW<cX!2GcA=#S*?tN-!j+eZ0!RS)Q)
zyt^siPV|Qkgmgvw>kCgABv?m7sY7&H3mA4MDP)|E$;xe_%6we+PpHnO0h*@sg|PB9
zn$%v=V7#;zUwF)*epFC0DTlC_U0g7=n@)1)tSI|$X)|j@m*4960<N(XIrNd9mWwm5
z5Phr>t~aBz9Th!am&PAe`=nCK6jIxi5@)WevynJyS8>mt;@y4Sk<##cYE&{xW7E+(
zjE8sAwWH#-6DO}N9$dvOsZmKjjZV`@PTdj*+$GvvuhPC!*(UejR&Rb5>G2S{g7uYt
zA%42hUpk4}dkLe)VOpWhw9wgD{i2?pYSUxtt7p{KQ(N6NSFC3AtQKmCW{TO4Ht&qq
z(~<V+z*y0Ax9(^?-QbFy)jGXZ@?iaUf1qP^gu_{>rcc#XsdY5!wb5@CjfN{b<#beX
zia8aW;u^n~)KOahrJN#qF5(o`eKC!h^Ew3;UWze(Wv2}3N+~?ZCHSwXF?LOjvOB64
zO;mDoLC_7I(8k2$L>V@AHW~aXBiUEsi?70Io<NpACM=H9b*y@&QRz_hxc<t+^vE8f
zx1Oq}-E~9f>%y2JsB3$b*H$=et@`#+`OWojyr{ko<N2*r^SXL&0)MIjZ>lY5Yv`yd
z=&Lx@g_l~YMQ#0?ZJ?%jR$aZTuGE%G3)RVFN)zGHTC=gvMhdl(TB+>j3Te&T7D$~A
zU?GUvNJm4sWIZ@xeOkUQaMVx<4OCh!-COwvOI7_>5N0dVI@R@DS@^E5r_wr0D9l=-
zoUYb}CBc48y|1AhYLioa=&BL5Zw4eL5!+)C>8Yc)XvSpgc<~?8DW6mSd`?`}v__LJ
z-%GyyByPM@$63j3(;ls-#;V7rb<?}q)MNFe5&Rt;*PL_GFn7^kx9ER8yl<r>TcEei
zlms%p^mRsjGtq=>{4-Dd(MC|8Dc(}`=r48sQXwngo1ZDhXOf?Dl*06;sc3o6h#HJe
z2BH6V7Zr4YH#TLw&{Q?9#c6n`s&+IAt)Tz%*nle2y5)4W_HLk9jTPJaNJE{*|9UIW
z9->*Z+>As&v=O`Mg9iQklC8_cbG{OOwu$HL7Jl|f*EuOUnkeaiOIpBfVdSoGlR-zU
zxREDrq*GYDAT95#B=#Xm+x_BMe+paQs>UmYt&f%GCz8JJNr#`WbGB+e7recxlIJmA
zH+^v~<I%Um5#-y#)J$P-p76X#p>~}Mr+p9pG?V-J3Nx+X9l{qWzjxtZuPen2>;i9~
zqr8b$`nu|BW9u0@UIUW16*^yKFH+r?N^e;&{=Hjmy+f^TTEuPDJFWP32JvuL*IeS7
zxupkZ5sjo4Cw7H}SaJK?;`t|ptsOdci;r6Ee^k8}D%XY5Dd#dKGD-P7@_q`s`xN0n
z7^|C&X#itA<FV~T$F1pI_0^ZE)03*Gb!)1xlu=J9>J;M4?c@s2JUR+;pUcVaWOB0U
zzJS6C@y23gck=70m_qHEM_jO=lSBNkkiv^N`E)JF+k6TsrQGwWq~fA1>!)^<5d;+k
zM=j{86+OQR+@KS7lYVF`1JOo?s7|Kwj>X1hnxBnRW`Xm!XkC+TD}<vBI@U|R{Vr@D
z6Qy02oV(^+kyJ|2Sj!Quc}}uxzgYFov<kf^Y$qv>jjoQUUz!c;Z&B(d>4>J8EEBEG
zqitVTD?csn{4k@;e!$iry}E~ZMJu$uhN?|daTVii4d7i3(d-(*0~?2&%&Y>Y2iDZt
z6pq&r4KUCL>xLuxy7bg$q^<{Nt&d(<OL^7OQI}k5(Q~c8R)z0Xre&)L=jD+@W#N7$
zb#Kzjq>)|A>Zr<5Qze>)Z~V{31nq_Yb~?LaukFfVmV<#<TYHO}3<!1oQAn%7;xVR?
z4M$fRjW#}nnEjDIof&O(g!8v0=XOYZv+;HdbtI$E?mYKkL}9w>!^+KUx)ZSiP7!x`
zmNDxSQ2Z-M$5%xI3uu{n`d`f0@k2D8FR=oB0)PBmym5){m#Y6P#mf7+&J|cGSE-HH
zDr^fq^%wD(Uv!ua^EVwk;nIJIe{B&}Y!O8mw>N%o)V4(2=u5`krey{E`&~xOujrVK
z-Qgu<_5?<6kBE96!RkJRQQ$L-311V(cvVkxlwvLx^jDy4<Kr)jo7y==GH04<{gjTU
z>EX{R%*OSPa(zPYpTt&Y7X9bI)1$h#vL9u{{urZn!{tP5<fh4w=X?YmVl>t*8!`08
zN@<$^K()dktU>+MCOxq{nFYS9uAR`YI-zNq9jc4MJBCLa^qHPmw2X#&F{U1jRdF!Z
z$00g<AvyY?4fYcpgH^hf8ffC9boUTCxb-!YViVDyhhyovulJZWbu8nOF<3Vq76wME
zMvr5wc#_kspf52eVcc>CSY9AJzb`KRp4!VK#R8=3CpteDjeJO$SrSdwe4x7z75^<H
ziphnybiAs3UW4yWLVF*B<~0CKvj-O77Q#+*v>4Mbtd~{MT@CtqRb*-<G?+lQtjJvr
z@#6C6D&@r+%c`fEPFV(R#`K(WN?8f5v>IAkpcU0Yb7{m_y^T0V8y#J-0`|i8XRT=M
z)=MqWTevo<FpzP(g|ydQJM^8d*naz{E&EW1ZedNjVMFMGyzdy=68fS|*i21dg_*@O
zuq;>)Z-!;TbcA|>rUCk2D?!^FP0qMrg9qARGx&W69UU1l4L~pN%jjSvunxnnF;J~M
z3=8E1_<`8~CqvJVtEar6_IQDrl!eUXEK-Ypq!#{E_sca3`d(xGmFl%?B}3Qi{ukyM
z)~F}1Rsa7%z4&{zwNb!lO0`7oy`1zP)1w#boQ1qK8~qG8&$C#>Y$R;9#*t{?{X&e{
zxWAq1*AC6rS|q?qBY1frCtAT3ZG37q4{*?qHs}P$Y)4P(Owa1Zh^7<m)q{5EhlRS2
zLVAZIn|`#ZS%!x&3h1Tqf%LgijB$sHLc7yvMl*&UM!y*j4;ag+egblBD0YKK)mz3Z
z+-TeM$S1G>&QPsq!*k6#{}x)#A}o!cFy8zc{cM$R{Jjnvd#=L%vI6_3SqGO9;|u0m
z-leS;3Cr&=ckqg|E3-k`{KxamRXimK9uW+Ku`v&!mIFdNMmOY3f2{6ZID0S}Zv#Dd
zhbB8<1qgaZGi+CZRBgnFrAaudG;OH-gML((aZYu;t<E^17B-nc{?-da>L77zaMV#)
zP2^}LdS)eLaRv41N{maYAeZYXzuH)RnlQqw%gDAVqn;LA+c65X-q3=%g7!#DvoJJe
zeA|*bG@{S66fA9-4{h^6=P;XGN30)#RnH{4SwUK0wX<<eL%5NZ)+p2^8iutp9#x(H
zx*?ycrfVg5OciQeEgbz-2TxTQ2ilmcxN27c{$wNLGH4k^bzd&jF^Zvc7*DIHw`CQ-
z96CukrK+H}Ha07Orcze-mG!=q!b@<Jk=|HDZ;LsF^<P5o%IaEB_l3wezd~%}ZDa3J
zq$r|rdoG1mTY|EShNToIO<C2X0vxrxYEX`=X+q_xU+u6}Yw1m0>e>L@1-72{*gJcw
zg}N}?+!xt60@@sdBz*#&^cX$H#_unRf?sCl<5fLRm-KlN31pmPI=p0-<o>G)eU_Ps
znYs&RC0~V~J<r_U^XhpoC{LTedkJg&i)cV*8+#6&;&Ciwc0Phlbb|WvBh0Bk1bpL=
zy8Yl0y_iAj5C85#e=%OufKho<Xv`?htia7fil`qRHP9972!Dntql0F`R5R$P4m`d-
z7S3A2V(rkPVAh+~<kkdAZU~(=5k6Z%t$`)Fwfe7FZj9=?p#}EAF4P0g)*I;)%=7ls
zT^}GHz<rPKt!bL3clJhd*fAVC-4JYV1DN6J!|a{e#(RtVjbc18nlZ(A#T<(Db3Afo
zgsvlzIyPHsR>2`Wj}C3^6GDsOxNuHvg4)9@s*ecY!;l3-nC~5kBpXDz7QY|!c0JI1
zde8=akjOSZ5A=r4;i$S7<F-D`L|AK?zT8pI?RDQCyJnm4Xbo@Z$UI-5S+`@P-wE#5
z9{$ipckRO2!q$3f1@=4B`ZmMamG<a>&fn#MJPK^3Rz_ResTtg+5iQ+>(OOe%C-p=r
zb>W<K8IhRHs4kYR8uTGsHByJMP+)1O1$U_xKGjpNudlPR?u--Hg9DkKR1>PJhb5_D
z$g^rdmsW1m&`#5gF_Mk4>N7LZ3jWqCjNbshTTAHz9^MoyVr|A<HASZl;eEA`2~FUm
z^%<KrhL#(u)@Fro0-ZO3j@yKNq!aeBmdNpD^rFU;ZKLcq;JpRB-LTgwv@f<|blaY@
zV>mzCn6$=YtRJ-sM~&8_f)QffP-m<I=c)oHtqAul&8V(KII=4NS2detV2iX7xQ)yU
z!xIa^8w=|&ep-xo`88%QppkqLIB7l|B^0kvsB;!4FS7)dfz!97#0qfp5^%}Dj%n7m
z%5eM&*y75o70biXD=NG^WBl^Uu{b=oBJV0wgMb6q3?*h2WQ|GR=CqaJp$?j}ag2J%
z?tn_$K<8~kt8NFZ?)|WDb)?^z9@LxOWpe~Q;0i<FB*Pecm<4_UJ$DQv*a7t8htP;7
z((4DYu4Hg%Q60(%r4O8^H+IzC@TVU1lU`^VZCE*BeXJQY*pxon5`DZnt>2RNY#Lfu
z8$-A4q0_)V+JLuB=|@eWL5pP=XbvxJilw_TbkZ1$K}#&)0pD(==hjerBYHx>k(**Y
zZN}&$prKmu=bEhNszpDoBlzluoZbHGqTf`ZFE^kSnnLN#(J=ygHrs7$G>wjo^t$Lj
z;5nTcTl5KeZvSw$X*~0lHfEd1NX=$GCMk51IOY_|uqPO;KB;yvxn}dv6D1J?Iroxe
z=(AiOSNKbe>uh#w8uoEpkupg!r!c;oN`8~D7EGa(KpqBT-iZpEh}HaI#*L$aYXHXx
z<U}v#54!;U0JU@=HG>srJ&{C%LOr`TXAd}fFfJYdy$yy!j8giBI%(H%-l-Rq+6L=;
zD@I67(d?Rr*5@{0v?-Kd3yjypZq$I*ZVTp(gSCPlnh>{MI71TT(+ZnYqfpyzLfU4`
zV>BX<I)pZ1CbBVHGHBO^*x*|MR}01~t(g&M!ciY?*cdIcDYoOr<k&Wx9kvo$!oS)<
z7p<sSs|WKk)(g6^9;Oo#sFNtAJ@st|7wjMmnbZs7TAv=koZbM&gdNc8+aim4g;drf
zoXhUQ2sY@Ko#6%T$g4wWS?U0{?Fm(Od?3f#qZc<rZW`>JsDIFFtk;>&TMg}|7UP53
z;#AgqO6jZwuPUclrQmZ_StD5iO}C^%Duwex1<_s0qRR$WIGgt=4acsCCR`ETS_#d$
zJo>2V+@+LbE#+GQyJ%Ic@}_;?w<A_ZItDYwfo!Nr`_xz3hV<N8qzmkbb+9A`VU3Ad
z7YeF}*581&o=sJ&Mo>iUP}T%9{ee8J17$W0b-+L-Hen8~A)KQz<ER>No%)O~YC|*i
z82y_xYl21B#=j=1J2OXT<6&#*R>;plyKYSjw+y*?J4QjR7z6hU=fK;A^1cC--y)o;
z32X@U;Gb;>wKnV!YM(8j*9PIZyE(ShR>ZA?<Zr^bs{x$ZxL+IejrzcD{4vlgnuL6{
z2{RzUYSfmY&9)gjZ7W*E@Ky&Mq$m8nF`TnG|IM&?Sa0h|Uu%ZlHn8kApdA9v-2nZm
zG1v`O3A7Ar(17~aqy9nv4SHzMryGFPCP3aGtYOf4K}cPwyg|73peb?g&j8gzbE<<}
zszzHkhHF%ZLIRzuHWX1Ex~W5{4S3%GnNlB#QUkiI#u(T}yp=i3x@9A*pqG?G8!5s1
z=dx%Sr5Tl#LQk=tQ!?x)HcBkUoP^CGlw<T}T1;v55F1?<WtDOzG?dcxJ)7|>!%-1S
zS!Jx@Hg8*nm=%Dd3ZvD^z!~T+_ca)U$x07&A4^v})T{#CsW7@xar7&TlOL#y17k6?
zD1#|aI0I6Ex|T-!vQenjst7R)5!1$|MW}h8uazKmDPSxPP692=N-qUwj8~Kn$I4|G
zNn1X}8SPq}0*t_mG6oLD&Zg%TP+FUf$sf+k1a&FIY0wuAb;golxf~<!GT^El^Vij|
zJsK<(^j`^W&}Iv(vO2sn*9y!PR>Z1VRdi52)aYuUc?UL@Y9a5c`apZUKND01dr3t~
zDGjBRq)z35stlw2a_Fc*E0h54V$3O-Mq8M=7ot^+VuD&*NI~ochV{I9F2W2}Nore|
zRwxp3;8I|`445sA?X@JFy9_pjQovdPh$^AER>J~RC7k~@$xs{muYm=jKK-aNYv(JW
zXIWTvuu_fxilnMSyg(1D#rV1ooV^~s(MBju;7iTun+@r+jd))xoGq$@4iIqY2H`w=
zLpWFyMoz6l?Xo2yO~V=P`r*ht;EJt6?$!+c(OCR8Sg~3kUekhk`M@^Ng!nDszb%pU
zZ9*$kFlMR;zi9!NX&TPvHwa};vykUB#$HwveX|x;mS9{{4T`7)2PuQZEsssS0;?uU
zKxt*+7G=U-68x7|+uAsz5dS5eob=byaF&w9DFa=Ur`^hhR8|ab5ztEoTE7xBU;aTK
zGkJY~#Y0tKsKk9B)2)|SKP*IECE*i6Un<0Ss$kd$bHfAjiz4&tK7V)?fEx2bmxY*T
z%>!q#+1A2vl|1BR)SDl=EejVc0B6Y^_T{|v=YYD6_Y?@Pfjz8P$O+2BKdOclT%2n#
zhOEdeVHIlD1f8Q6dP6ntYNGp8LgOe+dsPgjV|7N(73j&P0a?4%g4<SL<XD2U+=Epx
zWmKDD;W)G;d?YuPyJ8{63Wq$bG@%uV7jP)6M<KXUaoWBdys-@ZvSi3B$^&^NY<T72
zSOK>#`+#$n<UZiQg&$Z5i*R2Ej$oL}q30Yt<<L`RC!5+Lo0FaAjQY>6|C~-1CsX(p
zPkJY-!Yx*2-DM|MPQ}i~b8f!#DWH&?y3b4d=Vy$aml^V)C5?0CrNwQgJO`~_fELWf
zHHc#)^t{B$r`+?v%d@IJ*%X@7iDPCyJCNkjT_&K*ti%4ZbC)N4pOqN7ncdH+{IclG
z%3QwXY&a<Rfbz^5aGysO2d?7aurU9Dd?|u#DG<uLJlqG=oL6xQQ1hUq9Mn9E4l6CE
zO3k8cUhtDk>2ra*{9rqPC3^^eCi2L`b8hl3i0mpzj|*(Ug+jZ9!BZ68UJNc^R8*20
z*nd8?e}Pc?l_8fB#4bS%3L%LLg*g;}CM!atB|__QG0H27{3wYWDTrmdD6Lo$$y0zf
zEeEEGA#ICNZV@03EZ?Q+A0_D3C6Rnpka=a0w6((7gX%hK@HJLtIFI$fa&VyP@Wtv#
zjEZ4cz}Kt~)_TyZt00f7V3(;Hu9m9F$i5<4Q$;Lsl|va^iBbZKPFZAs9k{Y-Nr45d
z4mx!`H2vC)L>ps=tB;mgA8oKc+HO6@1I@!RMMG=}fhDh5C|AttRuRp&Q79!EA}0bH
zMNQUu)eUDS8ili@4d7387?(9gyD$q$t#I@fX#P#YnU%)jEMqW+sgFc!z$m8)>rEPv
zZ!>IvbwUYUol#b>>aQj_HwagS-5>h|vp03nm+K;D0}EqQH10+r1Wg&;H^cH;FO;fg
zi*1W-sBI{Zn}#!>jaZ4@j9H(iyl=+WVl9}v3Pxj%$e|@~o0GZ=w!~JUC9HWk57dU$
zd+iwIcETdumGvBL!mHVVyEB^Z3`8xF-K`mubthIZ8_<c7a$BHiiOsF?e`2+4kA<Ku
zWp=<a-5m>1d)C-?qSPJ_<}|xdn^xhPfo`k|=tdbmv6{7IKDiTCwVvVpXRmNYNC)iV
z?HR+{Y<3Uw>BxAo3$}tzSOYp?RcJ^4ZJ9^zge9OY@45g*J614s;LF4AD$DBFoB4y@
zK-(RwL3>ubv?Wb<Fl(c^7JQe}juvPKCfZ^FZq0g`W?09YhG!dW>m9&jYcSM-I(83N
zOW2HUJ7TmZr<UPr`}SB~T7)#x3@ck(MvToES+@+ewPxHmr4O_Xt>3M&p0vgu(-7Kk
zhTSfh`wM0PTZg(@6Y3DG^J&MdV<)iE0$Zh}=t2pt!Zo#K(WxKmp7o*G#*EEd(aV~I
z7K7%DLWA*jb6{^yO*&!u2{6zB3Jc~kTQlnK8m<Rz$DBrMD60*zJB90k+wi_KdE2`N
zic>$-Snsc*s)dy_ux8W^*D2ORj}Gj|^$4wwjve&xN}+9~8ofSP30fDcPc3F7YK7yQ
z>e$<>!bz(#imZlp#`3BX+GqkTwQ~4WH{{Z_82grG3{W1f9Lx|`hK~m`#KFqqnv5>W
zqfb@Go>U&~w+8bT_g8jRU{0+Zys<3Yy9ViP#j9zqMTryGk}8FIb6{~Qi!3R_*rqIF
z=So0TIn<o0ht~MY)Ug8g{4&(FB66aXuu__s70{x~hBLY4d0Qsb-K$b|C2CnZ#94)K
z{A6;i9An4oj4CSwd1dsnvW&9I17|t%EfJ27ONJ|WONTmqrBHLPL})S66b)CimBrpx
z94)*8lB@)y_ljXnsuH`{1M5Ih#?wX7$AUM(XdsARE}Xjv;3>tmqTs0k&MJa~a%h%@
zqf+5GqAWEniEa_ByDN_lQCzxAU{fd)#;nMHpqB?Wfl}mB4qYP9JPM*076i^BKwN?`
zKrqu&3_ZRK`gT!LmkezW#Td7iX3T7Gn~qT!&8R3EP)Y0zrr!k`crbzpMh(H-eW39b
zLYFhGGiNwfDadM2({Hj9nuigH>9VHxW<xK_hi|FeXmfeP*`;iZaDup|`(@L+9O#1C
z(dqJ_JLe!~a35&iw(2x1+O+9}x%Hn>XC`!Q)53E)8T8hkGqFZBz5Y#W&xl5w9nCkJ
zVy1V}g()-XKAV$D|8aOg$e{3ax~Acq{WJ<o$G7^H!aN}aZ_@A;e+=Onl{SOI(&Dcx
z6<!#8g{Q)!R4n0XxevTFq*nY`JQu{_F~P^%mBkLc5d<Es0&iWZLhn*e=(Q>XULFGP
z4yo{M;Nktj!xvYOOIq?VuUmm1t#qMJCo4w~MsJgsgRcTB$B!mbLag3fj*j^v!uJ9`
zr!0Qp7lqQS)JW(<!N-qS4Bo&TN^|fV75H-s$`5>Q;VBI-6jA(4dE^=RuL%59IOcP~
zd@?Cr1pg8#ctXh$_?WU>@SEh4+QlPCO7tfFukPWu;jW%Md@0?z@AJa^L<Bw>0#8zb
zcdzIzJW|A%uP!`0n7^x(FsDf9(J5KaH}M5=2VWz%@$Pju^v8j}BvP0^j-Zsl=h9vL
zR^1^l^J0=f9V7U&GT$cnbK)LvR(OAMLJw4d->#cr!s>GytR$NMDAEVsCL&<+78t!n
zeeMc3cko7$68I{^znO<`nE)QVj0Nce-ycACH^hqhR*QuGJOUqEf#<bI;6LqwXE4K(
zwUv3|hy`PJxQ2enppGc5o(iZuJbU1e<bk)52(`Uu>G5QBJEWHYw&Vc%0J;$7ARq5R
z+av)~l$f#9Fz68xO5$DM>&%UDee-Ofm%i)Sy&D^@@HQU?5&gRgO@)7h^a@GmrqMOV
zjdkwvZAPq8d8D=24yUX4cEq}=ZKb#yr!;BE$)3{S8^PYD(fbUFpN^QR6qd@(tTU}b
z<9HuOnQ;n9t-JKB^iQMz7(y+Lg{5^f>aa4>QI4gt@M3O$H<z2o%|bpI?3-D|%S`M{
zq{>2Si)(MJoXk2bUM3yB(xg$%((7G%a!5rD42CR(WF&0{U@<QjL4DH!V=9Ga0CQRF
z8x7?awQp3xuSb326w@$~M)_n@cqVFW-~43?@fI8z$TKb2vXY|8Gc`H;;KJ_HkY8*V
z*WRZF8q3|vv>1kAt79y<wU&$MNCi|;a&f};{Lk7IpAEO2MCYD)!Jzen_KYJ|tkOo6
zG8Hw8Dvi}N%2#(0s3)rQcL=)&ow;Bj6>(j~3(_m5O1KB6d?>>3<rv+l^t+1Z5-XK*
zwG@2u%Mr1!WG#l1qCD<GgWiK!u~11Wun}k9iBJQ}$-}G1b@1Zqy${_-q0<=f>o|8P
zJ4NyCI5(XHh1}G6kM9T5Lht4mBt_2#tJT_b(<pvwdO>X1V|>2j6?Hkc!@M1Gu<$g{
zt_!SDAWBh5H-+zH!x~>~6K?PV&27E8>)hgvdDHO0nWOw-Y3-<aYTyeY`#K|8dEM5L
zq9;32bSO37b=;<1e6SHAx0@=*^06o53#owNp5ei2sC3jA3XZe7(jq>XF#7Q<9baTS
zw2g1MDu+8k8PI!bFcSr5(V%2%BQB)t9a`9>W)8TrJkuy<EYD6z7e05!)?8q{2PIJ#
z!RkP7H>rDyuyDyai{}9IwPOF5ozwb1>zvX51--q(_bxYt^%Ol_<}2H4x(5GA_<l*|
z3-tuPz`n|PN$)LglHk9=+pGG&;>0UWg5KWKo9jk5igiurRdTzbH}Sf^&JnM-*D2!y
zZFQZmYAoFi9r5I7N0M^Ct{4gWx9{8yf*U%6d@t}7eLS$7r!JQ`F9ETIT;SV!`yTd`
z?$4>_=O4g-g}PdND<=Usuk$V06`hxr=A3YK8O&Ybi|zntSExl0JDxh+0H*6IHOT1(
z?~=fb;X9rj49<&!;DU~L-Ca|td3CV%I0IxS^~PE#ndi&Iv@hF^P+O~YJUES~tOUxi
zZ~qN{DpmB5_<-7Pb4>!f0rmon8yt4t)cr-EPXX?rrv$WfKE!<zm=Ef7Q>}f!&2Ex^
z60L7>?w4}wKck47VT~=#RqoCaD_Lo;;#DY7Z>$~$LjrkT4<SwA{|0oFtXyw8Nk;K}
z6PaXR{weM~>o<zWTjIhg;O|IxrMw5U3B0`mMJ5X0Nnx$5{L_NvDo|gc$6O0j+~VzJ
z;wC^B*WoUAz^w6y+v;r*B!Q0%@k1Gr2KjLt-fr>lft6d}^By%z3HezHJS}K5qxxiy
zo4|I9mbH>^Qcg7Baqt-9b+>7=AjK_mPo`aN(wgF;mcO7(2q_|wo^(6x(YN@rFbWpc
zvcj$9aT{(U{zCjay554DCIZb({8iW&aJP*+hd90);DgvVfj}}4*^weBQv!+0cbmp1
zQ=qRq;4hGlft0Z}ya(jh=-2W5UxPcvgFVB^O=Q!pP)-Ej;ib@y3H0M@q_{3ROMrrJ
zf$J3eavdB5Sh)oR$#}5x9=y9v4FjoRw4OqXCzDGGxf$N<%^hgc@OlwQ5)GGOu6K}S
zw`l1*;1<cC|GPTxfVqgt1>{=_@*t2UsnLM!$cT2934JZSG_wr4%YZ(ang1+qcKv5_
zv+6lL8fr$gx~w{LxjCi(6~t>sUblc-SWlVI2Xph~XkLZn)Z2V`SjeRuvMGI5(q~e>
z>GYhNw0ZFCm7V-@phsGa9B6B~b>wl25+_&a?<TL}2C=O)^WKmJ?b5zn%>>N31W#_f
z<fIGVTSz{|$*2EfdY2RZ()7&C=%#7WTeDGrt3^89<;B}rE{=k35uHV;rTMulLe2Am
zg*=LvTWK@7g%m$8P#R`(15r+$hJ%7CA%~9q)FV$=n_|kbm~tzov}JVW)wQ_N6jw+=
z?(MFeTT%Db-70Qfx2D^|?cla`yWnZBhpt21{_Y6(arb3+rn|!Z#r@m8<Yn?Ic&)tA
z-gNI%?=$Zk?|bhH?|tueZ>l%e>+KElhI*5{`Q8pc>W}l+#}tYAHMUFa{#1{pE|7Y5
znrNDuX*#5-l{zu?j8sXfdc?jIb1$Z^zsn!&$9aEvOS~tQ!)UL+H^6(uo9I2`z39#J
zW_r`SDc+-AQ?I6%(Y@;K5)?nUAG`0mZ@5pnkGPMylilZZ_l7&qo$D^qo3Guq?iP2a
zd)bTiDtWyG*+Or<_oKJL``laPec-+0%@yQ7cz=64y%g`JciTJc{i&Kf?~U_Xc%8iV
z-oxIj-c~Q!uO!H(`}6&k{u2L9f3)A;ujkiLXmP)YU&^oI7xYv6sl2`3M(=lTt+&fh
z<rntb`A_(-_#gQ%`Jehv`j0Dz-a0$^wfwSv9zT<J$B*@M>At-`)}Q20^WV_5iQZ&Y
zK0gTuAF0+ebPn@6c#T!(LSCGE+f8;)xd+_??(gnacayu`UFm+WbCp`<XZJ7nANR0(
z%)P8wiS7;kUv&4myWJh`k9xn-{np*?UU3t>>|P14iPzBU=r!=ldbvEuJ*2#Tc9*#y
z32RH;)w)0G-tlU94+-yweBX~zZ42p0r<xTI#P9g=F%QM8k8K<~Bz8{h)Yy)(Ud(ER
z6!DW|qW&%axPQpM;;&cDC#t?_gq1hF30_Mtk9*sTx)<Cd?iu%*Ac^scdF8#%YUTI5
zb>0!*6E<7=UHnJ=M}(E3es|$HowrYIwm@|DruT~CZT5}|qI7<oFn-%h^7eQ?d*6Di
z)lN6m4%Pjx{&W6ff1zM}Q~7jK4jH`!?_age+uma;X_)F>*Q+IbruR|_qvr+9DPbzb
zO%Y93^tyQCy*b`NTD`0C+2Ze4ozD9w{H6Z8{$#aL8Sk!lT;(knOalae0nwx3JKjs<
zrSb}TxxIW|HJycYS4`N>>}3<it9WIE@A{(OCSG%uQd{-zrvFF0#meitU(_GwzwQ6w
zC;7MiQ~ox8gFo9J;Meub_?7(@et*^KQ-6>Dn}5*%!vDbU=NI(usMhnLkLF%El~_}4
zI>_tiO;$}m@m6`4{4Ao)2L2#na*$umFDX3iQg5B%jq&<;RlVX~YW1TdqNl%f9C7!$
zC*62ALBqzJUMb}{P<`+@)pDnIRk#@IzbtCr<NxWe_E!ngH-z1>{tSgq_h0ZI^E>-h
z{Sw}3wZ$~$-oPv1Cb{R_<D$sp?j_+iizuzS>f28kXzjI8j55McTH!3a{;R3Ck5|eU
zgwuD_&xeb*RQKwr-&WGKt#CC=oZu1FZLH!A6n|)-e5&hgq58Mib9eIYsJvTy?G%5I
zdhu-UH}A4&x3j2WhCfdf@toh&FXdhEwt36cw}&gI0Xilr-^YcuH%0GXiW0YbN4)*Q
z)gIk{FY5hMoME4L+fOU%&!aOUs*Km$AH^;9s&~Zs6-8%*)Zd>|8DmAaH5B8d_nq43
zNkLxAtEcvEE{<7OcZ~(<^MdUw(d2K+=cISaJLVk{=lDkaXqC6gJEoQ^;Mep!3fkss
z!NT4>LGg*8>?u0R=cRM6yLW`$c=w)r-SgFt47-`sYHhrc%KJO-uzE->@tYa`*Zw#D
z$Ey2G@t|J*D8G&0%x~xy^RtV7PN-J@h$5y4s{@3ymdd@3*VpTzp8u%m@@Fqz`Bd=h
zE8PUqU?;z{A1f;QS=@7>u-8GgsUqsm<z*FxXBQRL7T@gUz2waj|N2RF`CS<NSeSiA
zISy9*GG1lTT_M4mRdg2Be;O}?S6Ka|hSy9`j1r%pB??&Ty{j}&NQyM3jO<F8QT^<$
z7ZEp)gBRXX?eB_aFAEcU#p(9Cr`4M;il#5?ZKCM!vW`=Val+jrX|Yi}bF2HCWWpah
zwu^`E(9_?#|5Hx~+<(P8lf;*<>$s_$Z-`gjQIF1``ehM(Mvq-ZeUl|g9#<cFMs54B
z@ZD3iSV#S-s^aAoEoW4ZPp>1Z{<A2gsE(>?`#L(y3P;vgYbi}B(ROjw%l<2<Rg3G$
zsu+2crl9arOeJUV@~V%d^>QfhVv1EubUr}6<P-JE8-59Kqb}kSqt!km)jn<ga%$Ps
z-epnL5${)Tjil*1?-y@{TH|G5^l|Sg^^wl%CC!vqbsa^4rL686>Fln$JfS}DfqKBN
zUV^AFzqn5yzp>w1<rMPED<mpOdC@zooPYJUh#Rj`kNL{`P-T3g{_~RBZ<r|KAyH9R
z(LzrhWAyZ}IQScieaO2eSy@~(Ra$wK_j5`LM!hTQ2Olf_6!r1$f~Toky@q&YZBa}w
z_0i$t3~z~wzEQ7TrMQRHYj$|My&F32NG28WGYZmdeqKMlcg?#b+<Yde7D!$^>y1$A
zp5h>#MBSZ~a~svYrrM&KYTQtqqo+7eKjCzwTJvS;FLTB79uuCdWqT>SkK)%C1(p#0
zbHm-UizZTe=|y8V#o0`9oE8OMR!{WQ6XS%<(#o-q@_R+_Zq>0@FkSHO`i^%~=WTJx
z-KxV*_4FU5f4nd3%~So}5M@mf_Ie5jwM7MmL<6Z+#zoQPULA)d-*>pbihj4~`llrO
zZ{pfV-IHEA9cctvVd1TlN**UJI#D?LT-^IBaj!qb%k~L^lU}kUSF-O4<JWb+Pc8V1
zq{u>*ZTz*r@KjCESC&l6B3jHUO3bHRi-`V;>%X$z)fB~A`!o_(n(M!+D7l=%>j^g|
zH*yK`BBG^o!f^*lIK%Agf@GfP?<?Wr59wP+1dsh6((|v<$^Q1f7H#|}NY<<8zoV9(
zua+Ancsir|l=ez0SI>)8?>sI2!SMZ$@Nq=AIi>3!_20d^S|9#X@@$*5!@a`JK85U5
z+><&kiZ|RA$GoZby5}Z|_lR$bpJWvO%B=e3Q43owstN9z!eL|elK!e;J=MB~>Qz{M
zrGRQyNIF6ZwQ*U|X<cEWv$)nH;+AvO+ABoG#=EQzZ%KEXt~Y~4cXfrO0xBie__fJc
z!DPDGCFx@ab$3+tx*?8p)4iv@9;epK3|!Xhv%^ucsrISRQCy|Iq}aFNQVDRXJL09O
z#VfKZMHa;_tW@d6CtY%jQ?3z}bW7>tRZ_f{LA)(a@iM3;mDQe2L^akIx=NaM)_pUz
zUN)5*=lLq-qOf;V*!|i4M*Q<DX^7uQM_lMGc0X|!xbL~2yC1r<r8|B|$fr7%N-O<N
z+WC64(jBVlPH6$h)o!QY)c@-GyIN`s)cmjB?oh}vX@zG!M}5fpS$@$_4dK7Ga9kTs
zl}DjD#1G>{XGQc>K=(zZf7MY-wUMqeMABlST49ke|Ar{;V^P(+YKxCVSsTR>mZ+zF
zBi-%=aj8k_X^)FChe^-qCVAHp&d^i!udAmvXlRXfG#8Z{6ehvT30pOwj|zI*La_#@
z)N#tm^rWfEceq;oX=%FMrGwO0o0m{6vZyUmtL08f3Y`)jf0ev3to$kr98$dxs^$mu
zyi@Pu72|^NZ4&5;QK@uflRo)H|D{xRBhlq3anrFXZH9X7I~vO@QO)f7xiqhD)Wg>3
z`F+)UuDJLN?=?X)Sv1%~5cd(p^;AEj-O9pTW#w#mtfKpZs$C7?pr>%yU)UL>a-LP%
zsjAV7@b#C)rDlq%pH+S{bUrFv4_2&^!uv>cuy!h=lW3_PXB)LzJsl=pN(y7eRE}Y=
zfR36vO;#3AyH*gUI*8&-QuJ0^3|Far)h@lo_j~BMiQaZl-mP_SIaGohR0O-FmAZ<`
zsSht|s5n+$d&TUeHfVz;*j_Dc+Gb0|X@r!ngHBmV5aknAv#6g$)HiOM1}_@?N3CI_
zra#0*{&Y91t+t4cH@a&yiuzG>|D*f9&ds9k?{$2oQRW(rt-ezXd%xEGNylFrBmX3x
zv`xou{qIumv9Z}+wem5w`Wf}aM9Gk}>ZQ5W(+aBoCh5kg=1+=(UKNIC2<r>fmNV6o
z@93DWH^YVRo{Zbd!H;sOe~Lz=@fh#>O*FMuaI90=U+V5FLHoY@nU1g3N0+EqzOVlI
zp*vsW;|1<p8q3di-*jKqsQx8|Jg@s#+^5~C?rREvTj8&}GZg-g(!8sbU%Fo?&mTm!
zn^l)nI?jpvTy>Mt;bX*2U39wCddjS81a5OxSiNMUNx>N}-gQ|q(y7)tROhlfE2tf6
ziyoTlsV<ziE^TAA%c%H?s^JxIc1S(tPvP@tcY~n#NwBQaztwS_YPVGIeWc?99q$P0
znX1bxf`5+cVl{h1$3l0O-WU$P)mV3h+U#%TdQ5!jj9Td*_pI(Oil3enMz83&Cb*C5
z|D14pQM~Jbu)JUR-J)I_wEjAk{+@EOW0@eZ(eoGJ_!HrLnaWxw?7y#4KN8m8cIOGA
z1-ibb`ws-$96|QBLf+Q#vO?w&K3^$5Qs@GAxl%6|xBW>t-z>~;5+(hmbGLX&qQ=s$
zxI+Q;;8LRHV2sg3nn!QOM+2q#j1$F-P>-IX9z8-_W0Lw-fA!j)>ZzkeYt~B!s;?VG
zHC7L4tmk&RZ%uB-DXOZE<W>oJBqdC*DIocmRblzmZ(`KWS=G|1)ss`JO{2DFgL+eH
zoxbFigNB~0{}i?2O~TUY8dX}8PU%DinUqt0tN>d;q`v@_#E+_qyVigns;k%LQoT&;
z$R{pUO!QzSC@(iz`6fu}pHmARN7p~8R=T0E)9x+BF}<abxI;~J+H&F+^>p8cr~0a8
z196ImNR`Us9`(da3Ml{lDl4BLGRn&>*m9!Dl+eBLUz5SP6~iDh%`BH>kLmU%bK{`t
zSTC(gkHNxmPp~9f-39GU^>atHP6KvKqQ@zX>HO7%(@IE`4uYx`u(d!x?Evo^q*m;r
zyZ&mqK{}q%$Zm$Tx~Ig|=V^4dRJ!9ftXKQIzoZraA`S0v-F>a`-xrd3E2K?*Bu(mL
zNvG$<IZTi4s`@risimk<7K2=U^Pc)yL>RQO&kaF+MZGma^+;CeO}&d%*lmS4ikYGq
z7uB;b={T$7l=P~j>KDh=J9l!NkVHSA_A!}%2;JeV(w|oUJ+631#0O1lKCE7MMjY|5
zdedLXzn{c4zY)FvB&z>Z)W1mQe0s*)>M7IR$2rVb`eb*MJJfy1eMHaCxKngK>prRT
z8TTo@o2t0ebiSZ-y8EKI+dJZB*8AR6&wERp;B{T+D(p?=`x?CAO@+)B$9P%cFN#lC
z?|erP%oFeXN<I54L9|l6{vXcGXfA)NHV0JyeWJvx!kKB9NyhOsMollxGQF2m)L>dl
zUbS>N(VyYIx&Aw<9ePUB>LKaWOFectnuPVl5qi^GJ=4bG&Cx?TiXXN>%Pt{qX`{f*
z;+yHkb<;_&vo`WoUQ~DIh39i%^{TLaS<eUbe@5q7)0q_`Q9UuW+EMUHD=|H*gebR>
z@-<3qgw?Z_$}`#<E*QFtck~j)O^~b~DM>UP3(Pa(Cxdlo^!SYaU)5OY38-?KWYi;~
zv=NFuN?{|YQ8(48J@sv_ylpgJTD`20s4t89ziIWSt=|aZ<AVPbV=0691lMz-w<OWw
zRn<GQdQ&zu>HO+RrG<-{@QZTjMzvIjDheqoToqKWE-ET7E6!2@D^fxA+br~1$MejR
z>ZK8$Oy9ahSx1GZLz4QxiWawvmUoHY?pIqM)VqCP@sxUp`i0v0u6n{n!IT82i&F_X
zg-si)=NAvj8;<OY3%-iFw{|Nae3wSMtRmjiR(!gNxUJpS20pV#mQ;*_)Gn>A8O$~!
z%|1qDm?kfNs^?_k=mypwlZ>}ilgnz=n|3EW#w%Pr$NH(baE$5yddi^ojwm<dQ@-$K
z@;RSMD-ITmLItJ~Rul)Si9S|M7;J#GuAyKKw6Wo$hVD>?(drYT*0D&HA(AqqrCWAW
z%s!%*p^7scJL`DS&2!RLCu%(Xs`TzprI)@ht>$BmN@sZQX_WV#?w2V1BOUf`sYdN@
zE9N4`PP0T^W&;|p9x_@KH%PSDNpRIbYpo%i=Mgp7n8!xsS*^Y{7Q*g*8k^85Mu2<7
zVRq{OZyj6Iw!f-PcWERO*o^*ycbyR*x}Y9&-Z-H8$UVcljknC=B-%^m<q^dg$F#9_
zCM-K9BQjd62!r`mem3>O)aXBP8mnDLN*Uc;5d|I5d0f2kkf1q&uD?&u|EPQ${roE3
z&Bj2cJ+4EK+aO9@D{W^d|NBIbzc6C>Lp9i?)9hB;lw!NIPfKAOX)B|tZPF4}>E3kD
z-=vX#FOB7A<+~Ey<TL3gA4z9ffHw5DINnR*fG>(?J}=HXUHtDE>42|@cfRaC$N%$s
zZ@Vi!C7$|%!k*SSO(Cx-rac?ywe-&^#Z<+6UFQsDie{l_zNY{8+4trnX+=w<tE~}C
zKj^wuko`hUwxiV?6=wFUZH&K~-T0vDeMG1A#9tKWZ>2F^e7kV=uj;x(STbAQFFH0d
zgRxd=x9QDRz1xDGxJBXHmET%n;%6P}#K~7lD_bczJ`+CP)z$Q38^g{EHL-Uj3Fhhg
zy6)eS9GE9L@SbA6r01^`K3_6wi8MabtCy=zt91QV&&yRW8zV23X1PMJuF&&Zg__=M
zdij@%^&>Mk8wAr1(ZYUF=y9%xM14m^AE&TDo>vdPqMn@OUNP-jRGlQ+zA8$*E_ynl
zcL}1*B&+}_>f6TC)2VmILb*N`+4Q2#7*S`eD7BF2)$!uc)qSPCA)b+}o^l5ZYP@nu
zQuqz{joA@AQL<T-vMCRv@@%5${ANi&TPuoAXgZwPC*xFJM(YvcL9SrGt8^x5?x8K*
zK#w+lZd&{~wcBpSLjS79yLJ6tt@SG-E#tiZ3TvCxX1kf&vNm5YTy0>?yiT~?hTV1p
zmW9>AvgzP!^uJ8)@~!^A*7Zxh{g$_z^>(vj|E!#LDCHXH>QA&1>-lFyVMlepOT59X
zM#mVb{mp3nC}V>ojNHt!^c(HATcNwKB5&ckQ*dqso}X3r2CO3+p|$n&;nm95=IMS=
zdh5{}MJuaC7aR0%vvC_$(jSWP3pBe?d2iF(zxA{oooEH4O2fe~s{dw2Jr?hX;@FsF
zx1c_+x|#lUSP<^Q_I+OOP6?N%(Bw`_I-FL^$Ea1VsHHE6ZZ7K0O+DY#eX^H9@e}l)
z4qJCx(MmdWTpLxCR7)3<Jg{+gMg5l(|1}F?V^KkUg*L#hT}QIQByT?5*|<N@ZktQT
zt|w_|I(-9awN0ecRAsc^N|MFw1>JOSGO@k1oT0k6nTOue6S_*q*c`+#T?guojo^p#
z&g>Y26|bMddr7Bgh?Uvw18tOlE0tg~n|0Cb8%e5_67<<st8Ajs97yT3UPe)Bgc-=o
zT+gfD1@mCm-baMhLujRc!)^Z7xtVrb&KNJy27gqW+MMbKdiqf3V)2mI#W&`N=gr3|
zHdoIJ#Xnw?ZaE8X_$vQ%&^b-Vd_f_mgHBh>m%|aOaolNe&>7qrAGVlJz?GkszB@_x
z&*;sQ;<zs=>>0(jz3*Ni->E9`b(Q^s?q}-$6*$*CUFYar#K>})AYP{9W5)Dfs~%s#
z|BP#yrQl0(w=Wn|ucSX2pZrJ|_>57ualLQE^%g7SJz{^N>$^(-8Dn3w3w{BoU(QJQ
zYlVERcT1H2mskkDRc=cp5ti%!GsRereE6K%=lRNMq3#yz?gOk3Z^4u2fD;=7SZ!ZW
zy`EEDUltywg>Pn{?N0+&j|*EbqW`~+PCr9<o+>=f((|i&S`3G`{NEC+b9KI_IxSFr
zKT#dO)%^yw@J8LOQ6K*S`T7SvevhbRCo}N7#6$iTZ@47-v9XM49o8Fd6m?7gSFqz<
z)_D~h>N)kiy9zZ9ZhSEbs=KKew@gz|Z<MZ~cb61)itW*pvDjV`XTB}{I9Z(4hf_O>
zcNYn9N9RrHfcM0C?}+c(FJj|REW%Os?AylWu^mezWMq<BoI5zNN2{-!&Jt(bKz$>Y
z8I0WG2c|)q&Y3nGxvLnZHi?i!X`;qYBnwiZP3HD;2*%XvV<tUZh2&Bn%P$xeYPKJf
zCxRntTB~YtSM|B7rv%j`h53_x!o_)U=G(&Lapv)ogs(*Ka|LU;jS5Z(3-Nkq+WKX^
zH@nb9{a<DFdY|xbHk<=$t5a}Mo7?+coN%M=erN7)t5TTm@DEaDGrHFAw5g3kZ8U0{
z$iE8t4SmWalWARhmBK87dn8jV_HN|&0p=F}VwPdQ?k)hsDLo%o%wvqF&mi|~Ci1S@
z#VFypuIJr&^vihWb@r={N0s_4=?x#p^v1NtBh)Y%`Ds>R(~@qJ+ZlykVqW768s<%~
za!DyJ2(P!XKqR>5f)PA==xwljRhT`c^e2%ZMuiu!f?ZJVN5JZSJ)K8$K21y;!|y?2
z?-71%w)9`&^Dkl0q~hObuclT1jNCR`)pzPQU#lnmsHg9-h1rOHk<Rboq(ABUjY2<G
zueUIJvl=U^>8Rf*m-j=d{uP|$+mQRL*VVMgdEyx+{g>+f4@zm8^BU~1>y^svu4{Go
zlOWot+Wd;PWu-3D^Jc|cjqUF{g|AlL>(L{YqZh7W6^#9F<oR2butG3=C5Vg*8b|zG
zZ@yREmg%%IztWxYy48aGdqMk+_}nU;->H7zD%Dpi!8plM*6OThz0NA?WR|@z6z?l$
zO>9=>EA-NjSiQ7DA*;|Ut(F^<dIj3U4?4ck|58$YEN=E0I{k;@o$rXNy(Nw~PaN}o
zxakLa|Ca7%vP<flI!r5n6}#^oan|XIJ5wz%7j9@zZzyy&mXCLI{Sdh^UnR{|ULUHw
z4+PO-ap}(#?-SMYU2MztW(Bi8rUicsPFI5IPX+sWT4XhP-3B=82Hk%Tp1(n}*{b`W
zRbP{>U+c{V?CEQi-!km(+sWHB_#e>)zek_580*pfcVm<J6&-E|G--6ZnGya0^)j<0
z+|ku6h6(Cr7Z}T*Re!k0dZ|QlzlgX~I`ro>(xB6bo8@7QX}i(p(osfFHd;1|P8FRM
zqy^=dj!{&aQaQcNEPbhfVr15R0cP&9pfeZ4${);J6=t<WDe=>cXxr&nFOZH|$V|3w
zKs+<Oo;|o^3Vc1PlripgLFi(2jSbS7HOFkKHabum`{2XTzqq}4bZW{rn@0h~jT2-!
zq`?(uy;33IHn^-#1w%`xL0kk2L@xBEyb8_5ItHt6cIA>)xXCIga$$k7)fgEBT_)Y#
zLlWe{%1{97QYMw08JUz%b#vhRDT3bM%j{)Wz0ylYq*5!~RNa!q9VK&^F}Q~{HwkWe
zI^>);)Kd4bC0?|-6S$%Az2l4;ZFGH56mU|#`UoR_8)y6}9`!SpoK4|;+rOfYKg1FC
zFk}1+Pk-y}?|L?!f193cByfh@Y;>@f*~|TK%RN{K4l`Oyf%9GzTsN7`y@k}j6>8Kb
zDXqq7O*XriRqHfZaMBAWsj!phuvsUhu(g&jsJk4j^T-C>*i&X!_N3OkIGguXxTE~9
zBURJu-&J|0TU^2(ds+Yc1;q)h8K(v3MM<T@g8m<2-~{99ZCGLd6^?97^fP0L4eFT(
z89{FiSH=9Kc;5>v8?Yg)fv4NJ_6POOHOzNyVZ>|v>lgJ(<7n0omox5KPsm#J(Y3<)
zj|#I9-A2-X4cA`9nC)9Vtt8cIo{Xahag3*0%vH>%eW&*}<7}L9HEC8W*5`uBMuvaF
z`8TLE<2&nhe8s!Z;m|e`Tt})^aF11RS}SuSoW<tqjDM^Vw=h|@kvki~ZD0idJEPEF
zmB+8D#U@t1ZV>*q2~XPz-=?~)W8`PJvN765{coh+YnTP!4!mpNXC_frEA(6RU90zZ
zTurk5NZq~(XBk&Bv-Pb)Rw(Y5)WgPu?=vT~M7e!VxXtu^kEH!hZ`PA?BeKwH@*R+U
zN$A&#`;9_B0;k49zlR1kLJKA_e?uesS?4x1pDn!Kq}Xdk85>wlyB#gav|+>75483c
zV*d(0)_}d8Xw7D;+RI3G2O7f;bm-lBcL=-BCZ0Fw{a4ECJI44sl-}U}4U51YM!{Pd
zDgQ~UY-e0;)M&END0Bm*uG8_0LVg3w>p6cwGHjBpT&=VwTZ}Hu4zwDaeFlE51-?+b
zEY`UMNw!>)Y>A}WELJqUjm_*`$;`#Net}e+i3M#gGWSi%MjNY`Ep4u@izO{>ocDob
z=t8y8VwE{pZLmm~H~ZUSm9T*JU!c@0u}6KQvcIMed?t7{AxD=2+ZVLlcEt`LwSKUi
zk=ioV_*335r7wLCb+2Oe#ruq}jG{hOjuvAnDRwBAFNwPped=A|$lzN}PuZ+@HWplu
zMr7k%8{d9}Ze%6=h^6ZXsOfhk@CK|lTfnLDgiXj~E8}P0ucZa7AO8YxFbdroLi#hb
zYx>U*@PMy%+L&>va{Y-?zJYK2sJPZwjYF+KQ}~Hej3RzTr~d=m+Cj)4*hY3>F*56+
ztu(RqK}W^?_F&IHhlDu9YS)vjPPMxm%vhafR`C>^-&Sj!VcvPaa`}t7;q$B{Jb|Uf
zbbqr${-HdrgkQ1BuE$QfT{YjV`#+Vx$)C-vcKK6v-maLd!~XLp7R%MxwN?pFYgse!
zlhT<+v;sc-6I|>&xLnYaHY&vy>`xo@<{NNfy0_tIqYmqjf3rei6TM)o&Obs<zlEN$
z6@6(N8m`%mH#3vHjvf>6s?Bhp<&5r)@;-!qtW`b<?H}K$t*rkUHQLPB67_|zu?;N6
z4zO61^D#CC(@M=EV7mTS>IDmR|0VkJa&ms3-u4l_V=?vtOS_O>7g#JlfSMNwg2nWi
z5A@FT(sz`<*)~2Wp3Ss>BDmfarCE%31<B_?_XW0x6_mde8v7Eh*(|t=^lx_Qk9GGs
za9El}=+)NK7hngT7uvEHNjILwYJwNAt_1es_t2%^(ADPi1AF-!Si-04dA8n77jJl-
z)fTTPzZbA6PiL<2H7r9j6mIsPx7-&)E4105ZJu(L;=X}3XqLiXK~G<Tg=qn69p(y7
z)9yc_M(>4|_77BN)BdeS^RUP)MDKr-S<ktwkC=|l>3P;7Ovirzs!D$?Tnl0r{}<h7
zSOqfGeZqZKah}G`^dfVs_Ql0iz6hC$h2?pLKCgH)v28u+KCI_w_$uRZ-A_>1Q@Vda
z{}Yt=6vZ`*%~Y^9UAe!A<?1!v&jhEl6!Ib%usPb-`CkaH{gAnfw^(Cg)Dx_(cpn_R
z!z}K5Sm8d#2KNzbD&A4bcN98PrM*w<yp0X%Rcvyv2-ct;FEE?&icW*hY;-~Go>bkZ
zg>%X;f|KWz*9)QbZMy3HlJcC&NNOHquh)?gbCC@*8Hc?M-#17;fToSgtrchJ?L1NM
zbV2^U-kYs!f#80N*o$=9{K-NcGX=rBiv6168|LQfd`-v8SiYtsbzX)#-vYLo(9~1V
z&?`#!rk>x?-5jXSaAmVN3kByp<ZJ6r7GNv<g70TOgN{}pvlj5~b6vkiZY)+GdRzQp
zsjl-C!=%}lNVOI8rgw;KIljxte?BuRA2R2(fZqF|?%rU8`8IRyZvnB5CawO@6Kg*0
zI#1YmS9yFWXiXx&NiSFqbT%em2&^Bo(&jz5z#{Y{;~};NXA%9}`ire&nx&X?kl}CW
z`E^Q}1ARQJ<2B*<MZKHKIw-TwPGi2yVn3rdwnkt&bUNLgtoYB-Q>K!3qK+4tADco?
zcuI8hhC<9L`3Cc8uPVmlg5Wtg$YZMIE6k!<Pk57Avlm#6H9@&eQOb!>;&k0l#Ns<y
zX`W=IL(n^)py!$ebc#xQR?m}lJgwtlJwL8<ocpNzkdATgFycJz4$-@bdLH3UQaNLE
zH`E>Lj$%c{5QPm^=tQNkl@^b<<CW*bD)CX>PviTlsp0c9)#hno;xXMlq5DS_`UJCw
z&#M-X3qD($@tB@%g~oFVouWLRP<aoLzd=8RnpvoY2WvQ<R!$Qs`*C5%{>Q=}CWG(s
zO7W<UDT+T?sqFn|T3{;t=V>@`u<qkca6SzS{2cnq9EIA-kC(9ozr+1(diAq#Ve6gm
z!gb7s{%+WlXOY7j^no|f?iLENH<{VAQi8d{nXIQX+IdFdFN><)VpYk<3bDC>`5_N8
zZWNR}pSeWq*T#XDp-;Z2JQkr%z78j`Z`o#{XPRDVX<viK*b0_+;Q{ZE_hPK%2JtKO
zt3{+Vj<*<l_YCFvp30gBFM3}g^O*Jg9NzgcQu}k}XurUk^f|ilV)9u6$1+K|g#Kh}
z0Y6~9@B2EfMkYZ&U=F}~;8J9=S*NUbe}a5pEZMu58ow*ZKi7RQE4)nUOh;YF`*)Gd
zABDR3kF3)BgxP}k(GWf+_J2BGVD_hlq*)lw<t{)ne1VQ_I5L?yPxmX(W^CT$9mTe}
zoKJL`wej<CW#p%5pNlE;Lm>MQ{$iF&(<VMvj3vzWEMv^@J>$8hge_;J_CB*g#)($2
z?lM?;X`|N<!<Z|S-x~6;^@?9n`f~K7ui>etoqvh$wFEok=V&fA+W8LaqK%k;VkTu7
zoH&@R_=@?PWmr^yWJTh~;D0GPkj-`*e_Y92wYBrYPz(ATE1GHjA2KRk!3@t&dcPdI
z=LYJ&0$tq3i(iAIub`G-%)S(z&Bl`-(`sg|U56fJGbsy|=2OP}t5w#wXpGCTmzoCn
zUa0RcR-A9q4VMa<4;1G+MhM?w?OZF(e<kzhrr(=I*)-6V;h5f_U4fn8TVM+G)>X^`
z{{%g3ptUUihgc=QVT|*!!agD04_GnG3a}3S*hY<8unE}zH;k0O<6F|zd}X;F4ShXx
zxSLoF_9Lq{)?-oHOlyCO#rHevY2)`mt6WO!t_1IEpv3vC5Pcu}@kdx%KcOdmMf`d6
z&G(>rqv}Oy0dvrCKA^9C0NuZgjv44HZ!zomBK&C%R^0jUskeFmGOIHtGn;0d?^Srj
zj8F@DMjX^MB+Kmy<|${vNna9IoyFYZ6!gDG(KTK}>zjr2dKS%bs-(jc$em~T7WXkY
z@)PKo(-dx+(-TU)TvFyS#eRl3uZrtGh0K|({B7p$Ddfu(WXCk+^_1>kQ0(c*7mGg$
zX=2iDtfZ0UHA#1q^go$6wnp%2-93j4oPy?N^QX^~+f(Fj+N{l`PSw-nD*YMdWD;pA
z65M3u(@6D46n_%XnB*A;g!VKRsX2kr$&#HDDSZ+-Jg%$NW+cxO^gl{DjzMRh!k5Zp
zB>@9Ctn_Kf>B)j&JkoI(*chqMQHnWSIgFRQeqNGpobnm1d`upXA+J#?V>~i(9Oq-m
zM#KG7U7ujaIH>Jl<up(-{vqWtN@)zb;kq}8JXB>2SB{qF2(*Gp<UB&hIF&U{rS?_o
z5rS=?;tvS5hQaP2JrC0VXoZas+ymV{`X8yIxAGj|_Rw{LO6jT4;R@^H_7hBF^k%%$
z52NLW>fIn>kJ9@ADybJK`?%fQPHunY)zj^+kUomvUw8dfUN=4U)wQGY?95l{E%nr0
zcb#<YpywXE>!Q56yX_RGn~vrR>*BW8(ZOxzw$inO-n7%vQcvyO*2=ZF?%FAC8~yiE
z{5Eb2y=kMEO%&R}?dmpi+bX1;TVHv#<!t0OR^H83c00vvrf18srQWqs%m&J-wytdz
zqnTTecLr}~#qXx4_LSFD`L|FkE3Xyl>MGZ!Jats625v(gjrHF`B{$TykzzE{b4%sh
zz^$cgE4PNi>*>FR>Qa|?4OEWRuDPyNc-vA}dupf{mSZD51sG_k``WtJ*R?h!Gy|p@
zf}@sV*4NR%t*pDoZZ)NDq};6DwG~!daq0qR6T#j@@0z%El*;mGtMJx3YwD~IEcKM4
zjY_Hml+~$g6}_*hvz9_?>U}wdS8yxoxvE<Rh$<^}4Pw;gsGv6nnLSrkcq4_>QmXp8
zR#D9A%A=MbtwXB%q^_gTnmQZnzOq|VZ>#I9DOfDDGASD?R!zOHMcwP_EU%o(DRv3P
zs3w@o;w{18tH6Ct{TB!3T6!*{_~jK+*)6PVLB*`Elr<HeOX0QgwNRBjOX<I&;+555
zZ>sCRqDrWur>eTzSr+dNmTM6~P)uieT}zXHP32HQ*RptXD5j_4DygW_6;KR&F0ZqU
zN~)&NDuTSSn@_Qe=qRDMWeBYZp3CScp`)16mQg9?DAhb~l;x=~WfyVtC{6+5714hl
z@+!)GDP1kc020f;wB8%6d39P2MU<yq^O442F3o!@(|leOcXQ}Ir`}c2b78%=+TZtH
zQHmT3=~_}pVb!GsxfIg1v}#%qPZtG&x=dI*tCQijv{D<+3h7;tzM`NiM9GB+HIEy4
z@BmWM%?>6C;MJoDkd;ta4*eI?dxN0}@AA0W6mH%_tX_qca}kwe(3jCuQOYT<5Gzfv
z;5ErSR-M9Ml6hgesKb0TT@JlEUBSbW`AoX+0m{;x(|>|u+|ZqQ!MYTBR62*(rSo_s
zx<K0do|Y{Ccs%i#SD^Fcc9nFODDAvbT-Ezap)aQE;rsJ=i@A)~nnXMv#S?xNPghr!
zpZTS^gcqrcp)V<eIvyWifybTr&@YjBb+Wu~kjpi^bQv5$$yY)TJ_-2IN@UOac%Zn7
zN2M!axtD?Ga_FP#N*E`&yF}ft;IHdCxVjwrqdMap!w1zB@Nx-XJlD884;=BKAF06C
zRy;no%-7Wga=V7Vt9ZO}T>@JMfx&%+oURl1GCs7dKG(qYB|^^8YS*dx8CvAL;J8eC
zpTQH?S>l{0SG&JVtDaMuQ;Km^$1xoz^?wQ+2bj71Aip!DyF#0vR>)E3gzir&_5sB`
zuCNn2kLd2C?oL7-7on50dcL3#JI-<%1zm!2P6DUV<Eile0%e`$xCG=EfbcTc!(5N!
zlkKd|qfpmHFp~(DE(75yDEy4_JfhN%>j-i>&%fdG4Dg)?niD#XQkxSh!JxHTSg$#w
z^rxZz1JJX17CRNDxTH9zX@QGjFE|UXE&|axAUsd_Wm@lg=snKD4}$SSVDT{ZIIA*)
zTn)n0<b9UV^R(M3@Noe;I<A&7SPahxX}1%4e_Z$W=CDGKE60=I={RW(?u*pvq+%Rb
zoB+zxI!=N0bF`qf(ILe+MXOw)9;d<5dA$wlb^*U`hGV0K_>dO_FrNbZC+G|3LtLE;
z-=3xhhW*pv`Yit!$o({RJQw2UBxPKnZB7wxJu5iRP@7XBw5Ng9>U>b=0cWp{UCvHt
zpYC@#|LE>tXNR-f`Af&YdS`F;3OD=pK1gv;EqqLEV{Ku0IikBminU*F_9*UQ-5uub
zA%z^&n<Jz;OUxt0JD|`Y_I^s<t#bCL{5>515<f`0Uu76Y?o)miYGnm!>~0UC2Z*;X
zgzqrzaZn+a<G<v+pIrae{cc_Nsct*<ZZCDSTJBNJcM}@C`Iqay5YBzda}V(iR|m;u
z4{3LE?$o(U$8M$D6^2_qcY_OiwszPD<sAZh2dITXwV%{`N&UB=_=mC$jy++XLC7C!
zm46gt2e8_`LHZ|Y{-)dmdOjk21TAtvc-sfW`@()>r(xb=9EN)ZcPGK1!4mxMS8n@w
zvzyra!ge@7eU6892+BE0?>|OQI!K)k(5FsP!oiRhjzS-n!l>`Go(}V5W$p&b!{Fc_
z+IbhWupdeYXy_1JGT^nxsM%54`Iy2FLr;f*_c+|^c*q$pzybHGFBqizRPJH8)(OQv
zPQN`0og9N=4$v+K=@Cc5eD~7+);0$JacZ}h(hh=w{iHb*_J||;zXHF$&(TlNzt6x=
z&hy52K_FEFK5+p^1AGP$9EJlO0>%?aiPJ!RHq7;i-XD3ubIt(iDO%tP-0Bq4Cg98`
zz{zpm9zh=oS}N#`hLy9xy+<(*a-ISbtJ7)zgA&hxYpcyUDETNYaE>-KN<INB0pur$
zcN89Yf*PCxh5-6wVH=!*S6xDqp9f1PkRAcYwLF8TQ&7wqayt{k8}Ok+VGA7(<-u|2
z`7~GK7YD*O$Kg?dwA!y;6mW?>P-oD3$H2jH+U+!QGJrks;(0EVoX3&o@uBpL=Xx1E
z?V58BuYniPD*|7pm(d5WqHA13T3-o$a>k>FTt;t8#80K^J2#0N=x`TFkr>K~8)$S%
z<`WiQv>rYX?>TpZXZ#r6#Uo$>em5<ryZ8}I4n0dI;Yl$$NP*AURCxJ~!8fjp=ScHw
z>xF)!V?r;*>G1m+ix0*-_(8-UCSGV`@bc@29(~i|lQK14X7A#8IErsa^WEzcf+t#o
zGxV=}+iKya!mqBSRB0hxQM}W7c-A!E!FYAX&oSPMRl;rj-A3H>c%$`*<>J%WyaAgJ
zL-Wp@UC%i+7BJs}MZ%Fwk<e3M;Po#x{<mE`Ij0SM7w5#ovUx(xjQ_!Gc<;;M=GM3%
zBO?eK@7UNSJ7dk#8gUdMe;dh^4abF*G#WKKK_7RlJJWsF-Qr&2+roN$Q_<8b@1^J4
zp0n;r_nLdfi+K6Hie5)=inql3%a8Rd_`Uq${-gc?zm{LjJLrAmy{we>?WB3rsO9zX
z-tbl{-YEZ%n9?z`V=l)wjeRtBx{eO9Rbr0BEQo33r}&rsZT`>xm6&`nrDBH0JgKv9
zOaXtd|C-;@&*bg%wtN40|9ThvOn!O4lRwCB<2Uikc{fzrGhRb4gPUMqsdyO#TT48k
zee5ms7I-gsBUOWfe3NYJ=&#_#DVY_@wr=CBd)d8bD<>7l)>P(TEqX>)DAw?Xd!Kr{
z{i6O5|8@UI!MDRd>|gXx_y_zex}Ne+`+xc$`_K9#{1U$Bo%Vk8-tuO6k9iZlsovY(
zTJNM^+8^k@6B85DA?Aaa12Gq3V`47EERGoxlfhpmd{tCk$}0D7{IfAtVqT3|6tg7e
zAz|Z^|GwYa&*dHR_IpWwZsqZ@e=H_@OvRYiF-83I{tUmmcftEy^&F^nn5eQ2cz6BE
zeiy%<U))Ra{`B7TnyWsZ`;WVtd52)e-_{J66@8hziuJ7arQpB#r1+M(7Mn|1=B{@y
zc<H_F-c0W|Kcip6@9OvQ>#Ak%s)jqfe|*nx<$o0ujTsiRH0F5B`Ix`drgi=O{xr46
z6>p`e;$5})TllMaTKTjUCJW%ZDvoc!?92W%_LUi}aZ~M*;zjwkwK~32#(0yxhrLI=
zX=>Rq-gwcV`Si%an$e=lZ?gBbciXQmyv_DM*YT>~(=Xzk@YZ_^Rq}J*lio`z`B|lZ
zT&agBeG@@Y4nJ5$@Sm57uba=P{kLP0x3$B+y9eB(?p3~2vTurddV>W0H19o?w#wV9
zw#+VEjPpMcO<s@58Iw0Avwy>1<ah8R-X?DmUL|LH8w6Qnf0+NI|CT>N6dLFKs$BYd
zCG1;H{Pft@cnS6uu6^C+`J%pzqS;EK;ZAsrTPr$`_tT1^I`|K%hRgj;{vQ9Bj_v+0
z{yKlEdRj9-zjw_0PAxQ4*ez;bUc2{1;kQDM3HE)JeI3=?8z(%xtk!s4=d+@h-d<gm
zmdU*(SnM0n^~_H!cYkzOvgUFf-+ON38-XNN`Zf^;-w+1Q`9=Kh{tN!s{=fd27+)~0
z^OuVDhx(2D+@iT--uK@7-W+e3@Lfge9Ko|+$07HGdsi6k<IVGS_?bmJll@18n;xR5
ztHSLYYO7i5tH1l{{dWE{{z8AAsQoFwg>wB@m|f_7;C<r#?Wgf8`5o2M9`pO@F0HrI
z`^X#YwNveV)#W-Xug$y0zv0)`zqz~cjdIt^DeSforh2L-1HFF2b0>VH<>iY*JdNPb
zNPIxlc-y_L`#bi<t+<JO-);CbZy2q;5u(RO#8qYr>LubatJKqu`FTW(Px<fppQ?p+
z`D^^S{zSilpFzEMnYh6awNPDAw|SVUizk~7%Bh1l${X#C6?YmTJ~~G2G(s5aEZmvD
zq_%3O#}qbAxS1`SzU95D)|=?{5FJ-A9}BF`y^inAbb2;VIOcn;nYe*@$C|9z3-RTU
z<Y!g;^cBr~DC*fMKI8fc{!#I=1^$bEbM@F{@2s~~xP0AvUJ#8CT+i@D^>5xqzoa<(
z41cYEP~7f}zgc|hWpRW2O7pchSMhtQzgAVP%BybX^{KFGX<wi>!)MqO?=`jT2g1|)
z!o(c4{|s-E*B=jwJ^4bfiFk8UwP8E;kT&XXLxhpXyy=4FZ9%kLy!~tM7vXrXcU|>p
zsFr_P{px-HcVT(6|EuU^jyUruVSkM3_^|(m|E0fP{qvY0J}o+3sW;=rVbiNEtdEZK
z9#Z*3gyDgFfo`7M#tN#JgyrugVfK0nem=i|pI@{X>s=HM*67V-@ua$5O;J%H^<rDs
zUPRoah-f^Yq((l`S6bH5o3GAT&taXs`3b0xAIMqaOD9G5)y2`ri+Udu4;dwR`}n>6
zwtgLjR}ejyP%9M_q$PEi%e(EJ^8OO%StO3o#jB%|GV!gC`4qb1rkHOHL1I2m8Vi3d
z`G(QHS!^V(UrjAgh;Q(-vBKWGT;<36RXTh}m1J#xY2D}1JNv4@{Hm1~{<{k!PY4$)
z)bEn~IKP-*-|wdW+D`newIo?S;M(DR>3yLd@Pu$VN~Lzi^MLt0sURGcgdQx<D$3LR
zoV8Vqhr|Qllyv;ryQ+N4NTLrA_Z}eX>L58@L^ZzY?b7?tyjMhh!_)_wD6cBQVc`(Z
zC6rrDVbpw?^ijKw7xg_XC{}nIy(3;Cel%<P<<#%mi%T~V9t%mj7L)8O;1~Bx`Bhbq
z<~loo@$zcrh;)k0;-Pazmrtn&_7J44RIYgjD<j;Qm#y^p!??{?Rp;^3V4g?!iPPBE
z07v+CcU!m;bCb@%f5*S}1t071Gb3@#gH#)}P)~1yU>=80O6vzh#fwbC>Y@6Yuc_w3
zq4`iKsFE}C<y%B$AH_r6QRRA^FHX#Z#VJ9QfX9@}$dg;<J<z^<5HHKhw-V;z#wet;
zTA(Ccrw!ggdV9S@&F1gRB<n+XK%FQq^Qz9N;%x7#AAG2Ox7=GN?5q|2uhIQnaiEEO
zJKIn+Q&_b!KX6gLp}WZH>wox${ufq+ZfA|OePzE(Z|v*xM7{xx!_!7NyaDx5FSO$Y
z@wgAfZOn)AU(#aEh#UPYTG*++_=8&JC2^5~g1w{C<q%e)c-T12aS)$Tm-%MHu#sY4
z;fgoj!=r-v0L`YBG#?Z#1p6e_Z<_axYO`G2Xo;?$sE5r}{!hb&`>JlWgs-xEv65G~
z%gEO{9+LH*`rZ}3xHRvK_7z^TNpZ=FG&;;9XA#kBHGIfc!t0cIkt@TOJlXiV(Zvr=
z0=_}csMYLS6Z6g&!#6^{N-PdvsUQk8&q;%Yoyll1?+ebgYLBgIk=^2kzv<j8x;LLZ
zv++ImthnZAwQp<Da8p5H6kIgyImNikj7N!Fx)#7cRufU<NYUaG!oGQ|-XeS-6ZcE&
z-H<#>ExjelOZHQlr)KejSU;UOVtR$fi<7y!OXFveguCJ0@~%nqP4dorht+<6iCeD~
zW<M7-J&rdw^YGDJ9HEjhQbfHtD_<p<=c7z`5b@Q|%)4;`;k>Hq-BoEuiZW-4|9>gE
zSm=GF>wDgO_4i47(^a|ERLka7ZW;N$+`eD3Z(NMWnLouEYQ<i{MHf-{RLSXCqUM$2
z!Fxnk|B8QI!;|SD9rpaApnYGZO;tY_A_-)^oQmU-uK<1zUB2bI2-U@lnve43*Dlff
zN&2LDhrJAEuy1jb+{@~-iF`p5ul7ENf9;!iO1z^Mx36r|h)T1nRm}HlWA(@Wl0oK0
z^+ol*Ig*v{>3?D9`DOy&ulE#G%|xAbRPVy7U3H{=Wqdoe(EFCE?+EphheZV@J?E-M
zpGbm!uXbIdmR&C?x)#5o->7BY)ca||<OJcepCpEPiK?gk%JMaS4Yfio-POhyWq-Wv
z3=wTTCR%(_`OZ?GTqX|jovzE2>$l!dg4r~``NH*U(%Q{mPgnKVmO84dRm=~JwM<^T
zoa700uDoiq0y<0LW4bdwlgFr($D!wW(&C>JPkKTjL-nSgAZ#a?>cG`v`HJldt#Sk{
z-oA`IjMu1h_|`d%ryskXzz3x9sndAWzA4Sld=;fqUnqzl9rNPX5Im0;#Xc;4@B+T!
zKk}9ei{A-*-w2P(g}n{pO26wkC^@!Uw6jB_vmJP>{aNq6m8QQ6|IMp}k8kj}Zk`lB
zm5lmO*ZJbD3xxeQz|$OQ9j~K#ydar3N9QZ*%b%#6PgUj`<-A?x7^NnwSEf-fb0vMv
zH*Jh}N!qshop;$gC%L&#9P=;r-ai!oS6$cRx66D^Z&Jxi)!J{0dp{`(pP;_gNi9=D
zw3ovxh&P$b_(-y^8us%&#Ad#1`JQ$DD_D8-HQq<Q;v4<%SUa`}&lErNP1bLG8~X=e
zPW+7@Kl|QmJD%e=k=KuWTksv<6#T+BKK3>AVZNd?xthZ0yO3I<2)-6NLvbTT$A+od
z`Va7DJ}Ipw)~a51{-PE!squm8`ki|C*Yx8jCDX=>R=VRA%Dk&)P>;JO8n7?t%`@LY
z=)ye4+gIVqdUua8KqkCkm4tiOLu={Gcwve-k9iJSp<|`W-7oy^^^R)%y+^H(B0ce%
z9}&kCca)CmX&fHwT^C2Zq4v6{7ThHY*@S1ck400n)Z%ZbMV?Y0G_L)ydW-oDHM+A9
z^MN@<e0hSx9uj9TZFRWXt)H-BzPqZc7gQ46=ENgLG4XlR`%5t{XojDPHhAFcr@Wp}
zUQY`8$925PnD{kO!P5$#B2L#A{})|_t7dp3HGdqH@hVmnsbM}OGcs0Ag^!E0NRJZu
z$f|;Gy)t;dY%Y#z{>Pf*1K;>bDLiS~*PkWuIh7HQ02*<7vF=ScY6{wbjj%HF9cVsr
zoJzuaBk8dHR9mb6AaG-P$y37E9LDx@)ni^&PkB`o{j@m5%UBAGSD44BsnV-@pj}PV
zv-PjXl<o=DeujG49K|+0=NX-|l*c0qn=0Ni9)H{BS;V+%dA?H3VZI3@<x}|X{RCg_
zn1A5?_!T(DH<0FgF7WEPn-S;Fk_+~Q+t1;*ME1?mM%MoQ;BIAPy@s!rH{v~LJAPVh
z1a3Yb_DP!TR^EG+r+ry@i0|b0K&eO6M-J<~L2{SzX`&k+ctSJ}fynhdYLilU9IPS=
zE~op-YMHu7hz@F-QEKO2qUlk1U+X38^pi$3RCOOOj0I!Qkvhy<sCfhJj2_ciIaEg<
zE`m0cS)-8KLQIOZuzmPSIEr6_zwo}ZRTv38?`($)?BMIXgM963-@xw2GwmVWpVjp^
zwzov{T7YjY^FU_4|Bj<kUcq~@d0W5dUQvmO`0$Ovv%6`5MbH`ws-6{9&!*^yT?KpK
z*UR*d=R_AT>-wfNKGPlM=>HSZ&`h=bO!~lN=@a8rWAiv>zGmCv8M>nAyNYU?hi{zC
z$4jgvMh0j%5x*6&Zh{vl>?h&BBAfZ-!|P#g(M>){_T0dhL$q(bDA=*Vd|lUN^xu?T
z+(~7%V@xoB9@rg!;Y09tHjJnK=rF-yBdqR%u`@ljk)Enc(=%^4P4Gxr1JA(Cklums
z+8X#^uf`~}l(1C>e>;U$ehJZsdA=@;ZfKAjoTZ_n{Hj4&zE3y(sv@De#0`q$sizXY
z_-o_W&#+z^Pk9|e?3?b{Lzpx@d#w1&L-a4}uQP>p+r{N|@xWEyYP7M>#m~Q1d#n^E
z|6bwi#aq9?xAJF-ZQf}YsgJ&({`!pC>QS|;S@OCn_mRR~7nNsYrj~-H2Hst(V1X!x
zx4c~VZL=?((_`5+uObeXwj}9b*YF&9R#bPEF`a$6cL05EH<W6lxwU+E8hqjQyChcd
z#i(8X<vVZFH+JJceJ8!u{5f60C$0GeFumj&U!9v~c$MQ4UTe>bmd%>vpns&t4}eii
zQG6HLxV$iTMeqh%N>o!wIM1)XTtsbP<M{0Q&%*cd=1I%?ei|>UbV`pfmv6=s={r{#
zqr~HB`wSis&ob_~f_Kd`g7rM!ijLuP#Q4iOUC;5Iw|(txo<Hnr-^Sm@mS=L(v2l!G
zw;dBQ<0Ue^bg`Rwb&2AA#cXFb4vR%@m`}UBY7e8LilWHoYBSSgJBivmGCCM0PX8D_
zAYWpyj0K{G#iEiGqLVd}nHzQ8D!SRAyZzF+{**l3&OQX+O7GgL>sD!GTcrW4^0rBL
zUMXE+5q_)}u)oif>f?_|(v4ARW-INdGR=E>W6^INUCWDp%c=L&!vbr2F4P3Z&XQvt
zb+*$vP(8D!ARZ^Gn;;(gFk0?oc;=oixTlG`%vHHdq^-QIvd#1U0$tw_6w}b`Y}bHS
zByFCP1fGIF%cro3n7%n&_oI}%S-)(Dpf2kB*86+F0ZbltRSye%QneTKT|=K#E$~j=
z8L#5)@Mzsi&t2HFq@V8l3%4fS`imo)ZarKj^q}w99t0hfPY=avi(m4Nj2o@~W<hF(
z95#7g9~?Ep9%CMFo9MZj`dnjS%XTm*EPhc8-)(^}i@<}MdGK}dH{k0{jHn|Uwz2e#
zg74xfGlSlx_A<KHqy>2RH_Sp`D6CZZ@Fh`Pc~@a?fO?E+D=<E+q<iy`-%YjYgFG9n
z`b`opZM5`?Xy|Qm5gYxy#U2Fn)GiCee-^8a%zyh^qObSR#%=GP*VKB?3;*VG^kuco
zcwuI&Fw;k8H@IzU^c(Z<TN<8NRQ$4xAgswA90iaRIq+>}{x!2>F;0!o;*92lLbc4G
zzH>LUBqge6SWhvZdJ*&DuK4Njc5HJaY1!o?8~!xo@O2T)MVa+E6TUl5`kGh&yUZXU
ziSfsmQ91ZnjS9lMbEBnIL~d8Yv$?fiIkjUgMo~5J%x?H>fY#Uvsxg0QgTd@@tkbsN
zmW{|JNLoIPfA)ujsi%air}X@g=y{y($BEAR;!}8#(hpD>&FD1^p;GHn)$yI2*Q}WM
zKyly>HWeCS&y^&6%v}vfBPRWAw0#VF*9E)@oyQ}^3A~(N!*j=3d^=qV{kt9!|2A*v
zN6;{i@CEic@o4jSWIG0(Vn?Qf*rTo}$3(?79pt>if>h?)!+Zn$&Ue(?@Q%GD^cVPp
zv^V=|V>w@~FXzjlC47bRA>R#uz*kKR`A)*V-2I5Jgo1B~7xRtI7koEpp3y$SyV<As
z1o#RMjz25^ZIrkXPZ0LS$8P2?%x}owc#hkvdK_kidj#HYbFk)lH5EQmVnsD3JF<wH
z%)d$%^_3dTxs@08%dr<s5m7-|?5U<LmPFnc#6L?m>{sH|?1YmVit<E@W|zw7rINI~
zZW2bc=VQN0)V+BLF>A+7Vc7m}<Lf>ViDLGSYk1oX{AeX|y{fR=?nU!1Y(87euQfg)
z<M24+;FTl?XHNFU$tw6VBkc+x{Y(~?5f#}iUQztp)<pW-2&5MFkq+#t(nu8DM)ceb
ze%Y1NJpQ*8UA9(?u5i0<>{nA&eV~>OySF}Gm2qElJP6thMk8^WGI;u}ue%DNExH1_
zQx$Y8^JrK`q51G|lZRb0vZ)59NtIM+X1Jq;1{!)^{N<QExGEaD?MKm&(wnnmMhC3<
zwzEJRdZf)0SzQ8Kac^uP!OX>I^)@>vVapvQNit5lQGX=K6FQ&PIh1{Bdg3#AC~y1H
zt9xTD>WefmZPawo?$mjJp4&1%)c{}7jRZ+sQBiet%m%`O@e8vUbr;<Aup6~iKFyis
zt*bl+;cePH{B}f+^%gIE9N*331?Oa78jB5llHi;ne)72fZRBgC;AbUIpBJBbf-&$!
zg_v*o36hMx7#H?cI+KcK!|p8jIv}@<mvv#@%pf)iRavx=3yW$MG{h3jM^qBlZNCSb
zX)ddHr38HmwP968)5Vy<uy(1XwyUN3)kn)Mum9@d{7+578Yq`0jCETob^~@7>cD;<
z_3?M#K(MrD2Z=!AH*0V+K~zj7mt)tb8p3c{c5tzI>B=g%JfqKwc$F@UM<t`YqS&y_
z7gP~^$>-9WvZAJ<Xo>mRIVd|8|ANdl<iWz02^}$mLNegTIPi*XqwVbIo|)kk+0l(t
zDcrpO_~^+I<H(HnZ9f+uo%x2%jH<_*+%|nWmVIvE;EHR0?L9oh=2e;I*~z4NI{Z?_
zV)>4!EQiD3Nhe+s=!WSe`=d&cNg-*Ob@kv4>471J-Dr~W5`PtI-*tR6UBwrEiulYm
z{a<5Og{$I@Nq9yM#*)TwOrtgJ{7?LC9~2)yfxnK!>~vs$Isd{R(_XaSz4+=rg2z4c
z<a(I#=`p<iS=?=Ue-zKb|KjiUAU=<N$1l_YJUSg_9mOHZrJdM^%_Ed~dJTL7{*9NL
ze?tF`JH+#M!0iv<Gh+>2>H|+2-}5csk9ZUQ3cnYh@s;dSzS&#KckoO2HuH<{TiZ|Y
zNbv!CJA8sqnUD4E1Ld^@KY8{&qxo1_$ycCj@j_(ZWp2Sk%lCp{J-&$6<NIVAJD8aS
z{0o_S6yH=ku|ottOithz(dJ-I;^FoJ67~odi_>a_L(Ib;3U{YD9eR&C#rhnR!<X=1
zcoDzY*YSvQ72ku$)RJcyq20pra)$BQCA`lbR*qMg^SOaf<9NKNoJTu2s`MxENP8Cl
zSr_rba*mRZvYXRo=7~;YsW?dson=RsGpg|sB>qk;nC3Nilj^<)JE+NIvxu(8OXpU6
zIhpqvvu>`#Z|5J_eh%VqdNbZ#53&Q?U&{LrDD9}8j)A-5%=;W=M~U-zSWFH*O<uzj
z<2n42*&NnYW`{1~IXp>n(pQ*9l=zsxi3ew^buuH^tISFUSU98Wc_{8EdwT4~+v2~h
z^4X)B{7cJjhI;>mM*qUc((k};ePc80fwtjCX-jCuwH+4@pf~-^-GT5L?7R^45^Ejn
zF@H0rK8UsbQs~$IlCI`K%zTU`;l=ch;v}mbPcv^4=yqq&?aq+?Waz!x_8HiRC$?Sq
z)3iCpKSLkgzX|?7fYm(D><E24?+E>IuE&etT6{RI!5hvxzMlO>z2P5xe63|Soei|1
zdHC5RY;B-5|HiYFSpt4#2J>J1X&+;+Df6X$ja{XJG4xfu{209*1NY~lVuRRXUWG=F
z(i@D*&*KC0IGX4g`phA?%?UiV?*WIW&`M8IbF&8iieFgsxn|Jpz;^y8)`#EmJ#XuG
zcB{tbWAqUGCfFJ4?~np)AI{VGAv!3m9>t1z2G8`z>2HVOZl)ve3w?zjWB%j>UPA4D
zKW)8(o_-GBM~CP;$Jm7@up1m>k66=FPgD1s>|%Erzlc}xR+|W(PNAzOOKx1ko|a@b
z1^n9?@4qI>NU>1nLp{a^8cmtxu~C$yhil%%@kATPE(s>Re7w`zILNp45xU+%Zr#I+
zp6#x1NwVxZ_Lxhoyt0|Ob2_dtzKEw!8svdzz`eAV%?@0rSKUTB1oIWgkPL_6Y=__>
zfxq=Lc!)g``c^%HAMi6FZsS9ac@e+R7m-+(6mmHn>m=wo9v{6IL(kEd+?(tk75D+X
zVBC;Vv+c^3!frJ;@YfqyT5R?tV)aHQ#~^z%vR_UX;iL%CJO}$?m0(|=yzCKEk#!$t
zFD}7eKQ{YPS#M0!t<0`JW<#`bLmNC_H$_iv#SRm#*hi$Tw49#o?$(l>W^4p$Z*1qZ
zcA=Kt9~(wjj=|Uz%)ZfwbtZkWKGc?8)I;%GvUa5fT6hELaV?}V**cc`?4DN@Xj-#h
zT1{puY;U15I_fjNEXi8a3d~KEV@J%QjB#vNkfLbqd6@w(i6(BkdU155g1Y8r#8gCY
zvW8=$Oe(Pm^U?XxAPZrU$gGs6*JsmnYAmNY&@i)OBhJUjs|Z?GM(kZ#*$FVUc~xel
zX1<VZ&7;QeYE84CUp5OeR=Om{SofF>yTy#u9k`~wiHFNvV4a8UeH8SnV@TA)oHmxd
zOwW#on_fh^o@HM?8y%a6=(A`<hp|B(#7cP#Y5cF=|BdIdGmN#5!Dml}a@(Yn_3$IC
z@CbIkIE*L0V@h+9J$X!G{1f(sL(F0vVh4;p=v;g8WcClEZ1ZQlTj$?cA5Vtd`~W*?
z><af!J%kqZ55ARcH2x>MtlB7ir+E5a{BQ2Y^X9J5U*Klt@G~;(54=&@x|3i9<5qIo
zi$pZ*?G|<h*vc-Cza!<=GRFTCedinY0W<&mThRnIBOTWfV>MpZf*l`L>Ha(Pf}hb1
ze#HmiTC_RyYPT7mYpZlMkKdc|inalnwH2QZe<<JeNTiMUk2YELi|+nH&)9_Jc{?+v
z>+zmxJNx~k7)O|A{YBybgdPod=?wha{*KnN6+9Wl-=OiW#9QP~_ysm^Y%B3|yFPsS
z8ee(eNk?3b@8Iw8sP_ZDgTKWe-&#E5t-=S$Rzkl=16qZ4x)FbTHoLWh{mXvD2k$y|
z&e)7U&fo9`_Xl%bf3j=BW_%`^pSjiSD7TjNLR*#dM$&8nM?a`G+n6T{yoH+Iz4d6*
zJ866Kwi<X;-Gg83oyfU8qNwYl_joKk7XV*Cpudo`C-9kW9?`F3uQ+R7&CPa=ci!8`
z5A#&+VL`W@^WyN;n-wmRiGG}&*#z5P%hvhi!?u}I*9`d9_1Oa;mHAUu%CzCGUFor@
zWP~?lf$L@_Z6-b2z8ATaV=ndp%gAUfj#;7%#IQAbIoTB^54(JqVK<t5>}ysS>ti8t
zwd}gLSw7oyCqH{Zm0`CXvocgxxN-5a;)JEyov=K2rP+nGyf|73ab4SMv<lvat7DC*
zgty@u?8HzO-d~12hRUhD;@FGI5vwR`qiklV46CxMuy<)8W-e^5*rZ4a#;~^2LqTSh
z^5O3|yXsJc8H+4Pqr$o`#Xhj58Qtb)E-H`ivW0u_m{l~VO3R3qH4}TV<zX))vkqlY
z?is+LjbSseUytqoSA^DyW0hKA_Et0R$u<{JnE93r>^PDQKf@Uqvl{Qtz^WvVT;kYk
z%dFE$_|}z<fmit?_CmU?|0LvbFrRc4>zJ+hN!HUfbn=_x)r?l*-0|r5myrE;u!o(-
zk|$ZOoNbQtg3gO*C3h4Wj057s`J3zT-V4l&URNHbV<h0K*hUUXjI1uR<H~I){~8)j
zyiqvwP}kw)H}C*|D%>UZ09^ebd!+usOzm#<%wOT{e}rD{x51Y-g}yMiFalbS_u6%M
zXb-&itihlC_voAJb^Qg8uj}ysx(Qu-9o{Ba;<IN3-hNFpUxjDcU-%MX9sVhQVRW?t
zzPN?mi?+ZmHsOnM1HSWZpO>ACUJRyP_{l%WxF*;Gb~kUglfz#0;oljjZ^dK(Klr6x
zhs3hkyp6#551eWv_ScPgZvKwZ@Mb&@{|q18#CT#W<M!X-&)e~=xtUchKY<;?!wx)!
z|3jX?<MaPdWaQt-tv!PAFYEz_(H9ROIkz*W*`@Z`g|z$w2_5V+ydGblhnQ{L&3NQb
z_P8-AwgveXNWLBHNo4Ts6!d=*e@nOq-aLich~PIy2V2EG@6TiI3wNqHz?Tn4*(c#R
zdj}s1t?@RVj1SkEpTkCf37Sme{ucYeB;euyn(nTK{UQac%w@Auvs(EY`(NJT8=@3=
z@(sO<5-$bX40a;8WZtfA=E%KZ>l<t(wequFDq_&4V)b;<?8dsLWzTlAVwn&0%<LeU
z3tN}zamHh_!DCaiZ?SnHHydmWGgL9+C&3I$D(qr~LVH=@A3FnUM>Dg7MH+U+3sz`4
z3Xg#=J8*nkx#(aG%ft*<CT4I_GbTxc-)*y{rxLF-Zd0818CVaKg;`OvmF2+}XYwW&
zv%zuHCJVEy_t)LzV65Xa%VV<Zmc~0a7n>d{TZCPg)3Bz_Va4zrcEfN2kKugRU~?=f
z@QMW1ke_26b7HtN{Uvt34D>~_ab074bA=rUjbrT(SKFR)FDvKEtYf@_h2o-ew!KPD
zGrB!Xx-*O{PqQPf?f7t>Jp&ID>nyVZC+HWunA6ya?)R5M|3>rr7hA+Gc#g^bf1%dj
z=?i~Cy}Qukg54ojV*xPFvn$aAZU42+<n#|?=WXo1_ZRx&F}Q^72lWp-GVR1tvzL8!
z|3RPn6F%@8b_H9<Z5FWK=tW!6YPO?${S)dV=GT2I{AwHFKjW2q9lpcXU~5=Id0XLY
zTUammJF)*pTl+V(7;Pe@@spL|elW&&f5dyYX?ttf<LPI3+VA*4Uya7LE%dYf9bUwY
zw{FF=@fN&}ZARzZ9PY5albvT)!My`3<Ik+#+sdwHJK*KNp>1!+it-0Gv47ClcCgBC
z7aV45xEEYtH41i4`w=`_nSp(59o~PpQ{V0ECASu?yB$5(zO?!Y?erJCtN#QC{(<+a
zh_PDF=C6D!n)M%Oh3l!$7WUit0`2uL{7G-bJM~ZKwN`)g-u9E=_#97ZYtSTDFn_lW
z|J*-9Bj2DOe-8$}XSb~%@GHF<_*R3lHF$N~$X*$%*<)=Ldv&fx<Ncmm1U{%&;aBb(
z<d|8VR)oH`SK>2%BmTh6-`%%p+va_66)>;FEArP!zfI)#J#m*2Zxvoo*V0};Au$)@
zS8g>r`4%MWPrzg{cs+Idj@6pq;5+}mXFt>Zzs2A6Dn<(Cp>I90f-k<-@&7A6`+i{W
zyfw(>b>Qe{#uw}H9=|2@SHBUdxrTi=e#MgZ6Xk3{>aPb|LA`AZ^mXWeKiI#_<mZo!
zyMAO%+%L4y7E0X!9c<yd#BJ=N^9Q4fUy;avBh&suX4-ghBkOcb3;B~#oAsr@cXzOF
z$9ld&*h0VCj%H&P&_A%-?qsaAjj_jSMylKB@qaT~JBsAo%^r?{1$0BGh5UrBvl$Ed
z2EKOK2^2r0f&7ZxJ_yI!21nV&7nZ-U&q~lk)-kFveP}awWb<+U6+L7VwEqjO`6GS+
z1D#`q`-9hreO`VF_k&)`F5KTj<3Hdhdj&h%EW;c2BK%5zjlby+m^WC056DmP1-KN?
zn&z$XlhC94ay(7GkGJ`S;ZE0!@#bj$LIY3Mi|`lt30`vF#-nuLUH3CQ5HDmu@Gsog
z@NK;iAJgyS&-5)k^)A5Usm+Ve!)xjLO7mQ}ANWi>51PNgckzPz65e~~hQ6_1#S^ai
z6nqDNrtjdTc@EEu^mZPehF`{`?mKwKpN|jXH+Y_hckKmuKwiZA5AdYFKsBDDTD^&H
z)pvkoK0B$srMIu(`OrKhF2)P%o6PQ;KkeD%HwzrRh7Z%X@xJ{sp0DTN#rq9>FVDu`
z>c@BwT|_BwxzFS0+Pv{Dz$@<@d=lGk;=vAYU*NOVys^&3*J|KXJMaoT8;^*u;C*kd
z`;>Aruf}hN{$b~{ulgdzdy8j-a6#zl^-X*>E~JbPmFw)#H};cwmNp;H&*P2wdA!uV
z8v5*h0q??3;}3coJ{(_E4%6@~`~tp#pT<|U-94(iN8BmyB>W6Mg%`%aOYe*9pghHW
zIP|V-{;((Ead$Fa5ue5@;p0j@DfH+2tYVq>VDq~;3@?mN;yutj6b@0`A^7SWqq8rb
z{f4^3IXdfUl)?t{c7WT@9q9JQtKT4{vAZ7b2%UZ1k&4|9e}UcIo_O=?jYq%k3hC)~
z(^Fr<d+X>%oc4O^sS*b2zY}q~5ZC<kbymuLZaebm#B*0X`E^yQPP((Sow@JKb0@c<
z+uUs&`U-4Eyw)nwyal$!lVAt8m(G@MQ@4%cb=I|~-n4dGDQ+wL1-4OW2e%G>1kI~o
zJN=u_!IpY!>6#PAya2Yw6JbYu`*pxSU`NGiuKQMc*F|Szw*@}?tb}$-+f47<;<2wm
z=ntR)zWZ7dRvUkU=7X>qe)w7|WfR3{z*8GNx50Z}L%nZC=>}UB{P;Bnu6D}3nf~ht
znzr~CY^`f+g*C)`U{ibn*3o}cd>^*cSsTBEweaxQLb*4^dtP1q=ULfRRC+yfY))<J
zC`}vkYo<Gc)cg)M#VcVW(l*wec@?Zrc`eDe9v%-Zb`#~(h&r`YK1~H(TQJxJJXndf
zl}k;<ZK<-V=_&A4SUt?6xgcw!xUHy*<=7NIg>CS0*cRLb9u(W+LD0N9n#aYK_*S%Z
zhS{#v*I;Ri|HTgA+Po1q0p13BUqj(F@#|<fvO0IbJ7W{lHo#9}3zcEs9vdj7)wHH)
zpb@myz^#OTLc6OE+;yOidQe4UsI7sh#5^}v!Ea$b;<N?V)?)R*qhY0y-qwavtnKRX
zrj4-FRH603X){`|A$N`O4cP#XiRNRm4jvrqD@`4|DptbRVlA*-kNP&@XsJ-^JyoHn
z25v=YpsAkggBfe%YHnq`H8!EHHSy_KlN7aquz3h|1=Xoq=%cYZo)$~F<y3MVUCsYt
z6?`$)z;mPd$Eb);$nyHHs~E-gUll)+mGp1vOX)0x&&JYtY%EH?Rmib2IS0N1tKyfj
zyffYz;S6$yIQ^ZG&S3qI<~mCMqx5EoGfw|woZ-43uCU>H8lw32Zm8~tDr}gJ5u~=1
z!*q^x#_F^@Mv!tCA;H}ULPt@~aPkb|O(f4@iZ_Pmk-8tF|1p#~j#xqYL-jO9#{|V0
zqx<nZjnX?yV^@o1B|hpr?L6c>;ykSTapBeCj#b)+b&e<AP+dn+;%JTlf{_Xt2h>CL
zJYLTe^la}RrrePsX2wzW2udDCea2D3C?GS~9#Tq!dYH};ItGLBpf>lhV<n9z%}B}`
zMfvw(8lqzirHvr%2rxJvxC0!GbS6=|Q4erDG=$0i2Zs0@;Y?PH{*+^B1`;+@IS$r2
zl(w*13?|iJ-i;-ffleQ%ubvFIW5YHa4V;6?V;Hp?9oBI;5C?CEP?LcQA4rS$4=H45
zSo&bXhmyna|Ku8AYA`f7K+yFI%Na!YAo3nV8RK*e1xrCr{mI>6Hu@Ya>|6VdCUivD
z#zVo(P~rsj9M1oUkS0g)b`<pp^09Jzfu(`eW>i>fgKj8T2wK?U4<Oe7pJSk!@wDU^
zY8OBjz&29H5MgvIP>u}K52i;BR86cu*>!l>LL;~i0)ipL>PLM>kcZLGaOi1p7|U9=
z4{7`87^J)g0CE2ZZ9ftk90FuRxElhs1T8j*@WIqHz}zsP84kscrFJ8LHK^0*Ft4GM
zX*7GE>PLocI)dKW8w>?JV;HSESWpcJ<BogK5@SLv4hd;L=o!N(WhgO*hfgDkIh2^A
zX^X*>J`mdJt*0J3x~UEOI6Zakq5obwy6EW3eQzDzb>B;8PeKOkt{>EA7z=RLA2<g=
z3%&JrAh8D#ub&RXb8m7S%yl4G@25Dy+rE0+hjQ${lft@Fl9e}rT!MBo{8<YcR95D2
zy|;Q;E&7vVKk^s`#6y5|AR&FJU2m1xSMj>)zdzyKDXAyd-YU5}@p>qg!PTES_952+
zde>R^JrtuGwKTZ9>F5*YZDIZO9MobUPd$0lE5ucQps|t%(Z_pJJHxl(w=a2Gj)obl
zRZq&Z_UY_&(0@mTbkW(9_`N8%D{yqzU0>bzC%>M+GJqWWfscU32k|_Ja!tDRre1yZ
zzBg^ulUf8g?-OD(=y?|3VCe#t_T>mLexDBdfUo}0Z2yo)*t@|Y6n%8xOC|N8T?1_O
z<KLj^O<6sGx`%4hGlZuPy|gb>7UX8Vs6W^ZavmJ=o1oNz<TF%H!;l06fMgKVGl>2*
z9Ij|Rp`Y#tLA8CrT0p0LRenFHv>zC{kA;4;bHA|OLEZb(Uia}l2<Qy2qv?CYLcY--
z?i}>GL6kh`0sj~n_S8W@HYDWh{h{){dJ1?#P+nhJaS-(gIQ~$|8^-?#>Uy7FjiHpm
z;BzP~K9IaEWlvgaP>3_beb8$MK@I%~A4n+!;3$Da7^GGi31=LsR70u%fRGmiPXlSK
z;UT9U0;d@nN~<9uO<0Lzppu~>&kS-L3>OO|&Hy;z@KD|i4Y~C&!UAgR71C2b+OW4`
z-lu~gbx^auA&hn(@Rr`RY9Bb?;PCArWJ+&p9GoM=It3Iw9O*JV<kTbKp!cPD&=x~O
z2@tgQh)}8pGG}<$CV}J`NUZ`LU?lN|hcb6K`q2oa;b>@dymX|IP_f;Qm4-D=@^F&#
zxb7ZCf19XdlKv;_I#IDr=1<Yn1mao9qiA;Hko1AB_poA2avpP@Q9e)ToTBqlVn41t
zA0uRv^02Tc^=!GCuJ(xXm_$4)H^^f$;g-U5xknZ6AxfF3+{cr{WZv2vi~FeFnf5o1
zx;>2K9D~f93gi<>^AK>4SNuTF4eI%*j)^MGbkv8a_c(Ac30wrB5397toTs=>77UN-
zv}3CCqC%gN-uslop9QMPVa*>_*c2U4tF})IBTp;sW6txWnx?o<>+UJ%Rnl9?3(iZ<
z4CguLbseuduQ;#i|3!tquJc8`c}1Z!oS8c3I3GA)INv#&oL$ZtC((^{)46f@{ENXm
zwRuJT)7kF)rT2f~HTA0EWYtKdk;d@@-I4Bicd*-AV@C5OpV4)kJNRNuaBjL8+`<|u
zb#SM+AG*J}H@tja1HRZB?6vi3dpX<$_g8kbvAu}qxl38qvWq>uzjYV6&$)dxTC1fI
zPYsQBY=qyBy&eWByobhPCEScE>7et6^SiSHkDCU44t%=ja<d73^MQQ?udoO4dTD+y
z1FyLIcs`G3>m=uf&f9pDyp0#fJQ{6vb{};YyMMd4yoz2IZ>aaOH_Ln5d)|A+8-q8C
zf?gc!aDQVq+U%rnu{+x%>_+t(`wVS#PkS+51;wB2&GSC--qO{+EUqX_c+9=uW=Hz6
zUOBJ4m)}e4UKS1(Di^ai4HQ-%7j8bnDsC3&PlS^J8VeS2GrMWrh?_~H#floE276C*
z(`dGun_o4#<m^>j{pPH4zI9gU_=@W)o!{%aMs5AGvtH*qUDrB4DC|2OYt+hzoC~h!
z<`;ImxI?k5+3s9Tu@2ZC4x`<fs_Rbox_K3H@3^PkZSH*c3AIN9y!jWy+kGMBkl)QB
zYDn!y@WZJ?@TPUMD@IkflW68O?BL(<_0oKIww}#iH&U%@yLJr3D%MD2-{Q(8mui|z
z^wm=Dr@NmDueMr#KYK|ocAsUBl1D^^y}(&JEESamML{>8O3bJK0)ov(&?U?>CjLXs
z<EZ(NHUFeHom*}U7)>v_$%mi)qU_YrP&FH%R+#L*!7fEVGDmK6^()oFPqG7wl{$gF
zRTf|a{{%0IPrD<8!xrosQ3j9vxpbsa@5<n&(lwi&^3i&>|3`23411IvUZ%No+2!aP
zzI{K)I$m4%X8X~aUHuu=w6j{Hl3>iOBbVxwOIXS$EEUjQDdE1f-qypa(giDH8>}Ox
zg^esK-*r7|9IN|G^q9>0k5lbq3C*sU)s$+4=xqTz*B)e@>Qz>N9CLSzO21`KyE*LZ
zH_?4qun!X^I=hXrb=ZCowtq!!<?({r`J7iwz34?9PkO_=>YlHfy|0>%c1Nk^PpS1k
zW3Q=i)Q@bpy6%EFup+fqUwDL_dfsN=#UXmvi2WUMs?MqKQkq5B%&Iz=htoJWt&<{3
zORY96pgPx8{QgS+rrKr|^P{_1`Cv073x&&}qQ<JiWP0=aDq1x!vRCmVYdq|hd2EGl
zv$MlPzHlFfN;>MhT}7);sD5Tae_z*EgoU1J&w7F`ulUbhClUYk*OYHEyARyeH6!q*
zhZ5|FbA3S^>)g}3h|ctsm`?S|rZc0SQ;S{`*>~Yc=xN-1!ke#Mr4tT3(NzZadMJ#)
z*NW_4(pS_O?0acn8Gg+?pY8c&dn-*)-|oR~F=g0Iqkz&D5Y*O7I*H=PsBIRqkFm{H
zearq~Z?e~pStRRWy~?A0W!_?KUy6+EXJI>s)L_?{k)nv{>;(5Mvs7DIb#jump|-Bm
z=2AanXUj*_gGRHj&Is}Mhup{5*XcvSxn3#a-J4!k@yqIb>t;SA@_MN}$33SWXgj{X
z9qwfM4s%d8*SS*nUx=f;pqdX<YqU`7mQ-tG!;5VJwY2T9QA70IOc)rZzVwuO^2e&_
zFRUD0&YqA)nZ4D=%CN6UCLQMG*F5Z+FWwko-2C^ZGXKB$@3nrEMLAa#$LJ_5O><`n
zmfh+rxA{K5fO$v|zqj=XYuQcsZRSv(Vy~!2*h%nVVXd!Hcg4zS`+sB&Y4QfUM_kq2
z6;Wm~eN=RgpWf_ntE_nLO>5qOO^UIvhV2q@gIzMr8}fO)F5i}PmaG$3*1y$ADa<2q
z7V(WjSU7DKVJQ1Dj%A-i+aYQIHr+;|jY{y+Y|yBOSLGBZLD-1uKgE18o1bFm8t-E0
zH@QWRRn-f-LRDkcL!N>vt%OnP&AqUjS5g}l72nE?_K{xcZ(83|T?6mWF$y<sl^6fR
zdBJpD_B^sVoJs6qWjj%s1hE~PhKiP2Dfa<-o}l)y>j?IO>MHs+J9b(2S;?t<QwsyB
z%=5D_bS>Pc;}SaxoO`gR!D;p@F%Q+Jd3%wa4UVyA!(sL-IERn(c;%52;8(dCcg}+>
zEFq}N&}&MwXN~c!9I9<r=q4L57+=V&cF3(a<?y&%jva$qs!fKeEuLnN&rkRgcs{$#
z+6?Er>=iavb?b=@-S#Z9U3Mz6_l%XEoohDbmkoKC6<^RfY4f7+vx3;IYbi}_W?q7w
zh)jwWWp|hYf-RleAS!xFQF|nXUd;F7FZ~Go$UNr<nw358!{5E(C0Q7?)7sMfP1~L{
zCWDG&|1QstMb%VNYvzmUurpIlyh;}mCbFxoGbwgjd}^nH&*!KAwop5E5k(DUX7EM!
zP<xJ@FQ>Dc=4`&5Uc~N&>sZebd=Y2!*S2e}@jsgbtD&+?a*7VjKeu{HGP{FZ!jJk<
zwXpfO4|WGR%4r_#&5ym+>z-)S#jAF<usyQ~X2WhSdZeAkd2+#ftUYUp@0i3NEKWB@
z=d;W>zs-(z@3JSW?X~s{dyg5v9YhZ_4bOHb>mg~@UM<s7T(}}L3%2J|8EC2;T)dDl
zmP>Ht)_?v`zGoMNnFNz@K=a*Qlf9d4N3c%HbqKqwJ)%;cU{}?l>QiGBYR52kMjN32
z-h#NN-t?g#*{r6`O7>zF(q_jRu!~h)c3CQ*GIOZx)W#i+=ZJC=@qKQZplRijhj?}m
z@Rvr=#Uj58GH+6yIgonHu2f(zC6hF9@HX?uo&p`-ac(HzTS^@Rze%k)`OvbAmsC~_
zZD*|}!gfRE8#}VES_}QxWVbH!V_r~s8%1igK%X`4l>(m)_UJLc`WM+p<^VqOPqJUl
zS!$4iFZp!p8zxms2-51v##X{=Uo_EC!lUgMIEh{No(XrEw%vMd?Zd}vd0R&?pP6=(
z$}cGPaHZ`lIBTOp+3rs{)RM7i3mM`3v8u6$^vS4RkwtikLk{Pl9~-Z!&iqhC=9FqM
z^Hdsr$@pt3#WWB05%^s)I*xhCxBltUB1tMCn_^_3Ow+vcz?%yp4J)u?RB`x*afbp>
zcP99AjPgoETAgR#gkYDS)9f8_g8eoQvQNQTeEwflOl!5&f<F_oESqYOSM|t;_xX(G
z0bi$sU;JA-E`__o*xn4g*_~n!`<&RGC%f1|W0&3q`&S&I)YI&7a7kqbyBEZx?ccE7
z0YVS{u_`$aeER;5Smht=$Y!&j)zzN0q|<azuj?f0v2jUDW^?O`XElXq1v9$!*_Evh
zbB{JxR|+X(vwDTufy;K@%7dKE%?POgBNW?n%=X{19mtGk>#-YO8|J-RhV%WM)$=;3
zueH_LgY^bYb=R7?<#vL}VC%prt)-x94i(lx7puYiY!!BgE6hG(Il>mpgWhk{Ql2@;
zTFhwHQ!ee<q0n|8?5&>PmDLTsSeek3xqX`-wi(&7N@shel|+V_Bn>og(I>k%1p8*i
zt3O>s^GFfR*}e(6kcc^SRupu>oNQn02)3W|*l<_RVBh)a>@xklju+YA(<J?9^u+;!
zv9HdqtcqyL9DhCfU<LM~E5WXBrP1HY>Zy=$VRNt5bYDr~^}$ms)(bRagw$0v?8G{c
zp=b^U%Q#k#Ok+n-+ei8t?o1XxCOu}dps_uyCoA4~amC@{kpo!$(VO)cwkE=6s~a<t
zti?)&dd$YxVKqey=*m`l^n|bXWF<#1M_)trs7)^}rFP0n4^Pc*5vgq?0jIhvT24mu
zx+m=VaIhHl8#{6^0?#a3%My+_GSN#@!8tTOvYj#Ltyjd$Y?PA3o*x(3rRggBaP3F8
zIms?&7umhz23q7brL<iwtVL}njl1lv7Hbw1Yh%08*RG-;1$&8|Wfzg->|AzT{V&+<
z<GS*2#d&PJmR*#QT~Mb-zq5AB$NmzwyI)z_(6p5j@S-y6Io6A8HoPq3vV8O@lRcG$
zIiq(QAKNZ~_P&b3iYaYrcET%2T;n>PaG^1m;JC`}X=m7HWuFe)3&{2u`b}ERHg<*j
z)!FWB(XrLpp|B0k8s`^XH#ln*zDd`0&PL~F!q@A0o$h|pVK$a^db>f_O-iv|>Hk%3
zTbw_X<DV+wS8=UBl%wruWV<pQ)LYvH=ug59ggevhW4D_V?4@QBG!Z<<v0Fzb;jaiX
zs5pBi)`Y%nCC&Z)N=J!0O*gikWGAC}j9^8SNvRHuSzEJ4qcVD`afeKdFk(bofs{Cl
z7JLG{{Kc+JJDlHzncuO#Z59qT>)0k7{H6Qt?9^m?X#ErJZ}mGhIl_KsXV|;!2D{wd
zWoMPxa2#I{Ze$#^DZQly>zPd3n7|sXDOegtV=Z}}J$hecuixj`<Ms*m@Et8KF^L^q
zN2?$A!;%*8iFWLh+LV<owb<XYijK<g$)Y+cVW%-Yxh#5mW?|G|%7Ru`Ks1_LeJSWk
zIfS3ASaeL=E2N%fdTI>1U>fwTSS&s1vGmw}EM}cB{Uj$+E+=Cd)7J7aPACBF=0-=e
zv3yQ6-AuY>7aZBqa<Z$pnFT2w`hZbx8l<$1VXTj5MP6qJ_jF0at~Lg#t5UP*$@Zg3
zub3IwfhLX~VAmL^$V0QRBaS^~GBUC?`-4xNGcq2{gtn0h_;O)eGyS9lV~#RtY(>$m
z46F57XH%UuWsO;>)r=KcjnML&AhDV<(x{3aZgR7#D7XapFUM|`#gJBo(b0{IWv0e9
z8ZaBE@iL>)yNtwBf?a{sGwwiF5k~8oRX^L;C%qs}Wus)}l9y3Yc5s}RU2ckEEzFJW
zEU=;2-le73;j=tDo|;Bb4(?Lr!L>4Lnrs)(s*LW+VC~CGUU`x2!3ZE7x_K^OF&xIw
zW*$2U#hTR_eb%(%YwY}Jqu-nSU(y-upL81g^-*@Ex_~Zvm>r(Zpjqu_KdK|_%D6k+
z3GEQOMeSjqH{)iu&zbe#L)eiHu+!L1Qtl0TkJ<Wz9r2DU<P`f|9cB-$6X?Mg8U0>j
zU$4{bw-xOFW#t8X2_9$8;3zRJFj7i%60kVlVK1X}Sghip)AYi3PV|!e!hbL#uPjX8
z-%qF(ysQekm928C!ydGikc^et*R~P5Zevzb)xhpp4l6||c7?V5Xp6H`QEqljEx|6Z
zb{1kZRv2BNr1CR4TaI0EYwO>5LTPrct;JffddjUT>(^?qzN|4Ewh4PJH$!W%6^^D0
zHj;MOob`8g*>Siz`yw}IN8_g9s>XJ##_Y(>%}vo<TCnr7@$7c2#%n@7ThdQ#g<b>p
zF0Lym8Y1y3Q@<)`tYzsV!H&0;LMdk>!fMcP33j0^1V!iNo!OzwptqSVv%KyrfTi;E
zJ;QRPa4nqGHdtd<Mev!nWZFr?aM$Hv*XZV~I&8t3MQbUmVP$O14Z&muYEn%l*e=2~
z;jyLIfw&Nmm83R-t-b(om{bq;t2Ldn7~^KM0%Sm^$;qy_xv<d}LEf9(D-OS~e5>kO
zDb(}IfupKune`M>9}ZKI9$kdeiotzLp;MSvnpUNj3i)&?LbAbma<T7jUZ5+3<)Se9
zNSScmUJdfCtJ;{2y$s{Z0>r4o__YKu7DYlAVJF{WjGc^c*f=VX0R=)`Ew}2L6&`Mq
zBi1;XM!FI40n@+C_LR(?mlxP|Hi5l&uP`pQU2Sg>-^Qj<<ANpw#9vYcdKy}Iu#ehp
z=PDMJ)QrBPNRrIhob$pL^Rk0*e#X=Jv0)gbxdeHB>`FP*M!De4xk7t`%|K*>*JY(1
znXu($fZqi+oD9fOOP`&QNJ(&8EF1xq5k@NNsW9zSO}MSaO4}y%^M;`WX-!|Ng+^@@
zSQ2f|bp9If>=OFV&ED1}Y3Ce_w{nB`JoEya1IdTJnGsp%qXkNT)qez>MM67+jT0|p
zvoH+b!k&7|_N0SH-@+z)k$r!Yl*aa;yAkN+$Y$Hq&8(|gl&{(G16*WAikZdSBxjMZ
zN9GfK1XiOwyv?f|vMSW1Y&Nuqbl^4%xDNJq&Sf(Lj9z{0m%+@EVcx-}n~u?Q6m29H
zUEj3*8|-Nu&rXE4C*%En6@$5ji;T^Wv!7xxXL_1_VUHtOPAbMhq{w0R9^41dKNjwi
zd6ZouZ70uQ_tK-1EhpK}@fa4g<Ba?dJlLW35?bIn_V>Mj?7juQud<`x4MJ{kZ{rD@
ziHR`siDlP47hNdOu+r*Gg*`kyI#6aE>5=eh!DCwCBztHRGc3o^CYhkj^k@WejD}4k
zu-<L5I}5E*6n;}6<UyHrmVsUigghh%Es=+7ZpQQl=p|Vh;~JMWn?fOaQz<MuWf+B&
zgJ;;@;#Cx*CfY+eG>%&An_fZmUrI-HI9Mg<yCS+#)lfI8P7Wo}T+7jS@`%S-d3mu%
zWyKz3k}s1W%B=gM3Mq^>l7k*;I$RpY?GBWb7QGL5Ip}}s%(@@a@g1~B2h2Ngm>|S7
zn7Ggm7E4=Xf_r5^A1%ndnenxJ;5HZc`RVT^;E@#>o!buVbybHv=zc{B$%h5F1iPP?
zV2Adi>^fMGS*}v-M_3rST$+{DC6SEfz_m$`(s1YUthufT?y8{01+u^-T_7W>ATi2-
z&A?VtAzZgzN)j;83M%ui68p1PK&}*L>{$|tYEq#fa>!;zax>}-wBzj9^E067n9h@q
z*}hmCDVvUpR_fU7iDA&}p}Hn9n_?W=xJ;t1chp-Fg>_q@a7Vqv_|i?Yr!xLG-gJkU
zcNv?<!>cUab#}rG?0a{`qY^D|PUB<7sjeYE64mDt!reG;vRC;v_EEnQ&N!t!SRG;I
zrnqU8+l^ojIT*bGIh+%y?<&{3SQk>@ib=NjI#!B+r`{sJTb2%e*LLa@oY0l=fMnez
zQ>O%Kcbys~VM)5o{EF4>7WSnZ%s|~x84g<V9rjcY_GLdw-sjn&G=UvglfymTZ-*;X
z?xB;idndB-9_?cM-&T^?-kdf^7G)>Sdv02BpbX6Yxp0)s;p}Y;)|u>~d`rt1D=Qp6
zExUMTg5P9NesSo(Q8<(*IPTD@iQ&AS?UQ>0%g9x1FlWL&w~xY)4@);c#eTfOYL)}&
z+{fAJ*m$??y?g?WeU4pQ&#@Qwsc;webDXwQ?iEHBXPj$j6xOD<X_0$`-)7Vl%U+-v
zvEZj+&(k>U%UM_%l!Gy3M#iRD;HH@wz5C&KG95F2Ss6JR@6CmrjbUffK*tEMk%`e|
zI^ol>W*pY^g=}z;Y~-Ga(UWm;FIctUW>D*-3+G=wW@R(z-$vp#YZyVx$cW`44&EQd
zT4rsmF)Lil59TB2V=2&fKw&p{z9o#A1Ug55xo%c!X1y*VnXX{5xE1V5tF|-BHCve3
zVy?0uuF<v2&auf@!cqjQ%M5)w;IjMFszX|=-nLV0W@NQVE2EXvP)!=~$UIp7b2CE9
z&sZ`i+F3#3SZ={;hfK7Jcr`5%Lufk2`?mTftMUwJ()OCoLX6C41`hGkhw_j4FTG8J
zrf4x^q2bKPh>TbpvViF{th>mE?8}3swY_6)zQ<Dv8_{LO?r3w$xv5#^P&>>Kwx`+M
zbMT*D?GWr^Yctm#wx;W}!X0?c4YaQtw8IrF_|~V-(<hFFbC3Jk$9P}Z7i@>}qx!dz
z@4xJ_ZX?_S&R-hM+P>?5g*(05KHEFk(R>#cs$j431I%Ck8}8|S3_IYV2m62Tf3TnU
zVRqR*!P6;bKTn5qp!?YiJlJX4N(**S-yOc&7l!Pl*X{-0f7t7M50LK$I@<+&tM31B
zw(I&k`_c#Yww=`DUsk+r<$p(**M7ydw>uQNA4m_dm-7MDVlNhgU?1y~>{xvoxK9&)
zl)9bc?b*;$d!09D*iqW}#$_xIr`WUl5<TX!{%@!)&O!Ir;2nu@ZPv`7yWJG`jFCi3
zpk42>ud%HHvtDWAju=`$78&Rx74L@oDf^<6G_0_2=qah_{XTpphW?)_Orto=+L_e3
zMc*?mJc${jOZ3$E(8hg(9&Oz48Y^<HL0uQ9&l#*M7kPIQTku)%a0ZL`S+H>$+!znI
z#=hNG*v0#@!mozofQzKPhTY>lQuQLd<f>py2w_V^_T6EnPb^d}S!5DLJR}tyA;O9y
zM<w53wj`DrvcMV}OHXvr=rd!jOOFnm3F~5Z_;OnKa6Wi$Fq+GYW|AEZ(8kOb*SJas
zY>~y$%8H`97DFd1fYw-)S=4f9ueM^QfMVEKwjlHN#juwZMBgljepZYzTqVZ$<%v}m
zZLKKz<z&=Xf-!e)$~E0OALFu&57uuPzsro=$%MTz6B5?$d}?lzH3NJqE7CVLbdrhr
zP{T$PX&q&U?0c-{Of5RNhpdP))9l;oRQCQ3o^8|+?9gpi=nU)u?mie(c<hs%mKM-h
zL2a0peX?Uij_$KwF0&h_yfPx`vp}PkE{(1KVpXB75Aa#T;!xTRlM2c!6|=diLu+d+
z{5TaMSZbNe2}Y1Xx|?WPwpJ_+JA-FYNK|or;@xE~JkVBRncq#r${9!U#&ot6X35Pu
z>Y&HF=v%j}6m}Dj5azPeda7_&at}z8nAP#nilW#m6GAz6gHmt8ukVm=47Id*|3q+@
z5g2^hCk9-`8BGVJ+K%SRIkoB$2YshOLZ(H|q-9;)y|5M1pc|w{%11*kkp=z1gVM9G
zHYC^uJ&w_b*;vg+p9YP=RtjbkmBxYRv>|<&)b+w$&@&<j)3EX`Cfrj!hJKcrk)}gf
zT3SAaS*yFM$1QrSX;F8W|4KoRyot@++9eh$iy?I|x=I`3$Y>`5u42JkdTccwZ#{H^
zh+v8`6CVpzq@{1ChWq)96f&^p!T4pm2T<9J;4Q`rci=P3%F&vpZ{KA;-8Af*iXZ5-
z=@{V!dW;85E^TFP9moFi5qNV9_M!~*#0Yem4h<#_{G?%hZxrfuLoBCPyQHVj#xY(@
zO;5XywtXGCjKNla&-7qXTXHbor006T=dda=xQ_&*5Z2(Cjl&>KWq7C8rdOJ@!3s)b
zO)6k>ZB4JujVfI_C@X>%nwnmn2};WX&k1tP6wYwiY)Kl%2iBvqqQClJ-$uvQHZj=K
zOlLHx?xMFOLkTySk4;7{1v=&pWKa^LE4wp2@fwoi7Gso4$f-N%I`QF(sYL8Fc7Fvq
zcGK2pDC90{X>PI}G#;61yetWA^rmUMj0+!N4y#Epg17!1rzb|BX!ZBysRuSA@Qzfh
z>`P{JcN-4iLY2{=O<2Pk7p~ZGp_Th|?30I2`$s}6jmLcyYl2DhJghN}VxNfweTgFq
zWu=Ag(}prFSf7!J{uzfP@UT<(y3!M&sZ`-?cP6Z5en4&5B(p<*X&6gnh90wETg}Lf
zS%z@UW_nh*WJOEONFPg0nW?~4EO0sSu%H(Q+Im`gum^2LgOMvTT=+o$VI)OAyNx9l
zo^A9HuFp(T&%4RW7T2^Do7GpkP(q>cMBwz$GHrevt;P>pmoo)k?S}0TMOH)@@pw>f
zI!Xv^y%$)Sd4-YvZS)}<d0$|T{wyQTc<D43(QvMz%Uoc#$HtInSlxImTn~AURehJF
zF9tKhiHdbp=?|h$9Y;4ljb3?DcQ%)F2JP`G<J(~7_Y`(Uvk2Pt5_4FWSaom`4eJ#8
z{&iLz7_13MoFu)o^`MvNC$}g$fz_=y(5sT^7uQ&yc$fYbtej0GH=Dh>8tQ#k%gfl!
z<I&QtU?Z?{FJT9<x?jQ0eu-Xs5?e@MBQcyLU^z`jx4ddr2tgN*WhMzLjB$YLNP{cj
z+c>a2B_YK<w2)-9)?|gnnI%B!E@2Tct9>%?-#~8+R(K>(mz!8*k|;A+KVfydAuL~n
z?_5Lc4(uUO)?8j^Y<mYh+yt_CR(std-+S0X%u16S+L4lxB@VP4Wvy{6)aeIYjoFAq
ztVl6v8OFms<Lk(qTX4e!+TkYkzVe_q+=KTeFfvFYUJ^C90QOU;b-Zw!%qm<PWgB*{
zV<EYXRqGx#PiCZk8;jB%V2Yr{M6h67V@^C8TF~x=d@VwL$#As<aB(I4DkZR&C8~|D
zFrrDOjB8lX4AVw~*IBKW0KHi&CzAdGocl5mCDX6&+qM$IJgla->AA_QDYY72<EyHq
z(29B&yURUh3|us-OCd!W4sL^`t04uMB)9{m-$BQKg3u;K)5wHt*pzGxb{oiV2*yM#
zdAFd2ct$FhLaW$SXg-M%OFTU;Mdu|b{R;PIkug`pG0Uyc)_4OORdR^MtCW9-cD=?d
zwe_nDaFi>IBrj8L(8G?yVJ=|fif8`eIvmFO`3dF+PBS(=2qm0nj^aEk2<^PYDC{_+
z+B1B~wO`|9<1xYb)yCw9;3db%?=X2M=<Q`jcfr{95>~NzRtB0i?Ho3;ldM?0!mPD%
zip!z3>^ScaGY4{kQfv*&8Rp^7!2=I64`TW6Vvghlxn0BxXXy^YRnEfk&VY>*<a7y$
zPO~EMY}lL6hNEudxBKC=X6Lx6=M#+2kMsRqFgtUcn8%q3v~@X#ZTq6_C^Pcs!9}7l
zb)32TGguSPv2NfzH8%K80mp@Kh5H58HlJmjf1Gwa%gFXD<=YzAleEtftdgh0_0cDl
z$B}TI<tgTp&cfqQV3#>c{1dFHI*NTGSYLGj$WCH|IEB18Ozfky+HT~>F>rkv3(Ved
z<&a^(EHitsf*vRI6n30L<oho%cVm4y9<BpD4g~fT*lvzfpM$i`QPw`#N{A!aXAWaw
zIZS?gXis~896OM$C*8~H_T50X4=4^(n|;iT1*<Ri^M8O<sfVx!nHB2jgH@^fpp>2A
z44T2Phn)9dgF48n<MXt%)o~v<IfM*70)-sL4ty-6iDTh9J;T%iEK;Yz*FhlNMaXgH
z=S+qlrbZ{g&l&8*$C;ly1O*(YO;3gGc8F3=(~B<BM(1glGpzsENBM`LxD(LqVOrc^
z4f@PE<`vI}>;KFyZFSm5Pd-MB;0uaiweT6J^CGl-p3n>7x|bw4(KWd8Ik;M|s_-P1
zsq^7#ed|>>=s5wcUx3!Fmjzh6z)ZkN`rH}pJJ-<zZiMOM(T+^6CczKSlD|=BU<Epb
z&F6}0XX_wO!JQJAfj<LRO@ynRrMF#x%UFLuLHZMLvdd87v9L${s}w;GI0x+pmPA|C
zb5Qw+#@rh4xRboy4`u8Z)%*%A{;8Hdz_+>kS^NB}p8nSVPSzCeQ0wk+ep7F=tF4g!
zleKxjJKGg&C-L^Miti7-|IPV@6?@zCWbw8rkKc9v>in$Gt*r9f<ZRU2^?Wt@JKqCu
zBi^ry|C`=!P#!<({zt`ItB_xnZlhxSsdJlB1@V5+J6j|9bGRCEEh#rUKk@%Fs|PnJ
zkJWl>U#M<Tu6F#a@O7-6T+d3%9~5g1x&5NlYjp;zF4rpNCRSMn`EDiWO?=sE<*yCD
zeBGkwHN;-8ct0xs8e&;_zp3<JR9f(DtmV2!rLWSv^?GCVUkfxp^2VU}fjX_y^JeO1
z-_>p-{U)VYqq`sUzX@pVFbu5{WLxxRyUx|R+W<z^h3iJG_LjeWt^0#=_)@XIQ!0b#
zrw}?@clw>PLeHDSHK-d|kNR_%*Dqke)}*c>r!~&E&PwI>ty2BOVYzPx#^t(Otvpui
z-Pek>%K1j|e^lIWb!REQQK&twQmmCK^-Jd~g?*;j-zv3zUHrLHe?j`?3SZ_d)%`NX
zvoDaBDQu<QEF+gy`VYQHUMd*AAfGREe&&4WEGErognZ>J(esxIeP73i&PUEC&d0?1
zK;a+h|1(_|I`8TEQ^jAR)7~xNd{410&U;F`MCleP%|aauoJD%SQ19&SbA?)*_jFyL
z@Q)PxZ9ToK7#|S+fivHkr?7YRKVPBmDAju^?_HpKSI;w*@*Q%RPb`aT#|H{ssHa8F
zY+dK+d4Y2OSm%7*e-7k!SU&dVUFR(w@96xHkPm>xN?V|Ji=DYjH(PfLl-B}ESV&p(
zNHtgga};;JQY=x*cXYQvAqy2_5pfN&4|MkiaLp&iyUKAk?=4p=d$#W0Qp{Pzn5!Ht
z$C=KXyt6Xq=zlID2E|;J^(MXq-q!tG(#}!p`%t|rnBD@q*L2Jy&RoS=NNH~Yqv2;J
zo(g6v<xEPSiO+&JfzR@pt*5sI`<n`XD}4Woo?qAf9H3dO|2GsmTkq!+V!6%I^Gv;Y
z&3Q@r&vsr`s@c4mjSqxZN%Jx_noio;<Zd;er*|{-^g8ig*ZY@seFGl~uj&7dF#W44
z>t&^RmAlud%PV>}L;o-9c@|+WDg7+f;T7ujGO+>(?fNo!cpcmYdAy>#8A|hlp3Gyz
zJe~G5i#ogt1cuXhh-ddN0@3r7Yn~lmC(hh3*Ljrx5->hXeP#gvOW@Vo{Y~2D6+KT^
z_zPg_W!+EbYJMbM!iPjqtC>J&FwfJwX?l81IlQirSBPV!P6q;uH-q+iP0&qOT&w*|
zo@dgAFHu9w^*Q3bMCf!{Y!+=AU~g84;kRiQ^KxNtUr>%Sb-u~_0NPi;*32-*>%bIX
zE%1jiRgg^6`K+$foTn7;Mdul%cv`6~zvsx^o}N?O*A(MfF#D9kpHsXSbv4f$=7r-0
zrJNRqzXB{q%Tvk6JakyD)10RxG5^aBpW{F7eD3~N<{R^0-1+|(W&Z!e@So=t^Pj-=
zU&itOi+ujakC@1RS=N6E|NmGn|FbFn?;ii_%J_fMvZ?;h@qdp0myXB(&+&hb|Cf%+
z|L6EW$N#dU(*I2C)LkAKH1UywogW>as>>r29<rN^K~R$kW5*5~^2n$O<1_H)Kb|B1
zy`K|F8_5-^80i#wI`VboO0-(^`RGokurpHQFtZzc;Y@KVMUO^jM>|G~MB}3Aqxlu5
zrJh<wD@4;ojzm^R7DeVn-i>?{*%e7tjO@|0k;{=S3Yi$`8fg@%6{#7i6KN1>5^1WZ
z+K~#8B9ZKobkaYf|CbQCk<^haic=%fJ~BM=WMoEUc4SuMg~)_RH>EBT$*lLLf20=V
zX(F)^@4u4I|C*l@$rLFc=@XeBITNiBeLDJObiK}}qSYd&RPW)D=8^h3dqhSEzOj)3
zkv4+6jE;J`e<QL<7>$c&jk=M;k>!!8k^ZW~=*Yszsc5a}E78r-W6?d)PosSzcOxH1
z`bA2sKL4#>nn;OA@5m?7nCL^%znm;i87FIWXY`S1`pCE9Ov56NMLvt1juwcvh<1)P
zjAo1MS4l&K|9p`Q!d2QxoKC}Ctm;%e(kwDYm|dxs`ZcmP@=4^S$f!t{Nb5*PrFlN`
zY2>%axyW6W6^X=0_C_{}I#x!0i$<cIqN|-!8rPn&m7mUTjaa<s%xKBT!N^k4!OKef
zbYzk+(@z+9Sa{nTEg`)9=6FtCC!=coPPA#{y7GD@G9~ha;=e5@-;TT}Xxc}rMhZr<
zsr7S5N(%1Q!fQX(xPx$9T4Cu#8~@QRp6ZcWI7tl+_^Mk@rK+PA=qfC?5v`Pr<j{LZ
zv7^*EU!<&ZZ73?N7pX3qub}c8MY;>hH-*7Hk)&t_QFozePPNyG$d97DernA;qP72=
zB7CSXwXQz7|F?dga9=P|O?4QiavqKhj<i(Cxs}=|J$)p<o|*{nJq2|$@q>bbGe+-x
z{TI}`M#4gCT`NZl2`{PsJLP$*Z$|a5JUVhHhYXRdk;1BTS5fB+>P55E%8#gB+A7B;
z!tUd0=e<!knooT@v)cKW$UA!9U(gItiswWh@2YiXN1lz06kXI2{)*`+Df%v_vzRcN
zLr`Un<W>9BiL_H&4ba(EJ-(>gF}?a~0YTncwVtf<XGC6AP7e#KZN&>(M}|aZMmCGa
z%17Hrdq&&p-;MmO^2P|dB7)uhZ`Sqy%fBd87K^qUqgMT|wYsbJ&a74_C3<cm9zH1Y
zXymoX=aJtd$-?Hi=*noKQ^gsGch7-N<>>Y3=h5Ec7uyu8uUe^qupIM0$UmbhEmplO
zgG$V%BZsIszuKv^sI;oeuc;o_P_5caeDFEZ(Td1cNrwb+kgTGwqS12EI?*oC#{|J~
zr-0MbdC6JgeB&&0W=qyoie8N_kB*L(77ebC%oAT2DJtwMY8n<9r#d|qnI=v#Q@MT^
zSr%C(I^7kyBw18DIw86&dfBPuOmbE@$62G7)w%8b<;->3JJIM@(IL@1kwfB4FA1tX
z>V?fjr<KG<^NU+#rH7=~kq*un``^Iy|I=TrdS!WWIOEZWqB){HqVEgtCeA$Pgqt7F
zik011=Wpj7XQ)%l$r(+N%-t;6@RDlKAet+3HL^XjIP#3J(nNhPpL$&;wLuYKy_>N0
zNn}?vRkUt&d~|+vZFFz+d^9n7&q?j%aLPHYo$=0m=NIRqo1SmaOSxH`OU`P^^|H~!
z(Kn(El=r8SN_EtpG5^!`as@}JNGoytk0bv??ud^xiS~;=9DP#9glP9@CHnM->i^xu
zbt?$-#T374q=jhpd9}-a$;YOOyCQlZdfUn9WS5M%7d;XEDf*gH=Z~BgXMRa^P){7i
z_}~9dS^q!&Gd`O|y{C%gj7iZ=k{y*)-xbkIl8t?x=bZ)4d(NAp%9fJR`=jrv70X0!
zMRr8Kl#HAvY&;Yhuk#U6_REryOC#$de@6C6hVB;@w?w{IThGwjzQR*A$?Dv~avE_2
zlX)4$+bgKt3F6H=)Vmr;1Nb=lhf0n*X`I;TO;OHT>1%_d6@{!_!rvk^sJGP$D@8?T
zqZy?gJgR<k)QJ;)G<2Fd4V>~$_GnV{A5q-n(jT%5?>|U?86j#bseTgszYuqh`deXf
zicyjGB735l#P?s4PIbd6;dF3DI}@GZPAezBDEMnZ(l{CyIUvpHMNvy*(M=BZ(?BXj
zk@%U_i}UNqrMq-UV+Y+Zt)Aj^q@!n>miS+j)B#tEQ_h7YshX>tXGO`ssXdEFdqrnO
zw<*i2>XWaFzx>Mg5Br^M&gW|3?oRP&LiFe8oahL(K|bkl$JBCPM&^q9JuLmFZ=|zY
zudcXFN%hkrYQ@r$pJnw_P^G0;ssHzQO`v}mAI_vBqjLJ+p#^&?Bc1X#oiP@i2i!kB
zrDlTrnB1u&sWVQ}<m<@3s28m)s+$-6(@Ettb{=<@I=h?%zA`Wmj5nN<&Y#XoVX~hv
zcR{l0Imx0r(PGhT(bUms<aXp{Bq@>*xuzo_ax3afZj=%?87%r(7X2%F)ybf~)yx^>
zJgdI-le5z~gAYLa?%TW?cEcyl6uc$do@Xz)Pw2TX{!`2H<$EG)2Fw%AM(0asmNQng
zpCNiklE)yaB`M`=<gzESA+kg@ny40Rqj5`3^}x#Naizt%3W?V8N!!V-K9OD+`v0zm
zVxzDOl39h&nOjM#8zWxzhWOHI@$>W1s9LRXw5(dZdbFlSMpdGvr8{SgI*}WZi_)GC
zM0QHc_(8hJyvTG(s7c~i<0NH<3acHF!c`;>%ZP%?=)a2ehw8#|8TG<^I*O^+)K!nS
z(PKG<<xxM+BUnl*Ze_);B&doiUUt!cTJ&%?r2i;9z>X+=+h@F!iZit+I)nIjHl@oZ
zjuEF2pOHjr<&#7C6%<d;r5G7S-#JuXIkkR0jXvr~Vwvt+0O$(Pn@dWT6&5XIr3a=_
z-Wio=W}g20<AVR0UzFqi&r^-F2pc89QETDzVabrik)OotuSGL!blzL^{JD7fU8k)2
z+H7Z=8+B{DlibhTeV*@?@mhPsyr;Z3ym!6DI_7!Pyun@#FUI}HUF<&Y_I4Y%MV!0p
zUmrRXoJLNb=&k6%=*H-h=<6ECO^!~9J`;UeBfdG&x1)=qpGi{xD@`WW$>kJP|17Pu
zgzgGDxt+{TYRU5J8uM*aylLX6l{Lyp7Io~9gnL`^ueDk{i)!@0?-#3<E~ysmrP5x~
z*y8`k-g$>tQEhE}_RI++k&s>pp(J!js0j&|APT|Iiy$H(0#Za2u%n0tQ7(!oqKF+o
zMMMQF3SJd_KK;ak{UYkstJw8=?G4-aTL4o)tiSI}LJ)XtSpIP4IVW@GOxd&d+V6Vb
zwbwqm)7uP7X#o?R?Uv&;Kl2;-75-${=raFq|5@-VJ17qhrXJ1>E~m!qKia+!yc>KT
zd>w2HJ_@!5n}VBz`N1LZwRjM1qkpS^nSZ)}h~L@Y%e@X~yA2<D6}5Akn}8=RboFVI
zWLQoDP58O6?R)x30eqng=-1h`qcn|OE@+p=nohsUarO9I50;q0k##_&@90(UdvAEJ
zz-3>ABRtPjJmqbohdlsV-2)@O)w==zelb0C9=vJ}&$^Hrz7k)y0>-%#hH<mE25$Wb
z`1U$1`&*aD9f~O76t~E&bN_bV`sscX)IufRZaz=71$0f-4E6G$kA4|<bTBNa2-*h?
zY(9_wDfqkDU+-UoFPs3+X^*~-r?sDleJpcx-BdVk1-Oup-q;48*bMi$pR%r_w0BaL
z+bQ#n*zHA>_(a(Gcr1AYO4zh%Cwf>W{pin$uQ8CL9%#@J#j`g|W<Px3L~k~=e=|&Q
z6HodgE%he8<TKQ5JZ;+0wLz=&cVppQ3*6Oije7`I_@Q6NZ|4ugQ(l4+dXU<D4+YaI
z7#f@wtPCCt-VDBo#bU{^yjWqZJXRSS7#kcL#5yE4JT^LZaBM`ZU#ujSi)B6^+!-th
zW(H$|zCl-7tRP531-<OAgM&`;%l%B+WwW~*9(p=Vw3ln?QoOIdcj23xyn9hpmx3V2
z^9;jz7DL>o;94daXxRGOX`<h23H?AAv)Q%Ab9jlm_?V{n`4VcN3oUDF7e2Mc7LBj{
zRGs|uOP7c>wZZB~pn8w?PM|l;f<vB-+Fgk*c*c7RHD3!1$p$A{gBtzeL?^=VSHhd0
zb#KB#zlHmI?i-N$E4CBB;x_)?@aa+hM1O{VGMsCfzs7$U?rOjNV6(c5f_;Mi!N8!G
ze)lQ-J^B**`3P)iR4^pysr||R*Zv#+6aHN=uDSjcG<9b%A_JY_+?Q}Tv#E<wdwtM-
zF%arspwdHF)G9R196bKP^o+jPl*N5J;z8SZ?eSRy6d63#n~$Qukf$`1S_LB9EhM{{
zPnYn`Jec@NX#W{t!xU_DJo<eojQVf1NK<%NeOQ=9pF$pHygyO?-PC-%M#*D(1>yp~
zrhNjgwms7L$0$&<&?LBqv7iE8jd^cDZSD<6JqT8H1pI6=2s!|+QUo@&z>>?o-rgYA
zzVNLIaCIatG7lekGxfX?o%tdd^|AMjY%9y<DMr%;k1*U#L{rW|{rrzx>;CD!@EgiU
zo(7s&7T6MH(Ol?X<=^2y>HjAPH2W#=KlESnpVDtoKCevbr|}Le{DuBWFzrLD|6kSt
z_=--b;`iMKY<Ln3zlBSN`@e!OTaMKqg>~#t$t~L0Fp7r$QHv8dv^Zuqh*%&lT<IM^
zeIJc=p6@NggRSPZ3{`J__e{L*rP#0e+w1XdmvGD+jvYrosH7hZ_70VwxCyqlp4V+W
z@ltI4Z2H2vc)~0Byb_On75!p9cbH8tIRk9A$mv;pp2@YWoeyOlub0JJhblr`ruxc^
z6!Pw()Zr7Q@-!{!k>%J$Kgu>5<T;UhT+01dVIQkt6D#!;x4`!|U@cF2&%zv@_g?ni
z_C9yD!J>SWTLGTU?55ZaaED<r7sK<`z=2-GX0rSezkl_AsvCtLI@w?9--*S%ra4$P
z_hg&qm!<0$eeyKNE?qOR<ApmL{p<aC*v?3QfBgrxar&=VBmDvBwqkf@BN(O!3Oxe~
zEr*RRbo1RA@Y9JPWP6u^hkFOUWbu@>w8;XHWPk9yF&Gi|o7qcHom~@1i^MAi-WC;6
zNe}Fg4TOraGj(sgVWc;fcAVf%qFs-oeP^?t<Q+>-osMRj<;}$|F2EWtVqHr6T;*MZ
zIt@A9O|;Y<pyqn-LAcc>+UQA`^<!-RAA2719tDjz(`GNQzDUcx0q^_XrP690-M+4$
z8|Fs2akSepu!8g9Y^!Ozb=2iOu>DQ$W%mg>z5%>$A8`Lb{nxkQ)V)QEx+!YZm;D3r
zGDB#c1NC3|2EsL(`HAjhw-sIes{0RK;(Pqk2Ux@g+Gru#;TU%Wy?%__-}Qh4=fjR_
zqy0bhw$f7T=}l()3u&zd^ozyxmCL*<z^tXz!Z{jSnn}G(!y`<fSB<CMj-a+q;B`3u
zvnPEZjEx#nnpV$I<SdL|#49Rf{-O4tlv#!`mQ+Qxnxc){qVYO_<Tlz;2-=&~bZ0I1
zN~M8Ya8x6nG>d0W<C*JW-L3eh6rAeJS^3~W9Yu>WxT2|NQ?a=y)!G_gFwJVUl_Z|`
z*Yf)=0Z5b&8VrYfUr2AhpZ@!T_bPnvJ?|rL8-6(xZ0!uY8ttZmt`~u>>)azKthd~!
zFuo)dS0R0IAiniTRK)4Zu)W-0?%&|AM7=Lj-smE@-(CJD&6u&-HBb8Y;FT{_rtW<I
zBJ|rW(d+}uq+iA!%c?!upXnc?|EoL}kKLc%zK{BRKd?CbpQ(f31f_m+aNc6h|8;M}
zMBiY2oqqoUy!25}<SsDfI@IuG?h<^%`JnSu*OzDVyw~8hPlL|?MIj})1QhPOJpCH_
zx{V7@QIx1ck(ciBQ3Jd_U}&MnviCfCSH)DTG74;o(L1v6`E8{L%DiH>tnZ}Br>5{t
zDP^1tL!AX;p8zTy!~1MFz&Rk-BG!d??$c=7BRFaz9(EciHIwx?klv#IC&2R0q2(`O
zT@238<J@`T0apm+ufuCy&GuzlFJ-mASMuE|JlaF}<9EETTnumQc^`ON(4K4H&kuWV
zQKQXW30}Dw+WSlF>EE!c*I2jW1-9T5wy@`IxZl?bEPd^LLhWyrX8qJ9(mvhXVAT5%
z{x(Kfyv?1S#Fsovn>_++S>Y|=*%ni_HTaoFvD+JXj;V@w_koR!!*`vaTCr!H&eM;g
z1&z-YfL6`Hv#$8QfgC>^?m8NkV9b6$5UaTmyPmjx7PyqK6HbRMWjx=ID~sa_z_r$#
z*$|AYLi&UVLmMkTmqeS^;+$-b>I@gQI}gSeSF&9RKORAer_dtPd4=nATF2s*Q`vtQ
zuc@@*;k2QRAojo>TB8ZWSfE9NbEK7%lw0w8sb%vNiIF#pua07-Qg=<HvN~a}9TZQ^
zp{{JKA>hayEVx)P3(LbP5L^6Vtg<TdA6|KPULnvpi^V-nYnjHfQIt$-qp`9AQl!e_
zxJs^a1Nu|TW5riTQ1|^{tb=I%vDk(wm&5Sm)<b5%LQjG7&VuJ2CYC#u?Q`h^*MpBM
z=?_=3eKlLRdFxOyrWbF)`mSN`#aQG5vE&mudx|%PJM06;Z6&|gMGDAJq&u~fUu`RY
zEmezg)lB$AXZplo`r}|USa<5JR5>&KXt&Aq=f6|W*D98{mbza9|Gbly*Z>+m0X}R|
zZ1OoF#WQTb=6&pZm*yI|mT1d%uB|I{tz9eDHhd~}T~UAiL7K_#M0bw6)LrYY!B3p!
zj&p~@OOIyj3U@2a@d13v8u;V+ZWjATflLG8kE7s`GvNEj;Z;Vu3a;J&cDok{mIwk`
z=F%75``+tt-+zK$PvURP=RAVd+yI|E3#>jFTMO~}Jgn?&X}D9cpQ98DtK`{jw9YtH
z7f@q7m|&JQocbu#=tHi?M@r~TW%RgKAWk|xDx8gAQTjX(rvujC1ElG}F)cy1Wcrom
z_H=-)4)TVf0n8>lW1}rJGMGX?-rnn6^}1)5K=G1f?$=0+u>@Qw;{F-R?`TYUhVZ1b
zP_L#sr-Ode_;eon@NTI=tII8Lm5*rOR97D!Ux2r1O`BGrE5@S14u!Q0!;cK7#ZGlg
z-Hq-J+H!@vobAi`wB9|1DtHMt^Nf4iZGky_=KCm)+U`5|A^PDt_XJ#LBd;geeifbf
zvHJv`v6bT=bpL=`tabNd8~5|R#@&E^xx_7Y=eY&$Z1;C8=S<kf9PT`u^%S<|V?7sR
zV@pvXr=medP||j&*Ld%9?DRQlr>FR9YH2gu4`b6C#mHX61HOfS+``_6@OTgK{)qQD
zpX{8+QCu6@dmsH_HT843blSD_4D-;haNY}Ovkml<)!^20jmDpejagjFG~V&}$RqKA
zm9#<w<>N#@GEt4ozO2dGCG;}8#^i7mD+>>h6^(}Py4`C>-ZMGUK`z4b_z1~&T+H7l
zY9z1$w%!!~(NqYZtLz{1<z-lQACPs3cK{eMlJ!9RYhU_E3HIKQGc)izO|Y;1IKtHK
z!TcS-^H%b1nQx=<tHaqE%9&%Sm6`Oy1@NcEtTvuu`Gki{>CIyA3K+<PDBKOg{?&K_
zL!njPGR0bE^IC*IxE)lwLs=BZaqdyD%3HvJ?=;5ZVYm0;N#?;)X3(Q&V&i8k`m%!S
z-O754cO%=&d99+|Hed_Z(iTTp0be_lyUgNsI_mrk&OI5XGmF1-Sx<%IO`um-^8DS<
zY2}I`+vu^elp?m;YwWU~Jmjvp!f(~%f6fx4bdB+yz3>9omgS&Rb4uNsXQ_x7-fVoq
zB5K2O3T^DbaxN<saU4zyk7v(h5X6}8SlYD`L}`L0#EV}TJ8L9%mRW77zM`y_xskY&
zKCc?{EMPT@3K?BuG-}(B>tt)RqE?L>t;vuQb}=IBD}yAJtL1RE<$_t>X>;t<Ms#{9
zj+#$9)#JS#2t5cZoq#Qw4>%s1IUcK;tS2j{4_F*_G;HMr{Ks6Z&GKz5W-%9gm`r^g
zhJ`G~@7UPa_2B4H%7-dcZ_4Mch1|CskFcMj<z>`&EBryBO4A4C(ucjK=xx-wNFJx0
z&xO>YY5#icEu+kRxk4x9NE;JPW2+PAS8!}0wO2>cg-p(A!PT3xCpEG`!;U1?Kyp-z
zG3u?p@(R1EG{z&-si%e-`EIHxOM==g6RWT++CypQ!5rH}5tl^HPf>P?`IuH5F<Ode
zI*fmBu95mP;tf^!m#&fdn$a64URyKD?;^a)q%AFLAWg^r{v%kHA!a!Q^_44<^oNw;
zr!AqPN>snwIiq>|xI^QJ*_#(i6ZdJL+^fd4cuP>Ngtjk(F%`3#V(vzp?@L=3)B1Uw
zQ(G-mOYA3uHAULv&ydd-NY7_0v%^^34>Nl#%hobsOhtszw-S_9zHq2kWOXs2O&wuP
zt?F!)U$<06CBiH=>j7au@1wl<(bCLi!h|-;WFH7ZO^Tunv*eX5&u}uD>mYgN@#1in
z8DRN<3-OH$*t!ZIcQ3x}VR+3yG$y~2J$K+g*J*rWF+S}GWwQ;!$B&R^n<{lSlFz;I
z{(DO$6oWPG6k#li{9KXre0sHtcM-D*_E7!o$)!ra=3=Y$#96Yj>>{45hrB@#Wz6>h
z;fApezzW)70mgv}LD&Q2875LogYXCY>eyZyb?d3KhNxxCb4<r4ng%{VIrh`=7Uz1G
zdDkhHf3r013f2GZYLmy|*-v|q!d6znE6;)3%)z%T;h4L;|AlpK<o#Z@?@)WK=ZvSk
zmy~(%iT7D`F5Oq&_b%oFs{Bjz(5tZ9M>y6z(cPS3QKZkjZ@g{F+<Kc&A9~wdZI=SC
zPhjs`9Pv2(=Xt*Q61E@nzUP|nDwbpsqxZSjHt0%im{miRT_;z963gSbw_(O>;ZnDI
z_oEhG_dbGYf98F_6>U`JK}x)uCt1M}_i_Dyakb~L!5iTero!gH$rkghi`cR;!9lb`
zkEk{e!U`uzlUR&qBA@%yA{L>uh`HfUC;CJqT5&Ip*lv$jB<MX!`HLA*4%m)kx;tBG
zEsk!4EtJ!)<@{~5%TY-~k*e#as>dcP_R)==GfqtC5K3Nw=Ps4n>JaJ0onu^o)beZk
zXB7e_DQDFDZ$3}ik9L|Nt~3M080U=<|F>A1=^o?EXJXHWN5+<}fUjSVrH73EcFj0i
ztJuOO)(6;L&G$F*_ff3n9q&Dq+0%S~6BxDxTUn&_0+{^e8iQRy&zg&!^nuAXQ(UZz
z;*Nur*V#c)paeZ_7%yy~v6M`4pafY;yv9k)dXo9JNGxxt##_76di7{!d+L-(=XX}#
zNH=WMka!9>Y$$9>Zz5QE0Jw1wTgRb0mgq^BqZ7~J`$>G)2Nda|EXXotJ{r;-C}ngY
zR|{i~1yS~40sO0pJXP|K&ItOgm$2Qfo~m-JedVZI9I{Y-(PlXoQCm%vTbZGp<rHy%
zTxE2cx3FicCq|H<d1}eLs#HKYVqHhs+=)9d{NM8#<0IaZCEt)9<v?dhJ>+O#N|bl<
z=kslQW(m1=utPr0c7~EDW%p-)@|xP(7wgNx%UiaLtu~XXl%D-JthP0_nFktJZ>#ES
z78N)3WXCtroQxl0cUVWUJ&<+uQ<gZ&--t3-h?NW$8*HmML$PLqjZwUPDBJCnNt2+Q
z?p$RKcg2@gz}^PnR|kSNrV#V^Hm2*Eax4*6hDevqnN|7Kp=!>qo@2NtSiD`e4t=PB
zW*1ssb*?h0lcGpL0j*?nJpPO^`*3clVVNOZHf6Rtti{tb1I;UxeN~Eo$d0&3&83Pn
zWJ$$a=J;O97iq7VbbawRHrK0e4ZXXghptk)>AFHTtBsxIY4j|GZ?@krw3Uvq(*v=I
zv9Qm+_?wnO-MZ=r1>CC?zt{_F=&g|x%fSuXJx+F0fMwaN&pc(%TjaPkJgbD#Hsd-;
zk)pRU*?gKNTw!nS*O#kx<Jw^^mt{NV@TsRf<aGSuFurZ0e71Jj<WR~MMvMlCD-}yc
zG~%8Ou?vgBPk>L%#fQ$(IPoaOr}h)i?j`R$7Djk1?BZzn;h}I2V~R&AN5pu@vFx9r
zbsFD~k2H+U2o6Vh+bBv`A~ki8qF5HM98PI^Q77e^4bW5l#>Pm7@IFBIui)G6eA`{|
zmM{u7Mls82n)h&+#(z(w<O{^(rz=~fGxb-BcOOhS#%L7O;y2;wl;xdSmT{3{Zw(^O
z8P52$NLVvPr&4ODtD12`pW`y9)i%l>X|8dH1kGB@XV1R6<2cG^W1B~^T8`y7%G{fJ
zXif_y?Iu36ecqK>S*En|&-KW=@+3PS6GSs$Yws|-Bc>h`#v^P-Ra=c+7;owz+iaw$
zgyqhJbFEAR?Ebd~s_qnvFnjk$Rppm%k4{<^czyBvepu@$tYieOzOQ&?n(8`-5_HEt
zt-lS&O1jY_+G@6JnR1IuHMZ8BIv+}F*i83f=$M|$dI<B6OF6o==D%b_+1Pt_X2~D1
z7~4)0W40D*&Q{tk{Af(PA}N}G7AIRsh{mPsR{xU0_7>aG`fXNfGkWX(%B(wxR%wH+
z+6YI6Vxm3iwf*RK#fnKAx3t-uEu-0ayPA2h>wL<cZD&We8W+t%sul6tx|$=DE{z!S
zML)WFJpI!~Nm|j~EhtOok6NvH%uJ0<w%7c$mhzG5LS~zn-9i!G^cv3+L@YK_zM`HG
zwViCxMr!gj_VmjZR~<o4tBxT5_+n38SGAEYbh0{3plnSvs#Ho%{F3}%>z6r-;~QF+
zMq{qwRcb{euN5HoP%NOF+RLH5p>C-awNag&Vgf&BamsqI=uu0}{LGD_>>(nD`9xuK
z!eXMk$G`9@`I<G_imPR*Ty><Z+e#&NjZm*8wqBsvY;sicu#Yw3%rfxBB6Ou1-L0~!
za8xg)TD_#oS`#(DGg(YGL47V>nZh>eW53_hgL`(ArKCo-U2_TRudevSPql!*mcN!?
zzJw!&bs~HHX%^?IXHTbTO|7wpdy*qRyK~Rne!r^Rs9o`wnln&$SAxAXf|4!Vi`RA2
zm3h-!QT86-UxOM9Z1;TW*Xzx&G#TRZ9q|NRc@=90SU9IXzB-?M$1%20_1CPam{`AY
zulxw}s`iKT#?vE@7y87V%U!eH!kVtDUm3|(JtakcH%>kyOCGM3W)61}2Ifn7?Yh-0
zvY)2wq*af^h2vUTLTQ_q)Izz5^?7Q`=1URBsH+T~0{!MqzVhfoe{E_gk8>=8zqfvy
zr$8gyR=Nan#1KELn0UP6p*E77S>4_iPi#$H_mp-iSB^lDev!x`h}|?_sx>9bkwqqJ
zY&J7eczKFJ*w}EW;(Ky@F;9>yKNlyK-%wG2a(!=EnWiTDNW*l+7nJGD{iIF1QGZRu
z<uf$a-AZ}pW%`Ar<{BeTj50v1u3A-lw9pdbBbCufnRa=K;h7yY)yQ>kDam3!RjJ=l
zuUgc_v|~4HeINd|V2_QLmV3u|E4;_NXS`dy(<pbYRKU+&Y)rZ%y6sli)ZORL3I@a)
z#x}=IirX0XZLNg3cjK1E)r}1ZCiq9W3%u9RK5g`D-QbEBc=vf*|DV0{fUl}({{GIM
zODG{B)X)hDp@q<UC-fq{_YTsl^eReI6j2mVnt+IkVnao-iztYSUBuoH1$#mC{qCG|
z6G|xl6(4=x=bX<?x%b>tc4udPvpe$}b4)z*vw7D%WR`H2y7X?$8L?OvzL|n&x8A&H
zjw0CB95dgTBj!5^Nq(u6%9NJLyu~vuGYidi<^kndn=8BJxXo>|$yc&dmdH@)Agy_I
zlkU<cU?cd2vlNq#vPd43*W`fgk*%^&26M(ryk9_KxkfRm&Jh!3nQWBxa=EmV%w{`Y
zZY`eb@3Fx#+S;qldy-R<*$YY*iR77Q$X9lhecwy=QoO?UMLW(Gk<aA~`A~kco_sG)
zao5?+-L!j>@?oWImUAY7&=#28l2w|^G+8V6%67R$=1F^rHE)`m%}ibCTx>R*$2A6d
z1KxETUHj=m8^155X-SuXotgF?$4JY0o=@W;#VyTJ^95JBO+J-hx#zn%Q>3{US*d}f
zo?Rj(HICBdd$rY!#bo8Y=|ca1Mj!96h3p`EnVoFw%NKH`)S|sYQbs1pep|x!wWDnt
zn?cq{GEX&%(GjEPb^5g+E#1+~F%Oy_rK$|)yVuDa=_+x^@hv=M6Gmu`bnh<%<Fp(e
z>UHK5X)If8X4~1$vrFt0+rcK;82-;`6Kw@s%0|f3GD1R}uP5XG{Fq<d9GHt5bg__C
z0&MHgRz#{Us04m&qU(1xb>*wF>dv-!#hp!S^_k<<AE{=Bn!D)nF|yAVu#IhVTU_3k
z%Xq$r&1hOQNAN7U(M??#OOKkvl38*vy1q5<XpY)fl2=+FS69(CW27!)=neCv*=K&0
z6uDMDvI(5Ev5jLa&6OhNG4xHX6MEF+%#}?)v%<VCQBqOrOEoEIelo9XockduEWKr=
zJi}PrCD+SETy-_xWr<UyH@sz`H+q;&JkMpAwbAxTt+(~2U2g~267mygaa@8cWw!K@
zisra^3VqW@x$d0JalCMS%v`h8d?<0!UpB}=8==`22jynzDLKtva|JzGfqM>}&@LU#
zrRILV6LO3K=67?D|E@5DumdOZ=Y;RDFwZ{#sd!pBJ*@eXzm}Tb^kSZWTt<*+Tv9~9
z<&pUWmLK19$))r4ew0e~VBX-&b2^qY<VIFoV`-j}+%ig@w%Kh9JKRpRL-}0*$y+DA
zq=0$P+-WYS1)I~>g&B<zr<}*nqspao;%;`~B1Ym`Bq%o{^G13tkLKt!QNEz<GC?Yv
zACcT8=)HzqzmQt=czUOt@}Shv8O9bM!CvT_%gh$@4jQ$;Y>`8@AZKdHsHkBJqCcO+
zF0_;=tmS$$L$ecH9_I|CcL%ySBbvCqjFYR;Vvox!@{xRNt<7ai+Z5Xc{WF-KRnRkg
z<r?lY9;@{XckP(|x-l|aFjk%KoL>=B8V3AxGyM+dmSp6QGAp^-5hS#dT*R|YU<}NY
znKBY<nIys!Z8Ve7=H(chf1LBna?eH3G=0ofXwdJlkZt7>#_RpEAB$wscDZSXtTu#h
z{|*g&fYE#h`eHbirX;%LQ?m=JvcL>8tu!V#`n1`g^frGL*+mdmMBBACea$5F{XOPw
zG*nGA>W%WO9OcT@(7dDU4CVSCX1m&^^k!LfZ$X=bvHg>LA}`2Y+|6L+eftUA;P{BH
zL{oJ`E-LE0PNJ^zlvW1DoawA9oVcAlGj=ZTByIEOH_M=%J0e@-k&LCZ%F|e|D0;1v
zj0cI_fL&h8&qdg--qHY#dd$3v##&@9rUhy$F3%T?#lL6e#$~xUHiZ;M&s4LDarU7^
zNFr_79xXcvS?hr1%&G`t1kYBKr@WBsbi(<IV(t3UCif`EXf&g_h~z=ney-6A_iGM?
z%Ljkb>^84~J2Ei_+A=1b#J+;eWVVHEvaM=s+1j?Qt!L}=s*a`3A>S~1H_0rJPE~aM
z5%U~Y`*P*#tgW%3xz%rqP!A}NuE@A`jqYYJ8fvatPES3@^|DE2&M-|@fODRex8;x=
z<@Fl>%>zxwn_tY^+}j=I1~Us=(G)b3#>Hv_mW8lx@MG!ntNn6WULE+xCD@;hjKue_
zNu_lxt_1OZXfuI4TH5}0EF)pMon_~OiCpI4DBBYoUB+f-biPU(+yIgsh@Pk>@e++i
z`xYy8h}Qemd<^dS7(EiAhg<Um8^A8_$d~f7&A@0X3ZAKFTQS~x*lu8|TD;?-2i<7D
z28rz<wIx5gct7p10BxMY*vff^`9^<+Gn=BBs_2CwXy)~xk{7WKUzqQa`{VcwUx7lN
z1?R6c^OWbb87=M@T`yF=`Cqm9vC_`p&8rc<<r%vT)Vpn|>lb6qe6z;fhqSzhcT@-j
zIZjs7j-R4Pa@k_GGX2%r4g}+jvm<REtY@;#iVQu2c9@QARhPW9(7Q;{CdR=?(+>YK
zQCU^81bGJ;PMBNBtSockndI})8{sU4Se?_ZL{D~9OSlY;^$^JIE%S*vN>BevFCEud
zw`1lvF84e7^$@yX7l`^Ep6?NQ?^R^#TXaT2e6)60q=lfZN3a|p%eTt2;+R&BV|_o9
zm*pPx^gy(G4tjo%xgDE64lSLctG3zyRLrjztRJ<YwH!;c%S3qroB23x_ySV)rN;Mt
z&XYZ-nJ4#vQMQ0a7jp-lXx+GAE&uP^91iklW{T@da#Q4HHu`8E7C0vwt&X$;wT_Vm
zc&QK5cJI-Ghj@LAKllMy>s{>d%OI7_G9OJ{MY5sKUgx<V=E+u~d3xcY7uETN?5bbN
z>AIiGx+<dUrCE5l5}I$MW{)gFzqvfXQOcLmmtJY7`3a4K+3+&Kw@#O?P%t0nI2$ek
z36JAk8^PuugQ!YKBkpYy-ugy7@~6?3kIL=n>3Qg$DKZtmV-UW10`m1b_kF9m2_5UW
z8&+!0;_d94@l!YQMDBbs_$R|T*9NfNMs(s;*wMxOe>GAykE^&$xAvT`4y~7+*4T~B
zn#<F40LxcJ&I|mB6`S-n$CXw}EvI8QaXAdD(E3lA16=!81V00oDVyYz1hlyG^UGs(
z8c7$PVLE-bh>>y`_q~WGxkp|CX=TEPD}~)^4xYZoK4pLO61)_zqu0yp=k@pcdR@Jy
zUa}WsztakwFWbF#r@h%uMSJ7{1?|AM9g9{k$tc}VyUhaK)}h~XY2Lww+?>~%M^|24
zJb+_Za2XR-f_%LWx<*?|Wv{&QDHKR&1@oV>g=2)8VD(3unT!mVo3=$+UhXv8(0M!1
zD9@u^_Vd~e9(h1>I~^CnyJ$5R+3Plo^k>HptpLhvL9eu+=W8o_T}eeVks1~JDf;Mn
zH10<5>KMji74%@_1;JP0mAs~SJtL7;$DgnZ&3zo7qNLPd)O1EO`^+Y5z|)T-k?*2!
zzLjHOgIu<xZ2&45uhq~Ng2g9dw?^6tV32F<8m&0E%|3v~?kZ!xjO=c)S8{ZJzSA9a
z($!uBnka6w;Xye6VK36^_z}l3UMorr<K-nR$}P0@Qjo<|#%x<GYANNHblS0!MgY4k
ziN<*F;}~h%XzxR`wPRw6mAqJ=;^3XOc%_Tc5BF;h>=WqCd(joEWvR^N*#==*+oDxn
zE^H_1h%Z<}3aiKeC_S*$%+cJV9w5GYy5d+&<ERR1Y*2dg8unm(S$CBR=AgSanA_Ml
zsnk4VUNK)wBs!n~+DkxUU*R|Y&Rxez8Bk<Zp1uV4Z)pL?RrncCR8$(GGsl2uU6yVN
zy%UY398~7HyTDLa(?0!Zhcc-vu@`#F$TL<)voEC8_aLzcz_$m$kw2?H+D?X`$ERu5
z=xn(ZeYQ;2Awf^d>sYI!nt}QfeX)Z+d5L#^x7oqx#gK;LHUTd#T7Hwm$l6=HoVS_Z
zmREE%z>Wavjzx;5Axm5AOZJ#o)T`sQWN+YA@Z!82UKTGCuN+=JuQ0l@xL49k^2)L&
zdGTIO&)CEEZTp<v!MCpiCl3HU*TA1IWTU_%`>~vp@nGW^Zl9Ys6c^mBEL3ao>(^s}
zRxv6kp+)N<gE`MRvuAY;Ilr#6Bx_`31N2`%WNIOH=t=rECtg*5(EKIR4;z&StM`o}
z{2o|>EwUZ|VI9_NHf=c_A7wVLsaVNr*a&CkE<+~TAuk0b2bv|9=4HNxoQ>f+h5k~;
z>3{#`$C*TEj782M63=B^)dC5$L6S$QW?#Xm-$t+RL7ER^v9s#xKxyoB6{#gn@O=A&
zXU8%QdrKQeVjZcE9`7W**gK%tOM^0gF&|+Gc3}q|2YbEd7(u|wKZ7^lP@az)KtprP
zG~{R^e%(~?$YSO2TcPX=b2V3dXb^Yj_?h}?wy(?nET++f7h-&eR}(V?EtDG!>R9GW
zoxl+so(l}GK)ERNs36bFk3DtK64kWcMn`mJA7xf^95mIHak!@Xvb~gbtuLRsjLz|3
zl11pRt26_)Ke(VaTD=BdQ(szU85(mdxcq*Q;4bv$`;5xNx_`?kDTJ<W3m)!<_O8$0
zbr}o8851|4-ERORPe5n3#?NYkZXd|_ajQF9@mp`<^ObTV)@HjrF9*>^KjD#NMh7{p
zRUJ*!&UR6rt_FBzWo%hn)3&u2+nHFpskWc3YxB$Rno0k=&1Pe5PAlN=$H3%E<Z`aN
zl&iZu`b%X5SFR4$%Z+x=Dw)yg-y&C!A!9D%*RdwJY>S1+!Z6yU3wErRMqBj{VlrL!
zQ+Uq5yv|hRPo3wiqOosog){D)kxu{o%~Ow|kY?tVRjw|7FQu!-F~JOGMvf`QlQ%=Y
zy0Uj>Ty#bo_t!YsiORL$a$&C0y!5^tR|!2`l$J}PrCeOPW8vt9{#~NHpnDjd?|{+X
zrB_}-!XDDR^#{Rl2h0~(<)i#`^CO>|??LXdjBdy3GXTk&Meoi)4-7#1x~OfwOjapB
z!`=K`k94g@e?N?M`w)Bgz5I-<MA{;@nleodMVf}%A$AzH%+)!)BB&KR9m_Thgyi`C
zx`UH?fRftTW=LEWTLD?Di9|N#|Hd{&xuhD{dRVVASg&XhS%@pdVnxexWHsctwrz-Y
zbG&k$xN2ithws<1P55sh*PX)ErhwMQgWG0eO;_7H?1Ngz`a!KJve|CZ8qRlVrR;rJ
zO;;uUEBl50(7pktdrH}^{A$$qg7j{)>#(S<#_A+HMrX$BW6LdG$V;-DarPQE|8w?t
zL3;NwK4$8CRBh03Y4A)5NdyDul#uxv)U%(Sc^-80g8Htvq6emd!W^4O4V~@J@sFuu
z@&DuIN8Gz;kh}p;M#dA?h{CZVxitI0$H-P^luPOutQf@c|9LAGj+jh~B|7=j2(9x`
zifcB+u5@JFyE)q#XkM4K>!ROhVuu%M-L)4KXXip!m&MZ8kebTJUk+?l7q4If8vOy;
zBQJniZ<T96Uzf}EjP;lCTz;10yuQO4{Ky!Ouvu&b?|dyE$r~K+SXS=9d%7C^FheW4
zOaoz#mBG>#+)$e<#A6*I(JmpK8OQ~W^UycD!3o!Lmu~*RF_<kyXLZDmx~fq%m4~)3
zyUSqitGaIle>XvM#%h*k0rXyL-n)!*IL0%_qTrr*9?v|7r=F^uVvdn(j3SU}%HrYv
zpGfQ6g!j7Jys9i`FDWz2Gr_(~y<Dd=KR_>j49@wG*Qea?A^tl+D?W+ev<nRS15e_r
z71iWtK8XMmxoQ-7Y2A9#6mO=gn}^2xan;fC(aJ4BynVn?&bP^?T<zcCOBlWrLCYA;
zto60=`&{QuG{kQ7^v(3%Xw5C?sx9GgQY-9cC!S>yzN5>(-h!?lgKcf48HK}@8+sha
zw$S;X1dSkSp_aF^X89D*Y@A4)$1R|Y4UuP^1(bBxf;?rC$*U3eNm_BCvgSr4oRAkF
zLH)HbYfO07tPDNeT$!vdp|57}b0~M-Nx8m8DZAGco_e5Gc5=0<)?u^m)7i^yV2d}*
zcgRz2ZN)>%S@#2Sm4GjtN7pBBL<XiJ2`l){K6=k_>AQU7Z)n#i@lscFzU}5MTD=r_
zwyDmX<&lhHmE$-ssH*^a+V$u+c&={$f<D=Ao;EuarM+W*!Vf9V=&7bz%!%}GG%|h6
z`~;r%z(Luy=f6ab9^;-jalN(d>(s+?tYi->7wgmN{a<6IgN^#oJ1!^1=LsCcf6cW<
zpvyRO5yJ5&alwRR{Vsg=*dO0AF+v@eTXW49OX9vAevZ}%VOJxhlji1J&67J$u-iZ~
zBS0*UZOw59B`Nb<6U}RNEz;Ap1JNWSr_m>^kGL7DLL6OPt8SD$rS4yN^Jn~{Pv8Wx
zCwvx4U9Ub>Q~OLZ`IXBkfuBW{y&_rjaB6cuDeQH)XIG;#i=N5P8&BhfJpE4mDE8QZ
zG5_C<W&is(KVQ$W8#yMUo?2(F8+&hT(L^lFe6v7#oTj6z9G~~~*c5++uVajFV9aku
zFW-)Dcc-qotmlZu>Jz*Az>cBYX9aR`mNnHs@1m?&-PMMV)uTq>A-U>%k;aXxJlOf#
zjEf%1>EUo<8TE^zPLXQIC0&@2QI&DjSb4j<;f;>snzOX#hht3~sF`z3kmUL*&3;Z?
zFP_a+U|h!C-la3X&KmABZ=0j&#Y&)r5#WRo*sy9+5DlDBqR^B{Si0Ki(ArqS8j34w
zV*wjUE9or#<YN5Q!FaH(v54*nH=E!**<`H)lnITS6-{0k?OlwY4kw8D8B6%R`OzH5
zHb$eFi=bg0dX955$at8)i)cJoF3GBq4?D1uD|F>?zd3>y&xEc&WL`$QY*J*fQrS=)
z##pIbVOJ<G>GkG1{+eM%D&xQ)o_sN9S*?|b#-e$8;B!sTx@&7V$2^TysH(nJLQr9-
zJi57%&g%bl^A&!?agHGOCo;$q&53_kJrxu6)@;Qw+`Hp}y-N3G$lq-slUI3i#|a#%
zyQ?Z&6dToCy5q+=Pp&0BP?^5088G;dlj$J6rE-&O#GAVn9Oq_@r|8_~0x;pNpu(r{
zXI{s*`4aqhTz&=ly$@1+KsIY!#|FH?tvcVlNX9F|=_*6;eU@{^jdC65>cSm3g!C(Y
z`UBSZ>tJR65WkO@!&vB7xbs`-55MN!7)ID!?BWJx1=*x=X(_aNl<^}s{1{`OrP}3%
zoz71BZ{A#QyDD=j`1XF>bxDnuFRXc6Sx;EYvzmF6Prd&{%_`2Owl*!B*U!gw7_gvb
z@8m)+G^I6X>e}ZtB)kdl#0C=VR!baHO>O1eb2TAc_G&ks#Tun->b-fVzE-(%6}if3
z#c9V{S4`_o6jQ7c&L;~6XwRQzD-pz*q+cH;9I+RX8jBaU+^4Vbd&<!pr_b!O`JUeQ
zezaW<+NMZQd$gKn8Mg*~^gtU9M*9v#-?c~cy2^=RR*9^dv+7n~T>e!ZWdZit2B+XP
zELBZ%6F+Y-%av<?DLP{YE#va%FH#-eAL*T`Jb~-X9cZ9umEG}uem()>aXcQA&?T<I
zl=C+3;kb#4>PPaOt#~5us?Tu{r0SUX4}(CzRj=SPofrIC*?K-lBkxge9>?VTpmG>)
zRg}4gmv4J+=e?&m?t5K_iIog|>p8~L%{r<cS60d=IC3u6cFb>$(Jd2n-OoLrTaR{(
z(>J0&ui?ojX%=)pZMmV!!#hytI30W6&>%Z_6s_d=P#bHOL9u{gzN%WO9H~<KpJy%f
zw@|?I?`Mu$jiksKFbgD{z<K9q^oF@c(#sw?^@(h19?sdG(kfe60+`aTXP4`g`qBOz
zgrE1ATj!zuRhA^pUoLP;e5pV4?_@rw+WuO~#5;f<8LJFBu3p3x<;U!&OffEJzJktt
zC#d)4GeK8WjT)zn77mM-(9D@?nq}#<P@!O4r)4=u26N*f#rMgYncqh%j&#?EZI>P5
zRv;XrcZ^q6l+7qV*C>aa^hT~0Yt+L{%HK3zGvLRnc3O_)t-uy9=d)YQLwHO3)gyig
z*}hS0mfePL<>t#j!T)pXSda0Ui_CcwyYdqV;27iPePxhxHB=r!=65k_97E^RjEyzA
z4zUQNvrDV5$4V5V>jlQqD&>>9iE-kpXKYb6*46kc(~<fP!J2**+QYF(RnrQ!(-|x4
z7+G%RY!2=0*aOBgA{?V*Pp#SAHkFyNxJDiq&@7*rb7nyLQkh>_^$MKRPyhFB;rcoL
zj9Mnu{js{jTvuzO#-B0b?yuOwF-ZkgHgg4BqgGi6-Hd(lp!TH8dvn|k4UpYt>fbiv
zowCY@oH<w{a(tLc+;ux$1?o%RHwaiYPxnqQ1cz%l{?O;2DX!Vx*-xo8nK3{Z^|j7S
zh1A$X8)T_x(CAE8bH1svm5#?ojZ-F!p;}?9CtALZ=88F1e8(3!N&TRiT8U^L=z0~l
zZW}i4ZbrotjY)P{^yPGg%xAf-q4l{OHgWtPjkpiTB$89dLo|2fRzSMxijiYP@Z%B+
zo#gFUUCE0Gq5{)z*R=W5Y-i=EKXvo?PJW%QaNLyson_Q(x|pA0S`*37rVBHggqb`G
zD&vLYS1G1-w^}I+-5_P5o1imWGttMFXeGmL;18!4s%b5*!YY4`A*>!)qAS|5m(J<c
z4c5iN^#ig5)#*;GV0tcz@N@1@odG$Y&Cg;it@9qvW)#!;!Wd<fbtt?7?>1KK(?Vs*
zG1V3eyyosaMJwgPOAIO-mr~9i-*&mkfm~WWwVE=cR}9v~$|$lg8PrZF80gAuXY4(H
zlorrgn!*9wnSW&X3gwkOqormUR@K$SSgq-vT`PB#SF7c?_b$eAb=A17`ilJAT<TP8
z#0spygUaXqsMfF;s;h2}^|7taKrdI^wHAxvP}g?#S(ft65o*mYWi;H0{dp9$wjQf9
zk*jo3R+tXDx7B)2DcoZ%ttnVTtC_fr&*qwq*-W{9UG8VHW|$`Ete0coZ>M#?6Ev60
z=a(y?nW6QRjnaAkJ_}_-j<29H+e+CaCurS-Zk)SrP-V*DG&eqdUK^K_*(zWU?WlOJ
zm{v&g`CJRC1e}RE{O{hp)OgYa#V&aR<mOi<&Z&$^*;3<}LYirosLVZ06py%-n)Ez~
z^tUt?+_Z7{PuwCD3Fg=Ohq?bm74d)DmcB&|+qJXzmemaODBaJ*o`1G2%>9xj;G8-C
z?`2UvR8HrzYiO);+$sFR{xPmDO^RZUWJY21Dfbv=Dv#Cd^ql9#Chhy(5rN<Bwusbu
z_4<L<sh|knRi<mH)o|+SDo>f9;!&-DUp!~(9741*)FcOU14%mj;4|Z$*s3SjkMV23
z<kKoW#e<k@8yuHWv-mQfac2GOn-?&YSJ7JH&R(CoE-NQwJDsmh{ZDN+V8t(_vq67k
z=JC&9P2b-O^EaL-*(b9p`Ak<;m2<wduE^MQk38S2W>8HV9dIOt&*kRj3(=!Kr(6j|
zg)sr+)`=rL%wy#99662~x2n_$tC+&~3hDT9)*xOZxQm~G*~p(siVpmLf7K>}mM^Mx
z4?1B_2Wy3n(OQkH={Yh1{n_1oT+Laa=348qh4LS?3|O-rAM9+c54w(h87QJFqpYyT
zM`zTr>DJa-C~w?AWu5DwW3q<k;<QpcezDd)?5W&EKIdISKJ(}L>nYn&5@*bzI4Kfo
zD#iCZ@Ej8~o_~qPsx8EmoeX*z&hGI2T;6qjxf}So2>j4h87-1^p0YFOb{aS+Tvf@<
z-_A4(IMWi&Ggp0s`S{3d@ub&q?n&HxGp&bEQ~8O?2h0zCje#hwKUGQNm^yN#&m-Q0
zC-GOV{n^1&*Y14w<s{|#D5=^p%y$<GGJ(^pTXLqg?LW8qHQ|ct45^#jIh}LFpBXKn
z6?*fZa~#`Lj=Mj{8|(Z&S79XuiE;I<iXcxRlh&H2*CjhSCp2tdoS)({s1vmIM0w@z
zP11G$^Jf~C6I$Mnx6GzqpR4-pB11bM7l{E&K`5vhRy6Qt(^kRV9mOar&8Ibqd_Jmh
zm5Oj3oHX_~-xo@=I_Ym=miGdhb)EAZk%#_#biDR<X`Ktml6rr>^$J%jIoB#hxb~Wx
zjVq&d*D@OkkgQ{d@tJATX3*1cO?b{cD=krm(d_2AJ1K*8Q)QiWoPxz@r~k`JReF{q
z+<WP1bf1&apUqE`rwHXKE36D;c}`i&_rDdPs}-(RP`O}TEo1PMkvw}TjhJnte4noN
ze7qw4a1HOjFA~C^D>_*=!cXu=G)WkFWlX*MGevZy|H=7X%}br-K9js#wJP~_9;UX=
zY&FrEOKzUCT);7EjUT<5TUSO(YTHNa-Dg#PZr{r|)7s9dn=d<|AeS_|@?>W_A@|$m
zmz6~OcUL~vQTVC#G~+g;Yv9gurl<^*PQ`MLMYlNbw9@)eO&C3KColr~jCw_sv8bHd
zh8(A8sWk3Ie@;8|88{&_=&V>dWh`n!`-Cx0NasjO=^T1e>S{-Z;9VCjo}#muiDzV=
z`XgJo+IY^O<+7YpublZzUXYWWK1bQfM@F2+-|nL;SK%d2xk!rX8swQOR{a&*pPw%k
zovDk~+A=vbw*PGR>T4y(uUj#|DwQ;&GW&Tvqkp9wIxAB_=U4nn%aNxb=!jsxHX)S}
z?Vszb`%jcla~<>lpVlMNw3$_#5T0ACu9!4NwP_e><kpH?*@BhXoZ6D*H6yN~awU~i
z-r^cs?W3il;BrV}PStq6#b~5+e&uyco+($z3!-`RDy}K4&sI37@DTP`eWuKOK{c{7
za|Mg~&vD$Nt8m+zYnS6&(a2AGGfSfwSA(isaKx#ehVNsYzD4mIZTarq<_+_idCxp)
zR^e+j!^#)d+8I6Y5nh$N(pJW5USX_x0VLj%@tDRolm*#p1vY=w{3=P(h`o%6*~6J!
zq~T@eLCGTH<qO--K4yQkKiD0%tvoM{%qyVxVW9QR=4)vvSIAD;BX@ITL9-LjpsI32
z_rp_pOCqJH<TYQLdwIG>w9xs?4d$kGrkIB$B=uydTq@Vedf6mvWikKNkPPN!+G_$&
zl8n~(`z|M%^a}H>OtBGmk^SDQ>NWE6*#~V|StcQKljb~pBz@%rdy$=Q=h!;3SDJI4
zd1k!XAW?F?O|&=ISL{B!z-E_A&9CMLJf-pGPM&|5+$V3ybFxG#n!P+lb$b7NHsS6X
z;48f>Wo0sVzgi|pIrFL6X4adhB!^6s&ux7>!uGfE@{rUvyRmA?r>*sdV|?6tVk@0-
zjXzI5h|I`GA9I^zrT?FjZ{$09mix%b^#?FIBGbL&Fe*K{l2;nLeuBn}<kq?+ZYzK+
z-zIUg&DOG;?0fbdyV{nQ+oY7)WmX^^UrHC*Yb)5{JZELuC+*DZNKIvp*KwOw+mZRS
z%3)FX-9yX+k{~zO47R(y!Y;RyZ7ul%S*UNmL*}P}_{yG8SHNw)^~<GvNcj~Lhgmky
zZxcpnS-j&l=9u)CJvP~1VpnnHp*FAFgS>o<r`rzQ5`EekW9gl%84H8t1)GQG%`5vE
zbJ6Arb2DQo#NUT)7rWBlVrST5a<4QsKe%`-DJNIU_qLI}m}iWYty11R#&egtfGe8*
z+D9zU*}*JEKU9<(Z6=;@tKDNCvGZ&x*}>f%U}Q8wk7UxA-6ZsAFUGYWf7}N-tgdX4
zJ}=M7+@T@Wu)e3_BEDmT^-agj?D!~Bw2t2ljl_3rU2djgq**{;8|fo2+NSnCFOyf<
ztLR18`)vm~Bnzdo`O0i(1iLCuJsFpa%%hT-w%%<^*(vrmyWQSo``Sp^EDh<S<!HXj
zs*Q_i1cT4bSx75OyZ8rJbA1M9b5+x?Mt=?m8#Yp=bZ0^8XdH5Hjc0K+r3dRO=M1jt
zG9_M<Owvr2%U8Au`r<7w!praFvA^2a?Cofd@pb}|`jGv>tLBaNmU%0^*<Mroon2~6
zpdtG)_TJzeYqbXZ#-K9jKJ$rWq!$Lt3UtiZNV}EK<N=u^N#-r?vLn(Eb++zI-6Ck~
zYG~zqBw8+!_qoFx?VI*jFN6Jsk@=`yV`n30E~~0Hzb7!BM%hlbBx7o=v|>!HHGQ#3
z=cn7wN6P#P#{R5S2Q!h8aFFplQtn6M6Kq|izB0P@UAY;(To8#{kM(NI=sMGSzSWig
zB>HDGEx1=QNQ%spXKcvUuzh%*30SE*HX2>MR)$M0i7|)Fvl>M{30u@!S4)fQOhJN1
zAl1f#^heI`K}%Jj#U7AvxUVLhYqXtYr`l<DroG%=Z|}A5cu`(`Z<M#hTjgEjjq_^Q
zBlLbvIVkg`1}%3#vfKvUo$D`L`SNq=3n;Fs60E{iP(BGi3dxW6I~!}4P4%^Xk0ost
zBE2d@HmHZ1C#YGIsO-2dJET8j^;R@RNUF#XxgJ|`)W+JXwxw-r8`=c<TDD=A^PA_*
zrD%p?>0*_0Z$1-jB9?!!xz_9!58FRkZdD!-V<Y4@`5gOoBi6X8cqj0?#ionid`~Dw
z*A2>O4pav-l)m0<_VXMykiylR?Q=P9Lvozo&&w?`Q@N^+nukFW{g95LXXRHv^?H6x
zVh){KI<dm&**8zQee=<3<uos%7r5s}^NjgkN=k3q`X!r{aWavS{D9qMciWwIBj}}*
zO~jf%g)JORpICIrT6AeAt&-v*J4$I)iwXfFa8*WCFEgF-x6k~Jqz^*VyuhfbWyf;1
z7wxxRBw8%qD~;Ao@j7`Uym{VD-o4(l-W%Sh-nZWIkQa&wWeACP%=_B=$lLEd;;r{C
z_4;~MJh4wOPRhwgvJTm(BALy*jHd<4Lg{KZ7vjmvYJ{aj;_cBem(aTpg2i%5W5(PD
zbl%5cldt6i{@TKL?kdI17og#Z*q>r&;Z}1M8cH&PC!0IbparCrVyvg+L;5tE&2J0Y
zTo|Pf7}fJZz_I2XBxVdPkw|-AD5ez`pHd79Hw@(aJQ$*+bd(vi%uab(-jY}33E3#K
zK}2Q2u<w}rl)<q9cNBBl9fe0jZPN{jScRSVOk$+E^pL6a`t8ab;rNd}MceJ9KSxP@
z$&HoV3%XmWIn|@FVC|I)G@trnZl<gZz2GA2mYUnSzr&K9Gxh;rZ{W@j$PxKjevzZ{
zjy%bIUIqfH2Xa4b9>Gcu#zK}+@7A~Ya>~8Bd6@?E?rgBrBVfEQ#nQuZv_NSoF8L)R
z_x2(^<su})am9bltXw9Zs}dG`j@fG7M84zkM+V4TtjbgJk+Nqbp{wfH6x-Z(040n<
zvtMc#+QsaPu-T3;Zk!!rd)bb*4c<X3+nV34(QZxAZuR(PZS0H7gfDEPktoOa_z{}_
zRoM+{zfD%jl`;#@=VC1QAo^jtEJc^>1pj>|zkvmlIZGEi7;G@dE&-=(Weo4dF28R-
zvtO_uwqMzA?Jr))%jV_v;=E#Bab9s=F3;n$eH_2Uj^u7ipaEZ!HE7y$=0|+J>*(P&
zjP3Z;_0|8(=4ReXBUgjWmH2)?paUk$b~$3>Xz$T>nZ3`x!P6D+YI!}qOT2~N)!rh0
z_wt&cZHn`LCfea4+9m}Z{{mWh9QdlBIf6%eHRr6yc#1iTRTX9JDu-?vV&)?GcbTWn
zK}KE?X^M8)EC*~1`T$KpvcGeJU1y(1&*k?Tco%aA_j#{---lvCr9$;WtwWvJ+lHEj
zQbKh?HA3Y>g}mSSe2X^&U0BJBwa4wp^ut5=H`m&^b`0pLHRnvR&5);_V2(cYZ%aJ6
zs<x~xZVRZC90k|x!Ed}C$!IQxLHqkbup96ymttKO;#tqusN2zC-_htWm#?|k{D`mI
zAmG#J!E2C=mMLhEDOkPsQdx3fo%Voe7J*4G0uL0?c&T&qaAv0!T}09##{T8zdXVR{
z<^%Jy=G;c3i+(g8ao%la8QQrQo=hcOVaR&c8600jm7?V*m`&yY=cz8;=sm}F_cS)U
zFz8^0T?>YP!ai-Ew2#}z`0ELz|316HUWI4X!#1!bZIpbA?s--o!S8sSHhWdxl-K1&
z*@ceVq5DJfAX@xk#`6n&azNhZ)5kytSI7w3Hc<qd^C*aVhUtzCEqVd<``^8}^^N@4
z@W$BFN%Z;+W*rD-E0XjyI`%L+*5&Y&lw|zK^6X`$gycil9z_#AjeT*sWvkT38LCXQ
z;Wg5~^9dq!zAmqNU#=EeEwt9fAjKPzw@1xx^D^W02$Gm6O_1^{@PS_hhi6A`Hey^2
z0f{dLr95pv^Rjp)y?S0-uZK6l8{!Q{pELurWV9df>78~xp88V8=Wuj*X`30#_$+wB
z$w(_HBT?9&{pJC1(jt&Wf4ukxL5;?|TIbHMX_HCWtKv0-rL@MI_}MkC277*uH}s=t
zBJ}7;T~Vu#?HPz4>sLS<qF&<=^&AJV57F$pxga7p=4WUedw;FT>Q>>p1%Bor@MaIr
z(^1#xM{Aadt3$hl@66H~uyfI_j-6+#xf?5bi`IRe#hEAKk<ZbU`6Z0(shqtlmbwC(
z;nbCkKi`j08V^v9yPk~o*=C+I@1sL<qnA3#SWworaub&C5qZx>;oS{Z@99!I%U)(z
z+8y=-y!vA3(<)wh`Z3-s!XD3Fz>88&^9Sj_Id%lvwJo|d3D59r*(Z15YtNA}VBwY^
z*Iek)x6Bi?f{PV!RmHn1SEe7Iaqg!*ab5X8xk<osTSU3ONAfIpFcJ=ewSF+iB?4Sl
zh*4buKcybe-5dSC5-s>Ly6-ix*%n!XZ5sfNY$c7P4i-0=abHvlYBo<!$zpz{XLh3J
zC(u_ele4Z?Crs8@tZ?0pFc13KInMuSn`5X?rp+cI0ndPmGlDUzDpy}We7b40%x$t)
zzO(skb!>7+_I9ATj#%kS?A3OQeH0w<BCkj6tzeVsb{N*XC)lr-?To%j#20)C%d$`=
zfU^d1&K|UXISJu8EyFTaR1g1rR+>T}+^T%za%6QE-+rFavKP#MOcFTbIJt(AvK@;C
zO0*emd2s0xyWPHQ57^i6^X>*GF0u0%L6gCa!}-*4*fh0`xyQO-(FB`CzT!@|V{4bo
zRqV?^8aMEJy7ZJvNWkaVhgXpTS4G5eFB$WV`A~TZ?o;it3@_|P?Dielh*gZFJ|H+Z
z%g_>Ju>^#%Lt~O}!Q!}V*v<GK2k=QVOJ4AGl2k)icL(dvQNGbjd7eJ_&Ml=i-dlf=
z@K9Q=EAO<Y{f2PdDCvu(E{7iwBYE%#YSLq^Bn5lrvd?~_F*Bn_3L(RB%CJz7zx=G<
z81oC(eJA%gnXz71Gsc`2&K0a~UbrnHs6kye$nJ3UC)%N%r)d3^_i5GYJmuwhN{`{&
zeTT)Wgd|-7!uc7i)E4_R96Qy;YvncdT6*2UozuK4y;a^uZyWyeZV=|j-eK=c{OOmy
z?cNREWUsf^!mIDq^&0W}BED74D`<bQuh={AQU-%I%Ocg8<QP4F5OlN|PqG8!-kQ(M
z+t~YqV7O1rd)U*5v2yd!D!p`_sfE`5PW+2lXD;04GbOmnKCU{Q%N%g^hus>Jt9E{~
zqMn_M`F%X=hvo}BgrnwLv}Fu>vWF~?ZCHzU@%|6e8*lLQFp54OebQ3r^QK^j=GfVc
zs2S|j@c}0()AYs4Ms=|rXuC1GO4&$S_jP#&D|VmUA!`{?(?BIXXz4b{cN3|FKbsT%
z`VLmeWhKu;6S>^RK3aRz)!QwrH3$F4&~)Lqkj6y02*r-b$t)1lTC~~SjLyf<x9_0)
zVz8pMu#wH>B4rs~44!ydbJf3>Ls-+7@Hcj=r*Su)=X_91fAzZtD$C(0{&RJd;yI72
z=XBJ3Y+f;sfT<Ulaav=zKgiGJ3b#Q&lnD4f{#l!!spcv^meJ^2mow)wHvPQpBD$*W
z@{$T^lv+*Gj8WGPO;=gx6=H&zv5PcYq&1#liq<f8xtcydxfkTXMx9i#EdA|5#8aMa
z3)dENoKX#f4DWu*M8A$+d_!6Hzf<k`GPcrH?Q+b&m9b8>@WR{3V3~^scu=0lCw&`@
z@}7JoAIoR*1rp@5AI8~=wiZakd9h#Ox9r4A-OX`7*^vB>2l6;pc?^=*8iefED4CC@
znvcbFoTejr*V$@^)oxM#pDpHIEbk5^_%7aAtt=Fm<11YnuyYJI?XgAisq2q!ZLSPY
zHUKR&nNQo%w=TEORU*3rKj8`Nz2kO&z&r&WI0U-<!F<V+zRl}LY<XQIeU>bh6^b1$
z<qij7*PRWY%y`%%$80=!qZxjBImb(Dv)bG|YaKkS_UP5>wusFjM|s{?<vE^w6X%$W
z?eEWPl3WHByNaKV_n|qhT39lnvmI0ZPFmmRv;0(fv)mfZd^Bin`YNmOV-;N%e+jKm
zlK+B64gGKX-}Z0VLb^7W3r(IQwPL!PuW(V@HLySZb@svK(w63!3mHA|cWpMvTP%g$
zYM@-O^|kh!t6AC1bVlb5S6+z`{2Z^@v$M<$ohi9i*)k59U)jGzx8Gw{Xy(Fte46*n
z?`ZjgcpD!2|5bF)b7;n+5+#Y~V#h{bM54`acuSvwsP_k~sCS~5ALE>_a5l%hw^?~G
zR)9+HK)XJqEE{*C#T+aCT^xTq-sxgx^zE!%z=OC)mnA)r9tvkicMkGHMk&MFg+&m4
zmO$np)4|1c`V}^-(5~&3x5}|fT}mtYGmN)leKu&8iQ{f}9RK(8x{JRz^NEXFc*?wn
zkNJc0_I!yB-$zTnfL-}YL~`K46~U7$f-jdxGGk-kR34_~c#^lE{a-`te@;)lh^KP9
z=8fFK71v|!<|vb67v)zPYKCxUE!Cps(}>nsT}@2ZY#qlXF%SgSN#}nGXdPa^qH1&X
zdFt?Yfgu0d<>VwHJ8iN4!;qSbm6c?ia!+51+)Ppi$q`7=RF$Dg_)d<+WEeeoIsWe|
zJmu>HkJ&Lx>{n)qPn3)C0G8C@h~vo2aoWQ1v3!bu@~(LcY1xDQeHhuegLd1<>rTxT
zeo^i3XXY?1_c?#Pj!ZpF`#SbrH@CN(dm6x#yIkG&-0N&}4YGC}Hgck_>ACDwm!sNB
zv077&#fiOuYd|)r{^TmVmO;NHC?}4K_w}pT*3b;1>U>&2W4}+_{OHI$I)9p5xk?=`
zq+64(r1{L%G`F~vMhF+z>W_7FzN(UXtXUN=y3B<n-t9=AySdXgd|p9$gGy@Nc!FYt
z|DHTnKYlu!wpOIZ(mU=Y7qOD8V<A$<bF8U|EKEc$Zqe!rtCVqQzFBCl(t0s#b#~`|
zbe^mH^Ewg<{u3`?u`H~6A<4&R&1il?4i9P_gOANu%C2T4Bw6r#a&vSpWmfx@_oAgJ
zNUpY2mtx@7BaDFe(48TPWvu6Cq<_m<UQo<=zv@88=)M@OvOHi}yIJ{MR&b~D(Kkbt
z!NDQ(_VnvmM&A_1Tqmv3lJm4U{J)<Y$k&<~gKQNy_n2MdT2q2-*ZS&DHP8&Yv`UB0
zCoO@^YNV0J%{i`_GDY=Q#+^}UmadxB-^%nf6R=8K82itnKVPNwKck04GSMTyp-CKf
z&C6(!x6DW88_9rHb+ry1f7+GG^1fPD@q0Nw#!6Wu8|4n2QG87f+mOv`6K!es65#cU
zwxR86huQIVj2&n@+9u%nhPH)mt#gWXY*qI9yg$-jW>?q^_Ex*euCdGQ5<AyUvE$e$
z*#&mJ-DzL7AKHWVIeVL3#L<qYyANj^#9ys#O|DiHf1$K;b(gWR@{7DFkH~HK1$SzE
z!S^<c&BL8#w-Fj=@VR`*5zlki>+wM@mpOPKm+_j3&oD%K<A-#?8*w%FM#@B)D%0^Q
zhDckfLQ7;czhlWWBE5yM+@<i_iXx|m7Tkxexf4zL2!FkY%pX#jd;*!=MSC7Wh$1B`
zzQ}J{ZRP+v`XNTjb@=p`n#*+bEakPBzvo~LW+`)tlg#OSex-5`U5`{x$42zWKDoUs
zQd|xFm44ma|84(&ZsE+KC|&(5qTK$j+EX!Q=*pB%{9PuEmMpF-kA+XFEp~d%O@FP@
zG0C`9O8@AH)H?AlHzK@B>DHP2+VQ#0lJ_6Zv2&WMKDsLfdtO?Z0o{sdS@cy8<@agL
z`+mhsKPx{$tB4jof!F!Jc?)N#q?e1Ai8gR?C@#igD(JF5c*U{)xz)XGW-nU&RW$t#
zW(=6E9&OwnTd){=c)PB$%mmvspf7W$GuIK$#mbPH&H3N5r7`HmXx?p9YEFKlX7H3p
z+8QBq?E@~HmdbH^G1_>Z;)-i@b!wH?Ct9cVrM7{#?*sR&LVu6aIwGCG%#Krf6Q0_m
z><=jG_8M@=YW+?cC*n@9`E%If$FT@^t4HGa-mWx@=)oIxHtl)yBu6g9H@FD9-Ua_)
z4e!38mBa7GD)gskOKWyfS1iP8P|zb-qpe))3VL|7`hzZqqXEa&2IIPn!x+uC$fb3k
z8z}?!Sj~xFtQ80yyJFvf4XTb-h4iDL9Ct+_{;#WEKr5|)UNqnuvsz0%UcI|Ed{$3A
zq)3gGisQfDw4Y;B?WP>u6**=qt+11}*^JHWgcRpj#N8Bxwty$R1>Ck&<4db4FIPD}
z8K^M|^R+TX2jv~9s+HR-^Ar`8f1x^iRgO*2%*Hg`aK6&)9~TO;3(jxzwU~=wE~q)c
z|H-(xzi;!otO_Z|YSAG7_Mf$#nD_mkh&J$}kg_SW*O{~XMf3e4mG?8u=NaZ^&x;hN
z$D8BFnL8GcsB{?{{c~njhOARL2TYLb?8bj&z+&^?FR%WpOi`TyD2JZ+Yxac#HcPh}
z6&rZ-63hT52NlF8n%U^1E7Z%KqfB`d*j*K|@#<IgP%h18{B-q47hn_aG0$LiKf;$f
zhUXihl^%Z5%0}PgJ-9mBCA9ja^JQP<*eCI~zU2LqQcbGzGrRd!D?EIMR~D}RkdNQ_
z@STfGIgY9$4WyAYW^cq_^_1(pw$x>>$>)W{GoNTZ%k7-|9ej@jK52y)*9bp40guH+
zX8de^Fh6mBx%oy5t+3`+oEuAde3}9}msV8b@p8&?h2AntZo;41isyHUR=<nK7q22M
zrJs!Eor(N(kt+ju4U@6FGf5`!S5MAdou@6xHFIhdM|tkGsWju9<$0Q{%AM|NbY@mI
z?jv}g2hF?ckw$Q5#iR_^s={85C(kF5=9u{s|KHUjc?s+HB0u+I2@fcv@j;!_@~bm0
z!*6mmD;#%TV_m6r)i*ZKJJ-;MgO!EORVQi9Pgg6gtX6q(nf$FaexV-k6b$%+vS@9W
zmRO&0^!ZS%Y%^sZEUj}uIh29+Oq)NSoKLxHODbDlTu>XUyz)_12-vC%X%6rCM3beR
zIa3hfSnvYpxc_fEzb#y&FNdySpNmQN|9TBCb^jywEL>~w#H>j_t38{}a$l(X{d1cy
z<FOhEn@15wdh9NKtLIE@bwAS3OXVo~Cq){{3A{7$0n^f{+C#MFUQw;?QeL^>!@OmF
z_26=7r^d<^nfQNNy9w#+cwWs-J(K1Lx1Z05600)_j$zMLEzc9g==&%mlcI>s`rECB
zIKG_9+;>Th)o?6rIkd*0V^ED#wh0@|EtlrFs+=?a44nDl&F4!gsEn;e0>%=zx{|=R
zTj5u@*yld#-<H)mi5O*ONK$suZd#wBv+|NADw=XWMq}*ye5}O1_+?x1vMxujyY-n-
z%1u5Q@42_~+*ZS<s;ki{T}^k>Q}-U~7d6EKl;&zqHj86FE;9Y_v@TI};H<<X&NB^^
zFof^cRj%en+{X-EQ@MuUgS4)DJMMfoez;quS*sEAqx4BqlwmrpRl@TwC3y;;g{(XG
z(Ul{cb8G`$nH-MAyFpibwsO7|%5-*_#&JyN&U$l)^#d-~x~Z`=F`8+egH|oa^VH`v
z=g;M#mz<ZE!gYEoYg-dt11+O`AUTvPpb&SkO>)S1t?bzaEU}y?bXmOFXpcHrP{+yK
z;2i71VT68eeC|hQ6yyGC(c0xw>l|H}EscfpLSkd9Gj&-4eolMZXMSd94)q_R6s<?9
zk8rX^^ZDr#w4y}ifcY|$&f2+|Jy&bIzQ!PR<<&Z1yf3P8E|rxNxreR{RM(kgzo$-S
zfbsdwGAjRc5<S~OIj>TXX*Z|nVgvGP=59R47Sw7|d9+Sdl5(XtQocVYSH;yk&K*<_
z2s4^m{)*%C?q;fv4aZX44Jj>hO3p|IWz#FCXRNEWx%|7$!e8~x0G0ifW)YI!fqN{g
z*~*1exp!^A5>rUuJ6+?2wOy1lN+l~_nH%wLj-fo?$)>uksLqwNVzgD~{CV^&Q33x_
z8+1ZTt-uwpJeX1G^l5~yT$bc4m6Vk!=Na;R!`UmY75#Zx$F?1-ZSC}Hd7bent&E9h
z$`p>!xtPkzgzeU9i}UR?{wY5S|DR<U|F``ow=-20@%ce>2b^ko&WpL(m%U0_FUVE1
zDW<hV&Nrjo*F8R)U5-?qY`2B$kK_sPs-HcTQEQ9mQ&#poTAL?Y_b?x}f8CI>#l`7b
ze+{jB5wAGrk8+>+XwzR?NzjTviOMA(ubSo5x~%DKJ|9A)GPt@K=<LcIQ<!@z5-<^l
zXKQ>ON1tQ4@kv_m)U}z@84<(%=~qMv>HJ4deg107hFeBC=W{EwvWszWkuL)^Z>O>{
z|GT;~j{mui)<y8=c&!OnyK>g1me!qcoXm}sEw)8axhPh1wSCU17FZXTW7bmbOD<)z
z%f|1#I@eoBnQp5p?`#W|6~_|a2IMeEneRJs_9V^z&Z-QDt`<SEa^{s*#=jWlm2mk?
zj`_ANdqd4ZOJiDf_u){J<5y{@n7Nj+-sM;8R+%eIHLJ|+W(&4w1lLZ~NYJ!ej;;<~
zQ)R2HLMtQ&HKiP<Yb{+(sjYL(C6(tTzpi!_RGyFGI%DldOo7zeP1W?+5^8&kDf@3D
zbaQKs-Y>7#;LQA=Cre;jMU4{L4~?`kz(Cr})x&Uc;dM0YDvz#jL<bDwG0HPvm3Ho;
z*sQ6t66R5hSB{oxquGHiltnO~N?~TL%Hir>bf-rKapo4vaFZ>t+!=Ic^<);&H0DD8
zs@XJtFu%@H<U3`KBV4s7Dpf|q??$TE5fktzooO`r_$ia36F24}wcc@g<$jIRd|aP-
zbv&}vTq7qc2fV%~x3ip3E2FTYlw5lC>>B-*U+4Ax>>r=iIr9lIZT6)52?e}TVapn3
z=MT@b{#jca#><)1<1IvAjWqX2Rv9VJ+gRJocDD6xq&y`PB*}bZUNX;`m(54!Tl16o
z%DiswGgl!Yt_E)f`uk#hg&(A)tdQ5_2l-L?Yr0C5c^-dg4&!3BMkOrPe8-MlskkEU
zf5U2PE=KZo=9o;B4{VZcXiLh+vRKNPH$jNw@voemI}ffZ;~}?7Paeig3p}U=Jo`qo
zL2EAh8S``T28V(JYxDfMm5(#8@=|r@=rOcm7e;Rhu9z{9qHJ0pE5|vx?j5^Y33{QQ
znTg+bEmw9cw3U#*+*+?E1zkK`{mJ1V(R#reZAQ&~Z^*Z%YHsgzMrBj(Jyv<lvY}h5
z(^sRk@8<LA2-WD-lpWu#YNlwFpoY9toae}@D`GB7zb4mqk*z}l3s6c~Lfg?=*Wyn;
ztW}@q;zPPMJ?9q=0jckkkd%=IQdbi2{vM~b`tnIdowaB{yNpA6wwOoFb4b(^<{qtY
z<!a5WFt1B(dCK;(UwS>ftGt<BlHF{x$S`w|wyvz&J5wsd`PnMu_{>Zt>6><Fzww-V
z9{UVhvZr!$7goINxT&^F0a;>0c8q<-9`iEV&+P_VUv^1T#)o6pi}~w?@E@{C5W}5U
z*%^x}%7{}NRzZ<KJ!N38tuc`<<Iv?By1biiTKjnh<KSWQg(S!zxl?|#ZS0NqJuk*9
z;T5qz+HJNQnq#>%FvravtmuvSU~A3&=78joZgPi>ppS2{Z`rTyA=-VBtt}tP0><I%
z$}g6z@wGlvwqFtCOumqx0bZY8orTVN1AUhwW93@eC~IV%bdjRwQ**bu3>j#HY}eJN
zsiJX<ZdJTAvY)KA(aLKj=k`d-8uO+Ulp%7z_3TCVO1sm(ZeOu?+wr!rJjS!eqANBd
z@dGsyxFl^>Ky6rDV9VVcN-bo)gvJ0z20XM8sjRg&mBF(>DkosnIWv|1{_VuNR1vyf
zm|HRQ`BduoGgnPpW0zCj&!mX0G-I-H5P{JiT-Qc%lEYzDm5nT!K26fTEvu13EmdNB
zX{7Ezv}1Q&!KtAAUsm~!TWA*6c=X~%w9&g*hghj5eUPFzZ5brsJ9N>GP-LiaXh>*c
zXl$r=sBS2m_o6q;i?a{dw(>Qy)>BHDU(KuLE;QLN(@JaaI_}lz)H)0&Z+;e>Khs)7
zD|eUBRi-jp=g?mVDx>ubtET40#j*R9H2%7Z+&=HK<BaHl=ALcVqr0<6JM8_}wywR@
zK4QP}a(k7%7G8I+pV!Ch;<fZ@dC6XJ_A<O*+pFm%dD-k|cDtQv>&bC>KrWH0w8bv;
zgTu|G{(y%U?&}OXGh9HiaAn4<W9n*0&ke@rxhjZ{m;>fFDFG(ATK3v(w!K|$-|`B1
zy}cFQZtqj?h<DJt&zs^^u%Dony4rkl5REWGDvQVHeL(HaEHhE7#13H}W=5MSSVfmt
ze!tdU+^umpZvEAd&)J9ua}`vVV)d@qimFSwlgrU8i?q_}I&+Ig)UV>qQ@PL1TEWZ3
z+q$Y2wXrzGbhH=LzD^8SJpAfZ(SZ+BM60$Z2N`A=6(hPxb5{?hrgAywRsSz*P%+Q1
zD0@0$&5*kOpXH<~5}|;bKfh|7>_H^A&rcc~L=&8!pYcaFPpfvgoWLQp)t%-wdae|j
zd4cSZBetk=@@%qu?NKk<E9RB=s(6+7S(d$mR}J~9%d3(X?`5`M*k|oJJIOY;dFaoZ
zWuO!{Uz&$#{|Q>dvoqSDiH^K~V&3b8*~0wlY1Jst?MaB{wL2T+sxO5tP+HHYtp|oz
z1Z^sdyKl7$s@8Iq#mngGcw)dZ{?BGP@^nTZkIpSPzrU#>?3LhyUFegaK{DO(c;2?T
zZDTvkE(D)E3l7bJmTTu->`nD9_ZEBe(JF(zHt4`IUYr+WzqilXrQn3jvPV{-`MQ8#
z6C~372<~_b<m0l87HVAp7iH(_6*SXXj4|kmJNW!#jjwlH6G_rWX3K-}oh@No*?xAY
z9l}1$j$j{TJEDzCaA%q1H#sc((9eUVl=&JBwS^~Gs?p)I&^(jPG_?49@b&fPCiIbu
zI)Bl81|Ba8G8(`YR>-Y#hisPBptI|+TzATo@`}7G@5$@(tlTH-v3pm`^|DE}%hU24
zuLtFJM%x;$xlV4Bt7Iy+v4O;EmF9iu%QcMa$y%eYm0DJ}{t}f=<he)dCvrqD?r|yK
z+DyyubZoQccgZIeqzSFpk5S!|ze*s)Z{b_40}swj%`*P);L!@tzeS&rp)OkQ#;qbW
z)^(RYx;EK|wsLyS;hgsTHN=dir6=P*4dIv$S|Mrxt+|SJe8(KYlYbk1cs<_TSj`l>
zL9<(yaKuRVDdtN4yBT?LYythWuA^V;x4O=o71!El|E3CjekJGfJcEn=TyAc~R_}6o
zfQ+d^Qk@aiM=r)6m?2ALtL&E_ZLCeUwQLi{(=fY$5&oFnga5J3USmhu7Phzz$p?&w
zP0DA~M;b|@`3+QeD`TrWHaPwd@UQ;gH{X+QMjx$Z?EWStr8UoR9pmtQo5fZF&rCw+
z+=6HFCLU`sw9^!D&+XnlV4nNEN4)1jKS#Wuy&t@fyl1^l-dvDdW3QAKZI9X)@TX_-
z^d;n&yePNeBV7!NYAY8>OKAu`ibHofUWsqaui(J^Sn5hrgT0a@D|2R5jvI^?S%&tw
zLMBTu+NdI*B=Sna=P!+3$SqbS@dXgnUVa}oKY<6o0eRhzUK)=6t4CYb)vBOfbk)4G
zt{PTWZ>q3n_4y3L)s$hljIQnH)w$sWU5)l*l}qWmVlhSf<&|ePE<nfW$1VEv{PCQz
z4*o(TMP>fnYDgmh6Li(n#dJ5&dr8naWfzA~NwXwe{oit0xvU{)sGy95S<a%7Y&yP-
z1l1(G0NoW-E{OVC<t#sE6Lef6XYU9y^{ceC(R!=()u&9<s#VciH@&!W5u{%qCZo<P
zrnh!{ep|TeO(x~}uY>GQLv!rVyyQ$$K*}L2-DDzCa1W#Eh|L6!tA$)n28VC8I~Y|v
z?L+*2)*i4wVnK_8=A6$E$DZsp^m=;Zz1jFr<Gfy8Gp~knu+{ULV^>>xb-WT@R{M=T
zXkWBX+Xs>JEA41dqT{qEY;)O+@{PP94<ozR$>lNuYf(#bqx<%PEtjMD`qN&?nv?k7
zU@QK8n-|nGsfl0heDpSq^9JgN_cL>``TNWf$so}Z<>ETgF|lZt=I9j1`mquWb*(Iv
zY4~bAc()3uB?rf4<hX2Trr*E{&nVl?WHA49eqW`Wgw7AUnsYyguKC^kg3h@W3)o2O
z;B)~GZ3Ic|H1}W)-OTMWj(kQ@N7Vmg?>pezs;>X_p5!H4Uh<yu%5q{$j*~bfPVzLo
zV#`aOVac*0J05au8QUR1LIxvj3SkrWE~8LNftDl`XaoHLWu(v&RtuETvfHx$-*euR
zN9?3_N`L+F`RB=!rFY-mXWo0yIYOimhF7w%3R2BuqA2Ez#bTZq3NEk*u>FAW7^vg{
z;X~o?Kw7mZ2>%fNBD{io{{w01P2sP?XMo1{ppCpBJi}glege7bbm2r$%veypx4=7|
zh7S24w8I~%HuJgQ4Q#=E7380*aPJ(J+kDU%Yrusw6~D`J1l0_VSeVDL>PVl<glynd
zU8DMy>UH$<uc}W~U!m=p!U|Au@^*Noa0j&SUxI)A3exBwgfGNI(F{3qE3ooPww^p&
zJV)Fq-U*KPmiVnY4w#mY*KBnXbgw{lkUA1N^c-O59CeC12srphNVh*1?*<Ou1io>n
zcnAAQ^+E&72B-W)_(=F1qY^D9iF#=MFSCxlTu6YHO?KyRvuD_?z{ql5OSJM%rHQ?m
z|F`xE$S*WSE-43GI60om>6ne1FhftMo@aa4F9B~Uf|330v<e=`0p~zs{*CY#F$7eu
zP_&43Vw>16Zp5nxl7E))1!&+NJn^Qefs9^^CyGTQo{bkHp%;7yDER|Y_d>dU6%vSE
z%n|2`siInV8}oD*V19>iD*Kb9^U(9bNpm3m(urmbw1eG%*|Pxcy^#2h<rT;5Lq;R`
zzkA7+eA(>7G=r_^HM}lB5z;97g$o#P8nF37aGASRzlQv#gFaA?QQ6Kq%FU48elF}2
z-WCOn+#=Bm2()69m*BM$^RZ4m0}#4Ld{z7i5|OA504#^9W0>0%;x$j5s16W66W<fx
z1V?&a+%4WFUI1>@0X@qpy2N&THbd(w7Uzp8VwmtXF#dq>9A<0}UQeLrXYtx6>;`_{
z3?1ka(5iEVGcj*o%v&`yD>`Gp3VKTg<f97wH}iS>Ld<7|5GRE4DfURnQ?meBON5o6
zZH>@$`h|_cX1x0#N0spD`ZUN<s~~xv${N_6{JIB{-(J-I4Bk%xlJ*OqigDs{@mO)a
zxB;(|ILgNcaU1${6>#-F^zTLS1B^m~IvsC~_-Ao1#^-!-3wxRy0tTN5j=B=E<Xm8K
z8uZE_P_jP?k7Jy#hGcgsXvy`$jp*qaz<?EkUiBBq)whA#4g;I3IHq$Z$JEkIYsKOJ
z$4lh>*zr+c$1XM7*O7fxHt$4*DPBSJz=svkqbVBAsh~|Kf=(6i$=E2~DL3#b&r;mq
z3Opg-@?<xW0^TSxH_K)3{#Sty+zLIP;By=1bGPuG7>;?Khj$Ek*vG=3q3s_4{rM|<
zqc4CyM0WQ^F^2iuN1${@@i=i4w4!qXS0_L-TE#k3r+6yvT?1IULA+et4){AxtVW6z
zG*1#&0DmNubOPY<G`xC&nfYP_%KSih7j=@4`j>!5Pct0v6&?m;-vT(hUbs%!C0qtN
zxKZd4T)>59p%R)#ETHaDXsc&{GVDZuA7_n%eCKQeckc&3y%hZAL5^Ruonz)yf|j(f
z?_;u2ti)Iu4(qG^-<#hMK1-a%XFrm7{f(k#(5VXxWY7}!5M*JlXXEd5UWC?uyyy?D
zVZW$)2R!_9aLRX}y_0v;->VLQYyJsu^5pV+_T};sW;Pa7p$Htw44PsBcOcuBl^CZj
z!rj6vn8OUvL5pa^=q~{Wq9_v|ve(Hsz@KA5DV&&%iy#ABC0-2<{(!g-{QpZe*tGa1
zDCXPZ8+g4A%J_o#IH<>U;w7LJ7eZ3FM%*P{0T>t--C`4Fvl+CqPaFXi*#L^u1NylZ
zwDVZZd6Ad`PWNZ_lm49WJU;h=mRtzRRtqVPta((B%Lqo(g*<4JvxFekYpMq@gJ<G(
z0p^rE+K?yg6EI5o>_7R?GQwo*^XXi|C`KO1*+$K1%=bBbHfHA01b^6<>^DcYx0r7H
z)Brw-U!=0LS8?)8*?}287o21_^nm9e$==87Q(J+{TOj9L3~A>9NR4kp3KLQMm!JR#
z@On@6HMnPnFb@=N9^j`KbZ$Vn2z2h}!Y}Z882aEI;n%`%!6Wwy_d*6gPdFRtHwlkI
zHhTkb`4+g_OGw=VsJsY#w-Nld3>dTlyzXYaE<$;BUUmE<bcLO&5zr6PT*`Tcjii&!
zX!(i2XF9chsOXH-y=2~?QKIQizO>*Ci%@?LM>5|D8h9n%<a=>5pIB<-lVL?1TfGBX
z#1pDdg(zq-I@O1ukhiKXgLd(A)f>>VOdLV6P>6>%@<-J^(9owqXWmtPgR~^%h=RUE
zUdQMZ#!Vc3jBMDiRo#zg4<O}zd_JkV3w3NmTh4*@@c^`}7ch6f<Z~ZRv|tsen|!9@
zHq=V{Ww)WtXMjp?Mh^0-|0HnzWAcxJ_C1NR+Ej~q-(fcNvvTya48ODZyqN*t>d@~k
zXvxKR(<z%%*$>z?Y!Oc_>4h9Tm!mSLsER=^PGPU~9<(BxV+aPY&t5t;naaFX)~EtT
z&y$5rTVhd<+JGic5eHhW?8IgBy6O0sCnConSpW{y%Td}c1BADueG53w*E0058>2(g
z?u{6AT9G|RbuxSH?ZW+=RWCwAULe>YB`yc$*9*arAX7j`Yaugs3de%>#{nnE@}E}t
zpMXC2DRg7<ne-Co?P-kmcYx(;NT;Vmo8Hb6rUzQ-amd>Oxw--+ECOsS1V52jT3v#A
zQXoyFqh3j<g9O@+SDWC(s|_-4J*2=KAx!lZbj~R7W*4-gTZG#o3HP9k06sx>6I%W=
zj=NC`sg_oTUWJ}~AD;A}#zJtdM5GC-FM!o=Ku6yXxFcK5eV_&p0A{YiNKw?$J>c`d
zg}#10=DruN%^0Dl(8ss&?0tZVA@;LJRx|^kD;A6>*;&Q{nwGOwZXf#|9pQ+6+W?1W
zaBPzyK9OZs%?B0N@tM9f%*S%TUZvv6AdRC~3cM<p2mC7M^HH<E2YjE&HB|)jAI{}p
zdkj0`wa1xUqGE@pV=r!c_WrU^*$ucD@N_kB>@>(*Zrt&3gzl4pi5CL0ehMl^(iW{!
zKZM`pKWPZh{s`3S1yECpLlXo@eG?G+8)&5a@cI>=B#gTSbm%F_X5=e&Kd|q9_Okde
zINIBg=Dr1$`v<7qyD0qy)ic1-M}QR%qQ?6ntzHdj#|!*l!mA)5ysA?SnQ#MIa4sPB
zL{QUg-kX=bMx?TxioD89{%w-@Ohg{XoSztd`CsvrvFGI7r${~lET6-TV-F{D*mKS-
zMVg)Zw0bB~CDmHA_6G2oD}kZ3M%@nlx(&Vk41NDt^(;p?JQLhxx9W2t3)E$`unZjN
zU5vsG_NPb@GfzhePpIApMOXlO(E^HdEa;mBbSV#-a1rRuDo~|apf+kj!z*;X!o|=@
zcY>-FL3DkMy&irG*|G@vE5W_%LE-v&#o%h_uNOf&CQrYWNY7!r_CQFX@hGtn)Q>FV
zm!h7zXrF=OROp3h(7(B8LA$UCG;52n7Egp=PG1D){0F3uGNh0l{4yaL6l@=6oO~y~
zfPQ@i=_Cgw9xt2>nfEf`T(q@BNCq6d4G4Qlp=Mj5l^l!S_ptxOotW=o{H7C^v{rfo
z(=F0smhnz!@Msk04CZ6gJ9l+tlJO7uQZp7sv4w9K^Y|Ey8J%HV$ow{*Wz|EEoEFr+
z09=61G?L#_J9vWZXG(jJXN-VReSYk&z!)dn1CC(}VXABelFr^wrqV#kJ5wHJzY#D{
z$FT|ZTyhYf#!o)T{#HIaFIz*7)lWWm(ol+Qc~{Rn#Dl=Bt?Wyu7;qG(v^|X1<QJ<}
z0=n`!!nl78QI3_Dttv!YDp3wu0nTO%n^caDv{13ni)61M=_td_C+Qq0Yc}o@zsyAY
ziH7Z9yr**rr$TZg>xqZK&37~1ycTqKJLqp8+mh6x&uhTNw?a0$8T9j3aQ<t7BR_`x
z_#9~KYrwk4Kx@whAMfSUS=*5R5|qCYGbN#BJ^C<PRRx-P4>0V{ptg@A|7Ktp#qXta
ze&rmGESyh$r0{vVT(mU)peSM*wnr&oO9`@pq_e?#wy?|PNJ{H~rKh6)9(*T1kTEO`
z2+B%w5oFO8^t}Zwp|cOOG3T@+xe(9V(1LP&(rzco>Js#cQpWe$yrLhfoGo7m3FUHd
zt4lFHeP}mDOEM^)ll)f@+xTX2+~6dR^&Y0|vXm>kEETA!4By((UW&f71vIt-eby@$
z86kY4ZWgakl(1D#k7_+&o;)<?GW{<G^jwM=+lP_A5~&hfFD(Vd+KM?MZ?IQmZjWX9
z6vby+b*!h<gRfo&9`_u$<zG~9;s5=ZC-OYyhrcmw5f9<3?7w{lV!SDiZ!e%sUQ@aO
zJZ^v`2l8n8Ah^vdkN|dKRF|>e*ts0xZxi5B_FFX<V{5|f)^gO1B8=RBZ<pggd(lcr
zGFt&iysBm4bK!O9c?F<lOkSS2-twQn{JUne8B6?8z7KT;DH^~sz`q%IG+&7yAuvVA
z0G(UScKvn0i@D?aBzpkL1#~+g%WMbDc?de~6MU+4Gw{g?i1C3E?o!<ineQj8ji13g
zI6c5_@)LI+;OTPce3$Ww(sO|;mqB{k18Ii#^K_7*UT4328$lV`0f8Nise|~v9nW5j
zH|a%Wdry}A=RzlX0eJT}(7@-o6+1ZU8toP>2e#+3eMbR%i%90EWHf`(ikEg5+B6Ir
zx|Kc3-3}~&5cKpK{Putw6tZXKIQEZh0)1)b6G;7_$K*Zy6!u~F5c>WbV8(;IQ{}}o
zHjL>~&`#OIf)jVjIo8))wk;xxO5Wa1M}PW(O>N-0PPXdn=2J>u+#P1T+77zggYho{
zHI(B^_+!u>!|SNWs~P}(d7y`rXIi#wn2x>8*y;B8BRbtKu$P2X@NW}FS+@8~;q$c<
zEmSm$<x2QCe_v#yG8eOC=M(D3Vx*e*L=45BKUsA)poBao-vwH9F53VVqU3O<{c(I+
zr4-Nh^SR|407190b<(Anl^qznP3&Q!4rAr#S@O<&HpidOW-T}frICdsSy@_n4JMkc
z;^O#xF=+zH%yp<HinmhA95swj(vW>d9G`HPZSB)Q56FY$shHUj*0synU$`CfOKbIK
zuvF5<zOoBZ=Telm2D7~x`0yjh!#lvSHnDbg1E5%jsh>k`xB(b;3*-XwLw+%Iv}4&y
zsS+ifjGkT%c)yhWkgo-{)^MF<|2~`T1S&A9YbW>!l`Zk)7tM13`azLMYtiD3XvvlA
zdy!%?_HcYkI*&A)?J>&%(I(zc(6C>HB-F41y&=!=<VC~+3`<quGz?{0QS&zR>kQy;
zDaz2PWPc2F{xpMqCrtD;5QIBqbvlgExQ64N)?<|7|Cc@Z$}^k9)~so0Ys6?9WqZY7
z#hXh6uZ8C--eaTK#)YJr65z5AFhC~|+t33Wpkh9seUF*sYwmyRQjdDgo*5q!*o&co
z{eI@K1WeYfGVd#Z+%tcI98H&o?H2q#i6U9MmUWXDKD|bfe~Lku>i}C64<Ld4rI1#g
z4j60#bf3kR32uzzyiu<Vq@j?HF*%|}GkZ>npK!w6Z<D+PrLN$&8L%(=;$O@s2K@5k
zGL+K@tT+)grUTeF1S-A>^F=Yk=tQV2N3KLk1#HP|2S#5C?ezffR2=}dKMQzPfZoYI
zKeeoF&1YGl3{n93|FE$Ck689?X2P95UIo4m?~D1IvP}6;Ks|Y*BM`(fn^&-0+J<(F
z(RI0R3s|1EV3g*uSM#YPtI4}N{*^ScnMg)kR<keM)0jTh1D_YM^>-!4bPfCBnTJ*o
zr4;$3@-o~b{#B3hAkASGYIm@Q^qWAJZe|=M52RTrI|JBH_HipYQgIZIOftrWA`vX*
zIOW8T{4(Qqw7|)_Rw?^FCC{;^U{;o6EXiZRd_1=fcj=7ujY?!yAEeQfkoP={<1I>5
zkNd!NA64xIwS1htx?aolhGw&qE$hjCuL6D82o7-@^4y5FpM(@ET1jg?My6mV@_zF+
zhP?|g+q>}OL+mmCYLrxiv8Vp%Syx%h=QL>lm1tfwexHnSxE&PxVYFr!Y9~FZjBWLg
z$1HDQud!QDtA`_vkfn7oj}-ac+YahZ=hJ_$+OK*>k)TdMn`ZGTPV%Z!h_V{^3^aLA
zA^(hIL0ZcY+{BSK=v*l2pH9?r1t{kQsI?l;#qlZ7Af{Qthgbm!0v;IwvE3|{k@i&w
zm`LF$2YSpI&G{_W;*&?MBxJ}F6~CO}iXFNPZEE(#l)|zA`MHw0?BTV5K(=a|%@oDN
z)?dV-i!f647~e)<;41VceOfWqMUH?G&u3`Ur}SnsMlnKJKGG}RGUR&{!J!7DaSCA4
z1$>*sTEA9Vhe~IArD&EwraoaiHKiqNnuF5X0Xt{o-L8~8IlrjHN6P~ylmOc7Xicr+
zYk4(ee;#YtS&Hv+l5Vs3OzcFdjiQiIjOyb#2J#w?K@`K(n{1Khu=gQ(9VCiZLn)&5
zDn57L1k58jC}!Nqg&@xY)V>A~OYssq*w6kNK5wv+ONnD&Owmm7LzqW~G3^gk+7*f!
zrnR0Hj=ns=RCfzUUzVd_Co<IuU`Qa&o6epHC`x)RMxh6Ic`aTS02>=w8jfIZ0&ysl
zc9_lsUf+Wkt;e3lD-|7R=^$X5BE?*eF&_XVtzzkvyja!%pPcL&trO4ovn9Eg=}`fD
zhM=~VvgC9E-%H}L2xqNl8QZj#Vt!2Q<(<5f<Z=Y&LA3Hx(4S4nR}BiYnlbV^Zr52D
zvE?W?fOj^@N8M`0^AMdNO6EPkZnS(oMpXj!qjjg1e3qk?{Y=}?Pl{LJWU4(6xoGb#
z4LDZ9Yac6lS623Va4e`D#i%212J_hK7|CNfY#BcS=<5MQnb1p(N?tn*<J}55a%&i1
zqXy611&!`kpztFoBMZ+=2kZQHbw}!LGZ<sJfN7fpJzm5*&kySavs$qxl%<_W-a*ie
zriHSF<7}pI$p`ISOkLW{r8aqQBUCy29*Wt>#fa8(1ScD)1##htR{-zfW->L&J>;r^
zTJdKx=GDXRb^l;0D4&u@VrnV-D3a6tYbNAjsDM2zgpT@QOJ!dzCPkLkGxyPs^C9B*
z9U|`uk)*MT?VrhxdA<^T=iqUWS0@*-<*bGM8;<wmujO4F7bwIfpb;B^bw$9YNS5kn
zb3C)9z*4erI6Ti0S%ZvY-zf5)QGil=m=b|=OnZ>M=1rbW4M+Y;<z0^Pe%WOX6*EqQ
zAM=S9JnC1*?=dM<@#rL9fh;r5XJ7OV_UW;jSM^D9oDMAcOO-t&1<Vki)$BK88R~9;
zY_XiB8MWfOCQOM-`ma|8HB8U)Fvn%AMa^cfa);Vsov77L)uK7<*>V$T<LTfJ<$(5R
zWh~Te7ffp<dbS`{tHz>aB`|LrTZyLoaf)p0VNWCHv*a`kUed}D5#$qiJ?sIcfjyx3
zSD>RX1Et^&ry~cQ;CG=68`}mHv;B+gvu>;wS??x0>SgTf>EL~o2s}~7`pMmpgYQsX
z2>wya`c4Y-QHld*V;O?{+^uAf7G-QlejKk!E#mbK8bclX6<Eq=0ao)Vb@J&niz9m{
zDHg9uyw-7e8&}!$=pwdks#aD6raH$a!)KndqDHG}ZOUoI@ibqf#6KxyjZXH%u|)9|
zmBYILhl3({H8h8JBFMYv0v_MPL!PYtCn(accJ$=TWDGl!OZL$g$v!J(nKO_*H&XmO
zvTvU?h5x1h)FpeaOXl^RcwXg@>-Bp-ls#98qbqbIi`p<lnNzIl2eCa?4qJ>JYF0GN
zjmUb9yvEXO7)Gh9$Sa6xpjXQQea(D+bpY~|7vGu`f8yj9fOLwbOq&nZEW!Z24Zx{i
zl6Q2~JJ8*>gYM;GwB>!qTt4Sgj=XafDl)NcvV?CyAIK-hQq~y<A)oF5hv)}BOT4Z*
zm-h(CX0MSwT9&Y9`&K-A{Df6<4ewEEM(HNWe2c+_*K>(yLh2n*Vjgy|=dc>Kx0}r~
zq38HMdOqi1QZ&7Gj%MD(IMv7+=S7gse!~0j_dw^|0o}Nju`Ppn5ZSiVib)mnkw1Pn
z=B|+K4ruk0cI=MlHT6!8)>z3W&`!W}bh_<k)%B3GedrIZwNAxZW$y}+%%#WHcjfiw
zIQC*1srbV3dn=1nVmt&Y(U&4wHVRQ7%>PU@`!Oaz32t!YO_=>gruxhA?RrR~WJ|LV
z^e|yUd(?{O&{@2qDzVnxgSn&gbL2btKET9pRWGYvSAD4ZRtOTJ1cQ(#tPo20j8~U1
zBy8f?ZM%d!g$IO3gkK526<%V?rmw{yw(OZLn#AQ|x#$qxVy`$PZWGTFuM}?+?-w5v
z_ld8FZ;J1WpQ+XAD0PZ@o_dMetgco!tDWjj^{{%o`a<<C_3i2h)O*#xQ@^HuPyMm_
zpPFDzyk?FjU$b0Op=r{1G(OE~nsYQeHP>nG(mbMhM)RuXJ<XQ^LO@hNQb1O~f`AnP
zs{>jB)&}?jP7gRcU}wOs0Y3|PGT`}u*8~0<@MWMFs11w{%m^$9lmg2F9f4~CI|GLT
zw*>A8yejaP!21G!5x6h#_kr&Oei0NH6c>~plpC}p$P!c;)D+|j>JHivv^D7bpeuuJ
z3%WmOPtemr`-9#HdOzs1U?Dg>I5~Ju@Z#WA!Ii<s2D^j3!5f0N1z!|=b?`00_XR%^
z{8aFB!G8#TC-}1vAtW>;HY7b{R!Ck*QHUkP9?}}p9?}ys60$wy;*hIDZVkCV<QE}N
zh5Rn$wUCcOzSf3n6SUddJZ+J7rM6t#tZmbFYfsXiu02P4vG!W+?b@GcAJsmoeO9|)
z`=<6U+E27!g=#{>LlZ-DLi0kGhT1~wLf3@0hxUe!gl-PKAoTLk8$<62eK_=q(Eka2
zCG^jspM-uB7918EmL4`YY++b&SVdSv*l}T=u>P>q!p;uc8FoY1y<v}qJstLP*qdP=
zhW%X^po`L_>gMW9x?^+|x;ot&okusM+oC&9w^Mh6?rz;fx;?sQb+78))qSk{N4O?D
zJUli$JA6U-;&3V49^MdsLbxZqFMLDzmhkh!uMEE_{QmGq!=DI$HvHA_KZSn~{zdq=
z5g`%!h~$W@i2R762x~-b#EB8>A_gP2M4TUSWyB2;cSig)VsFIL5idu)8S%G>uOkB^
zV<OWdb0Zf<E{`mYtd4AsY>(`Y^hKT;xjpiN$SWeRkGw1LfyhTApNM=R^0ml!B0rA&
zCMqy0GAcD{PLwffSyV|>ZPam59Z~&JCr53Mx*+O`sGFkhk9suf>8O{Y4n(~Z^=Y&i
z9Uh$=ofEwvdTDe?baixdv^#oz^r_L?qtB1NBKqd&d!rwU-V^;y^#16#qCbfKN*|z)
z)F<n6^-J_ty<Oj=cj^1|Bl^?z=jboiU!(uA{z3h2{XYGR`UCp+^q=a#i_yiT$IOda
z7_%(K7E>M59J4lNeayy~Gh;4@xjg2EnEPUW5wkDm#h3#zAI1D5RudZ*8ylMzJ2!S&
ztSz=WwmH@r+ZEd%yD|2R*b8DWi`^A_d+hzOzli-!?EcudV&9MbH1?}FbzE3nd|XD{
z+_=IxOI%f4W1K6lE6x|UIqtl;E8=d7yC?3ExToUw$GsKzVceJTf${P28S(St3*%SC
zSH?HTyW+dz2jWkO-xhyv{AKYs#@`$NQ2d_weeo~Hza9TU{1*v<3HpT0guH|$3DyLA
zLUTe}LRW$>;nak)6D~=(KH<j+KTCK#;hBV&5)LH1lkm5MuM&e2V-wR8=O->oT$xyr
z*qGRs*qeAt;+ct;Bwm+zd*V+L_ar`(_;TVKi616@l@ySqPfAUilVnOdCaEl`F{wSN
zFKJ`aSxJ{A-H`O-q(_o|o%Fk;KPJ7G^l8#J$wA3c$!W>C$xD*W$+gL?$*$zy<WrK*
zPQE1h+T`1kA4uMv{B-h*$*(7Wocv8nNJ>mfMv5_|IHe?|I%Q4Dx|HFREh!hK>`J*K
z<-wHQDNm>DPx({I=c$3IQK>1Z^HK{_rPQj_)>KcbH+4hm8L5|~UYmMb>iww?r~W$i
zrPQ}mKTZ8-nmR2qEhTMsnlbH|G)r1_+L|<1T6fxD+Sasl(=JcDG40;8y=l*<{UPn0
zw9nHu=@IEk>DlS|>8sN1>8<Hq=_jY}NWV7yuJi}fcc=e4{l)ax)Bl$KPeYI)-jHd?
zGpsO_861XoL!V*9u*GnmVW;61!@Y)I8lE&fZ}`384a56}FEfOUsEpK%SsBKRV=`<R
z)fufBYcmEiHf5ZXacRb`j5{)Znz1|M>5P{%{*>`a#y6QEnbDbs%-qZ+nNnt1W<%z2
znQJrGXP%b1BlD8XU72@eK9Kp#%->}GF7u7dPqKup$gHHSoUHt;qAXihUDlc`ca}G6
zBx_sN`B}TN?#g;NYj4(bS#M>%pY>_hKeGd~qqEbq=Vvd@HfL95H)fxZ-I?8=eM<IO
z*+0tOm3>F{gV}qtpUK{z{a*IxIjS68PHav_jwxqZPGwGGPDf6E&ZeC6a<0g^KIiV7
z2Xh|Fc`oO*oOg3R$@zL#@T|yL$+Kq9S~zRvtcqFnvq&o6j#pun)v?fItf{V9e6rbk
zN?wn*P2+R-_r#f<18$eIyW8ErKuOPQbM@)*y~^q9?;JK385bK1^Ll*4nib#msC3``
z{hI;JDc`wO;osf;ZMDYtol#}{?#*vqn#KQadWd8$H<<Dk=NXd<jK-x4j0Fn{3JoUH
zF$If{F_{dxM$<7yquJ`{^Y$&SbM|$%tCp`E?&&t1<nABn^!65Kn(~a926wN^+uqsh
zDb8$glq@L9Gz|Ehz3t9!Z?C&JbHqK6xpIYexzy|I9vSEysOk6mye@CI#oOy;U1d}h
zY`1-}U?>$tLb_X!kVZthV~C-<85jgqN*bi3TVfby7+|QOQxNHHh7l3Tp}V<!@A}rg
zKklEs&N}g|b<W?jpMAW1PMR)Bw#|b;p2ZbGqq$D&-Y1M}XP<;fzI`7)`J;}r)EZHC
zl5Z68DkFKA$-|y1Bjf#rke#A<QcOZ{`AeDarT_XuM;P<tz+bmd4yME|6QiQP9et&1
z-|tWv-jO@~QW9+Wu`Q=bDhQp?#|FaQN8Jp|Fwh8r7SOK@K4K)AB?DO4a<MyrxXcHL
z37+@@Z(S?Bj(zkOm(AUyMjRGb(lOTQ*jAi}8Q=CfnGyGsRsy|gh1tG6cFD!w7wR?F
zGjOP(x585$QER!D)?9Q9oIoGk+cMh;#`A5S+VJ|*GrzAPuu2UFMq%%Hlu7rEjqTE}
z@A=dxPzczaT!lWh1#vFpfA3-(JSBlGe_<(H-Z>_@W6fZ+b#&GQee2Vwj~k`P__IZV
zlp$lU)%aux&$C&*Pu>G3|1zA6J3Y>msc}J$Lz-XoZ;EQi6oE>@WIWEV7*<95s++t=
zCuST)n<CcT8*Ndku16a1J97USv^M5bjk~vvo1ZZS8;Gq$?v<BP+)cu(Z2ey|4s>-Q
zBEl%3Gg>EFKT&hQS1LuXZL<mElGUjB0=w2Z2vIe5v&p?Ojc#p0m8z;BVQbpHG4EiR
z_?)frn`H>ENesvhf6Dj`gB!$Pz}ewiJG2Tq$uvT>2nG8*KGx@kMNE?9r=z%$HGYs>
z)wsHQ$SPN5iAmVekzZ4MnhzQcg)Jfb7T+9^oQbiPrwy8y6ihGhr>Z8^Ot%;zD^&vI
z4Px}yM8JFc&s5B_hjyIItey7sYe_THjGCou>AKk13yIm}b(?KH3*3P8P9?U7sym=V
zvXVj0a=Pji)s=AF`kr~#DFfpf-=nmZHNQbzWPfa0HFC;Lcgz~c40g+$tDZFAm}<;?
zOBHQBT?jWwx3#)hO)8Vuh1$9&s=Dm!81o;Kce|EWPm%%+RJ#;b$@=E`y=h=<bhva?
zdu`pviDmqM7*dm9Q9p;|kD^NiFJ|Aq@8u}>6-k`}x_+H^)x~PNw4tZ%F!_Ivr?YTH
zx(SD@?0YNk9%LiZhvZj}-z^ftd>(%?6l5hKHs00^h-u9C@h<s$Jnt-}83QY*L=Nd$
z)}G8d&yb}5)um>mr-45Qq<B=>y2u3{G6UXg!Mnv$l~?3-XTH|TA^G5*%porHdv}!g
zl#hnZQVQqO-O433AUAIkZ<o|IWxXp7f=mg!gIn$_Kitv{6b<lob_#KgJd^G2E^7{!
z;kI3`9eph1m1a*fr<+i;heu3GBD@bEf}d*ZvIW!{jDuOOSLZ6dRR-}^Tv<6&bQID^
zFScPl$krnx5^2T7B2v`~k5T#7BfpI5d1=m}d9$zz1vTm#=TC`q_CM)rx;1M_mH;Mn
z^S1m2J)p=$^UZs^)lc%0r)y~oXH4fE+u2@-U<U6FMc{iW3GILAlegeOB&JziNWX30
z7QU7uu(w-?+E%q2dLJ3wr^bdV?kU4<6npnt_%vqsJLfM39O)<+m-Fe*Gbb@Szn`bs
zJS}|NDcYph9RJDK4jNs+goI`<sCj`)+S6Aa>iN`yij~=pzISF#YA|^FPl!p}Kn}UE
zoe+YN$!D#_<3BI1cTYfYy2V|V?b_}!ZEd&2H+<X2tK2SpBB2svcGVTQ1AVv3kF@#5
z<IXR%-ytg{P32dnA$pB&y~B*g-E6#N$aF=dgm}>YDc3+vny;A3%_Z<j&zI~>TCH}B
zleMat!bQcvzCvAAa@t#4i;O%In|VuqlZ-_W4{+_}@Q63@6!js~lHt@}-_=w7xh)*k
z31ldA<rhuO2z;WcOrBzOIO6J+iJS$A&T|(lJC{~Cq7>C>Sku;4=Y~y63;EUQzv-+o
zvsoBVLd2(F4tCcF@OBz{69Zm)#6PCVQaq8Co`J)?*gk={OnIaVZ#la03)YJAfo4Ep
zA4^^yTv-5W-u_VA#L3sUw7jt5j<;FRZ{;I$Bud((-gUgK5&o^|8|;2LERIFO4F>IY
zsHciV@+s=U<hjdSg)!M`TR+o^70mdCD9lbYp^3YaH2y$?1o(G*T307-hB}d19G!+*
z^L%zh^S}Tof@el0RKiV7Z>q9!MrKl1`<3<-@YN_t`^PL-<^Tm~aKc3KH0!K>Zqw1|
zN6O=k<3QImTW$kMMKR|%b{n3c8Wm9mlPZXW4hb$l$F_PJL--h3<w1*G+D)4KH3}Rr
zn=~$#5<RH`p~l9H3@zZ3>oW$d;mtTS^lHG~*>U}Zv)lkpAwDK_5lmw?6sMsIfJ$Uu
z>1%9fq)b~nTi|B;u3FKa(J9cPSO)H@1T>Wi`^orE+Co+O`UQC&C84&Pk$$KU_qJbA
zzD>+$)5#7iN2k`2x!uxzpObi#7a;V9eKY|FP!Eek9W~{UKPQ2keGV&@l-{|JffEhA
z7-$!$KzMwLF_8f;%Ei5YPSrjV&SnCZ^ggU)S>I0f7fF-2fUpw1PYL1+#NhjF-B;3n
zlj`-sdOBo-Z&0JGp`|`k;u9;$?<<j=K>mDMUNl3d;()Pm`K#h#m#mLk@n~`?h2hP;
z@lPv`cnXU=!a#4*X6kRGkxBZuv!P1pzqo^wI>}2V=Y?TZ9}e{}hO`ReXB$9cLMyAD
zNApOz0fd>`+3{}VKox1VTj=*X+9h9#Y_ok#(Tk5blbG@8PbvLWp4)q;D=*TI^s4Ya
z)oZ7{&Xty42FxABaBXZc?2Y-4Jd4%|f*t0UP0&ZFh*R=qnU@n5Ye%YGv`Q1X>~)jq
zicd`6-{5YQuMO1%spJvtOxXOB#&tqbY<z0et&w}Ds8PV;*gQEgy+OTo<UQPgy~$BB
zdTrm@kFM+&9~F`IkbEoHsq581qO3N=O0l&#8=(IsyC@`%!bxl{f5Lu0`=6Q7WjFjs
z%@~s6t4@EL?~Z>$<SlZ{cg<f?Bge3TUs*!aUrXT^C)QwFr^RQtZK6wNAN>667kb|v
z*MQMI{pw|#KP$H5WL(E3N}=u#YLnhM55n#o{KB*Jd929M?p`@Fy2jA4fo?_4gEn>{
zg2j*Oa{>aeEC##U;MN*=MfSY1FaA0{CwfHsLTquzLo$Gl4f~5JroMe~yHIdBjQ)M`
z#LD)@;Yp!YH~S}poou_xTUOu3RPZ%!SOrTD4uV%ed$fg;1CPh+?0wfBy{>9{<qL;*
zz3vbhN1yz@SwCC;R*Df9c*8icOSR#3SWfTj2d|<0y!OJkhJ?{U7xYWB<%ku0%6OW=
zzW*%O2lP)sRNoCHCNCK=*bx1qeO$175dYLY0@I#sWfc)8>qusAbp2x^%W5^+Lwq7$
z3vXL!>w<MF%PR2UBZt|&l2NM&1@$5mn@pnO*AQ}#pa`Irin@cCJNce>Z22$(r+;oV
z;gFB_m%-oM@rwx*KgGbYmZr2%{|{#>txseZzwy@DT8CDjd*ara#ioaHl00|q?+JIg
zq<1`L4Th?DXKZ5{G0<nXMdP|Dda5Oy_l(!$$kugYy5GW#_XhYqNsjbO!Z1m!LGYFa
zL?HJ+;;fo*us#4=hf!18J}L?YDWzjIao^wP@du8(7l<B!KN@$*nRV&;&$0Et6IV)?
zM&LicNhn)*)SR2A5N;}nt(#3f(1zwXFPYrzK5q^f|MbP~s9Lh2(TDp*_uRGk79_8M
z1v=Njpn6}Cs9KNuxihs$hq<bS>h?_t;!%rg4}Wv}DMScCNlMSxvZWeLIxOO&qF<=n
z<%k_O^5XNkHMt>iTrwC?H~^m?ynY~JJ-n@Iv67~@%r_~;AK~{IEKEj5xt{T1DIQxO
zWnX`J_r<c>E0EtH0$<IkBmm7%PemiD-|;n=?7Dm}DDiJ3-PP-9RoLgTAjs7Ck4t<r
zQX1f9hM7~=ZPhq6RU2(<ytz^ZOGErY71V!=lR>h-=RXdHBkxJmBSho6j@KA;wNPnD
zAt5W~=JSxkEh7SG^4g4%pm}mTyIwl`&-yy8!0(ZnCD8`O(?2BF=uCd(uwKdAHI>x^
za&AdKiGcgo=HC{@ZB?K%Fl)oa&D3mt<UY91U|FwE=EiQfi#t`!uYFJ<RoJs1owcgi
z1~-%%{$rMZ06)g`z&6hK+yit~Bu(4wQ@7;koaQX{OcpNg!KY?YXcshP>y_q<WF8c2
zD3ilgg|bO=wN$bt^15|KP7BWiU$u9a`|4(OTd(*y|CORyDW^$ir)Sp)$PgY%aRU1E
zG}MK0?;47gj~GA?{0LGH2?J-)2Amk10Jw2^8@_CMf*LtT@sz&+zlOA++YE4dT$p^~
z#z353Bl;Ov*_-_rz>wn_Pp4q=34=gsem+O*tdAc|L3=;Y<87W!Opy69(NyGtXR5Xp
zReEu5hR+6OdHgL$ajQ430bL1jDy+($P+Ty^@4BPYezj+Ktt1t+Nm$`$I)Cf3Ce;Du
zoDh?-^ULL{sc8i}(!9}s!b_ZOi<b;w&3>{ZM*22NIR=kH`<cocg{&S=#vG-hoO^|z
z87~OrI`mR3<-e>TAia3p`S~f!_HDTu_Q`DYBVG@W0+L@g3$>sB+6{nj4=3+llXLMp
z{3ZafC=@@zz{%LvHVg%v%X*8}9ICCz6otEb?K8Fr%fQJCdemdYEZJ7o?|GXIJ^wVN
zLR-48FoiZLW;qaPN9``ZoUfI(JI<4P^bTyinau!^mL5BR+Nx$j#OX8hs+_Y9Iis#)
zceywOpOSjZ_7~ozWCWjLnbyreWjE&OVu6C9^a^FJzo}H(>kv<C`5sK$*jhPFEC_-_
zV3?Pi^$*hqAafe=I&a0v23GzUYh-+=7@#woD=pEgx3K&;wljV>&sf(NwZgFz%3Kp&
zZeZIO=S9gb%=rAJBTdW)y67_A@IJlSul7dg6h_guQcD?xo;k^t)z1|5eUmGh;$|5E
zJm4SfY(~-V+gXPJ#15>y9|J);EJ&e;KUYqbO(*&<E@iv($d@0c<t6LQ+U7-1m%cEW
zt*q$#j(9pClOn*JTAmeSB%J3m54OVxxJ>R&5k=Xps2mE#Y)6GX<%&gU{>aQ`aO;)Z
zE18XWio;i?O6+GxlN-rBO&7BeCRu|Y2z4@By%UOcjp##lkeyPx-S6Uyj#01;OX;&!
z<YIxvGD@ms^18JL+k}lo|80H4Q700WD$P0PP}0*{$w!$e@V$bN1sV8`_obv7BvyB4
zCH!Nf4QlYyifRU}i1plM)Uh>r73T|x<)tBSV&z{?2W=K4HGpN}glCxlYwQ|1#udP#
zyL0&Nm>IyLC-Va1P*{-}4hwhMNwf}x-B%L*mDji198R$i#olN$`!2Y<nR11xSl%;g
z|2H37tm6-D-u*)NIkG(E<fN!ycVe~)2!uL0$EKlhQ`v!P58{t`UH<-^^p{{?AvT-7
z-PtR|4$EQ{eW#b>_%Y;o*saB)a=d8dLvUDu*Y+zgnPO4Q!>xINuX}iaygaUw2LOiu
zn0H_$*9jND5B^QkQpLD*pG@ZeK{7Eht3T>K`2PZO|1JHu{tlcL7?&o{EXrq}!?Z3Y
z<vQ{2^1T6hw`Kr!tbU@I9YCEfD~X6rK>J>(9Dq2b!*a$5pe_XC)kYoQcnyP-o)N3+
z($M*Gsstyc*vfLM;58d;wdYs=laR7;`JIJLO1G26j{H$V%5565bA>Jn1_U;=;8m3x
z02`#tEcY@96H1Q7qaG!c>}7oUZo@5AY<=hR@qUCP%t!7C0r~Th|NO_i16~BTu)|%a
z!LOg|Q@jD<{Xa+w4n}r*|0en0029G~OaJ=_W84dUiY%W8z=zsE<va-l_h;li1a}mh
zK+(<TUKHv<#AMz(VpYrh2ao=RP_m5TM)`kx*1nhgO%9+Ay%f0{fcCxnYyy@oebw{z
zBhiP8QVkz+Y@oEaWNVbh{QZzC7hZaYb8u@F=WTk-K@^3($3D)w(;_gM!a#9Z@FqO2
z`-7}t@B#lB|J!A0f^0>o&Ucd(i$6xfA(g<`6~h|WKdqzbudV#Q<1L0Nn10|OW-eQ8
zFp4FwizONZ{PgVfXS8aybX4Q#{t=Z%emfmcRI+cvv}{z6JX&+J`0MQ>ouhtV1wjwm
z`80+nB)nzukV4tO9}nURfqkbs@h%6qM~<zYp3nF>&Q`IWee|Zx94X2HuTvta-n6o4
z?meYoCcpRFx-*+9{XJ`J$L$ZAST*}R0{LF%_><?iUD5Q*2*c2-5GBvBi>kQ@52$H1
zTiSWeLxo(A=rr;);xL9p+0~p37iI|48R7{&B=ptqMSx$30_k$e&x)l#f9z?~2Mw%g
zHxm}vha(+%e@-QY`@~ja&hSPvzx$~xCi-`=i^fA2BRCcCk6%U?%uOE0@$zp0nFKY7
z`5KM4ZUYKJgRjR)WO{yk5&sLsTTP-Yt3O{=W>;bao)7c{#>92dcOWZ`XQf=Z>K<Xj
z0zPklC$;3L3i_kE5O%q*ex)ge|FQ%Bch_FzUi8^}e|q!K_OObs*S~|hWjlPABlp1j
zF=0sp<eG&K$G$b>uFL(1er3(N|3ok|Lyng*?Ws$2ebn}kwI57>#P+3ClGw*J>ewZd
zu)Y4(VYJGmY&}VOy$-!J5b?(N1=Sta)5M-$y}utbRe$z^`se%I(~nb*6H^C%_R=S7
zBoC!Zzck^(Fk+Z4-}<QgXvPm{K;TlW?K*+*EBABh1EvGP1C@i4gT@2Om5PDI)F5VA
z##@6xO*u|sLdB=r3q_U`SPD-C*>3G_`7hkv6JKPx%(csOCb{c)Wb|l(IY90dQJB`8
z;+zgOaFzR#Q!TYCbvbpaKePW~zg>TAKVQGZiusD%is#BHx2c_Wqdp(79@&J10NZs^
zOB73fma>-yR(#St4snii4t37nw3$jrLXo>u4WQEEDH-nw2|cU|9nfpDZS(u)(@oD!
zuFbj4waJ&r8Klb;W>RwMa&i&z(iu(D%wE<v`F?x>wo$+}Mm$bDBZbH;$}G+-H%1tv
zJ_2iW4pFNtL*_$FL$bnf5lZx{ayi_nB06&(bGIeC=O(*txvjh{w!J)WJnvAehAu^e
zofpRf5!a@dzS~aQY`LmRIR7StCekL!_tM@9O*c&tGuVzGRv&AMwZ=MQP41Ri^jIdW
z3O3<W<FBIAb(0MYP7>$0Npy65v~m%71iYZWXuRmYFgyaU*RRWt2Nm3cf>dvl<?IEh
z9OY*{pi2h#U49cQMBqh0<io963i<`QDmyACE2k^R_TraVx+o)9BFH0ZB7$h96l2Eh
zh^a9&lGHV^t#R!_za0EKjO=opOf5}a{rk?cJWH#F8+tzUp5^W{!}7~g5}f6|^WEXr
z`ZB<`B*hVWHVCB>u1Q{Jnc66jN;y<icUL=4_Ywh}<l0P9u_{!j*HhDz)T7jkFR3qS
z-!RvMZCFh_o8X=BpU|BEO(^Q+I@LS1Zy+{eGX-7@@_YU8hn|ai#fvYRTJsAnf&(X|
zx}_$h7OyA|oey8E@~zUXwyt)qlCKgyZw#+);C17r<1>CfJl>=0Tv8cZqh76EGgx;u
zcTjEDYFA^|Y?p4=zLK#LyHX7V9~+yPNE$U8)s&x4li{A=uBVmCv_KBVdA0m?sH$mD
zy@{{!sY!d)&AS1|yPJ#VO%&Mh;o`#$vQLcCv8W=3g1mf(vBPzmPvWg<DA*$WbUbon
z`H1==Bo4jd8p~(tV%I$Pymn>oiyN%Ys!p)3$4$uf&`r&))b)ic#?{X)(v8Dyjp|{S
z0A8_(m(WCNpPg!ku054dR%VB~eX-DC2HT+XDv3Q&P3~Nme|L`M@H~Z2jI`qj+86CG
zC+-&=@HHSKAog14QvZ_nlKFDrWM&(T@tyU>oMIB@+iNU5IO)(`YYpE$W0v`qw3MoB
zzS<Poge<G{(Doe0uf!YDnb1no`qARkanMobK;YdQo^|i*e0_X;e4k6=OY-C-h~+_s
zz4(3FwibT-k2Fr4zg`nuqh4c6AGd>iG;=ehGsBv;ngy7_P>Co2sstsD3P;(Yyir3a
zi5dPGycw<;w)%NDZ~TSr1>Xj*h4Y=joy!FqEO5tRL1c$w=XhsmN8;4{^y%qi`tY8=
zo_-)d_mj$RQd$;TjSeXeEo*=g+L5;-uSP&4+22m3nx!p14u2T-Q+c`K?Pu}<^HI_d
z`pX|I3oh|(IK>0k`Zk>!?~?60?;7lK{Ce4{)GB*sD+3+bAiA8tXu1%yuvipW>}rDt
z5C!lA-~zG(cF%pzNzd92b5D7$V`bMzjutm|cM>k~FL|z(uYfnyH;p%xSEbk4SGyOo
z`$4O+>#{qtlpXhrKXZJ2>PWdx+e`Wv|Kd@^14VrHN5v0ss1SfMf|lpAv<RXt04*Sg
z)RYhzx|%OL%RVdE`=}W|CgeI)KI9aifk=ifhrA4cB0v$j6SgrdP)kus(RIq}_fmfe
zn~#tPua<vU5Li$>iWqGe{X06St>I|5J~TQ#+EdU~uv{QiaA>74OM4OyCRn7|c|J@;
z8Hpbj8Nt&<-l-LS`ve83AgFi@CfOy}C1D`Cee#|8f`AV2ZeFSB9fYMj(T^oHF*=bt
z@jOu>(U2L(0#=ZT--_|46Q^s;DCp0BWlGKWO2T#_bxa5<0Np+2og+L1TDB1m8U~+p
zw?~|F+m5~aF+OC-6r;%GQ+o*PEkxZ5J?9p%fXU#GjSm|#H3#xpl^kmJ&T{{oHddt~
xYZ2ap`7#>>X(PPT`xeNkfbjh%k6w{@wY0;ZBBSCUraB03yw@iz+2;N~{{!Ho=?nk>

literal 0
HcmV?d00001

diff --git a/backend/app/tests/test_analytics.py b/backend/app/tests/test_analytics.py
new file mode 100644
index 0000000000000000000000000000000000000000..7e2a0824adf400f5d4da486ce8b1d8dce2a0da9e
--- /dev/null
+++ b/backend/app/tests/test_analytics.py
@@ -0,0 +1,381 @@
+from .conftest import client
+import uuid
+from uuid import UUID
+from datetime import datetime, timezone, timedelta
+
+
+def get_auth_headers(client, email=None):
+    email = email or f"user{uuid.uuid4()}@example.com"
+    resp = client.post("/api/auth/register", json={"email": email, "password": "secret"})
+    token = resp.json()["access_token"]
+    return {"Authorization": f"Bearer {token}"}
+
+
+def create_item(client, headers, item_type="sample", name="Item"):
+    resp = client.post(
+        "/api/inventory/items",
+        json={"item_type": item_type, "name": name},
+        headers=headers,
+    )
+    assert resp.status_code == 200
+    return resp.json()
+
+
+def test_analytics_summary(client):
+    headers = get_auth_headers(client)
+    create_item(client, headers, "plasmid", "A")
+    create_item(client, headers, "plasmid", "B")
+    create_item(client, headers, "sample", "S1")
+
+    resp = client.get("/api/analytics/summary", headers=headers)
+    assert resp.status_code == 200
+    data = resp.json()
+    counts = {d["item_type"]: d["count"] for d in data}
+    assert counts["plasmid"] == 2
+    assert counts["sample"] == 1
+
+
+def test_trending_protocols(client):
+    headers = get_auth_headers(client)
+    # create protocol template
+    resp = client.post(
+        "/api/protocols/templates",
+        json={"name": "Test Proto", "content": "step"},
+        headers=headers,
+    )
+    tpl_id = resp.json()["id"]
+    # execute protocol multiple times
+    for _ in range(3):
+        client.post(
+            "/api/protocols/executions",
+            json={"template_id": tpl_id},
+            headers=headers,
+        )
+
+    resp = client.get("/api/analytics/trending-protocols", headers=headers)
+    assert resp.status_code == 200
+    data = resp.json()
+    assert data[0]["template_id"] == tpl_id
+    assert data[0]["count"] == 3
+
+
+def test_trending_protocols_days_param(client):
+    headers = get_auth_headers(client)
+    resp = client.post(
+        "/api/protocols/templates",
+        json={"name": "Old Proto", "content": "step"},
+        headers=headers,
+    )
+    tpl_id = resp.json()["id"]
+    # create execution and set it 40 days in the past
+    ex = client.post(
+        "/api/protocols/executions",
+        json={"template_id": tpl_id},
+        headers=headers,
+    ).json()
+    from .conftest import TestingSessionLocal
+    from app import models
+    db = TestingSessionLocal()
+    exec_obj = db.get(models.ProtocolExecution, UUID(ex["id"]))
+    exec_obj.created_at = datetime.now(timezone.utc) - timedelta(days=40)
+    db.commit()
+    db.close()
+
+    resp = client.get("/api/analytics/trending-protocols?days=30", headers=headers)
+    assert all(r["template_id"] != tpl_id for r in resp.json())
+    resp = client.get("/api/analytics/trending-protocols?days=60", headers=headers)
+    assert any(r["template_id"] == tpl_id for r in resp.json())
+
+
+def test_trending_protocols_recency_ranking(client):
+    headers = get_auth_headers(client)
+    t1 = client.post(
+        "/api/protocols/templates",
+        json={"name": "New", "content": "s"},
+        headers=headers,
+    ).json()["id"]
+    t2 = client.post(
+        "/api/protocols/templates",
+        json={"name": "Old", "content": "s"},
+        headers=headers,
+    ).json()["id"]
+    e1 = client.post(
+        "/api/protocols/executions",
+        json={"template_id": t1},
+        headers=headers,
+    ).json()
+    e2 = client.post(
+        "/api/protocols/executions",
+        json={"template_id": t2},
+        headers=headers,
+    ).json()
+    from .conftest import TestingSessionLocal
+    from app import models
+    db = TestingSessionLocal()
+    exec2 = db.get(models.ProtocolExecution, UUID(e2["id"]))
+    exec2.created_at = datetime.now(timezone.utc) - timedelta(days=5)
+    db.commit()
+    db.close()
+    data = client.get("/api/analytics/trending-protocols", headers=headers).json()
+    order = [r["template_id"] for r in data]
+    assert order.index(t1) < order.index(t2)
+
+
+def test_trending_articles(client):
+    headers = get_auth_headers(client)
+    resp = client.post(
+        "/api/knowledge/articles",
+        json={"title": "Tips", "content": "text"},
+        headers=headers,
+    )
+    art_id = resp.json()["id"]
+    for _ in range(4):
+        client.get(f"/api/knowledge/articles/{art_id}", headers=headers)
+
+    resp = client.get("/api/analytics/trending-articles", headers=headers)
+    assert resp.status_code == 200
+    data = resp.json()
+    assert data[0]["article_id"] == art_id
+    assert data[0]["count"] == 4
+
+
+def test_trending_articles_days_param(client):
+    headers = get_auth_headers(client)
+    resp = client.post(
+        "/api/knowledge/articles",
+        json={"title": "Old", "content": "t"},
+        headers=headers,
+    )
+    art_id = resp.json()["id"]
+    client.get(f"/api/knowledge/articles/{art_id}", headers=headers)
+    from .conftest import TestingSessionLocal
+    from app import models
+    db = TestingSessionLocal()
+    view = db.query(models.KnowledgeArticleView).filter_by(article_id=UUID(art_id)).first()
+    view.viewed_at = datetime.now(timezone.utc) - timedelta(days=40)
+    db.commit()
+    db.close()
+    resp = client.get("/api/analytics/trending-articles?days=30", headers=headers)
+    assert all(r["article_id"] != art_id for r in resp.json())
+    resp = client.get("/api/analytics/trending-articles?days=60", headers=headers)
+    assert any(r["article_id"] == art_id for r in resp.json())
+
+
+def test_trending_articles_recency_ranking(client):
+    headers = get_auth_headers(client)
+    a1 = client.post(
+        "/api/knowledge/articles",
+        json={"title": "Recent", "content": "t"},
+        headers=headers,
+    ).json()["id"]
+    a2 = client.post(
+        "/api/knowledge/articles",
+        json={"title": "Old", "content": "t"},
+        headers=headers,
+    ).json()["id"]
+    client.get(f"/api/knowledge/articles/{a1}", headers=headers)
+    client.get(f"/api/knowledge/articles/{a2}", headers=headers)
+    from .conftest import TestingSessionLocal
+    from app import models
+    db = TestingSessionLocal()
+    view = db.query(models.KnowledgeArticleView).filter_by(article_id=UUID(a2)).first()
+    view.viewed_at = datetime.now(timezone.utc) - timedelta(days=5)
+    db.commit()
+    db.close()
+    data = client.get("/api/analytics/trending-articles", headers=headers).json()
+    order = [r["article_id"] for r in data]
+    assert order.index(a1) < order.index(a2)
+
+
+def test_trending_items(client):
+    headers = get_auth_headers(client)
+    item1 = create_item(client, headers, name="A")
+    item2 = create_item(client, headers, name="B")
+    # create notebook entries referencing items
+    for _ in range(3):
+        client.post(
+            "/api/notebook/entries",
+            json={"title": "n", "content": "c", "item_id": item1["id"]},
+            headers=headers,
+        )
+    for _ in range(2):
+        client.post(
+            "/api/notebook/entries",
+            json={"title": "n", "content": "c", "item_id": item2["id"]},
+            headers=headers,
+        )
+
+    resp = client.get("/api/analytics/trending-items", headers=headers)
+    assert resp.status_code == 200
+    data = resp.json()
+    assert data[0]["item_id"] == item1["id"]
+    assert data[0]["count"] == 3
+
+
+def test_trending_items_days_param(client):
+    headers = get_auth_headers(client)
+    item = create_item(client, headers, name="X")
+    client.post(
+        "/api/notebook/entries",
+        json={"title": "n", "content": "c", "item_id": item["id"]},
+        headers=headers,
+    )
+    from .conftest import TestingSessionLocal
+    from app import models
+    db = TestingSessionLocal()
+    entry = db.query(models.NotebookEntry).filter_by(item_id=UUID(item["id"])).first()
+    entry.created_at = datetime.now(timezone.utc) - timedelta(days=40)
+    db.commit()
+    db.close()
+    resp = client.get("/api/analytics/trending-items?days=30", headers=headers)
+    assert all(r["item_id"] != item["id"] for r in resp.json())
+    resp = client.get("/api/analytics/trending-items?days=60", headers=headers)
+    assert any(r["item_id"] == item["id"] for r in resp.json())
+
+
+def test_trending_items_recency_ranking(client):
+    headers = get_auth_headers(client)
+    i1 = create_item(client, headers, name="recent")
+    i2 = create_item(client, headers, name="old")
+    client.post(
+        "/api/notebook/entries",
+        json={"title": "n", "content": "c", "item_id": i1["id"]},
+        headers=headers,
+    )
+    e2 = client.post(
+        "/api/notebook/entries",
+        json={"title": "n", "content": "c", "item_id": i2["id"]},
+        headers=headers,
+    ).json()
+    from .conftest import TestingSessionLocal
+    from app import models
+    db = TestingSessionLocal()
+    entry = db.get(models.NotebookEntry, UUID(e2["id"]))
+    entry.created_at = datetime.now(timezone.utc) - timedelta(days=5)
+    db.commit()
+    db.close()
+    data = client.get("/api/analytics/trending-items", headers=headers).json()
+    order = [r["item_id"] for r in data]
+    assert order.index(i1["id"]) < order.index(i2["id"])
+
+
+def test_trending_threads(client):
+    headers = get_auth_headers(client)
+    # create thread
+    thread = client.post(
+        "/api/forum/threads",
+        json={"title": "Q1"},
+        headers=headers,
+    ).json()
+    for _ in range(4):
+        client.post(
+            f"/api/forum/threads/{thread['id']}/posts",
+            json={"content": "hi"},
+            headers=headers,
+        )
+
+    resp = client.get("/api/analytics/trending-threads", headers=headers)
+    assert resp.status_code == 200
+    data = resp.json()
+    assert data[0]["thread_id"] == thread["id"]
+    assert data[0]["count"] == 4
+
+
+def test_trending_threads_days_param(client):
+    headers = get_auth_headers(client)
+    thread = client.post(
+        "/api/forum/threads",
+        json={"title": "Old"},
+        headers=headers,
+    ).json()
+    client.post(
+        f"/api/forum/threads/{thread['id']}/posts",
+        json={"content": "msg"},
+        headers=headers,
+    )
+    from .conftest import TestingSessionLocal
+    from app import models
+    db = TestingSessionLocal()
+    post = db.query(models.ForumPost).filter_by(thread_id=UUID(thread["id"])).first()
+    post.created_at = datetime.now(timezone.utc) - timedelta(days=40)
+    db.commit()
+    db.close()
+    resp = client.get("/api/analytics/trending-threads?days=30", headers=headers)
+    assert all(r["thread_id"] != thread["id"] for r in resp.json())
+    resp = client.get("/api/analytics/trending-threads?days=60", headers=headers)
+    assert any(r["thread_id"] == thread["id"] for r in resp.json())
+
+
+def test_trending_posts(client):
+    h1 = get_auth_headers(client)
+    post = client.post("/api/community/posts", json={"content": "x"}, headers=h1).json()
+    h2 = get_auth_headers(client, email="u2@example.com")
+    h3 = get_auth_headers(client, email="u3@example.com")
+    client.post(f"/api/community/posts/{post['id']}/like", headers=h1)
+    client.post(f"/api/community/posts/{post['id']}/like", headers=h2)
+    client.post(f"/api/community/posts/{post['id']}/like", headers=h3)
+    data = client.get("/api/analytics/trending-posts", headers=h1).json()
+    assert data[0]["post_id"] == post["id"]
+    assert data[0]["count"] == 3
+
+
+def test_trending_protocol_stars(client):
+    h1 = get_auth_headers(client)
+    h2 = get_auth_headers(client, email="p2@example.com")
+    tpl1 = client.post(
+        "/api/protocols/templates",
+        json={"name": "S1", "content": "s"},
+        headers=h1,
+    ).json()
+    tpl2 = client.post(
+        "/api/protocols/templates",
+        json={"name": "S2", "content": "s"},
+        headers=h1,
+    ).json()
+    client.post(f"/api/protocols/templates/{tpl1['id']}/star", headers=h1)
+    client.post(f"/api/protocols/templates/{tpl1['id']}/star", headers=h2)
+    client.post(f"/api/protocols/templates/{tpl2['id']}/star", headers=h1)
+    data = client.get("/api/analytics/trending-protocol-stars", headers=h1).json()
+    assert data[0]["template_id"] == tpl1["id"]
+    assert data[0]["count"] == 2
+
+
+def test_trending_article_stars(client):
+    h1 = get_auth_headers(client)
+    h2 = get_auth_headers(client, email=f"u{uuid.uuid4()}@example.com")
+    art1 = client.post(
+        "/api/knowledge/articles",
+        json={"title": "A1", "content": "c"},
+        headers=h1,
+    ).json()["id"]
+    art2 = client.post(
+        "/api/knowledge/articles",
+        json={"title": "A2", "content": "c"},
+        headers=h1,
+    ).json()["id"]
+    client.post(f"/api/knowledge/articles/{art1}/star", headers=h1)
+    client.post(f"/api/knowledge/articles/{art1}/star", headers=h2)
+    client.post(f"/api/knowledge/articles/{art2}/star", headers=h1)
+    data = client.get("/api/analytics/trending-article-stars", headers=h1).json()
+    assert data[0]["article_id"] == art1
+    assert data[0]["count"] == 2
+
+
+def test_trending_article_comments(client):
+    h = get_auth_headers(client)
+    art = (
+        client.post(
+            "/api/knowledge/articles",
+            json={"title": "C1", "content": "c"},
+            headers=h,
+        ).json()["id"]
+    )
+    for _ in range(3):
+        client.post(
+            "/api/comments",
+            json={"content": "hi", "knowledge_article_id": art},
+            headers=h,
+        )
+    data = client.get("/api/analytics/trending-article-comments", headers=h).json()
+    assert data[0]["article_id"] == art
+    assert data[0]["count"] == 3
diff --git a/backend/app/tests/test_assistant.py b/backend/app/tests/test_assistant.py
new file mode 100644
index 0000000000000000000000000000000000000000..f4a62a099b9b9713abca2dedeea4ad38e7736470
--- /dev/null
+++ b/backend/app/tests/test_assistant.py
@@ -0,0 +1,99 @@
+from .conftest import client
+import uuid
+
+
+def auth_header(client):
+    resp = client.post(
+        "/api/auth/register",
+        json={"email": f"{uuid.uuid4()}@ex.com", "password": "pw"},
+    )
+    token = resp.json()["access_token"]
+    return {"Authorization": f"Bearer {token}"}
+
+
+def test_assistant_reply(client):
+    headers = auth_header(client)
+    # create a project to mention
+    project = client.post(
+        "/api/projects",
+        json={"name": "TestProject"},
+        headers=headers,
+    ).json()
+
+    res = client.post(
+        "/api/assistant/ask",
+        json={"question": "What projects are active?"},
+        headers=headers,
+    )
+    assert res.status_code == 200
+    assert "TestProject" in res.json()["message"]
+
+    hist = client.get("/api/assistant", headers=headers)
+    assert hist.status_code == 200
+    assert len(hist.json()) == 2
+
+
+def test_inventory_forecast(client):
+    headers = auth_header(client)
+    item = client.post(
+        "/api/inventory/items",
+        json={"item_type": "sample", "name": "Reagent", "custom_data": {"stock": 10}},
+        headers=headers,
+    ).json()
+    for _ in range(5):
+        client.post(
+            "/api/notebook/entries",
+            json={"title": "Use", "content": "c", "item_id": item["id"]},
+            headers=headers,
+        )
+    resp = client.get("/api/assistant/forecast", headers=headers)
+    assert resp.status_code == 200
+    data = resp.json()
+    assert data and data[0]["item_id"] == item["id"]
+
+
+def test_protocol_suggestion(client):
+    headers = auth_header(client)
+    tpl = client.post(
+        "/api/protocols/templates",
+        json={"name": "PCR", "content": "Use enzyme", "variables": ["enzyme"]},
+        headers=headers,
+    ).json()
+    itm = client.post(
+        "/api/inventory/items",
+        json={"item_type": "enzyme", "name": "Taq enzyme"},
+        headers=headers,
+    ).json()
+    resp = client.get("/api/assistant/suggest", params={"goal": "PCR"}, headers=headers)
+    assert resp.status_code == 200
+    sugg = resp.json()
+    assert sugg and sugg[0]["protocol_id"] == tpl["id"]
+    assert sugg[0]["materials"] and sugg[0]["materials"][0]["id"] == itm["id"]
+
+
+def test_experiment_design(client):
+    headers = auth_header(client)
+    client.post(
+        "/api/knowledge/articles",
+        json={"title": "Blot tips", "content": "Use PVDF", "tags": ["blot"]},
+        headers=headers,
+    )
+    tpl = client.post(
+        "/api/protocols/templates",
+        json={"name": "Western blot", "content": "Run gel", "variables": ["buffer"]},
+        headers=headers,
+    ).json()
+    itm = client.post(
+        "/api/inventory/items",
+        json={"item_type": "buffer", "name": "Transfer buffer"},
+        headers=headers,
+    ).json()
+
+    resp = client.get("/api/assistant/design", params={"goal": "blot"}, headers=headers)
+    assert resp.status_code == 200
+    data = resp.json()
+    assert data["protocol"]["protocol_id"] == tpl["id"]
+    assert data["protocol"]["materials"][0]["id"] == itm["id"]
+    assert data["articles"]
+
+
diff --git a/backend/app/tests/test_audit.py b/backend/app/tests/test_audit.py
new file mode 100644
index 0000000000000000000000000000000000000000..d6216ae4d6e35333cc1dd55c2e77859bdb45a8e9
--- /dev/null
+++ b/backend/app/tests/test_audit.py
@@ -0,0 +1,34 @@
+import uuid
+from .conftest import client
+
+
+def get_headers(client):
+    resp = client.post("/api/auth/register", json={"email": f"{uuid.uuid4()}@ex.com", "password": "secret"})
+    token = resp.json()["access_token"]
+    return {"Authorization": f"Bearer {token}"}
+
+
+def test_audit_log_item_creation(client):
+    headers = get_headers(client)
+    item = client.post("/api/inventory/items", json={"item_type": "sample", "name": "A"}, headers=headers).json()
+    logs = client.get("/api/audit/", headers=headers)
+    assert logs.status_code == 200
+    data = logs.json()
+    assert any(l["action"] == "create_item" and l["target_id"] == item["id"] for l in data)
+
+
+def test_audit_report(client):
+    headers = get_headers(client)
+    client.post(
+        "/api/inventory/items",
+        json={"item_type": "sample", "name": "A"},
+        headers=headers,
+    )
+    params = {
+        "start": "2000-01-01T00:00:00",
+        "end": "2100-01-01T00:00:00",
+    }
+    resp = client.get("/api/audit/report", headers=headers, params=params)
+    assert resp.status_code == 200
+    data = resp.json()
+    assert any(r["action"] == "create_item" and r["count"] >= 1 for r in data)
diff --git a/backend/app/tests/test_auth.py b/backend/app/tests/test_auth.py
new file mode 100644
index 0000000000000000000000000000000000000000..e7711418c9d766d888929ca9c5d19a808c951df1
--- /dev/null
+++ b/backend/app/tests/test_auth.py
@@ -0,0 +1,42 @@
+from .conftest import client
+import pyotp
+
+def test_register_and_login(client):
+    resp = client.post("/api/auth/register", json={"email": "test@example.com", "password": "secret"})
+    assert resp.status_code == 200
+    token = resp.json()["access_token"]
+    assert token
+    resp2 = client.post("/api/auth/login", json={"email": "test@example.com", "password": "secret"})
+    assert resp2.status_code == 200
+
+
+def test_two_factor_flow(client):
+    # register and login
+    resp = client.post("/api/auth/register", json={"email": "2fa@example.com", "password": "secret"})
+    token = resp.json()["access_token"]
+    headers = {"Authorization": f"Bearer {token}"}
+    enable = client.post("/api/auth/enable-2fa", headers=headers)
+    assert enable.status_code == 200
+    secret = enable.json()["secret"]
+    code = pyotp.TOTP(secret).now()
+    verify = client.post("/api/auth/verify-2fa", json={"code": code}, headers=headers)
+    assert verify.status_code == 200
+    # login now requires otp
+    fail = client.post("/api/auth/login", json={"email": "2fa@example.com", "password": "secret"})
+    assert fail.status_code == 401
+    success = client.post("/api/auth/login", json={"email": "2fa@example.com", "password": "secret", "otp_code": pyotp.TOTP(secret).now()})
+    assert success.status_code == 200
+
+
+def test_password_reset_flow(client):
+    from app import notify
+    notify.EMAIL_OUTBOX.clear()
+    resp = client.post("/api/auth/register", json={"email": "reset@example.com", "password": "old"})
+    assert resp.status_code == 200
+    request = client.post("/api/auth/request-password-reset", json={"email": "reset@example.com"})
+    assert request.status_code == 200
+    token = notify.EMAIL_OUTBOX[-1][2].split()[-1]
+    reset = client.post("/api/auth/reset-password", json={"token": token, "new_password": "new"})
+    assert reset.status_code == 200
+    login = client.post("/api/auth/login", json={"email": "reset@example.com", "password": "new"})
+    assert login.status_code == 200
diff --git a/backend/app/tests/test_calendar.py b/backend/app/tests/test_calendar.py
new file mode 100644
index 0000000000000000000000000000000000000000..31eaf35197ce68b345ee955c3b799a79a080ed6c
--- /dev/null
+++ b/backend/app/tests/test_calendar.py
@@ -0,0 +1,34 @@
+import uuid
+from .conftest import client
+
+
+def get_headers(client):
+    resp = client.post(
+        "/api/auth/register", json={"email": f"{uuid.uuid4()}@ex.com", "password": "secret"}
+    )
+    return {"Authorization": f"Bearer {resp.json()['access_token']}"}
+
+
+def test_calendar_events(client):
+    headers = get_headers(client)
+    evt = client.post(
+        "/api/calendar",
+        json={"title": "Meeting", "start_time": "2025-07-02T10:00:00", "end_time": "2025-07-02T11:00:00"},
+        headers=headers,
+    )
+    assert evt.status_code == 200
+    event_id = evt.json()["id"]
+
+    upd = client.put(
+        f"/api/calendar/{event_id}",
+        json={"description": "updated"},
+        headers=headers,
+    )
+    assert upd.status_code == 200
+    assert upd.json()["description"] == "updated"
+
+    events = client.get("/api/calendar", headers=headers)
+    assert any(e["id"] == event_id for e in events.json())
+
+    del_resp = client.delete(f"/api/calendar/{event_id}", headers=headers)
+    assert del_resp.status_code == 204
diff --git a/backend/app/tests/test_comments.py b/backend/app/tests/test_comments.py
new file mode 100644
index 0000000000000000000000000000000000000000..7916d6a4d43c8ba0c1c52fb35326078db15bc9f8
--- /dev/null
+++ b/backend/app/tests/test_comments.py
@@ -0,0 +1,59 @@
+from .conftest import client
+import uuid
+
+
+def get_headers(client):
+    resp = client.post(
+        "/api/auth/register",
+        json={"email": f"{uuid.uuid4()}@ex.com", "password": "secret"},
+    )
+    return {"Authorization": f"Bearer {resp.json()['access_token']}"}
+
+
+def create_item(client, headers):
+    resp = client.post(
+        "/api/inventory/items",
+        json={"item_type": "sample", "name": "ItemA"},
+        headers=headers,
+    )
+    assert resp.status_code == 200
+    return resp.json()["id"]
+
+
+def test_comment_crud(client):
+    headers = get_headers(client)
+    item_id = create_item(client, headers)
+
+    create = client.post(
+        "/api/comments/",
+        json={"content": "First", "item_id": item_id},
+        headers=headers,
+    )
+    assert create.status_code == 200
+    data = create.json()
+    comment_id = data["id"]
+    assert data["content"] == "First"
+
+    list_resp = client.get(
+        "/api/comments/",
+        params={"item_id": item_id},
+        headers=headers,
+    )
+    assert any(c["id"] == comment_id for c in list_resp.json())
+
+    upd = client.put(
+        f"/api/comments/{comment_id}",
+        json={"content": "Updated"},
+        headers=headers,
+    )
+    assert upd.status_code == 200
+    assert upd.json()["content"] == "Updated"
+
+    del_resp = client.delete(f"/api/comments/{comment_id}", headers=headers)
+    assert del_resp.status_code == 200
+    after = client.get(
+        "/api/comments/",
+        params={"item_id": item_id},
+        headers=headers,
+    )
+    assert all(c["id"] != comment_id for c in after.json())
diff --git a/backend/app/tests/test_community.py b/backend/app/tests/test_community.py
new file mode 100644
index 0000000000000000000000000000000000000000..bcd4e9bc1842360c31a415df72aa126f16e8971e
--- /dev/null
+++ b/backend/app/tests/test_community.py
@@ -0,0 +1,72 @@
+import uuid
+
+
+def get_headers(client, email=None):
+    email = email or f"{uuid.uuid4()}@ex.com"
+    resp = client.post("/api/auth/register", json={"email": email, "password": "secret"})
+    token = resp.json()["access_token"]
+    return {"Authorization": f"Bearer {token}"}
+
+
+def test_follow_and_feed(client):
+    h1 = get_headers(client)
+    h2 = get_headers(client)
+
+    # user2 creates a post
+    resp = client.post("/api/community/posts", json={"content": "hello"}, headers=h2)
+    assert resp.status_code == 200
+    post_id = resp.json()["id"]
+
+    # user1 follows user2
+    uid2 = client.get("/api/users/me", headers=h2).json()["id"]
+    f = client.post(f"/api/community/follow/{uid2}", headers=h1)
+    assert f.status_code == 200
+
+    feed = client.get("/api/community/feed", headers=h1)
+    assert any(p["id"] == post_id for p in feed.json())
+
+    # unfollow
+    unf = client.delete(f"/api/community/follow/{uid2}", headers=h1)
+    assert unf.status_code == 200
+
+    feed2 = client.get("/api/community/feed", headers=h1)
+    assert not feed2.json()
+
+
+def test_list_posts(client):
+    h = get_headers(client)
+    resp = client.post("/api/community/posts", json={"content": "post"}, headers=h)
+    assert resp.status_code == 200
+    uid = client.get("/api/users/me", headers=h).json()["id"]
+    posts = client.get("/api/community/posts", params={"user_id": uid}, headers=h)
+    assert len(posts.json()) == 1
+
+
+def test_report_and_resolve(client):
+    h1 = get_headers(client)
+    h2 = get_headers(client)
+    post = client.post("/api/community/posts", json={"content": "bad"}, headers=h2).json()
+    rep = client.post(
+        f"/api/community/posts/{post['id']}/report",
+        json={"reason": "spam"},
+        headers=h1,
+    )
+    assert rep.status_code == 200
+    rid = rep.json()["id"]
+    reports = client.get("/api/community/reports", headers=h1).json()
+    assert any(r["id"] == rid for r in reports)
+    res = client.post(f"/api/community/reports/{rid}/resolve", headers=h1)
+    assert res.status_code == 200
+
+
+def test_like_and_unlike_post(client):
+    h1 = get_headers(client)
+    post = client.post("/api/community/posts", json={"content": "hi"}, headers=h1).json()
+    resp = client.post(f"/api/community/posts/{post['id']}/like", headers=h1)
+    assert resp.status_code == 200
+    count = client.get(f"/api/community/posts/{post['id']}/likes", headers=h1).json()
+    assert count == 1
+    resp2 = client.delete(f"/api/community/posts/{post['id']}/like", headers=h1)
+    assert resp2.status_code == 200
+    count2 = client.get(f"/api/community/posts/{post['id']}/likes", headers=h1).json()
+    assert count2 == 0
diff --git a/backend/app/tests/test_compliance.py b/backend/app/tests/test_compliance.py
new file mode 100644
index 0000000000000000000000000000000000000000..c2e239df338b0ac2edf81e8d7d9b2ddadd91f948
--- /dev/null
+++ b/backend/app/tests/test_compliance.py
@@ -0,0 +1,27 @@
+import uuid
+from .conftest import client
+
+
+def get_headers(client):
+    resp = client.post('/api/auth/register', json={'email': f'{uuid.uuid4()}@ex.com', 'password': 'secret'})
+    return {'Authorization': f"Bearer {resp.json()['access_token']}"}
+
+
+def test_compliance_flow(client):
+    headers = get_headers(client)
+    rec = client.post('/api/compliance/records', json={'record_type': 'safety', 'status': 'pending'}, headers=headers)
+    assert rec.status_code == 200
+    rec_id = rec.json()['id']
+
+    upd = client.put(f'/api/compliance/records/{rec_id}', json={'status': 'approved'}, headers=headers)
+    assert upd.status_code == 200
+    assert upd.json()['status'] == 'approved'
+
+    lst = client.get('/api/compliance/records', headers=headers)
+    assert lst.status_code == 200
+    assert len(lst.json()) == 1
+
+    summary = client.get('/api/compliance/summary', headers=headers)
+    assert summary.status_code == 200
+    data = summary.json()
+    assert any(s['status'] == 'approved' and s['count'] == 1 for s in data)
diff --git a/backend/app/tests/test_data_analysis.py b/backend/app/tests/test_data_analysis.py
new file mode 100644
index 0000000000000000000000000000000000000000..fd15c585110827d5a241f948448cb30da8a65379
--- /dev/null
+++ b/backend/app/tests/test_data_analysis.py
@@ -0,0 +1,21 @@
+from .conftest import client
+import uuid
+
+def get_headers(client):
+    email = f"data{uuid.uuid4()}@example.com"
+    resp = client.post("/api/auth/register", json={"email": email, "password": "secret"})
+    return {"Authorization": f"Bearer {resp.json()['access_token']}"}
+
+
+def test_csv_summary(client):
+    headers = get_headers(client)
+    csv = b"a,b\n1,2\n3,4\n"
+    resp = client.post(
+        "/api/data/summary",
+        files={"upload": ("test.csv", csv, "text/csv")},
+        headers=headers,
+    )
+    assert resp.status_code == 200
+    data = resp.json()
+    assert data["a"]["mean"] == 2.0
+    assert data["b"]["mean"] == 3.0
diff --git a/backend/app/tests/test_devops.py b/backend/app/tests/test_devops.py
new file mode 100644
index 0000000000000000000000000000000000000000..a50488c9434a8af8b9ba871fbaa2af04657a11b1
--- /dev/null
+++ b/backend/app/tests/test_devops.py
@@ -0,0 +1,15 @@
+from .conftest import client
+from app.tasks import backup_database
+import os
+
+
+def test_metrics_endpoint(client):
+    resp = client.get("/metrics")
+    assert resp.status_code == 200
+    assert b"request_count" in resp.content
+
+
+def test_backup_database(tmp_path, monkeypatch):
+    monkeypatch.setenv("BACKUP_DIR", str(tmp_path))
+    path = backup_database()
+    assert os.path.exists(path)
diff --git a/backend/app/tests/test_equipment.py b/backend/app/tests/test_equipment.py
new file mode 100644
index 0000000000000000000000000000000000000000..83209e68393d988685340da3debf8fa98e8ce164
--- /dev/null
+++ b/backend/app/tests/test_equipment.py
@@ -0,0 +1,83 @@
+import uuid
+from .conftest import client
+
+
+def get_headers(client):
+    resp = client.post(
+        "/api/auth/register",
+        json={"email": f"{uuid.uuid4()}@ex.com", "password": "secret"},
+    )
+    token = resp.json()["access_token"]
+    headers = {"Authorization": f"Bearer {token}"}
+    me = client.get("/api/users/me", headers=headers)
+    user_id = me.json()["id"]
+    return headers | {"user_id": user_id}
+
+
+def test_equipment_flow(client):
+    headers = get_headers(client)
+    eq = client.post(
+        "/api/equipment/devices",
+        json={"name": "Thermocycler", "eq_type": "pcr"},
+        headers=headers,
+    )
+    assert eq.status_code == 200
+    eq_id = eq.json()["id"]
+
+    upd = client.put(
+        f"/api/equipment/devices/{eq_id}",
+        json={"status": "online"},
+        headers=headers,
+    )
+    assert upd.status_code == 200
+    assert upd.json()["status"] == "online"
+
+    reading = client.post(
+        f"/api/equipment/devices/{eq_id}/readings",
+        json={"data": {"temp": 95}},
+        headers=headers,
+    )
+    assert reading.status_code == 200
+
+    lst = client.get(
+        f"/api/equipment/devices/{eq_id}/readings",
+        headers=headers,
+    )
+    assert lst.status_code == 200
+    assert len(lst.json()) == 1
+
+
+def test_equipment_ops(client):
+    headers = get_headers(client)
+    eq = client.post(
+        "/api/equipment/devices",
+        json={"name": "Centrifuge", "eq_type": "spin"},
+        headers=headers,
+    )
+    eq_id = eq.json()["id"]
+
+    maint = client.post(
+        "/api/equipment/maintenance",
+        json={"equipment_id": eq_id, "due_date": "2030-01-01T00:00:00Z"},
+        headers=headers,
+    )
+    assert maint.status_code == 200
+
+    s = client.post(
+        "/api/equipment/sops",
+        json={"title": "Use", "content": "steps"},
+        headers=headers,
+    )
+    sop_id = s.json()["id"]
+
+    tr = client.post(
+        "/api/equipment/training",
+        json={
+            "user_id": headers["user_id"],
+            "sop_id": sop_id,
+            "equipment_id": eq_id,
+            "trained_by": headers["user_id"],
+        },
+        headers=headers,
+    )
+    assert tr.status_code == 200
diff --git a/backend/app/tests/test_external.py b/backend/app/tests/test_external.py
new file mode 100644
index 0000000000000000000000000000000000000000..0b2699796a6858c66971a0f7ef1bbe32cf353db6
--- /dev/null
+++ b/backend/app/tests/test_external.py
@@ -0,0 +1,32 @@
+import uuid
+from .conftest import client
+
+
+def auth_headers(client):
+    resp = client.post(
+        "/api/auth/register",
+        json={"email": f"{uuid.uuid4()}@ex.com", "password": "secret"},
+    )
+    token = resp.json()["access_token"]
+    return {"Authorization": f"Bearer {token}"}
+
+
+def test_pubmed_search(monkeypatch, client):
+    headers = auth_headers(client)
+
+    def fake_search(query, limit=5):
+        return [
+            {"id": "1", "title": "Article A"},
+            {"id": "2", "title": "Article B"},
+        ]
+
+    monkeypatch.setattr("app.routes.external.search_pubmed", fake_search)
+    resp = client.post(
+        "/api/external/pubmed",
+        json={"query": "cancer", "limit": 2},
+        headers=headers,
+    )
+    assert resp.status_code == 200
+    data = resp.json()
+    assert len(data) == 2
+    assert data[0]["title"] == "Article A"
diff --git a/backend/app/tests/test_fields.py b/backend/app/tests/test_fields.py
new file mode 100644
index 0000000000000000000000000000000000000000..23e112cbd8c0c45c2025d04b4fbd100429228de8
--- /dev/null
+++ b/backend/app/tests/test_fields.py
@@ -0,0 +1,41 @@
+import uuid
+from .conftest import client
+
+
+def get_headers(client):
+    resp = client.post('/api/auth/register', json={'email': f'{uuid.uuid4()}@ex.com', 'password': 'secret'})
+    return {"Authorization": f"Bearer {resp.json()['access_token']}"}
+
+
+def test_create_update_delete_field(client):
+    headers = get_headers(client)
+    create = client.post('/api/fields/definitions', json={'entity_type': 'sample', 'field_key': 'color', 'field_label': 'Color', 'field_type': 'text'}, headers=headers)
+    assert create.status_code == 200
+    fid = create.json()['id']
+
+    list_resp = client.get('/api/fields/definitions/sample', headers=headers)
+    assert any(f['id'] == fid for f in list_resp.json())
+
+    upd = client.put(f'/api/fields/definitions/{fid}', json={'entity_type': 'sample', 'field_key': 'color', 'field_label': 'Shade', 'field_type': 'text'}, headers=headers)
+    assert upd.status_code == 200
+    assert upd.json()['field_label'] == 'Shade'
+
+    del_resp = client.delete(f'/api/fields/definitions/{fid}', headers=headers)
+    assert del_resp.status_code == 204
+
+    list_after = client.get('/api/fields/definitions/sample', headers=headers)
+    assert all(f['id'] != fid for f in list_after.json())
+
+
+def test_duplicate_field_not_allowed(client):
+    headers = get_headers(client)
+    data = {
+        'entity_type': 'sample',
+        'field_key': 'color',
+        'field_label': 'Color',
+        'field_type': 'text',
+    }
+    first = client.post('/api/fields/definitions', json=data, headers=headers)
+    assert first.status_code == 200
+    second = client.post('/api/fields/definitions', json=data, headers=headers)
+    assert second.status_code == 400
diff --git a/backend/app/tests/test_files.py b/backend/app/tests/test_files.py
new file mode 100644
index 0000000000000000000000000000000000000000..043ab75c24340b6a081001b54e156f11b6ae1736
--- /dev/null
+++ b/backend/app/tests/test_files.py
@@ -0,0 +1,98 @@
+from .conftest import client
+from pathlib import Path
+import uuid
+
+
+def get_headers(client):
+    email = f"file{uuid.uuid4()}@example.com"
+    resp = client.post("/api/auth/register", json={"email": email, "password": "secret"})
+    return {"Authorization": f"Bearer {resp.json()['access_token']}"}
+
+
+def test_upload_file(client):
+    headers = get_headers(client)
+    # create item
+    item_resp = client.post(
+        "/api/inventory/items",
+        json={"item_type": "sample", "name": "FileSample"},
+        headers=headers,
+    )
+    item_id = item_resp.json()["id"]
+
+    file_content = b"testcontent"
+    resp = client.post(
+        "/api/files/upload",
+        data={"item_id": item_id},
+        files={"upload": ("test.txt", file_content, "text/plain")},
+        headers=headers,
+    )
+    assert resp.status_code == 200
+    file_id = resp.json()["id"]
+
+    list_resp = client.get(f"/api/files/items/{item_id}", headers=headers)
+    assert list_resp.status_code == 200
+    assert any(f["id"] == file_id for f in list_resp.json())
+
+    # ensure file exists
+    path = Path(resp.json()["storage_path"])
+    assert path.exists()
+
+
+def _ab1_bytes() -> bytes:
+    import gzip
+    path = Path(__file__).parent / "data" / "sample.ab1.gz"
+    with gzip.open(path, "rb") as fh:
+        return fh.read()
+
+
+def test_file_chromatogram(client):
+    headers = get_headers(client)
+    # create item
+    item_resp = client.post(
+        "/api/inventory/items",
+        json={"item_type": "sample", "name": "ChromSample"},
+        headers=headers,
+    )
+    item_id = item_resp.json()["id"]
+
+    data = _ab1_bytes()
+    upload_resp = client.post(
+        "/api/files/upload",
+        data={"item_id": item_id},
+        files={"upload": ("test.ab1", data, "application/octet-stream")},
+        headers=headers,
+    )
+    assert upload_resp.status_code == 200
+    file_id = upload_resp.json()["id"]
+
+    chrom_resp = client.get(f"/api/files/{file_id}/chromatogram", headers=headers)
+    assert chrom_resp.status_code == 200
+    result = chrom_resp.json()
+    assert len(result["sequence"]) > 10
+    assert all(len(result["traces"][b]) > 0 for b in ["A", "C", "G", "T"])
+
+
+def test_file_sequence_preview(client):
+    headers = get_headers(client)
+    item_resp = client.post(
+        "/api/inventory/items",
+        json={"item_type": "sample", "name": "SeqSample"},
+        headers=headers,
+    )
+    item_id = item_resp.json()["id"]
+
+    fasta = b">s1\nATGC\n"
+    upload_resp = client.post(
+        "/api/files/upload",
+        data={"item_id": item_id},
+        files={"upload": ("test.fasta", fasta, "text/plain")},
+        headers=headers,
+    )
+    assert upload_resp.status_code == 200
+    file_id = upload_resp.json()["id"]
+
+    seq_resp = client.get(f"/api/files/{file_id}/sequence", headers=headers)
+    assert seq_resp.status_code == 200
+    data = seq_resp.json()
+    assert data[0]["id"] == "s1"
+    assert data[0]["length"] == 4
diff --git a/backend/app/tests/test_forum.py b/backend/app/tests/test_forum.py
new file mode 100644
index 0000000000000000000000000000000000000000..cbd2f973fc15ede9d87925e530819d4f41d7caa0
--- /dev/null
+++ b/backend/app/tests/test_forum.py
@@ -0,0 +1,25 @@
+import uuid
+from .conftest import client
+
+
+def get_headers(client):
+    resp = client.post(
+        "/api/auth/register",
+        json={"email": f"{uuid.uuid4()}@ex.com", "password": "secret"},
+    )
+    return {"Authorization": f"Bearer {resp.json()['access_token']}"}
+
+
+def test_forum_flow(client):
+    headers = get_headers(client)
+    th = client.post("/api/forum/threads", json={"title": "Test"}, headers=headers)
+    assert th.status_code == 200
+    tid = th.json()["id"]
+    post = client.post(
+        f"/api/forum/threads/{tid}/posts",
+        json={"thread_id": tid, "content": "Hello"},
+        headers=headers,
+    )
+    assert post.status_code == 200
+    lst = client.get(f"/api/forum/threads/{tid}/posts", headers=headers)
+    assert any(p["id"] == post.json()["id"] for p in lst.json())
diff --git a/backend/app/tests/test_inventory.py b/backend/app/tests/test_inventory.py
new file mode 100644
index 0000000000000000000000000000000000000000..d9f13591878e9077f8869dcf4fc786af202fb03e
--- /dev/null
+++ b/backend/app/tests/test_inventory.py
@@ -0,0 +1,171 @@
+from .conftest import client
+import uuid
+import json
+from datetime import datetime
+
+
+def get_auth_headers(client, email=None):
+    email = email or f"user{uuid.uuid4()}@example.com"
+    resp = client.post("/api/auth/register", json={"email": email, "password": "secret"})
+    token = resp.json()["access_token"]
+    return {"Authorization": f"Bearer {token}"}
+
+
+def create_item(client, headers, name="Sample", status="available"):
+    resp = client.post(
+        "/api/inventory/items",
+        json={"item_type": "sample", "name": name, "status": status},
+        headers=headers,
+    )
+    assert resp.status_code == 200
+    return resp.json()
+
+
+def test_create_item(client):
+    headers = get_auth_headers(client)
+    resp = client.post(
+        "/api/inventory/items",
+        json={"item_type": "plasmid", "name": "pUC19"},
+        headers=headers,
+    )
+    assert resp.status_code == 200
+    data = resp.json()
+    assert data["name"] == "pUC19"
+
+
+def test_update_and_delete_item(client):
+    headers = get_auth_headers(client)
+    item = create_item(client, headers, "Old")
+    item_id = item["id"]
+
+    up = client.put(
+        f"/api/inventory/items/{item_id}",
+        json={"name": "New"},
+        headers=headers,
+    )
+    assert up.status_code == 200
+    assert up.json()["name"] == "New"
+
+    del_resp = client.delete(f"/api/inventory/items/{item_id}", headers=headers)
+    assert del_resp.status_code == 204
+
+    items = client.get("/api/inventory/items", headers=headers).json()
+    assert all(i["id"] != item_id for i in items)
+
+
+def test_filter_items_by_name(client):
+    headers = get_auth_headers(client)
+    create_item(client, headers, "Alpha Sample")
+    create_item(client, headers, "Beta Sample")
+
+    resp = client.get("/api/inventory/items", params={"name": "Beta"}, headers=headers)
+    assert resp.status_code == 200
+    data = resp.json()
+    assert len(data) == 1
+    assert data[0]["name"] == "Beta Sample"
+
+
+def test_filter_by_custom_field(client):
+    headers = get_auth_headers(client)
+    resp1 = client.post(
+        "/api/inventory/items",
+        json={"item_type": "sample", "name": "CF1", "custom_data": {"tag": "A"}},
+        headers=headers,
+    )
+    resp2 = client.post(
+        "/api/inventory/items",
+        json={"item_type": "sample", "name": "CF2", "custom_data": {"tag": "B"}},
+        headers=headers,
+    )
+    assert resp1.status_code == 200
+    assert resp2.status_code == 200
+
+    params = {"custom": json.dumps({"tag": "A"})}
+    resp = client.get("/api/inventory/items", params=params, headers=headers)
+    assert resp.status_code == 200
+    data = resp.json()
+    assert len(data) == 1
+    assert data[0]["name"] == "CF1"
+
+
+def test_export_items_csv(client):
+    headers = get_auth_headers(client)
+    create_item(client, headers, "Export1")
+    create_item(client, headers, "Export2")
+
+    resp = client.get("/api/inventory/export", headers=headers)
+    assert resp.status_code == 200
+    assert resp.headers["content-type"].startswith("text/csv")
+    text = resp.text
+    assert "Export1" in text and "Export2" in text
+
+def test_generate_barcode(client):
+    headers = get_auth_headers(client)
+    item = create_item(client, headers, "BCItem")
+    resp = client.post(f"/api/inventory/items/{item['id']}/barcode", headers=headers)
+    assert resp.status_code == 200
+    assert resp.headers["content-type"].startswith("image/png")
+    # item should now have a barcode
+    items = client.get("/api/inventory/items", headers=headers).json()
+    found = next(i for i in items if i["id"] == item["id"])
+    assert found["barcode"]
+
+
+def test_generate_barcode_permission(client):
+    h1 = get_auth_headers(client, "owner2@example.com")
+    h2 = get_auth_headers(client, "noaccess@example.com")
+    item = create_item(client, h1, "Secret")
+    resp = client.post(f"/api/inventory/items/{item['id']}/barcode", headers=h2)
+    assert resp.status_code == 403
+
+
+def test_list_items_permission(client):
+    h1 = get_auth_headers(client, "owner3@example.com")
+    h2 = get_auth_headers(client, "viewer@example.com")
+    item = create_item(client, h1, "Secret")
+
+    resp_other = client.get("/api/inventory/items", headers=h2)
+    assert all(i["id"] != item["id"] for i in resp_other.json())
+
+
+def test_import_items(client):
+    headers = get_auth_headers(client)
+    csv_data = "item_type,name\nplasmid,Imp1\nsample,Imp2\n"
+    resp = client.post(
+        "/api/inventory/import",
+        files={"file": ("items.csv", csv_data, "text/csv")},
+        headers=headers,
+    )
+    assert resp.status_code == 200
+    items = resp.json()
+    assert len(items) == 2
+    names = [i["name"] for i in items]
+    assert "Imp1" in names and "Imp2" in names
+
+
+def test_filter_by_status_and_date(client):
+    headers = get_auth_headers(client)
+    create_item(client, headers, "A", status="available")
+    create_item(client, headers, "B", status="used")
+    now = datetime.utcnow().isoformat()
+    resp = client.get(
+        "/api/inventory/items",
+        params={"status": "used", "created_from": "1970-01-01T00:00:00", "created_to": now},
+        headers=headers,
+    )
+    assert resp.status_code == 200
+    data = resp.json()
+    assert len(data) == 1
+    assert data[0]["name"] == "B"
+
+
+def test_inventory_facets(client):
+    headers = get_auth_headers(client)
+    create_item(client, headers, "F1", status="available")
+    create_item(client, headers, "F2", status="used")
+    resp = client.get("/api/inventory/facets", headers=headers)
+    assert resp.status_code == 200
+    data = resp.json()
+    assert any(f["key"] == "sample" for f in data["item_types"])
+    assert any(f["key"] == "available" for f in data["statuses"])
+
diff --git a/backend/app/tests/test_knowledge.py b/backend/app/tests/test_knowledge.py
new file mode 100644
index 0000000000000000000000000000000000000000..df7c1f851393de49fc952ba51f984e0f80a38921
--- /dev/null
+++ b/backend/app/tests/test_knowledge.py
@@ -0,0 +1,80 @@
+import uuid
+from .conftest import client
+
+
+def get_headers(client):
+    resp = client.post(
+        "/api/auth/register",
+        json={"email": f"{uuid.uuid4()}@ex.com", "password": "secret"},
+    )
+    return {"Authorization": f"Bearer {resp.json()['access_token']}"}
+
+
+def test_knowledge_crud(client):
+    headers = get_headers(client)
+    resp = client.post(
+        "/api/knowledge/articles",
+        json={"title": "Cloning tips", "content": "Use fresh cells", "tags": ["cloning"]},
+        headers=headers,
+    )
+    assert resp.status_code == 200
+    art_id = resp.json()["id"]
+
+    list_resp = client.get("/api/knowledge/articles", headers=headers)
+    assert any(a["id"] == art_id for a in list_resp.json())
+
+    upd = client.put(
+        f"/api/knowledge/articles/{art_id}",
+        json={"content": "Use competent cells"},
+        headers=headers,
+    )
+    assert upd.status_code == 200
+    assert upd.json()["content"] == "Use competent cells"
+
+    del_resp = client.delete(f"/api/knowledge/articles/{art_id}", headers=headers)
+    assert del_resp.status_code == 200
+
+
+def test_article_comments(client):
+    headers = get_headers(client)
+    art = client.post(
+        "/api/knowledge/articles",
+        json={"title": "Tips", "content": "Use buffer", "is_public": True},
+        headers=headers,
+    ).json()
+    c = client.post(
+        "/api/comments/",
+        json={"content": "Great", "knowledge_article_id": art["id"]},
+        headers=headers,
+    )
+    assert c.status_code == 200
+    cid = c.json()["id"]
+    listed = client.get(
+        "/api/comments/",
+        params={"article_id": art["id"]},
+        headers=headers,
+    )
+    assert any(cm["id"] == cid for cm in listed.json())
+
+
+def test_article_stars(client):
+    headers = get_headers(client)
+    art = client.post(
+        "/api/knowledge/articles",
+        json={"title": "Star", "content": "text"},
+        headers=headers,
+    ).json()
+
+    resp = client.post(f"/api/knowledge/articles/{art['id']}/star", headers=headers)
+    assert resp.status_code == 200
+    count = client.get(f"/api/knowledge/articles/{art['id']}/stars", headers=headers).json()
+    assert count["count"] == 1
+
+    # starring again has no effect
+    client.post(f"/api/knowledge/articles/{art['id']}/star", headers=headers)
+    count = client.get(f"/api/knowledge/articles/{art['id']}/stars", headers=headers).json()
+    assert count["count"] == 1
+
+    client.delete(f"/api/knowledge/articles/{art['id']}/star", headers=headers)
+    count = client.get(f"/api/knowledge/articles/{art['id']}/stars", headers=headers).json()
+    assert count["count"] == 0
diff --git a/backend/app/tests/test_labs.py b/backend/app/tests/test_labs.py
new file mode 100644
index 0000000000000000000000000000000000000000..b30bb275162e07a7eba9f6ce1fbccf04844a444a
--- /dev/null
+++ b/backend/app/tests/test_labs.py
@@ -0,0 +1,27 @@
+from .conftest import client
+import uuid
+
+
+def get_headers(client, email):
+    resp = client.post("/api/auth/register", json={"email": email, "password": "secret"})
+    token = resp.json()["access_token"]
+    return {"Authorization": f"Bearer {token}"}
+
+
+def test_lab_connection_flow(client):
+    h1 = get_headers(client, "lab1@example.com")
+    h2 = get_headers(client, "lab2@example.com")
+
+    lab1 = client.post("/api/labs", json={"name": "Lab1"}, headers=h1).json()
+    lab2 = client.post("/api/labs", json={"name": "Lab2"}, headers=h2).json()
+
+    req = client.post(f"/api/labs/{lab1['id']}/connections", json={"target_lab": lab2['id']}, headers=h1)
+    assert req.status_code == 200
+    conn_id = req.json()["id"]
+
+    lst = client.get("/api/labs/connections", headers=h1).json()
+    assert any(c["id"] == conn_id for c in lst)
+
+    acc = client.post(f"/api/labs/connections/{conn_id}/accept", headers=h2)
+    assert acc.status_code == 200
+    assert acc.json()["status"] == "accepted"
diff --git a/backend/app/tests/test_locations.py b/backend/app/tests/test_locations.py
new file mode 100644
index 0000000000000000000000000000000000000000..0c317ecd40b6d6e9e673bde928d64bb0b1545e9c
--- /dev/null
+++ b/backend/app/tests/test_locations.py
@@ -0,0 +1,20 @@
+import uuid
+
+from .test_inventory import get_auth_headers
+
+
+def test_create_and_list_locations(client):
+    headers = get_auth_headers(client)
+    # create team
+    team_resp = client.post('/api/teams/', json={'name': 'LocTeam'}, headers=headers)
+    team_id = team_resp.json()['id']
+    loc_resp = client.post('/api/locations/', json={'name': 'Freezer 1', 'team_id': team_id}, headers=headers)
+    assert loc_resp.status_code == 200
+    loc_id = loc_resp.json()['id']
+
+    list_resp = client.get('/api/locations', headers=headers)
+    assert any(l['id'] == loc_id for l in list_resp.json())
+
+    # assign to item
+    item = client.post('/api/inventory/items', json={'item_type': 'sample', 'name': 'L1', 'location_id': loc_id}, headers=headers).json()
+    assert item['location_id'] == loc_id
diff --git a/backend/app/tests/test_marketplace.py b/backend/app/tests/test_marketplace.py
new file mode 100644
index 0000000000000000000000000000000000000000..199d48e7b9b39cd7e40698a3d20aa4801e59cadd
--- /dev/null
+++ b/backend/app/tests/test_marketplace.py
@@ -0,0 +1,39 @@
+from .conftest import client
+import uuid
+
+
+def auth(client, email):
+    resp = client.post("/api/auth/register", json={"email": email, "password": "secret"})
+    return {"Authorization": f"Bearer {resp.json()['access_token']}"}
+
+
+def test_marketplace_flow(client):
+    seller_h = auth(client, "seller@example.com")
+    item = client.post(
+        "/api/inventory/items",
+        json={"item_type": "sample", "name": "Item1"},
+        headers=seller_h,
+    ).json()
+    listing = client.post(
+        "/api/marketplace/listings",
+        json={"item_id": item["id"], "price": 5},
+        headers=seller_h,
+    )
+    assert listing.status_code == 200
+    l_id = listing.json()["id"]
+
+    listings = client.get("/api/marketplace/listings").json()
+    assert any(l["id"] == l_id for l in listings)
+
+    buyer_h = auth(client, "buyer@example.com")
+    req = client.post(
+        f"/api/marketplace/listings/{l_id}/requests",
+        json={"message": "Interested"},
+        headers=buyer_h,
+    )
+    assert req.status_code == 200
+    r_id = req.json()["id"]
+
+    acc = client.post(f"/api/marketplace/requests/{r_id}/accept", headers=seller_h)
+    assert acc.status_code == 200
+    assert acc.json()["status"] == "accepted"
diff --git a/backend/app/tests/test_notebook.py b/backend/app/tests/test_notebook.py
new file mode 100644
index 0000000000000000000000000000000000000000..cb088675c9d2ed3c6fa521cda1f05a1233b6602f
--- /dev/null
+++ b/backend/app/tests/test_notebook.py
@@ -0,0 +1,106 @@
+import uuid
+from .conftest import client
+
+
+def get_headers(client):
+    resp = client.post(
+        "/api/auth/register",
+        json={"email": f"{uuid.uuid4()}@ex.com", "password": "secret"},
+    )
+    return {"Authorization": f"Bearer {resp.json()['access_token']}"}
+
+
+def test_notebook_crud(client):
+    headers = get_headers(client)
+    create = client.post(
+        "/api/notebook/entries",
+        json={"title": "Day1", "content": "Initial", "blocks": [{"type": "text", "text": "hello"}]},
+        headers=headers,
+    )
+    assert create.status_code == 200
+    data = create.json()
+    entry_id = data["id"]
+    assert data["title"] == "Day1"
+
+    get_resp = client.get(f"/api/notebook/entries/{entry_id}", headers=headers)
+    assert get_resp.status_code == 200
+    assert get_resp.json()["id"] == entry_id
+
+    list_resp = client.get("/api/notebook/entries", headers=headers)
+    assert any(e["id"] == entry_id for e in list_resp.json())
+
+    upd = client.put(
+        f"/api/notebook/entries/{entry_id}",
+        json={"content": "Updated", "blocks": [{"type": "text", "text": "bye"}]},
+        headers=headers,
+    )
+    assert upd.status_code == 200
+    assert upd.json()["content"] == "Updated"
+    assert upd.json()["blocks"][0]["text"] == "bye"
+
+    del_resp = client.delete(f"/api/notebook/entries/{entry_id}", headers=headers)
+    assert del_resp.status_code == 200
+    list_after = client.get("/api/notebook/entries", headers=headers)
+    assert all(e["id"] != entry_id for e in list_after.json())
+
+
+def test_notebook_export(client):
+    headers = get_headers(client)
+    create = client.post(
+        "/api/notebook/entries",
+        json={"title": "Day2", "content": "Text"},
+        headers=headers,
+    )
+    entry_id = create.json()["id"]
+    resp = client.get(f"/api/notebook/entries/{entry_id}/export", headers=headers)
+    assert resp.status_code == 200
+    assert resp.headers["content-type"] == "application/pdf"
+    assert len(resp.content) > 0
+
+
+def test_notebook_with_project_and_items(client):
+    headers = get_headers(client)
+    proj = client.post("/api/projects", json={"name": "P"}, headers=headers).json()
+    item = client.post(
+        "/api/inventory/items",
+        json={"item_type": "sample", "name": "S"},
+        headers=headers,
+    ).json()
+    entry = client.post(
+        "/api/notebook/entries",
+        json={"title": "Note", "content": "c", "project_id": proj["id"], "items": [item["id"]]},
+        headers=headers,
+    )
+    assert entry.status_code == 200
+    data = entry.json()
+    assert data["project_id"] == proj["id"]
+    assert item["id"] in data["items"]
+
+
+def test_notebook_sign_and_versions(client):
+    headers = get_headers(client)
+    create = client.post(
+        "/api/notebook/entries",
+        json={"title": "Sig", "content": "v1", "blocks": [{"type": "text", "text": "v1"}]},
+        headers=headers,
+    )
+    entry_id = create.json()["id"]
+    client.put(
+        f"/api/notebook/entries/{entry_id}",
+        json={"content": "v2", "blocks": [{"type": "text", "text": "v2"}]},
+        headers=headers,
+    )
+    versions = client.get(f"/api/notebook/entries/{entry_id}/versions", headers=headers).json()
+    assert len(versions) == 2
+    assert versions[0]["blocks"][0]["text"] == "v1"
+    sign = client.post(f"/api/notebook/entries/{entry_id}/sign", headers=headers)
+    assert sign.status_code == 200
+    locked = client.put(
+        f"/api/notebook/entries/{entry_id}",
+        json={"content": "v3"},
+        headers=headers,
+    )
+    assert locked.status_code == 400
+    witness_headers = get_headers(client)
+    witness = client.post(f"/api/notebook/entries/{entry_id}/witness", headers=witness_headers)
+    assert witness.status_code == 200
diff --git a/backend/app/tests/test_notifications.py b/backend/app/tests/test_notifications.py
new file mode 100644
index 0000000000000000000000000000000000000000..ca64e837ef22d263d29a3fe191b160500b36c64c
--- /dev/null
+++ b/backend/app/tests/test_notifications.py
@@ -0,0 +1,161 @@
+import uuid
+import os
+from .conftest import client, TestingSessionLocal
+from app import notify, models, tasks
+
+
+def create_user(client, email, phone=None):
+    payload = {"email": email, "password": "secret"}
+    if phone:
+        payload["phone_number"] = phone
+    resp = client.post("/api/auth/register", json=payload)
+    assert resp.status_code == 200
+    token = resp.json()["access_token"]
+    return {"Authorization": f"Bearer {token}"}
+
+
+def test_booking_notification(client):
+    notify.EMAIL_OUTBOX.clear()
+    notify.SMS_OUTBOX.clear()
+    owner_headers = create_user(client, f"{uuid.uuid4()}@ex.com", phone="123")
+    res = client.post(
+        "/api/schedule/resources",
+        json={"name": "Centrifuge"},
+        headers=owner_headers,
+    )
+    assert res.status_code == 200
+    resource_id = res.json()["id"]
+
+    booker_headers = create_user(client, f"{uuid.uuid4()}@ex.com")
+    booking = client.post(
+        "/api/schedule/bookings",
+        json={
+            "resource_id": resource_id,
+            "start_time": "2025-07-02T12:00:00",
+            "end_time": "2025-07-02T13:00:00",
+        },
+        headers=booker_headers,
+    )
+    assert booking.status_code == 200
+
+    notif_list = client.get("/api/notifications/", headers=owner_headers)
+    assert notif_list.status_code == 200
+    data = notif_list.json()
+    assert len(data) == 1
+    notif_id = data[0]["id"]
+    assert "booked" in data[0]["message"]
+
+    mark = client.post(f"/api/notifications/{notif_id}/read", headers=owner_headers)
+    assert mark.status_code == 200
+    assert mark.json()["is_read"] is True
+    assert len(notify.EMAIL_OUTBOX) == 1
+    assert len(notify.SMS_OUTBOX) == 1
+
+def test_notification_preferences(client):
+    notify.EMAIL_OUTBOX.clear()
+    notify.SMS_OUTBOX.clear()
+    owner_headers = create_user(client, f"{uuid.uuid4()}@ex.com", phone="555")
+    # disable booking email notifications
+    pref = client.put(
+        "/api/notifications/preferences/booking/email",
+        json={"enabled": False},
+        headers=owner_headers,
+    )
+    assert pref.status_code == 200
+    assert pref.json()["enabled"] is False
+
+    res = client.post(
+        "/api/schedule/resources",
+        json={"name": "Incubator"},
+        headers=owner_headers,
+    )
+    resource_id = res.json()["id"]
+
+    booker_headers = create_user(client, f"{uuid.uuid4()}@ex.com")
+    booking = client.post(
+        "/api/schedule/bookings",
+        json={
+            "resource_id": resource_id,
+            "start_time": "2025-07-02T15:00:00",
+            "end_time": "2025-07-02T16:00:00",
+        },
+        headers=booker_headers,
+    )
+    assert booking.status_code == 200
+
+    notif_list = client.get("/api/notifications/", headers=owner_headers)
+    assert notif_list.status_code == 200
+    assert len(notif_list.json()) == 1
+    # email disabled but sms should still send
+    assert len(notify.EMAIL_OUTBOX) == 0
+    assert len(notify.SMS_OUTBOX) == 1
+
+
+def test_daily_digest(client):
+    notify.EMAIL_OUTBOX.clear()
+    create_user(client, f"{uuid.uuid4()}@ex.com")
+    email = f"{uuid.uuid4()}@ex.com"
+    create_user(client, email)
+    # create notifications directly
+    from .conftest import TestingSessionLocal
+    db = TestingSessionLocal()
+    user = db.query(models.User).filter_by(email=email).first()
+    db.add(models.Notification(user_id=user.id, message="First"))
+    db.add(models.Notification(user_id=user.id, message="Second"))
+    db.commit()
+    notify.send_daily_digest(db)
+    db.close()
+    entries = [e for e in notify.EMAIL_OUTBOX if e[0] == email]
+    assert len(entries) == 1
+    _, subject, body = entries[0]
+    assert "Daily Notification Digest" in subject
+    assert "First" in body and "Second" in body
+
+
+def test_inventory_alert_task(client, monkeypatch):
+    os.environ["INVENTORY_WARNING_DAYS"] = "7"
+    notify.EMAIL_OUTBOX.clear()
+    email = f"{uuid.uuid4()}@ex.com"
+    headers = create_user(client, email)
+    item = client.post(
+        "/api/inventory/items",
+        json={"item_type": "reagent", "name": "Buffer", "custom_data": {"stock": 1}},
+        headers=headers,
+    ).json()
+    for _ in range(5):
+        client.post(
+            "/api/notebook/entries",
+            json={"title": "use", "content": "c", "item_id": item["id"]},
+            headers=headers,
+        )
+    tasks.check_inventory_levels()
+    from .conftest import TestingSessionLocal
+    db = TestingSessionLocal()
+    user = db.query(models.User).filter_by(email=email).first()
+    notifs = db.query(models.Notification).filter_by(user_id=user.id).all()
+    db.close()
+    assert any("may run out" in n.message for n in notifs)
+    assert any(e[0] == email for e in notify.EMAIL_OUTBOX)
+
+
+def test_preference_unique(client):
+    email = f"{uuid.uuid4()}@ex.com"
+    headers = create_user(client, email)
+    for _ in range(2):
+        res = client.put(
+            "/api/notifications/preferences/booking/email",
+            json={"enabled": True},
+            headers=headers,
+        )
+        assert res.status_code == 200
+    from .conftest import TestingSessionLocal
+    db = TestingSessionLocal()
+    user = db.query(models.User).filter_by(email=email).first()
+    prefs = (
+        db.query(models.NotificationPreference)
+        .filter_by(user_id=user.id, pref_type="booking", channel="email")
+        .all()
+    )
+    db.close()
+    # only one preference row should exist
+    assert len(prefs) == 1
diff --git a/backend/app/tests/test_projects.py b/backend/app/tests/test_projects.py
new file mode 100644
index 0000000000000000000000000000000000000000..d857b2f3fb1e7315b71257c6ad10e58622927a44
--- /dev/null
+++ b/backend/app/tests/test_projects.py
@@ -0,0 +1,70 @@
+import uuid
+from .conftest import client
+
+
+def get_headers(client):
+    resp = client.post(
+        "/api/auth/register", json={"email": f"{uuid.uuid4()}@ex.com", "password": "secret"}
+    )
+    return {"Authorization": f"Bearer {resp.json()['access_token']}"}
+
+
+def test_project_flow(client):
+    headers = get_headers(client)
+    proj = client.post("/api/projects", json={"name": "Test"}, headers=headers)
+    assert proj.status_code == 200
+    proj_id = proj.json()["id"]
+
+    item = client.post(
+        "/api/inventory/items",
+        json={"item_type": "sample", "name": "S1"},
+        headers=headers,
+    ).json()
+
+    add = client.post(
+        f"/api/projects/{proj_id}/items",
+        params={"item_id": item["id"]},
+        headers=headers,
+    )
+    assert add.status_code == 204
+
+    task = client.post(
+        f"/api/projects/{proj_id}/tasks",
+        json={"name": "Task1"},
+        headers=headers,
+    )
+    assert task.status_code == 200
+    task_id = task.json()["id"]
+
+    upd = client.put(
+        f"/api/projects/{proj_id}/tasks/{task_id}",
+        json={"status": "done"},
+        headers=headers,
+    )
+    assert upd.json()["status"] == "done"
+
+    tasks = client.get(f"/api/projects/{proj_id}/tasks", headers=headers)
+    assert any(t["id"] == task_id for t in tasks.json())
+
+    del_task = client.delete(
+        f"/api/projects/{proj_id}/tasks/{task_id}", headers=headers
+    )
+    assert del_task.status_code == 204
+
+    lst = client.get("/api/projects", headers=headers)
+    assert any(p["id"] == proj_id for p in lst.json())
+
+    del_resp = client.delete(f"/api/projects/{proj_id}", headers=headers)
+    assert del_resp.status_code == 204
+
+
+def test_non_member_cannot_modify(client):
+    owner = get_headers(client)
+    proj = client.post("/api/projects", json={"name": "Sec"}, headers=owner).json()
+    other = get_headers(client)
+    resp = client.post(
+        f"/api/projects/{proj['id']}/tasks",
+        json={"name": "N"},
+        headers=other,
+    )
+    assert resp.status_code == 403
diff --git a/backend/app/tests/test_protocols.py b/backend/app/tests/test_protocols.py
new file mode 100644
index 0000000000000000000000000000000000000000..6e54e5ed8a63c161d90e911a3d2f1261dac3c9fa
--- /dev/null
+++ b/backend/app/tests/test_protocols.py
@@ -0,0 +1,196 @@
+import uuid
+from .conftest import client
+
+
+def get_headers(client):
+    resp = client.post(
+        "/api/auth/register", json={"email": f"{uuid.uuid4()}@ex.com", "password": "secret"}
+    )
+    return {"Authorization": f"Bearer {resp.json()['access_token']}"}
+
+
+def test_create_and_get_template(client):
+    headers = get_headers(client)
+    create = client.post(
+        "/api/protocols/templates",
+        json={"name": "Prep", "content": "Step 1"},
+        headers=headers,
+    )
+    assert create.status_code == 200
+    data = create.json()
+    tpl_id = data["id"]
+    assert data["version"] == "1"
+
+    get_resp = client.get(f"/api/protocols/templates/{tpl_id}", headers=headers)
+    assert get_resp.status_code == 200
+    assert get_resp.json()["id"] == tpl_id
+
+    # create second version
+    create2 = client.post(
+        "/api/protocols/templates",
+        json={"name": "Prep", "content": "Step 2"},
+        headers=headers,
+    )
+    assert create2.json()["version"] == "2"
+
+    list_resp = client.get("/api/protocols/templates", headers=headers)
+    assert list_resp.status_code == 200
+    assert len(list_resp.json()) >= 2
+
+    # update template
+    upd = client.put(
+        f"/api/protocols/templates/{tpl_id}",
+        json={"name": "Prep Updated", "content": "Updated"},
+        headers=headers,
+    )
+    assert upd.status_code == 200
+    assert upd.json()["name"] == "Prep Updated"
+
+    # delete template
+    del_resp = client.delete(f"/api/protocols/templates/{tpl_id}", headers=headers)
+    assert del_resp.status_code == 200
+    list_after = client.get("/api/protocols/templates", headers=headers)
+    assert all(t["id"] != tpl_id for t in list_after.json())
+
+
+def test_protocol_execution_flow(client):
+    headers = get_headers(client)
+    tpl_resp = client.post(
+        "/api/protocols/templates",
+        json={"name": "Exec", "content": "Step"},
+        headers=headers,
+    )
+    tpl_id = tpl_resp.json()["id"]
+
+    exec_resp = client.post(
+        "/api/protocols/executions",
+        json={"template_id": tpl_id},
+        headers=headers,
+    )
+    assert exec_resp.status_code == 200
+    exec_id = exec_resp.json()["id"]
+    assert exec_resp.json()["status"] == "pending"
+
+    list_resp = client.get("/api/protocols/executions", headers=headers)
+    assert any(e["id"] == exec_id for e in list_resp.json())
+
+    upd_resp = client.put(
+        f"/api/protocols/executions/{exec_id}",
+        json={"status": "completed", "result": {"ok": True}},
+        headers=headers,
+    )
+    assert upd_resp.status_code == 200
+    assert upd_resp.json()["status"] == "completed"
+    assert upd_resp.json()["result"] == {"ok": True}
+
+
+def test_protocol_variables(client):
+    headers = get_headers(client)
+    tpl = client.post(
+        "/api/protocols/templates",
+        json={"name": "Var", "content": "Step", "variables": ["temp"]},
+        headers=headers,
+    ).json()
+
+    # missing param should fail
+    resp = client.post(
+        "/api/protocols/executions",
+        json={"template_id": tpl["id"], "params": {}},
+        headers=headers,
+    )
+    assert resp.status_code == 400
+
+    # providing param succeeds
+    ok = client.post(
+        "/api/protocols/executions",
+        json={"template_id": tpl["id"], "params": {"temp": "20C"}},
+        headers=headers,
+    )
+    assert ok.status_code == 200
+
+
+def test_public_and_forking(client):
+    headers = get_headers(client)
+    tpl = client.post(
+        "/api/protocols/templates",
+        json={"name": "Pub", "content": "Step", "is_public": True},
+        headers=headers,
+    ).json()
+
+    pub_list = client.get("/api/protocols/public")
+    assert any(t["id"] == tpl["id"] for t in pub_list.json())
+
+    fork = client.post(f"/api/protocols/templates/{tpl['id']}/fork", headers=headers)
+    assert fork.status_code == 200
+    assert fork.json()["forked_from"] == tpl["id"]
+
+
+def test_protocol_merge_requests(client):
+    headers = get_headers(client)
+    tpl = client.post(
+        "/api/protocols/templates",
+        json={"name": "Pub2", "content": "A", "is_public": True},
+        headers=headers,
+    ).json()
+    mr = client.post(
+        "/api/protocols/merge-requests",
+        json={"template_id": tpl["id"], "content": "B", "variables": ["x"]},
+        headers=headers,
+    )
+    assert mr.status_code == 200
+    mr_id = mr.json()["id"]
+
+    # author lists and accepts
+    mrs = client.get("/api/protocols/merge-requests", headers=headers)
+    assert any(r["id"] == mr_id for r in mrs.json())
+
+    accepted = client.post(f"/api/protocols/merge-requests/{mr_id}/accept", headers=headers)
+    assert accepted.status_code == 200
+    assert accepted.json()["content"] == "B"
+
+
+def test_protocol_diff(client):
+    headers = get_headers(client)
+    tpl1 = client.post(
+        "/api/protocols/templates",
+        json={"name": "Diff", "content": "A"},
+        headers=headers,
+    ).json()
+    tpl2 = client.post(
+        "/api/protocols/templates",
+        json={"name": "Diff", "content": "B"},
+        headers=headers,
+    ).json()
+    resp = client.get(
+        "/api/protocols/diff",
+        params={"old_id": tpl1["id"], "new_id": tpl2["id"]},
+        headers=headers,
+    )
+    assert resp.status_code == 200
+    diff = resp.json()["diff"]
+    assert "-A" in diff and "+B" in diff
+
+
+def test_protocol_stars(client):
+    headers = get_headers(client)
+    tpl = client.post(
+        "/api/protocols/templates",
+        json={"name": "Star", "content": "s"},
+        headers=headers,
+    ).json()
+
+    star = client.post(f"/api/protocols/templates/{tpl['id']}/star", headers=headers)
+    assert star.status_code == 200
+    data = client.get(f"/api/protocols/templates/{tpl['id']}/stars", headers=headers).json()
+    assert data["count"] == 1
+
+    # starring again has no effect
+    client.post(f"/api/protocols/templates/{tpl['id']}/star", headers=headers)
+    data = client.get(f"/api/protocols/templates/{tpl['id']}/stars", headers=headers).json()
+    assert data["count"] == 1
+
+    # unstar removes the star
+    client.delete(f"/api/protocols/templates/{tpl['id']}/star", headers=headers)
+    data = client.get(f"/api/protocols/templates/{tpl['id']}/stars", headers=headers).json()
+    assert data["count"] == 0
+
diff --git a/backend/app/tests/test_relationships.py b/backend/app/tests/test_relationships.py
new file mode 100644
index 0000000000000000000000000000000000000000..5bdcd2206209a1035e74c11e7c44943813362c5b
--- /dev/null
+++ b/backend/app/tests/test_relationships.py
@@ -0,0 +1,86 @@
+from .conftest import client
+
+
+def get_headers(client, email):
+    resp = client.post(
+        "/api/auth/register", json={"email": email, "password": "secret"}
+    )
+    token = resp.json()["access_token"]
+    return {"Authorization": f"Bearer {token}"}
+
+
+def create_item(client, headers, name):
+    resp = client.post(
+        "/api/inventory/items",
+        json={"item_type": "sample", "name": name},
+        headers=headers,
+    )
+    return resp.json()["id"]
+
+
+def test_create_relationship(client):
+    headers = get_headers(client, "rel@example.com")
+    item1 = create_item(client, headers, "Item1")
+    item2 = create_item(client, headers, "Item2")
+
+    resp = client.post(
+        "/api/inventory/relationships",
+        json={"from_item": item1, "to_item": item2, "relationship_type": "parent"},
+        headers=headers,
+    )
+    assert resp.status_code == 200
+    rel_id = resp.json()["id"]
+
+    list_resp = client.get(
+        f"/api/inventory/items/{item1}/relationships",
+        headers=headers,
+    )
+    assert list_resp.status_code == 200
+    data = list_resp.json()
+    assert any(r["id"] == rel_id for r in data)
+
+
+def test_relationship_graph(client):
+    headers = get_headers(client, "graph@example.com")
+    item1 = create_item(client, headers, "ItemA")
+    item2 = create_item(client, headers, "ItemB")
+    item3 = create_item(client, headers, "ItemC")
+
+    client.post(
+        "/api/inventory/relationships",
+        json={"from_item": item1, "to_item": item2, "relationship_type": "link"},
+        headers=headers,
+    )
+    client.post(
+        "/api/inventory/relationships",
+        json={"from_item": item2, "to_item": item3, "relationship_type": "link"},
+        headers=headers,
+    )
+
+    resp = client.get(
+        f"/api/inventory/items/{item1}/graph",
+        params={"depth": 2},
+        headers=headers,
+    )
+    assert resp.status_code == 200
+    graph = resp.json()
+    node_ids = {n["id"] for n in graph["nodes"]}
+    assert {item1, item2, item3} <= node_ids
+    assert len(graph["edges"]) >= 2
+
+
+def test_relationship_permission(client):
+    h1 = get_headers(client, "owner@example.com")
+    h2 = get_headers(client, "other@example.com")
+    item1 = create_item(client, h1, "OwnerItem")
+    item2 = create_item(client, h2, "OtherItem")
+
+    resp = client.post(
+        "/api/inventory/relationships",
+        json={"from_item": item1, "to_item": item2, "relationship_type": "test"},
+        headers=h2,
+    )
+    assert resp.status_code == 403
+
+    resp2 = client.get(f"/api/inventory/items/{item1}/graph", headers=h2)
+    assert resp2.status_code == 403
diff --git a/backend/app/tests/test_resource_shares.py b/backend/app/tests/test_resource_shares.py
new file mode 100644
index 0000000000000000000000000000000000000000..f579dc594cd8f0ae10c34f75ebef9ffde7d21ec5
--- /dev/null
+++ b/backend/app/tests/test_resource_shares.py
@@ -0,0 +1,34 @@
+from .conftest import client
+
+
+def get_headers(client, email):
+    resp = client.post("/api/auth/register", json={"email": email, "password": "secret"})
+    token = resp.json()["access_token"]
+    return {"Authorization": f"Bearer {token}"}
+
+
+def test_resource_share_flow(client):
+    h1 = get_headers(client, "share1@example.com")
+    h2 = get_headers(client, "share2@example.com")
+
+    lab1 = client.post("/api/labs", json={"name": "LabA"}, headers=h1).json()
+    lab2 = client.post("/api/labs", json={"name": "LabB"}, headers=h2).json()
+
+    res = client.post("/api/schedule/resources", json={"name": "Scope"}, headers=h1)
+    assert res.status_code == 200
+    resource_id = res.json()["id"]
+
+    share = client.post(
+        "/api/resource-shares",
+        json={"resource_id": resource_id, "to_lab": lab2["id"]},
+        headers=h1,
+    )
+    assert share.status_code == 200
+    share_id = share.json()["id"]
+
+    lst = client.get("/api/resource-shares", headers=h2).json()
+    assert any(s["id"] == share_id for s in lst)
+
+    acc = client.post(f"/api/resource-shares/{share_id}/accept", headers=h2)
+    assert acc.status_code == 200
+    assert acc.json()["status"] == "accepted"
diff --git a/backend/app/tests/test_schedule.py b/backend/app/tests/test_schedule.py
new file mode 100644
index 0000000000000000000000000000000000000000..213cbe756799f40cf95a41b2747c7621fa3daaef
--- /dev/null
+++ b/backend/app/tests/test_schedule.py
@@ -0,0 +1,52 @@
+import uuid
+from .conftest import client
+
+
+def get_headers(client):
+    resp = client.post(
+        "/api/auth/register",
+        json={"email": f"{uuid.uuid4()}@ex.com", "password": "secret"},
+    )
+    return {"Authorization": f"Bearer {resp.json()['access_token']}"}
+
+
+def test_booking_conflict(client):
+    headers = get_headers(client)
+    res = client.post(
+        "/api/schedule/resources",
+        json={"name": "Microscope"},
+        headers=headers,
+    )
+    assert res.status_code == 200
+    resource_id = res.json()["id"]
+
+    b1 = client.post(
+        "/api/schedule/bookings",
+        json={
+            "resource_id": resource_id,
+            "start_time": "2025-07-02T10:00:00",
+            "end_time": "2025-07-02T11:00:00",
+        },
+        headers=headers,
+    )
+    assert b1.status_code == 200
+
+    conflict = client.post(
+        "/api/schedule/bookings",
+        json={
+            "resource_id": resource_id,
+            "start_time": "2025-07-02T10:30:00",
+            "end_time": "2025-07-02T11:30:00",
+        },
+        headers=headers,
+    )
+    assert conflict.status_code == 400
+
+    list_resp = client.get(
+        "/api/schedule/bookings",
+        params={"resource_id": resource_id},
+        headers=headers,
+    )
+    assert list_resp.status_code == 200
+    data = list_resp.json()
+    assert len(data) == 1
diff --git a/backend/app/tests/test_search.py b/backend/app/tests/test_search.py
new file mode 100644
index 0000000000000000000000000000000000000000..a512ca020fcea8beaafabb4e03ae4ce5a9390f30
--- /dev/null
+++ b/backend/app/tests/test_search.py
@@ -0,0 +1,32 @@
+import uuid
+from .conftest import client
+
+
+def auth_headers(client):
+    resp = client.post(
+        "/api/auth/register",
+        json={"email": f"search{uuid.uuid4()}@example.com", "password": "secret"},
+    )
+    token = resp.json()["access_token"]
+    return {"Authorization": f"Bearer {token}"}
+
+
+def test_search_items(client):
+    headers = auth_headers(client)
+    client.post(
+        "/api/inventory/items",
+        json={"item_type": "plasmid", "name": "GFP Vector"},
+        headers=headers,
+    )
+    client.post(
+        "/api/inventory/items",
+        json={"item_type": "plasmid", "name": "RFP Vector"},
+        headers=headers,
+    )
+
+    resp = client.get("/api/search/items", params={"q": "GFP"}, headers=headers)
+    assert resp.status_code == 200
+    data = resp.json()
+    assert len(data) == 1
+    assert data[0]["name"] == "GFP Vector"
+
diff --git a/backend/app/tests/test_security.py b/backend/app/tests/test_security.py
new file mode 100644
index 0000000000000000000000000000000000000000..d112c0851d76a18a3a9a8d6ee46a3f22418cae38
--- /dev/null
+++ b/backend/app/tests/test_security.py
@@ -0,0 +1,26 @@
+from app.main import app
+from app.auth import get_current_user
+
+PUBLIC_PATHS = {
+    "/api/auth/login",
+    "/api/auth/register",
+    "/api/auth/request-password-reset",
+    "/api/auth/reset-password",
+    "/metrics",
+    "/api/marketplace/listings",
+    "/api/services/listings",
+    "/api/protocols/public",
+}
+
+
+def test_all_routes_protected():
+    for route in app.routes:
+        path = getattr(route, 'path', '')
+        if not path.startswith('/api'):
+            continue
+        if path in PUBLIC_PATHS:
+            continue
+        if not hasattr(route, 'dependant'):
+            continue
+        deps = [d.call for d in route.dependant.dependencies]
+        assert get_current_user in deps, f"{path} missing authentication"
diff --git a/backend/app/tests/test_sequence.py b/backend/app/tests/test_sequence.py
new file mode 100644
index 0000000000000000000000000000000000000000..3da7b2839e492ef7e6bb4961e3d520ec8a147f38
--- /dev/null
+++ b/backend/app/tests/test_sequence.py
@@ -0,0 +1,128 @@
+from .conftest import client
+import uuid
+
+
+def auth_headers(client):
+    resp = client.post(
+        "/api/auth/register",
+        json={"email": f"seq{uuid.uuid4()}@example.com", "password": "secret"},
+    )
+    token = resp.json()["access_token"]
+    return {"Authorization": f"Bearer {token}"}
+
+
+def test_analyze_fasta(client):
+    headers = auth_headers(client)
+    fasta = b">seq1\nATGCGC\n>seq2\nAATT\n"
+    resp = client.post(
+        "/api/sequence/analyze",
+        data={"format": "fasta"},
+        files={"upload": ("test.fasta", fasta, "text/plain")},
+        headers=headers,
+    )
+    assert resp.status_code == 200
+    data = resp.json()
+    assert len(data) == 2
+    assert data[0]["id"] == "seq1"
+    assert data[0]["length"] == 6
+
+
+def test_sequence_job(client):
+    headers = auth_headers(client)
+    fasta = b">seq1\nATGC\n"
+    resp = client.post(
+        "/api/sequence/jobs",
+        data={"format": "fasta"},
+        files={"upload": ("test.fasta", fasta, "text/plain")},
+        headers=headers,
+    )
+    assert resp.status_code == 200
+    job_id = resp.json()["id"]
+    list_resp = client.get("/api/sequence/jobs", headers=headers)
+    assert list_resp.status_code == 200
+    jobs = list_resp.json()
+    assert any(j["id"] == job_id for j in jobs)
+    job_resp = client.get(f"/api/sequence/jobs/{job_id}", headers=headers)
+    assert job_resp.status_code == 200
+    job_data = job_resp.json()
+    assert job_data["status"] == "completed"
+    assert len(job_data["result"]) == 1
+
+
+
+def test_sequence_alignment(client):
+    headers = auth_headers(client)
+    payload = {"seq1": "ACTG", "seq2": "ACGG", "mode": "global"}
+    resp = client.post("/api/sequence/align", json=payload, headers=headers)
+    assert resp.status_code == 200
+    data = resp.json()
+    assert "aligned_seq1" in data and "aligned_seq2" in data
+    assert data["score"] > 0
+
+
+def test_blast_search(client):
+    headers = auth_headers(client)
+    payload = {"query": "ACTGACTG", "subject": "ACTTACTG"}
+    resp = client.post("/api/sequence/blast", json=payload, headers=headers)
+    assert resp.status_code == 200
+    data = resp.json()
+    assert data["score"] > 0
+    assert data["identity"] > 0
+
+
+def test_primer_design(client):
+    headers = auth_headers(client)
+    payload = {"sequence": "ATGC" * 30, "size": 10}
+    resp = client.post("/api/sequence/primers", json=payload, headers=headers)
+    assert resp.status_code == 200
+    data = resp.json()
+    assert len(data["forward"]["sequence"]) == 10
+    assert len(data["reverse"]["sequence"]) == 10
+
+
+def test_restriction_map(client):
+    headers = auth_headers(client)
+    payload = {"sequence": "GAATTCGAATTC", "enzymes": ["EcoRI"]}
+    resp = client.post("/api/sequence/restriction", json=payload, headers=headers)
+    assert resp.status_code == 200
+    data = resp.json()["map"]
+    assert "EcoRI" in data
+    assert data["EcoRI"] == [2, 8]
+
+
+def test_annotation(client):
+    headers = auth_headers(client)
+    gb = b"""LOCUS       test        40 bp DNA     linear   01-JAN-1980\nFEATURES             Location/Qualifiers\n     source          1..40\n     CDS             1..30\n                     /gene=\"x\"\nORIGIN\n        1 atggccattg taatgggccg ctgctgaaaa aa\n//\n"""
+    resp = client.post(
+        "/api/sequence/annotate",
+        data={"format": "genbank"},
+        files={"upload": ("test.gb", gb, "text/plain")},
+        headers=headers,
+    )
+    assert resp.status_code == 200
+    feats = resp.json()
+    assert any(f["type"] == "CDS" for f in feats)
+
+
+from pathlib import Path
+
+
+def _ab1_bytes() -> bytes:
+    import gzip
+    path = Path(__file__).parent / "data" / "sample.ab1.gz"
+    with gzip.open(path, "rb") as fh:
+        return fh.read()
+
+
+def test_chromatogram(client):
+    headers = auth_headers(client)
+    data = _ab1_bytes()
+    resp = client.post(
+        "/api/sequence/chromatogram",
+        files={"upload": ("test.ab1", data, "application/octet-stream")},
+        headers=headers,
+    )
+    assert resp.status_code == 200
+    result = resp.json()
+    assert len(result["sequence"]) > 10
+    assert all(len(result["traces"][b]) > 0 for b in ["A", "C", "G", "T"])
diff --git a/backend/app/tests/test_services.py b/backend/app/tests/test_services.py
new file mode 100644
index 0000000000000000000000000000000000000000..2bc587c38fc6bf50b16bdd96aeb8c5d05f3c2239
--- /dev/null
+++ b/backend/app/tests/test_services.py
@@ -0,0 +1,51 @@
+from .conftest import client
+
+
+def auth(client, email):
+    resp = client.post("/api/auth/register", json={"email": email, "password": "secret"})
+    return {"Authorization": f"Bearer {resp.json()['access_token']}"}
+
+
+def test_service_marketplace_flow(client):
+    provider_h = auth(client, "prov@example.com")
+    listing = client.post(
+        "/api/services/listings",
+        json={"name": "Sequencing", "description": "Sanger sequencing"},
+        headers=provider_h,
+    )
+    assert listing.status_code == 200
+    l_id = listing.json()["id"]
+
+    listings = client.get("/api/services/listings").json()
+    assert any(l["id"] == l_id for l in listings)
+
+    requester_h = auth(client, "req@example.com")
+    req = client.post(
+        f"/api/services/listings/{l_id}/requests",
+        json={"message": "Please sequence my plasmid"},
+        headers=requester_h,
+    )
+    assert req.status_code == 200
+    r_id = req.json()["id"]
+
+    acc = client.post(f"/api/services/requests/{r_id}/accept", headers=provider_h)
+    assert acc.status_code == 200
+    assert acc.json()["status"] == "accepted"
+
+    # provider uploads result
+    deliver = client.post(
+        f"/api/services/requests/{r_id}/deliver",
+        headers=provider_h,
+        files={"upload": ("result.txt", b"done")},
+    )
+    assert deliver.status_code == 200
+    assert deliver.json()["status"] == "completed"
+    assert deliver.json()["result_file_id"] is not None
+
+    # requester confirms payment
+    paid = client.post(
+        f"/api/services/requests/{r_id}/confirm-payment",
+        headers=requester_h,
+    )
+    assert paid.status_code == 200
+    assert paid.json()["payment_status"] == "paid"
diff --git a/backend/app/tests/test_teams.py b/backend/app/tests/test_teams.py
new file mode 100644
index 0000000000000000000000000000000000000000..6f5033a461587af4ea73222774c18db8a0b37e22
--- /dev/null
+++ b/backend/app/tests/test_teams.py
@@ -0,0 +1,44 @@
+from .conftest import client
+
+
+import uuid
+
+
+def get_headers(client, email=None):
+    email = email or f"user{uuid.uuid4()}@example.com"
+    resp = client.post(
+        "/api/auth/register", json={"email": email, "password": "secret"}
+    )
+    token = resp.json()["access_token"]
+    return {"Authorization": f"Bearer {token}"}
+
+
+def test_create_and_add_member(client):
+    headers = get_headers(client)
+    resp = client.post("/api/teams/", json={"name": "TeamA"}, headers=headers)
+    assert resp.status_code == 200
+    team_id = resp.json()["id"]
+
+    get_headers(client, "member@example.com")
+    add_resp = client.post(
+        f"/api/teams/{team_id}/members",
+        json={"email": "member@example.com"},
+        headers=headers,
+    )
+    assert add_resp.status_code == 200
+    data = add_resp.json()
+    assert data["user"]["email"] == "member@example.com"
+
+
+def test_non_owner_cannot_add_member(client):
+    owner_headers = get_headers(client)
+    resp = client.post("/api/teams/", json={"name": "T"}, headers=owner_headers)
+    team_id = resp.json()["id"]
+
+    member_headers = get_headers(client)
+    fail = client.post(
+        f"/api/teams/{team_id}/members",
+        json={"email": "x@example.com"},
+        headers=member_headers,
+    )
+    assert fail.status_code == 403
diff --git a/backend/app/tests/test_tools.py b/backend/app/tests/test_tools.py
new file mode 100644
index 0000000000000000000000000000000000000000..743cfb053b1d72ec74252012c687ecafa662e081
--- /dev/null
+++ b/backend/app/tests/test_tools.py
@@ -0,0 +1,35 @@
+import uuid
+from .conftest import client
+
+
+def get_headers(client):
+    resp = client.post(
+        "/api/auth/register", json={"email": f"{uuid.uuid4()}@ex.com", "password": "secret"}
+    )
+    return {"Authorization": f"Bearer {resp.json()['access_token']}"}
+
+
+def test_tool_run(client):
+    headers = get_headers(client)
+    code = "def run(item):\n    return {'name': item['name']}"
+    tool = client.post(
+        "/api/tools",
+        json={"name": "Echo", "code": code},
+        headers=headers,
+    )
+    assert tool.status_code == 200
+    tool_id = tool.json()["id"]
+
+    item = client.post(
+        "/api/inventory/items",
+        json={"item_type": "sample", "name": "ToolItem"},
+        headers=headers,
+    ).json()
+
+    run_resp = client.post(
+        f"/api/tools/{tool_id}/run",
+        json={"item_id": item["id"]},
+        headers=headers,
+    )
+    assert run_resp.status_code == 200
+    assert run_resp.json()["result"]["name"] == "ToolItem"
diff --git a/backend/app/tests/test_troubleshooting.py b/backend/app/tests/test_troubleshooting.py
new file mode 100644
index 0000000000000000000000000000000000000000..286232fd4845213aa15469e49cb46e0e88531b2b
--- /dev/null
+++ b/backend/app/tests/test_troubleshooting.py
@@ -0,0 +1,38 @@
+import uuid
+from .conftest import client
+
+
+def get_headers(client):
+    resp = client.post(
+        "/api/auth/register",
+        json={"email": f"{uuid.uuid4()}@ex.com", "password": "secret"},
+    )
+    return {"Authorization": f"Bearer {resp.json()['access_token']}"}
+
+
+def test_troubleshooting_flow(client):
+    headers = get_headers(client)
+    create = client.post(
+        "/api/troubleshooting/articles",
+        json={"title": "PCR Issues", "category": "PCR", "content": "Check MgCl2"},
+        headers=headers,
+    )
+    assert create.status_code == 200
+    art_id = create.json()["id"]
+
+    list_resp = client.get("/api/troubleshooting/articles", headers=headers)
+    assert any(a["id"] == art_id for a in list_resp.json())
+
+    upd = client.put(
+        f"/api/troubleshooting/articles/{art_id}",
+        json={"content": "Adjust MgCl2 concentration"},
+        headers=headers,
+    )
+    assert upd.status_code == 200
+    assert upd.json()["content"] == "Adjust MgCl2 concentration"
+
+    mark = client.post(
+        f"/api/troubleshooting/articles/{art_id}/success", headers=headers
+    )
+    assert mark.status_code == 200
+    assert mark.json()["success_count"] == 1
diff --git a/backend/app/tests/test_users.py b/backend/app/tests/test_users.py
new file mode 100644
index 0000000000000000000000000000000000000000..eebb160556f67440b2d6dfeecb38815961c3f30d
--- /dev/null
+++ b/backend/app/tests/test_users.py
@@ -0,0 +1,23 @@
+from .conftest import client
+
+
+def get_auth_headers(client, email="user@example.com"):
+    resp = client.post("/api/auth/register", json={"email": email, "password": "secret"})
+    token = resp.json()["access_token"]
+    return {"Authorization": f"Bearer {token}"}
+
+
+def test_get_and_update_profile(client):
+    headers = get_auth_headers(client)
+    resp = client.get("/api/users/me", headers=headers)
+    assert resp.status_code == 200
+    data = resp.json()
+    assert data["email"] == "user@example.com"
+
+    update = {"full_name": "Tester", "phone_number": "123", "orcid_id": "0000-0001"}
+    up_resp = client.put("/api/users/me", json=update, headers=headers)
+    assert up_resp.status_code == 200
+    updated = up_resp.json()
+    assert updated["full_name"] == "Tester"
+    assert updated["phone_number"] == "123"
+    assert updated["orcid_id"] == "0000-0001"
diff --git a/backend/app/tests/test_websocket.py b/backend/app/tests/test_websocket.py
new file mode 100644
index 0000000000000000000000000000000000000000..609e6f54768ca5d9aae6d8722b274620e8512e67
--- /dev/null
+++ b/backend/app/tests/test_websocket.py
@@ -0,0 +1,26 @@
+import json
+import uuid
+from .conftest import client
+
+
+def get_headers(client, email="ws@example.com"):
+    resp = client.post("/api/auth/register", json={"email": email, "password": "secret"})
+    token = resp.json()["access_token"]
+    return {"Authorization": f"Bearer {token}"}
+
+
+def test_websocket_receives_item_events(client):
+    headers = get_headers(client)
+    team_resp = client.post("/api/teams/", json={"name": "WSTeam"}, headers=headers)
+    team_id = team_resp.json()["id"]
+
+    with client.websocket_connect(f"/ws/{team_id}") as websocket:
+        item_resp = client.post(
+            "/api/inventory/items",
+            json={"item_type": "sample", "name": "WSItem", "team_id": team_id},
+            headers=headers,
+        )
+        data = websocket.receive_text()
+        msg = json.loads(data)
+        assert msg["type"] == "item_created"
+        assert msg["id"] == item_resp.json()["id"]
diff --git a/backend/app/tests/test_workflows.py b/backend/app/tests/test_workflows.py
new file mode 100644
index 0000000000000000000000000000000000000000..9b6d6fb34a7aef5e3860fea94b2ce854811769fc
--- /dev/null
+++ b/backend/app/tests/test_workflows.py
@@ -0,0 +1,64 @@
+import uuid
+from .conftest import client
+
+
+def get_headers(client):
+    resp = client.post(
+        "/api/auth/register",
+        json={"email": f"{uuid.uuid4()}@ex.com", "password": "secret"},
+    )
+    return {"Authorization": f"Bearer {resp.json()['access_token']}"}
+
+
+def test_workflow_run(client):
+    headers = get_headers(client)
+    code = "def run(item):\n    return {'name': item['name']}"
+    tool = client.post("/api/tools", json={"name": "Echo", "code": code}, headers=headers).json()
+    wf = client.post(
+        "/api/workflows",
+        json={"name": "WF", "steps": [{"type": "tool", "id": tool['id']}]},
+        headers=headers,
+    ).json()
+    item = client.post(
+        "/api/inventory/items",
+        json={"item_type": "sample", "name": "Item1"},
+        headers=headers,
+    ).json()
+    exec_resp = client.post(
+        "/api/workflows/run",
+        json={"workflow_id": wf['id'], "item_id": item['id']},
+        headers=headers,
+    )
+    assert exec_resp.status_code == 200
+    data = exec_resp.json()
+    assert data["status"] == "completed"
+    assert data["result"][0]["name"] == "Item1"
+
+
+def test_workflow_condition(client):
+    headers = get_headers(client)
+    code = "def run(item):\n    return {'val': 1}"
+    tool = client.post("/api/tools", json={"name": "Tool", "code": code}, headers=headers).json()
+    wf = client.post(
+        "/api/workflows",
+        json={
+            "name": "WF2",
+            "steps": [
+                {"type": "tool", "id": tool["id"]},
+                {"type": "tool", "id": tool["id"], "condition": "results[0]['val'] > 0"},
+            ],
+        },
+        headers=headers,
+    ).json()
+    item = client.post(
+        "/api/inventory/items",
+        json={"item_type": "sample", "name": "X"},
+        headers=headers,
+    ).json()
+    resp = client.post(
+        "/api/workflows/run",
+        json={"workflow_id": wf["id"], "item_id": item["id"]},
+        headers=headers,
+    )
+    assert resp.status_code == 200
+    assert len(resp.json()["result"]) == 2
diff --git a/backend/app/tools.py b/backend/app/tools.py
new file mode 100644
index 0000000000000000000000000000000000000000..8939d7a43e20e84354ee65003b471081f2773a50
--- /dev/null
+++ b/backend/app/tools.py
@@ -0,0 +1,10 @@
+import types
+from typing import Dict, Any
+
+
+def run_tool(code: str, item: Dict[str, Any]) -> Dict[str, Any]:
+    ns: Dict[str, Any] = {}
+    exec(code, {}, ns)
+    if "run" not in ns or not isinstance(ns["run"], types.FunctionType):
+        raise ValueError("Tool code must define a 'run' function")
+    return ns["run"](item)
diff --git a/backend/benchmarks/locustfile.py b/backend/benchmarks/locustfile.py
new file mode 100644
index 0000000000000000000000000000000000000000..a09ecd6486d242b97895661959be00ec1ae19dfc
--- /dev/null
+++ b/backend/benchmarks/locustfile.py
@@ -0,0 +1,21 @@
+from locust import HttpUser, task, between
+
+class LabUser(HttpUser):
+    wait_time = between(1, 3)
+
+    def on_start(self):
+        payload = {"email": "load@lab.com", "password": "password"}
+        r = self.client.post("/api/auth/register", json=payload)
+        if r.status_code != 200:
+            r = self.client.post("/api/auth/login", data={"username": payload["email"], "password": payload["password"]})
+        token = r.json().get("access_token")
+        self.headers = {"Authorization": f"Bearer {token}"}
+
+    @task(3)
+    def list_inventory(self):
+        self.client.get("/api/inventory/items", headers=self.headers)
+
+    @task(1)
+    def create_item(self):
+        data = {"name": "bench item", "type": "sample"}
+        self.client.post("/api/inventory/items", json=data, headers=self.headers)
diff --git a/backend/requirements.txt b/backend/requirements.txt
new file mode 100644
index 0000000000000000000000000000000000000000..f53cb7f32391ae6f709aaabbd2a4ce74fdb1ab78
--- /dev/null
+++ b/backend/requirements.txt
@@ -0,0 +1,33 @@
+fastapi
+uvicorn
+sqlalchemy
+alembic
+psycopg2-binary
+pydantic[email]
+python-jose[cryptography]
+passlib[bcrypt]
+python-multipart
+minio
+pytest
+httpx
+redis
+biopython
+fakeredis
+pytest-asyncio
+celery
+primer3-py
+elasticsearch
+python-barcode[images]
+pyotp
+requests
+fpdf2
+locust
+prometheus-client
+sentry-sdk
+numpy
+pandas
+scipy
+scikit-learn
+matplotlib
+seaborn
+slowapi
diff --git a/devops/prometheus.yml b/devops/prometheus.yml
new file mode 100644
index 0000000000000000000000000000000000000000..13d7cfafe77d147a3ca28950c7eaf0295d84d1f4
--- /dev/null
+++ b/devops/prometheus.yml
@@ -0,0 +1,6 @@
+global:
+  scrape_interval: 15s
+scrape_configs:
+  - job_name: 'backend'
+    static_configs:
+      - targets: ['backend:8000']
diff --git a/docker-compose.yml b/docker-compose.yml
new file mode 100644
index 0000000000000000000000000000000000000000..d393a084256b55f18d24f565e6e925343ea8ee8f
--- /dev/null
+++ b/docker-compose.yml
@@ -0,0 +1,57 @@
+version: '3.8'
+services:
+  db:
+    image: postgres:15
+    environment:
+      POSTGRES_DB: labdb
+      POSTGRES_USER: postgres
+      POSTGRES_PASSWORD: postgres
+    volumes:
+      - pgdata:/var/lib/postgresql/data
+  redis:
+    image: redis:7-alpine
+  minio:
+    image: minio/minio
+    command: server /data
+    environment:
+      MINIO_ROOT_USER: minio
+      MINIO_ROOT_PASSWORD: minio123
+    volumes:
+      - minio-data:/data
+  backend:
+    build: ./backend
+    environment:
+      DATABASE_URL: postgresql://postgres:postgres@db:5432/labdb
+      REDIS_URL: redis://redis:6379/0
+      MINIO_ENDPOINT: http://minio:9000
+      MINIO_ACCESS_KEY: minio
+      MINIO_SECRET_KEY: minio123
+    ports:
+      - "8000:8000"
+    depends_on:
+      - db
+      - redis
+      - minio
+  frontend:
+    build: ./frontend
+    ports:
+      - "3000:3000"
+    depends_on:
+      - backend
+  prometheus:
+    image: prom/prometheus
+    volumes:
+      - ./devops/prometheus.yml:/etc/prometheus/prometheus.yml
+    ports:
+      - "9090:9090"
+    depends_on:
+      - backend
+  grafana:
+    image: grafana/grafana
+    ports:
+      - "3001:3000"
+    depends_on:
+      - prometheus
+volumes:
+  pgdata:
+  minio-data:
diff --git a/frontend/Dockerfile b/frontend/Dockerfile
new file mode 100644
index 0000000000000000000000000000000000000000..56e997083d77c627de70eed69e00179e6f98eb57
--- /dev/null
+++ b/frontend/Dockerfile
@@ -0,0 +1,8 @@
+FROM node:20-alpine
+WORKDIR /app
+COPY package.json package-lock.json* ./
+RUN npm install --production
+COPY . .
+RUN npm run build
+EXPOSE 3000
+CMD ["npm", "start"]
diff --git a/frontend/README.md b/frontend/README.md
new file mode 100644
index 0000000000000000000000000000000000000000..ad7d8f802df60dbabb7813cca61c27a495c72e69
--- /dev/null
+++ b/frontend/README.md
@@ -0,0 +1,24 @@
+# BioLabs Frontend
+
+This is an early scaffold for the Next.js application. It was generated manually to avoid shipping node modules.
+
+## Getting Started
+
+```bash
+npm install
+npm run dev
+```
+
+The app now includes simple login and registration pages along with an inventory screen. Logged in users can create new items using a dynamically generated form based on field definitions returned by the backend. Tokens are stored in `localStorage` and used for authenticated API requests.
+You can also manage custom field definitions through the **Fields** page. New fields can be created for any entity type and will immediately appear in the inventory creation form.
+Items listed on the inventory page can now be edited or deleted. Selecting **Edit** fills the form with the item's current data so you can update it on the fly.
+Additional features include item detail pages where you can upload files to an item and visualize its relationships. Files are stored via the backend API and listed alongside a simple D3-based graph of related items.
+Real-time updates are streamed over WebSockets. When items are created, updated, or deleted, connected clients receive event messages automatically.
+You can also browse and contribute to a knowledge base of troubleshooting articles via the **Troubleshooting** page.
+General lab tips can be shared in the new **Knowledge Base** page which lists all community articles.
+Templates for standard lab procedures can be created and executed through the **Protocols** page.
+Notebook entries can be managed from the **Notebook** page.
+Sequence annotation files (GenBank) can be uploaded on the **Sequence** page to
+view parsed features in a table. Interact with the lab buddy AI assistant from
+the **Assistant** page to get project and inventory summaries.
+Use the **Search** page to quickly locate items by name.
diff --git a/frontend/app/analytics/page.tsx b/frontend/app/analytics/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..16bad94a0dc8bfa19264abcfe3703c210003ffb9
--- /dev/null
+++ b/frontend/app/analytics/page.tsx
@@ -0,0 +1,79 @@
+'use client'
+import {
+  useAnalytics,
+  useTrendingProtocols,
+  useTrendingArticles,
+  useTrendingItems,
+  useTrendingThreads,
+} from '../hooks/useAnalytics'
+import BarChart from '../components/BarChart'
+
+export default function AnalyticsPage() {
+  const { data, isLoading } = useAnalytics()
+  const { data: protocols } = useTrendingProtocols()
+  const { data: articles } = useTrendingArticles()
+  const { data: items } = useTrendingItems()
+  const { data: threads } = useTrendingThreads()
+  if (isLoading || !data) return <div>Loading...</div>
+  return (
+    <div>
+      <h1 className="text-xl font-bold mb-4">Inventory Analytics</h1>
+      <BarChart data={data} />
+      <ul className="mt-4">
+        {data.map((d) => (
+          <li key={d.item_type}>
+            {d.item_type}: {d.count}
+          </li>
+        ))}
+      </ul>
+      {protocols && (
+        <div className="mt-6">
+          <h2 className="font-semibold">Trending Protocols</h2>
+          <ul>
+            {protocols.map((p) => (
+              <li key={p.template_id}>
+                {p.template_name}: {p.count}
+              </li>
+            ))}
+          </ul>
+        </div>
+      )}
+      {articles && (
+        <div className="mt-6">
+          <h2 className="font-semibold">Trending Articles</h2>
+          <ul>
+            {articles.map((a) => (
+              <li key={a.article_id}>
+                {a.title}: {a.count}
+              </li>
+            ))}
+          </ul>
+        </div>
+      )}
+      {items && (
+        <div className="mt-6">
+          <h2 className="font-semibold">Trending Items</h2>
+          <ul>
+            {items.map((i) => (
+              <li key={i.item_id}>
+                {i.name}: {i.count}
+              </li>
+            ))}
+          </ul>
+        </div>
+      )}
+      {threads && (
+        <div className="mt-6">
+          <h2 className="font-semibold">Trending Threads</h2>
+          <ul>
+            {threads.map((t) => (
+              <li key={t.thread_id}>
+                {t.title}: {t.count}
+              </li>
+            ))}
+          </ul>
+        </div>
+      )}
+    </div>
+  )
+}
diff --git a/frontend/app/api/client.ts b/frontend/app/api/client.ts
new file mode 100644
index 0000000000000000000000000000000000000000..f9f39bcb7fdcef1a50ddc99f833ac60ac2c60e5f
--- /dev/null
+++ b/frontend/app/api/client.ts
@@ -0,0 +1,15 @@
+import axios from 'axios'
+
+const api = axios.create({
+  baseURL: process.env.NEXT_PUBLIC_API_URL || 'http://localhost:8000',
+})
+
+api.interceptors.request.use((config) => {
+  if (typeof window !== 'undefined') {
+    const token = localStorage.getItem('token')
+    if (token) config.headers.Authorization = `Bearer ${token}`
+  }
+  return config
+})
+
+export default api
diff --git a/frontend/app/assistant/page.tsx b/frontend/app/assistant/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..5a8297a07e7633c381df6ac72fa03d86fe9d1f75
--- /dev/null
+++ b/frontend/app/assistant/page.tsx
@@ -0,0 +1,41 @@
+'use client'
+import { useState } from 'react'
+import { useAssistantHistory, useAskAssistant } from '../hooks/useAssistant'
+
+export default function AssistantPage() {
+  const { data: history } = useAssistantHistory()
+  const ask = useAskAssistant()
+  const [question, setQuestion] = useState('')
+
+  const submit = () => {
+    if (!question) return
+    ask.mutate(question)
+    setQuestion('')
+  }
+
+  return (
+    <div className="space-y-4">
+      <h1 className="text-xl font-bold">Lab Buddy Assistant</h1>
+      <ul className="space-y-2 border p-2 max-h-80 overflow-y-auto">
+        {history?.map((m) => (
+          <li key={m.id} className={m.is_user ? 'text-right' : 'text-left'}>
+            <span className={m.is_user ? 'text-blue-700' : 'text-green-700'}>
+              {m.message}
+            </span>
+          </li>
+        ))}
+      </ul>
+      <div className="flex gap-2">
+        <input
+          className="border px-2 py-1 flex-grow"
+          value={question}
+          onChange={(e) => setQuestion(e.target.value)}
+          placeholder="Ask a question"
+        />
+        <button onClick={submit} className="bg-blue-600 text-white px-3">
+          Send
+        </button>
+      </div>
+    </div>
+  )
+}
diff --git a/frontend/app/calendar/page.tsx b/frontend/app/calendar/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..b37028cc4c9486147aac4742a93860be2a7be7e7
--- /dev/null
+++ b/frontend/app/calendar/page.tsx
@@ -0,0 +1,82 @@
+'use client'
+import { useState } from 'react'
+import {
+  useCalendarEvents,
+  useCreateEvent,
+  useUpdateEvent,
+  useDeleteEvent,
+} from '../hooks/useCalendar'
+
+export default function CalendarPage() {
+  const { data: events } = useCalendarEvents()
+  const createEvent = useCreateEvent()
+  const updateEvent = useUpdateEvent()
+  const deleteEvent = useDeleteEvent()
+
+  const [title, setTitle] = useState('')
+  const [start, setStart] = useState('')
+  const [end, setEnd] = useState('')
+
+  const submit = () => {
+    if (!title || !start || !end) return
+    createEvent.mutate({ title, start_time: start, end_time: end })
+    setTitle('')
+    setStart('')
+    setEnd('')
+  }
+
+  return (
+    <div>
+      <h1 className="text-xl mb-4">Calendar</h1>
+      <div className="space-x-2 mb-4">
+        <input
+          className="border p-1"
+          placeholder="Title"
+          value={title}
+          onChange={(e) => setTitle(e.target.value)}
+        />
+        <input
+          type="datetime-local"
+          className="border p-1"
+          value={start}
+          onChange={(e) => setStart(e.target.value)}
+        />
+        <input
+          type="datetime-local"
+          className="border p-1"
+          value={end}
+          onChange={(e) => setEnd(e.target.value)}
+        />
+        <button className="bg-blue-500 text-white px-2" onClick={submit}>
+          Add
+        </button>
+      </div>
+      <ul className="space-y-2">
+        {events?.map((ev) => (
+          <li key={ev.id} className="border p-2 flex justify-between">
+            <span>
+              {ev.title} - {new Date(ev.start_time).toLocaleString()} to{' '}
+              {new Date(ev.end_time).toLocaleString()}
+            </span>
+            <div className="space-x-2 text-sm">
+              <button
+                className="text-blue-600"
+                onClick={() =>
+                  updateEvent.mutate({ id: ev.id, data: { title: ev.title + '!' } })
+                }
+              >
+                Bump Title
+              </button>
+              <button
+                className="text-red-600"
+                onClick={() => deleteEvent.mutate(ev.id)}
+              >
+                Delete
+              </button>
+            </div>
+          </li>
+        ))}
+      </ul>
+    </div>
+  )
+}
diff --git a/frontend/app/comments/page.tsx b/frontend/app/comments/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..37f2e465a463eda1b01cf822fa8a52ce5c574db7
--- /dev/null
+++ b/frontend/app/comments/page.tsx
@@ -0,0 +1,68 @@
+'use client'
+import { useState } from 'react'
+import DynamicForm from '../components/DynamicForm'
+import {
+  useComments,
+  useCreateComment,
+  useUpdateComment,
+  useDeleteComment,
+} from '../hooks/useComments'
+import type { Comment } from '../types'
+
+export default function CommentsPage() {
+  const { data: comments } = useComments()
+  const create = useCreateComment()
+  const update = useUpdateComment()
+  const remove = useDeleteComment()
+  const [editing, setEditing] = useState<Comment | null>(null)
+
+  const fields = [
+    {
+      id: 'content',
+      entity_type: 'comment',
+      field_key: 'content',
+      field_label: 'Content',
+      field_type: 'text',
+      is_required: true,
+    },
+  ] as any
+
+  const handleSubmit = (data: any) => {
+    if (editing) {
+      update.mutate({ id: editing.id, data })
+      setEditing(null)
+    } else {
+      create.mutate(data)
+    }
+  }
+
+  return (
+    <div>
+      <h1 className="text-xl mb-4">Comments</h1>
+      <DynamicForm fields={fields} onSubmit={handleSubmit} defaultValues={editing ? { content: editing.content } : {}} />
+      {editing && (
+        <button className="text-sm text-gray-600 mt-2" onClick={() => setEditing(null)}>
+          Cancel Edit
+        </button>
+      )}
+      <h2 className="text-lg mt-6 mb-2">All Comments</h2>
+      <ul className="space-y-2">
+        {comments?.map((c) => (
+          <li key={c.id} className="border p-2 space-y-1">
+            <div className="flex justify-between items-center">
+              <span className="font-semibold">{c.content}</span>
+              <div className="space-x-2 text-sm">
+                <button className="text-blue-600" onClick={() => setEditing(c)}>
+                  Edit
+                </button>
+                <button className="text-red-600" onClick={() => remove.mutate(c.id)}>
+                  Delete
+                </button>
+              </div>
+            </div>
+          </li>
+        ))}
+      </ul>
+    </div>
+  )
+}
diff --git a/frontend/app/community/page.tsx b/frontend/app/community/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..60de9b54d6686e951424e17fd89163a012c35c45
--- /dev/null
+++ b/frontend/app/community/page.tsx
@@ -0,0 +1,36 @@
+'use client'
+import { useFeed, useCreatePost } from '../hooks/useCommunity'
+import { useState } from 'react'
+import { useAuthStore } from '../store/useAuth'
+
+export default function CommunityPage() {
+  const { data } = useFeed()
+  const create = useCreatePost()
+  const [text, setText] = useState('')
+  const { token } = useAuthStore()
+  if (!token) return <div>Please login</div>
+  return (
+    <div className="p-4 space-y-4">
+      <h1 className="text-xl font-bold">Community Feed</h1>
+      <form
+        onSubmit={e => {
+          e.preventDefault()
+          create.mutate({ content: text })
+          setText('')
+        }}
+        className="space-x-2"
+      >
+        <input value={text} onChange={e => setText(e.target.value)} className="border px-2" />
+        <button type="submit" className="bg-blue-500 text-white px-3 py-1 rounded">Post</button>
+      </form>
+      <ul className="space-y-2">
+        {data?.map(p => (
+          <li key={p.id} className="border p-2">
+            <span className="text-gray-600 text-sm">{new Date(p.created_at).toLocaleString()}</span>
+            <div>{p.content}</div>
+          </li>
+        ))}
+      </ul>
+    </div>
+  )
+}
diff --git a/frontend/app/compliance/page.tsx b/frontend/app/compliance/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..6ea739073bb3b642375bafedd4f34199bb9658a7
--- /dev/null
+++ b/frontend/app/compliance/page.tsx
@@ -0,0 +1,73 @@
+'use client'
+import { useState } from 'react'
+import {
+  useComplianceRecords,
+  useCreateRecord,
+  useUpdateRecord,
+  useComplianceSummary,
+} from '../hooks/useCompliance'
+
+export default function CompliancePage() {
+  const { data: records } = useComplianceRecords()
+  const createRecord = useCreateRecord()
+  const updateRecord = useUpdateRecord()
+  const { data: summary } = useComplianceSummary()
+  const [type, setType] = useState('safety')
+  const [notes, setNotes] = useState('')
+
+  const submit = () => {
+    createRecord.mutate({ record_type: type, notes })
+    setNotes('')
+  }
+
+  return (
+    <div>
+      <h1 className="text-xl mb-4">Compliance Dashboard</h1>
+      <div className="mb-4 space-x-2">
+        <input
+          className="border p-1"
+          value={type}
+          onChange={(e) => setType(e.target.value)}
+          placeholder="Type"
+        />
+        <input
+          className="border p-1"
+          value={notes}
+          onChange={(e) => setNotes(e.target.value)}
+          placeholder="Notes"
+        />
+        <button className="bg-blue-500 text-white px-2" onClick={submit}>
+          Add
+        </button>
+      </div>
+      <h2 className="text-lg mb-2">Summary</h2>
+      <ul className="mb-4">
+        {summary?.map((s) => (
+          <li key={s.status}>
+            {s.status}: {s.count}
+          </li>
+        ))}
+      </ul>
+      <h2 className="text-lg mb-2">Records</h2>
+      <ul className="space-y-2">
+        {records?.map((r) => (
+          <li key={r.id} className="border p-2 flex justify-between">
+            <span>
+              {r.record_type} - {r.status} {r.notes && <>({r.notes})</>}
+            </span>
+            {r.status !== 'approved' && (
+              <button
+                className="text-sm text-blue-600"
+                onClick={() =>
+                  updateRecord.mutate({ id: r.id, data: { status: 'approved' } })
+                }
+              >
+                Approve
+              </button>
+            )}
+          </li>
+        ))}
+      </ul>
+    </div>
+  )
+}
diff --git a/frontend/app/components/BarChart.tsx b/frontend/app/components/BarChart.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..016b6a6c9d710177a4775a7c5248abc9441cea2c
--- /dev/null
+++ b/frontend/app/components/BarChart.tsx
@@ -0,0 +1,45 @@
+'use client'
+import { useEffect, useRef } from 'react'
+import * as d3 from 'd3'
+import type { ItemTypeCount } from '../types'
+
+export default function BarChart({ data }: { data: ItemTypeCount[] }) {
+  const ref = useRef<SVGSVGElement | null>(null)
+  useEffect(() => {
+    if (!ref.current) return
+    const svg = d3.select(ref.current)
+    svg.selectAll('*').remove()
+    const width = 400
+    const height = 300
+    const margin = { top: 20, right: 20, bottom: 30, left: 40 }
+    const x = d3
+      .scaleBand()
+      .domain(data.map((d) => d.item_type))
+      .range([margin.left, width - margin.right])
+      .padding(0.1)
+    const y = d3
+      .scaleLinear()
+      .domain([0, d3.max(data, (d) => d.count)!])
+      .range([height - margin.bottom, margin.top])
+    svg
+      .append('g')
+      .selectAll('rect')
+      .data(data)
+      .enter()
+      .append('rect')
+      .attr('x', (d) => x(d.item_type)!)
+      .attr('y', (d) => y(d.count))
+      .attr('height', (d) => y(0) - y(d.count))
+      .attr('width', x.bandwidth())
+      .attr('fill', '#3182bd')
+    svg
+      .append('g')
+      .attr('transform', `translate(0,${height - margin.bottom})`)
+      .call(d3.axisBottom(x))
+    svg
+      .append('g')
+      .attr('transform', `translate(${margin.left},0)`)
+      .call(d3.axisLeft(y))
+  }, [data])
+  return <svg ref={ref} width={400} height={300} />
+}
diff --git a/frontend/app/components/ChromatogramPlot.tsx b/frontend/app/components/ChromatogramPlot.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..0bc48df365b235894b8bd2cdd650ce40b978e778
--- /dev/null
+++ b/frontend/app/components/ChromatogramPlot.tsx
@@ -0,0 +1,31 @@
+'use client'
+import { useEffect, useRef } from 'react'
+import * as d3 from 'd3'
+import type { ChromatogramData } from '../types'
+
+export default function ChromatogramPlot({ data, height=200 }: { data: ChromatogramData, height?: number }) {
+  const ref = useRef<SVGSVGElement | null>(null)
+  useEffect(() => {
+    if (!ref.current) return
+    const svg = d3.select(ref.current)
+    svg.selectAll('*').remove()
+    const bases = ['A','C','G','T'] as const
+    const colors: Record<string,string> = {A:'green',C:'blue',G:'black',T:'red'}
+    const maxLen = Math.max(...bases.map(b => data.traces[b].length))
+    const maxVal = Math.max(...bases.flatMap(b => data.traces[b])) || 1
+    const width = maxLen
+    svg.attr('viewBox', `0 0 ${width} ${height}`)
+    bases.forEach(b => {
+      const line = d3.line<number>()
+        .x((_, i) => i)
+        .y(v => height - v / maxVal * height)
+      svg.append('path')
+        .datum(data.traces[b])
+        .attr('fill','none')
+        .attr('stroke', colors[b])
+        .attr('stroke-width', 1)
+        .attr('d', line as any)
+    })
+  }, [data, height])
+  return <svg ref={ref} width="100%" height={height}></svg>
+}
diff --git a/frontend/app/components/DynamicForm.tsx b/frontend/app/components/DynamicForm.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..2ae9da7777e5e4049af433fb54a06c889008845a
--- /dev/null
+++ b/frontend/app/components/DynamicForm.tsx
@@ -0,0 +1,87 @@
+'use client'
+import { useForm } from 'react-hook-form'
+import { zodResolver } from '@hookform/resolvers/zod'
+import * as z from 'zod'
+import type { FieldDefinition } from '../types'
+
+export default function DynamicForm({
+  fields,
+  onSubmit,
+  defaultValues = {},
+}: {
+  fields: FieldDefinition[]
+  onSubmit: (data: any) => void
+  defaultValues?: Record<string, any>
+}) {
+  const shape = fields.reduce((acc, field) => {
+    let fieldSchema: any = z.string()
+    if (field.field_type === 'number') fieldSchema = z.number()
+    if (field.field_type === 'date') fieldSchema = z.coerce.date()
+
+    const rules = field.validation || {}
+    if (field.field_type === 'number') {
+      if (rules.min !== undefined) fieldSchema = fieldSchema.min(rules.min)
+      if (rules.max !== undefined) fieldSchema = fieldSchema.max(rules.max)
+    } else if (field.field_type === 'text') {
+      if (rules.minLength !== undefined)
+        fieldSchema = fieldSchema.min(rules.minLength)
+      if (rules.maxLength !== undefined)
+        fieldSchema = fieldSchema.max(rules.maxLength)
+      if (rules.pattern)
+        fieldSchema = fieldSchema.regex(new RegExp(rules.pattern))
+    }
+
+    if (!field.is_required) fieldSchema = fieldSchema.optional()
+    acc[field.field_key] = fieldSchema
+    return acc
+  }, {} as any)
+
+  const schema = z.object(shape)
+
+  const form = useForm({ resolver: zodResolver(schema), defaultValues })
+
+  return (
+    <form
+      onSubmit={form.handleSubmit(onSubmit)}
+      className="space-y-2 border p-4"
+    >
+      {fields.map((field) => (
+        <div key={field.field_key} className="flex flex-col gap-1">
+          <label className="text-sm">{field.field_label}</label>
+          {field.field_type === 'text' && (
+            <input
+              className="border p-2"
+              {...form.register(field.field_key)}
+            />
+          )}
+          {field.field_type === 'number' && (
+            <input
+              type="number"
+              className="border p-2"
+              {...form.register(field.field_key, { valueAsNumber: true })}
+            />
+          )}
+          {field.field_type === 'date' && (
+            <input
+              type="date"
+              className="border p-2"
+              {...form.register(field.field_key, { valueAsDate: true })}
+            />
+          )}
+          {field.field_type === 'select' && (
+            <select className="border p-2" {...form.register(field.field_key)}>
+              {field.options?.map((opt) => (
+                <option key={opt.value} value={opt.value}>
+                  {opt.label}
+                </option>
+              ))}
+            </select>
+          )}
+        </div>
+      ))}
+      <button className="bg-blue-500 text-white px-4 py-2" type="submit">
+        Submit
+      </button>
+    </form>
+  )
+}
diff --git a/frontend/app/components/Graph.tsx b/frontend/app/components/Graph.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..8bda4c08f70eb9a3f79a27cdeec1214c0ef23eb3
--- /dev/null
+++ b/frontend/app/components/Graph.tsx
@@ -0,0 +1,77 @@
+'use client'
+import { useEffect, useRef } from 'react'
+import * as d3 from 'd3'
+import type { GraphData } from '../types'
+
+export default function Graph({ data }: { data: GraphData }) {
+  const ref = useRef<SVGSVGElement | null>(null)
+  useEffect(() => {
+    if (!ref.current) return
+    const svg = d3.select(ref.current)
+    svg.selectAll('*').remove()
+    const width = 400
+    const height = 300
+    const simulation = d3.forceSimulation(data.nodes as any)
+      .force('link', d3.forceLink(data.edges as any).id((d: any) => d.id).distance(80))
+      .force('charge', d3.forceManyBody().strength(-200))
+      .force('center', d3.forceCenter(width / 2, height / 2))
+
+    const link = svg.append('g')
+      .selectAll('line')
+      .data(data.edges)
+      .enter()
+      .append('line')
+      .attr('stroke', '#999')
+
+    const node = svg.append('g')
+      .selectAll('circle')
+      .data(data.nodes)
+      .enter()
+      .append('circle')
+      .attr('r', 8)
+      .attr('fill', '#3182bd')
+      .call(d3.drag<SVGCircleElement, any>()
+        .on('start', dragstarted)
+        .on('drag', dragged)
+        .on('end', dragended))
+
+    const label = svg.append('g')
+      .selectAll('text')
+      .data(data.nodes)
+      .enter()
+      .append('text')
+      .text((d: any) => d.name)
+      .attr('font-size', 10)
+      .attr('dx', 12)
+      .attr('dy', '.35em')
+
+    simulation.on('tick', () => {
+      link
+        .attr('x1', (d: any) => (d.source as any).x)
+        .attr('y1', (d: any) => (d.source as any).y)
+        .attr('x2', (d: any) => (d.target as any).x)
+        .attr('y2', (d: any) => (d.target as any).y)
+      node.attr('cx', (d: any) => d.x!).attr('cy', (d: any) => d.y!)
+      label.attr('x', (d: any) => d.x!).attr('y', (d: any) => d.y!)
+    })
+
+    function dragstarted(event: any) {
+      if (!event.active) simulation.alphaTarget(0.3).restart()
+      event.subject.fx = event.subject.x
+      event.subject.fy = event.subject.y
+    }
+
+    function dragged(event: any) {
+      event.subject.fx = event.x
+      event.subject.fy = event.y
+    }
+
+    function dragended(event: any) {
+      if (!event.active) simulation.alphaTarget(0)
+      event.subject.fx = null
+      event.subject.fy = null
+    }
+  }, [data])
+
+  return <svg ref={ref} width={400} height={300} />
+}
diff --git a/frontend/app/components/Spinner.tsx b/frontend/app/components/Spinner.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..3bf67f099fb73d3e1c4589870dd02f06c7d1c686
--- /dev/null
+++ b/frontend/app/components/Spinner.tsx
@@ -0,0 +1,27 @@
+'use client'
+export default function Spinner() {
+  return (
+    <div className="flex justify-center items-center p-4" aria-label="Loading">
+      <svg
+        className="animate-spin h-6 w-6 text-blue-500"
+        xmlns="http://www.w3.org/2000/svg"
+        fill="none"
+        viewBox="0 0 24 24"
+      >
+        <circle
+          className="opacity-25"
+          cx="12"
+          cy="12"
+          r="10"
+          stroke="currentColor"
+          strokeWidth="4"
+        />
+        <path
+          className="opacity-75"
+          fill="currentColor"
+          d="M4 12a8 8 0 018-8v4a4 4 0 00-4 4H4z"
+        />
+      </svg>
+    </div>
+  )
+}
diff --git a/frontend/app/components/Tour.tsx b/frontend/app/components/Tour.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..4af02785af125317cd6047e593e87f6098c1a8dc
--- /dev/null
+++ b/frontend/app/components/Tour.tsx
@@ -0,0 +1,40 @@
+'use client'
+import { useState, useEffect } from 'react'
+
+const steps = [
+  'Welcome to BioLabs! Use the menu to navigate.',
+  'Create inventory items and manage protocols easily.',
+]
+
+export default function Tour() {
+  const [step, setStep] = useState(0)
+  const [show, setShow] = useState(false)
+
+  useEffect(() => {
+    if (localStorage.getItem('tour-complete') !== 'true') {
+      setShow(true)
+    }
+  }, [])
+
+  const next = () => {
+    if (step + 1 < steps.length) {
+      setStep(step + 1)
+    } else {
+      localStorage.setItem('tour-complete', 'true')
+      setShow(false)
+    }
+  }
+
+  if (!show) return null
+
+  return (
+    <div className="fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50">
+      <div className="bg-white p-6 rounded shadow max-w-sm">
+        <p className="mb-4">{steps[step]}</p>
+        <button className="bg-blue-600 text-white px-4 py-2" onClick={next}>
+          {step + 1 === steps.length ? 'Finish' : 'Next'}
+        </button>
+      </div>
+    </div>
+  )
+}
diff --git a/frontend/app/fields/page.tsx b/frontend/app/fields/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..0dfd88cccb69c60732e1e41f9c63df7205e05d3f
--- /dev/null
+++ b/frontend/app/fields/page.tsx
@@ -0,0 +1,50 @@
+'use client'
+import { useState } from 'react'
+import { useFieldDefinitions, useCreateField, useDeleteField } from '../hooks/useFields'
+import DynamicForm from '../components/DynamicForm'
+
+export default function FieldDefinitionsPage() {
+  const [entity, setEntity] = useState('sample')
+  const { data: fields } = useFieldDefinitions(entity)
+  const createField = useCreateField()
+  const deleteField = useDeleteField()
+
+  const handleCreate = (data: any) => {
+    createField.mutate({ ...data, entity_type: entity })
+  }
+
+  return (
+    <div>
+      <h1 className="text-xl mb-4">Field Definitions</h1>
+      <div className="mb-4 flex gap-2 items-center">
+        <label>Entity</label>
+        <input
+          className="border p-1"
+          value={entity}
+          onChange={(e) => setEntity(e.target.value)}
+        />
+      </div>
+      <DynamicForm
+        fields={[
+          { id: 'field_key', entity_type: entity, field_key: 'field_key', field_label: 'Key', field_type: 'text', is_required: true },
+          { id: 'field_label', entity_type: entity, field_key: 'field_label', field_label: 'Label', field_type: 'text', is_required: true },
+          { id: 'field_type', entity_type: entity, field_key: 'field_type', field_label: 'Type', field_type: 'select', is_required: true, options: [
+            { label: 'text', value: 'text' },
+            { label: 'number', value: 'number' },
+            { label: 'date', value: 'date' },
+          ] }
+        ]}
+        onSubmit={handleCreate}
+      />
+      <h2 className="text-lg mt-6 mb-2">Fields for {entity}</h2>
+      <ul className="space-y-2">
+        {fields?.map((f) => (
+          <li key={f.id} className="border p-2 flex justify-between">
+            <span>{f.field_label} ({f.field_key})</span>
+            <button onClick={() => deleteField.mutate({ id: f.id, entity })}>Delete</button>
+          </li>
+        ))}
+      </ul>
+    </div>
+  )
+}
diff --git a/frontend/app/hooks/useAnalytics.ts b/frontend/app/hooks/useAnalytics.ts
new file mode 100644
index 0000000000000000000000000000000000000000..0df903dc70544037417e057c3a64e62da0fa94df
--- /dev/null
+++ b/frontend/app/hooks/useAnalytics.ts
@@ -0,0 +1,60 @@
+'use client'
+import { useQuery } from '@tanstack/react-query'
+import api from '../api/client'
+import type {
+  ItemTypeCount,
+  TrendingProtocol,
+  TrendingArticle,
+  TrendingItem,
+  TrendingThread,
+} from '../types'
+
+export const useAnalytics = () => {
+  return useQuery({
+    queryKey: ['analytics'],
+    queryFn: async () => {
+      const resp = await api.get('/api/analytics/summary')
+      return resp.data as ItemTypeCount[]
+    },
+  })
+}
+
+export const useTrendingProtocols = () => {
+  return useQuery({
+    queryKey: ['trending-protocols'],
+    queryFn: async () => {
+      const resp = await api.get('/api/analytics/trending-protocols')
+      return resp.data as TrendingProtocol[]
+    },
+  })
+}
+
+export const useTrendingArticles = () => {
+  return useQuery({
+    queryKey: ['trending-articles'],
+    queryFn: async () => {
+      const resp = await api.get('/api/analytics/trending-articles')
+      return resp.data as TrendingArticle[]
+    },
+  })
+}
+
+export const useTrendingItems = () => {
+  return useQuery({
+    queryKey: ['trending-items'],
+    queryFn: async () => {
+      const resp = await api.get('/api/analytics/trending-items')
+      return resp.data as TrendingItem[]
+    },
+  })
+}
+
+export const useTrendingThreads = () => {
+  return useQuery({
+    queryKey: ['trending-threads'],
+    queryFn: async () => {
+      const resp = await api.get('/api/analytics/trending-threads')
+      return resp.data as TrendingThread[]
+    },
+  })
+}
diff --git a/frontend/app/hooks/useAssistant.ts b/frontend/app/hooks/useAssistant.ts
new file mode 100644
index 0000000000000000000000000000000000000000..af1126659dd2d4e118775ab4d366b63efc4fb75d
--- /dev/null
+++ b/frontend/app/hooks/useAssistant.ts
@@ -0,0 +1,24 @@
+'use client'
+import { useQuery, useMutation, useQueryClient } from '@tanstack/react-query'
+import api from '../api/client'
+import type { AssistantMessage } from '../types'
+
+export const useAssistantHistory = () =>
+  useQuery({
+    queryKey: ['assistant', 'history'],
+    queryFn: async () => {
+      const res = await api.get('/api/assistant')
+      return res.data as AssistantMessage[]
+    },
+  })
+
+export const useAskAssistant = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: async (question: string) => {
+      const res = await api.post('/api/assistant/ask', { question })
+      return res.data as AssistantMessage
+    },
+    onSuccess: () => qc.invalidateQueries(['assistant', 'history']),
+  })
+}
diff --git a/frontend/app/hooks/useCalendar.ts b/frontend/app/hooks/useCalendar.ts
new file mode 100644
index 0000000000000000000000000000000000000000..9559e6c9f97ac4dc6a7c01b33cd8b5f6803e0e4b
--- /dev/null
+++ b/frontend/app/hooks/useCalendar.ts
@@ -0,0 +1,45 @@
+'use client'
+import { useQuery, useMutation, useQueryClient } from '@tanstack/react-query'
+import api from '../api/client'
+import type { CalendarEvent } from '../types'
+
+export const useCalendarEvents = () =>
+  useQuery({
+    queryKey: ['calendar'],
+    queryFn: async () => {
+      const res = await api.get('/api/calendar')
+      return res.data as CalendarEvent[]
+    },
+  })
+
+export const useCreateEvent = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: async (data: Partial<CalendarEvent>) => {
+      const res = await api.post('/api/calendar', data)
+      return res.data as CalendarEvent
+    },
+    onSuccess: () => qc.invalidateQueries({ queryKey: ['calendar'] }),
+  })
+}
+
+export const useUpdateEvent = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: async ({ id, data }: { id: string; data: Partial<CalendarEvent> }) => {
+      const res = await api.put(`/api/calendar/${id}`, data)
+      return res.data as CalendarEvent
+    },
+    onSuccess: () => qc.invalidateQueries({ queryKey: ['calendar'] }),
+  })
+}
+
+export const useDeleteEvent = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: async (id: string) => {
+      await api.delete(`/api/calendar/${id}`)
+    },
+    onSuccess: () => qc.invalidateQueries({ queryKey: ['calendar'] }),
+  })
+}
diff --git a/frontend/app/hooks/useComments.ts b/frontend/app/hooks/useComments.ts
new file mode 100644
index 0000000000000000000000000000000000000000..771ed5d0b55f86c2f0a578aa9aff95410f9dc3a3
--- /dev/null
+++ b/frontend/app/hooks/useComments.ts
@@ -0,0 +1,45 @@
+'use client'
+import { useQuery, useMutation, useQueryClient } from '@tanstack/react-query'
+import api from '../api/client'
+import type { Comment } from '../types'
+
+export const useComments = (params?: { item_id?: string; entry_id?: string }) =>
+  useQuery({
+    queryKey: ['comments', params],
+    queryFn: async () => {
+      const res = await api.get('/api/comments', { params })
+      return res.data as Comment[]
+    },
+  })
+
+export const useCreateComment = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: async (data: Partial<Comment>) => {
+      const res = await api.post('/api/comments/', data)
+      return res.data as Comment
+    },
+    onSuccess: () => qc.invalidateQueries(['comments']),
+  })
+}
+
+export const useUpdateComment = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: async ({ id, data }: { id: string; data: Partial<Comment> }) => {
+      const res = await api.put(`/api/comments/${id}`, data)
+      return res.data as Comment
+    },
+    onSuccess: () => qc.invalidateQueries(['comments']),
+  })
+}
+
+export const useDeleteComment = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: async (id: string) => {
+      await api.delete(`/api/comments/${id}`)
+    },
+    onSuccess: () => qc.invalidateQueries(['comments']),
+  })
+}
diff --git a/frontend/app/hooks/useCommunity.ts b/frontend/app/hooks/useCommunity.ts
new file mode 100644
index 0000000000000000000000000000000000000000..c5e1bff9672d6b3f7d71ece34469f179f9485f29
--- /dev/null
+++ b/frontend/app/hooks/useCommunity.ts
@@ -0,0 +1,45 @@
+'use client'
+import { useQuery, useMutation, useQueryClient } from '@tanstack/react-query'
+import api from '../api/client'
+import type { Post, Follow } from '../types'
+
+export const useFeed = () =>
+  useQuery({
+    queryKey: ['feed'],
+    queryFn: async () => {
+      const res = await api.get('/api/community/feed')
+      return res.data as Post[]
+    },
+  })
+
+export const useCreatePost = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: async (data: { content: string }) => {
+      const res = await api.post('/api/community/posts', data)
+      return res.data as Post
+    },
+    onSuccess: () => qc.invalidateQueries(['feed']),
+  })
+}
+
+export const useFollow = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: async (id: string) => {
+      const res = await api.post(`/api/community/follow/${id}`)
+      return res.data as Follow
+    },
+    onSuccess: () => qc.invalidateQueries(['feed']),
+  })
+}
+
+export const useUnfollow = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: async (id: string) => {
+      await api.delete(`/api/community/follow/${id}`)
+    },
+    onSuccess: () => qc.invalidateQueries(['feed']),
+  })
+}
diff --git a/frontend/app/hooks/useCompliance.ts b/frontend/app/hooks/useCompliance.ts
new file mode 100644
index 0000000000000000000000000000000000000000..7785657431ae981e8f224488df1faf39d6ee2dae
--- /dev/null
+++ b/frontend/app/hooks/useCompliance.ts
@@ -0,0 +1,41 @@
+'use client'
+import { useQuery, useMutation, useQueryClient } from '@tanstack/react-query'
+import api from '../api/client'
+import type { ComplianceRecord, StatusCount } from '../types'
+
+export const useComplianceRecords = () => {
+  return useQuery({
+    queryKey: ['compliance', 'records'],
+    queryFn: async () => {
+      const resp = await api.get('/api/compliance/records')
+      return resp.data as ComplianceRecord[]
+    },
+  })
+}
+
+export const useCreateRecord = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (data: any) => api.post('/api/compliance/records', data),
+    onSuccess: () => qc.invalidateQueries({ queryKey: ['compliance', 'records'] }),
+  })
+}
+
+export const useUpdateRecord = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (vars: { id: string; data: any }) =>
+      api.put(`/api/compliance/records/${vars.id}`, vars.data),
+    onSuccess: () => qc.invalidateQueries({ queryKey: ['compliance', 'records'] }),
+  })
+}
+
+export const useComplianceSummary = () => {
+  return useQuery({
+    queryKey: ['compliance', 'summary'],
+    queryFn: async () => {
+      const resp = await api.get('/api/compliance/summary')
+      return resp.data as StatusCount[]
+    },
+  })
+}
diff --git a/frontend/app/hooks/useFields.ts b/frontend/app/hooks/useFields.ts
new file mode 100644
index 0000000000000000000000000000000000000000..49a40b4a8cf712122fc3b97854cc325023212afe
--- /dev/null
+++ b/frontend/app/hooks/useFields.ts
@@ -0,0 +1,35 @@
+'use client'
+import { useQuery, useMutation, useQueryClient } from '@tanstack/react-query'
+import api from '../api/client'
+import type { FieldDefinition } from '../types'
+
+export const useFieldDefinitions = (entity: string) => {
+  return useQuery({
+    queryKey: ['fields', entity],
+    queryFn: async () => {
+      const resp = await api.get(`/api/fields/definitions/${entity}`)
+      return resp.data as FieldDefinition[]
+    },
+  })
+}
+
+export const useCreateField = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (data: any) => api.post('/api/fields/definitions', data),
+    onSuccess: (_d, vars) => {
+      qc.invalidateQueries({ queryKey: ['fields', vars.entity_type] })
+    },
+  })
+}
+
+export const useDeleteField = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (vars: { id: string; entity: string }) =>
+      api.delete(`/api/fields/definitions/${vars.id}`),
+    onSuccess: (_d, vars) => {
+      qc.invalidateQueries({ queryKey: ['fields', vars.entity] })
+    },
+  })
+}
diff --git a/frontend/app/hooks/useFiles.ts b/frontend/app/hooks/useFiles.ts
new file mode 100644
index 0000000000000000000000000000000000000000..67ea6264bbb53e9f9c9c11f45e44de386459df09
--- /dev/null
+++ b/frontend/app/hooks/useFiles.ts
@@ -0,0 +1,58 @@
+'use client'
+import { useQuery, useMutation, useQueryClient } from '@tanstack/react-query'
+import api from '../api/client'
+import type { FileMeta, ChromatogramData, SequenceRead } from '../types'
+
+export const useItemFiles = (itemId: string) => {
+  return useQuery({
+    queryKey: ['files', itemId],
+    queryFn: async () => {
+      const resp = await api.get(`/api/files/items/${itemId}`)
+      return resp.data as FileMeta[]
+    }
+  })
+}
+
+export const useUploadFile = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (data: { itemId: string; file: File }) => {
+      const form = new FormData()
+      form.append('item_id', data.itemId)
+      form.append('upload', data.file)
+      return api.post('/api/files/upload', form, {
+        headers: { 'Content-Type': 'multipart/form-data' }
+      })
+    },
+    onSuccess: (_resp, vars) => {
+      qc.invalidateQueries({ queryKey: ['files', vars.itemId] })
+    }
+  })
+}
+
+export const useFileChromatogram = (fileId: string | null) => {
+  return useQuery({
+    queryKey: ['chromatogram', fileId],
+    queryFn: async () => {
+      const resp = await api.get(`/api/files/${fileId}/chromatogram`)
+      return resp.data as ChromatogramData
+    },
+    enabled: !!fileId
+  })
+}
+
+export const useFileSequence = (
+  fileId: string | null,
+  format?: string
+) => {
+  return useQuery({
+    queryKey: ['fileSeq', fileId, format],
+    queryFn: async () => {
+      const resp = await api.get(`/api/files/${fileId}/sequence`, {
+        params: format ? { format } : {},
+      })
+      return resp.data as SequenceRead[]
+    },
+    enabled: !!fileId,
+  })
+}
diff --git a/frontend/app/hooks/useGraph.ts b/frontend/app/hooks/useGraph.ts
new file mode 100644
index 0000000000000000000000000000000000000000..1e6603501abf7ed9f4c05c751bd36fecc0726044
--- /dev/null
+++ b/frontend/app/hooks/useGraph.ts
@@ -0,0 +1,16 @@
+'use client'
+import { useQuery } from '@tanstack/react-query'
+import api from '../api/client'
+import type { GraphData } from '../types'
+
+export const useItemGraph = (itemId: string, depth = 1) => {
+  return useQuery({
+    queryKey: ['graph', itemId, depth],
+    queryFn: async () => {
+      const resp = await api.get(`/api/inventory/items/${itemId}/graph`, {
+        params: { depth }
+      })
+      return resp.data as GraphData
+    }
+  })
+}
diff --git a/frontend/app/hooks/useInventory.ts b/frontend/app/hooks/useInventory.ts
new file mode 100644
index 0000000000000000000000000000000000000000..5e128b4361f2b7b553435abd937dbbd9c8cf19cb
--- /dev/null
+++ b/frontend/app/hooks/useInventory.ts
@@ -0,0 +1,39 @@
+'use client'
+import { useQuery, useMutation, useQueryClient } from '@tanstack/react-query'
+import api from '../api/client'
+import type { InventoryItem } from '../types'
+
+export const useInventoryItems = (filters?: Record<string, any>) => {
+  return useQuery({
+    queryKey: ['inventory', filters],
+    queryFn: async () => {
+      const resp = await api.get('/api/inventory/items', { params: filters })
+      return resp.data as InventoryItem[]
+    },
+  })
+}
+
+export const useCreateItem = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (data: any) => api.post('/api/inventory/items', data),
+    onSuccess: () => qc.invalidateQueries({ queryKey: ['inventory'] }),
+  })
+}
+
+export const useUpdateItem = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (vars: { id: string; data: any }) =>
+      api.put(`/api/inventory/items/${vars.id}`, vars.data),
+    onSuccess: () => qc.invalidateQueries({ queryKey: ['inventory'] }),
+  })
+}
+
+export const useDeleteItem = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (id: string) => api.delete(`/api/inventory/items/${id}`),
+    onSuccess: () => qc.invalidateQueries({ queryKey: ['inventory'] }),
+  })
+}
diff --git a/frontend/app/hooks/useKnowledge.ts b/frontend/app/hooks/useKnowledge.ts
new file mode 100644
index 0000000000000000000000000000000000000000..879af3173fb3a7cfd19f27427d54873bc3e6e204
--- /dev/null
+++ b/frontend/app/hooks/useKnowledge.ts
@@ -0,0 +1,45 @@
+'use client'
+import { useQuery, useMutation, useQueryClient } from '@tanstack/react-query'
+import api from '../api/client'
+import type { KnowledgeArticle } from '../types'
+
+export const useKnowledge = (tag?: string) =>
+  useQuery({
+    queryKey: ['knowledge', tag],
+    queryFn: async () => {
+      const res = await api.get('/api/knowledge/articles', { params: { tag } })
+      return res.data as KnowledgeArticle[]
+    },
+  })
+
+export const useCreateArticle = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: async (data: Partial<KnowledgeArticle>) => {
+      const res = await api.post('/api/knowledge/articles', data)
+      return res.data as KnowledgeArticle
+    },
+    onSuccess: () => qc.invalidateQueries(['knowledge']),
+  })
+}
+
+export const useUpdateArticle = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: async ({ id, data }: { id: string; data: Partial<KnowledgeArticle> }) => {
+      const res = await api.put(`/api/knowledge/articles/${id}`, data)
+      return res.data as KnowledgeArticle
+    },
+    onSuccess: () => qc.invalidateQueries(['knowledge']),
+  })
+}
+
+export const useDeleteArticle = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: async (id: string) => {
+      await api.delete(`/api/knowledge/articles/${id}`)
+    },
+    onSuccess: () => qc.invalidateQueries(['knowledge']),
+  })
+}
diff --git a/frontend/app/hooks/useLabs.ts b/frontend/app/hooks/useLabs.ts
new file mode 100644
index 0000000000000000000000000000000000000000..9f9407118286b8ace9d10957b1b0aa2f115ebd53
--- /dev/null
+++ b/frontend/app/hooks/useLabs.ts
@@ -0,0 +1,50 @@
+'use client'
+import { useQuery, useMutation, useQueryClient } from '@tanstack/react-query'
+import api from '../api/client'
+import type { Lab, LabConnection } from '../types'
+
+export const useLabs = () => {
+  return useQuery({
+    queryKey: ['labs'],
+    queryFn: async () => {
+      const resp = await api.get('/api/labs')
+      return resp.data as Lab[]
+    },
+  })
+}
+
+export const useCreateLab = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (data: any) => api.post('/api/labs', data),
+    onSuccess: () => qc.invalidateQueries({ queryKey: ['labs'] }),
+  })
+}
+
+export const useConnections = () => {
+  return useQuery({
+    queryKey: ['lab-connections'],
+    queryFn: async () => {
+      const resp = await api.get('/api/labs/connections')
+      return resp.data as LabConnection[]
+    },
+  })
+}
+
+export const useRequestConnection = (labId: string) => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (target_lab: string) =>
+      api.post(`/api/labs/${labId}/connections`, { target_lab }),
+    onSuccess: () => qc.invalidateQueries({ queryKey: ['lab-connections'] }),
+  })
+}
+
+export const useAcceptConnection = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (id: string) =>
+      api.post(`/api/labs/connections/${id}/accept`),
+    onSuccess: () => qc.invalidateQueries({ queryKey: ['lab-connections'] }),
+  })
+}
diff --git a/frontend/app/hooks/useMarketplace.ts b/frontend/app/hooks/useMarketplace.ts
new file mode 100644
index 0000000000000000000000000000000000000000..4ecd674ac388ce16b43c34ca4b32fe6346be3953
--- /dev/null
+++ b/frontend/app/hooks/useMarketplace.ts
@@ -0,0 +1,64 @@
+'use client'
+import { useQuery, useMutation, useQueryClient } from '@tanstack/react-query'
+import api from '../api/client'
+import type { MarketplaceListing, MarketplaceRequest } from '../types'
+
+export const useMarketplaceListings = () =>
+  useQuery({
+    queryKey: ['marketplace-listings'],
+    queryFn: async () => {
+      const res = await api.get('/api/marketplace/listings')
+      return res.data as MarketplaceListing[]
+    },
+  })
+
+export const useCreateListing = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (data: any) => api.post('/api/marketplace/listings', data),
+    onSuccess: () => qc.invalidateQueries({ queryKey: ['marketplace-listings'] }),
+  })
+}
+
+export const useCreateRequest = (listingId: string) => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (data: any) =>
+      api.post(`/api/marketplace/listings/${listingId}/requests`, data),
+    onSuccess: () => qc.invalidateQueries({
+      queryKey: ['marketplace-requests', listingId],
+    }),
+  })
+}
+
+export const useMarketplaceRequests = (listingId: string) =>
+  useQuery({
+    queryKey: ['marketplace-requests', listingId],
+    queryFn: async () => {
+      const res = await api.get(
+        `/api/marketplace/listings/${listingId}/requests`
+      )
+      return res.data as MarketplaceRequest[]
+    },
+    enabled: !!listingId,
+  })
+
+export const useAcceptRequest = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (id: string) =>
+      api.post(`/api/marketplace/requests/${id}/accept`),
+    onSuccess: (_res, vars) =>
+      qc.invalidateQueries({ queryKey: ['marketplace-requests', vars] }),
+  })
+}
+
+export const useRejectRequest = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (id: string) =>
+      api.post(`/api/marketplace/requests/${id}/reject`),
+    onSuccess: (_res, vars) =>
+      qc.invalidateQueries({ queryKey: ['marketplace-requests', vars] }),
+  })
+}
diff --git a/frontend/app/hooks/useNotebook.ts b/frontend/app/hooks/useNotebook.ts
new file mode 100644
index 0000000000000000000000000000000000000000..57b564db2ece85d3ee83fea838c9144b39a5e07c
--- /dev/null
+++ b/frontend/app/hooks/useNotebook.ts
@@ -0,0 +1,39 @@
+'use client'
+import { useQuery, useMutation, useQueryClient } from '@tanstack/react-query'
+import api from '../api/client'
+import type { NotebookEntry } from '../types'
+
+export const useNotebookEntries = () => {
+  return useQuery({
+    queryKey: ['notebook'],
+    queryFn: async () => {
+      const resp = await api.get('/api/notebook/entries')
+      return resp.data as NotebookEntry[]
+    },
+  })
+}
+
+export const useCreateEntry = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (data: any) => api.post('/api/notebook/entries', data),
+    onSuccess: () => qc.invalidateQueries({ queryKey: ['notebook'] }),
+  })
+}
+
+export const useUpdateEntry = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (vars: { id: string; data: any }) =>
+      api.put(`/api/notebook/entries/${vars.id}`, vars.data),
+    onSuccess: () => qc.invalidateQueries({ queryKey: ['notebook'] }),
+  })
+}
+
+export const useDeleteEntry = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (id: string) => api.delete(`/api/notebook/entries/${id}`),
+    onSuccess: () => qc.invalidateQueries({ queryKey: ['notebook'] }),
+  })
+}
diff --git a/frontend/app/hooks/useProjects.ts b/frontend/app/hooks/useProjects.ts
new file mode 100644
index 0000000000000000000000000000000000000000..668ead71ed5ffdf703cfd4d37b5f2c04e222ef16
--- /dev/null
+++ b/frontend/app/hooks/useProjects.ts
@@ -0,0 +1,62 @@
+'use client'
+import { useQuery, useMutation, useQueryClient } from '@tanstack/react-query'
+import api from '../api/client'
+import type { Project, ProjectTask } from '../types'
+
+export const useProjects = () => {
+  return useQuery({
+    queryKey: ['projects'],
+    queryFn: async () => {
+      const resp = await api.get('/api/projects')
+      return resp.data as Project[]
+    },
+  })
+}
+
+export const useCreateProject = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (data: any) => api.post('/api/projects', data),
+    onSuccess: () => qc.invalidateQueries({ queryKey: ['projects'] }),
+  })
+}
+
+export const useProjectTasks = (projectId: string) => {
+  return useQuery({
+    queryKey: ['project-tasks', projectId],
+    queryFn: async () => {
+      const resp = await api.get(`/api/projects/${projectId}/tasks`)
+      return resp.data as ProjectTask[]
+    },
+  })
+}
+
+export const useCreateTask = (projectId: string) => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (data: any) =>
+      api.post(`/api/projects/${projectId}/tasks`, data),
+    onSuccess: () =>
+      qc.invalidateQueries({ queryKey: ['project-tasks', projectId] }),
+  })
+}
+
+export const useUpdateTask = (projectId: string) => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (vars: { id: string; data: any }) =>
+      api.put(`/api/projects/${projectId}/tasks/${vars.id}`, vars.data),
+    onSuccess: () =>
+      qc.invalidateQueries({ queryKey: ['project-tasks', projectId] }),
+  })
+}
+
+export const useDeleteTask = (projectId: string) => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (id: string) =>
+      api.delete(`/api/projects/${projectId}/tasks/${id}`),
+    onSuccess: () =>
+      qc.invalidateQueries({ queryKey: ['project-tasks', projectId] }),
+  })
+}
diff --git a/frontend/app/hooks/useProtocols.ts b/frontend/app/hooks/useProtocols.ts
new file mode 100644
index 0000000000000000000000000000000000000000..40e12773fe1b2db557de27be399606ba1f6d46a9
--- /dev/null
+++ b/frontend/app/hooks/useProtocols.ts
@@ -0,0 +1,79 @@
+'use client'
+import { useQuery, useMutation, useQueryClient } from '@tanstack/react-query'
+import api from '../api/client'
+import type { ProtocolTemplate, ProtocolExecution } from '../types'
+
+export const useProtocolTemplates = () => {
+  return useQuery({
+    queryKey: ['protocols', 'templates'],
+    queryFn: async () => {
+      const resp = await api.get('/api/protocols/templates')
+      return resp.data as ProtocolTemplate[]
+    },
+  })
+}
+
+export const useCreateTemplate = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (data: any) => api.post('/api/protocols/templates', data),
+    onSuccess: () => qc.invalidateQueries({ queryKey: ['protocols', 'templates'] }),
+  })
+}
+
+export const useUpdateTemplate = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (vars: { id: string; data: any }) =>
+      api.put(`/api/protocols/templates/${vars.id}`, vars.data),
+    onSuccess: () => qc.invalidateQueries({ queryKey: ['protocols', 'templates'] }),
+  })
+}
+
+export const useDeleteTemplate = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (id: string) => api.delete(`/api/protocols/templates/${id}`),
+    onSuccess: () => qc.invalidateQueries({ queryKey: ['protocols', 'templates'] }),
+  })
+}
+
+export const useProtocolExecutions = () => {
+  return useQuery({
+    queryKey: ['protocols', 'executions'],
+    queryFn: async () => {
+      const resp = await api.get('/api/protocols/executions')
+      return resp.data as ProtocolExecution[]
+    },
+  })
+}
+
+export const useCreateExecution = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (data: any) => api.post('/api/protocols/executions', data),
+    onSuccess: () => qc.invalidateQueries({ queryKey: ['protocols', 'executions'] }),
+  })
+}
+
+export const useUpdateExecution = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (vars: { id: string; data: any }) =>
+      api.put(`/api/protocols/executions/${vars.id}`, vars.data),
+    onSuccess: () => qc.invalidateQueries({ queryKey: ['protocols', 'executions'] }),
+  })
+}
+
+export const useProtocolDiff = (oldId: string | null, newId: string | null) => {
+  return useQuery({
+    queryKey: ['protocols', 'diff', oldId, newId],
+    queryFn: async () => {
+      const resp = await api.get('/api/protocols/diff', {
+        params: { old_id: oldId, new_id: newId },
+      })
+      return resp.data.diff as string
+    },
+    enabled: !!oldId && !!newId,
+  })
+}
diff --git a/frontend/app/hooks/useSearch.ts b/frontend/app/hooks/useSearch.ts
new file mode 100644
index 0000000000000000000000000000000000000000..f24fb3a15a2c08a5988f0c359e05635f9b4ef1e5
--- /dev/null
+++ b/frontend/app/hooks/useSearch.ts
@@ -0,0 +1,16 @@
+'use client'
+import { useQuery } from '@tanstack/react-query'
+import api from '../api/client'
+import type { InventoryItem } from '../types'
+
+export const useSearchItems = (query: string) => {
+  return useQuery({
+    queryKey: ['search', query],
+    queryFn: async () => {
+      const resp = await api.get('/api/search/items', { params: { q: query } })
+      return resp.data as InventoryItem[]
+    },
+    enabled: !!query,
+  })
+}
+
diff --git a/frontend/app/hooks/useSequence.ts b/frontend/app/hooks/useSequence.ts
new file mode 100644
index 0000000000000000000000000000000000000000..01ac86a033ed995d2f3c5a6cb491cf9e51e67f71
--- /dev/null
+++ b/frontend/app/hooks/useSequence.ts
@@ -0,0 +1,66 @@
+'use client'
+import { useMutation, useQuery, useQueryClient } from '@tanstack/react-query'
+import api from '../api/client'
+import type { SequenceFeature, ChromatogramData, BlastResult, SequenceJob } from '../types'
+
+export const useAnnotateSequence = () => {
+  return useMutation({
+    mutationFn: async (file: File) => {
+      const form = new FormData()
+      form.append('format', 'genbank')
+      form.append('upload', file)
+      const resp = await api.post('/api/sequence/annotate', form, {
+        headers: { 'Content-Type': 'multipart/form-data' },
+      })
+      return resp.data as SequenceFeature[]
+    },
+  })
+}
+
+export const useChromatogram = () => {
+  return useMutation({
+    mutationFn: async (file: File) => {
+      const form = new FormData()
+      form.append('upload', file)
+      const resp = await api.post('/api/sequence/chromatogram', form, {
+        headers: { 'Content-Type': 'multipart/form-data' },
+      })
+      return resp.data as ChromatogramData
+    },
+  })
+}
+
+export const useBlastSearch = () => {
+  return useMutation({
+    mutationFn: async (payload: { query: string; subject: string }) => {
+      const resp = await api.post('/api/sequence/blast', payload)
+      return resp.data as BlastResult
+    },
+  })
+}
+
+export const useCreateSequenceJob = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: async (vars: { file: File; format: string }) => {
+      const form = new FormData()
+      form.append('format', vars.format)
+      form.append('upload', vars.file)
+      const resp = await api.post('/api/sequence/jobs', form, {
+        headers: { 'Content-Type': 'multipart/form-data' },
+      })
+      return resp.data as SequenceJob
+    },
+    onSuccess: () => qc.invalidateQueries({ queryKey: ['seqJobs'] }),
+  })
+}
+
+export const useSequenceJobs = () => {
+  return useQuery({
+    queryKey: ['seqJobs'],
+    queryFn: async () => {
+      const resp = await api.get('/api/sequence/jobs')
+      return resp.data as SequenceJob[]
+    },
+  })
+}
diff --git a/frontend/app/hooks/useTroubleshooting.ts b/frontend/app/hooks/useTroubleshooting.ts
new file mode 100644
index 0000000000000000000000000000000000000000..d4ae0748cfc6e5b9a0388284a07cdb69b34c18c5
--- /dev/null
+++ b/frontend/app/hooks/useTroubleshooting.ts
@@ -0,0 +1,42 @@
+'use client'
+import { useQuery, useMutation, useQueryClient } from '@tanstack/react-query'
+import api from '../api/client'
+import type { TroubleshootingArticle } from '../types'
+
+export const useArticles = (category?: string) => {
+  return useQuery({
+    queryKey: ['articles', category],
+    queryFn: async () => {
+      const resp = await api.get('/api/troubleshooting/articles', {
+        params: category ? { category } : undefined,
+      })
+      return resp.data as TroubleshootingArticle[]
+    },
+  })
+}
+
+export const useCreateArticle = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (data: any) => api.post('/api/troubleshooting/articles', data),
+    onSuccess: () => qc.invalidateQueries({ queryKey: ['articles'] }),
+  })
+}
+
+export const useUpdateArticle = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (vars: { id: string; data: any }) =>
+      api.put(`/api/troubleshooting/articles/${vars.id}`, vars.data),
+    onSuccess: () => qc.invalidateQueries({ queryKey: ['articles'] }),
+  })
+}
+
+export const useMarkSuccess = () => {
+  const qc = useQueryClient()
+  return useMutation({
+    mutationFn: (id: string) =>
+      api.post(`/api/troubleshooting/articles/${id}/success`),
+    onSuccess: () => qc.invalidateQueries({ queryKey: ['articles'] }),
+  })
+}
diff --git a/frontend/app/hooks/useWebSocket.ts b/frontend/app/hooks/useWebSocket.ts
new file mode 100644
index 0000000000000000000000000000000000000000..2ee7fd5cdb050072dfeb20768f92489c5906cf7c
--- /dev/null
+++ b/frontend/app/hooks/useWebSocket.ts
@@ -0,0 +1,16 @@
+import { useEffect } from 'react'
+
+export function useWebSocket(teamId: string, onMessage: (data: any) => void) {
+  useEffect(() => {
+    if (!teamId) return
+    const ws = new WebSocket(`ws://localhost:8000/ws/${teamId}`)
+    ws.onmessage = (ev) => {
+      try {
+        onMessage(JSON.parse(ev.data))
+      } catch {
+        onMessage(ev.data)
+      }
+    }
+    return () => ws.close()
+  }, [teamId, onMessage])
+}
diff --git a/frontend/app/inventory/[id]/page.tsx b/frontend/app/inventory/[id]/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..4ec48f46a75ffe64bfaf42f56f14fae81cac6701
--- /dev/null
+++ b/frontend/app/inventory/[id]/page.tsx
@@ -0,0 +1,93 @@
+'use client'
+import { useRouter } from 'next/navigation'
+import { useEffect, useState } from 'react'
+import Link from 'next/link'
+import { useItemFiles, useUploadFile, useFileChromatogram, useFileSequence } from '../../hooks/useFiles'
+import type { FileMeta } from '../../types'
+import { useItemGraph } from '../../hooks/useGraph'
+import { useInventoryItems } from '../../hooks/useInventory'
+import Graph from '../../components/Graph'
+import ChromatogramPlot from '../../components/ChromatogramPlot'
+
+export default function ItemDetail({ params }: { params: { id: string } }) {
+  const { id } = params
+  const router = useRouter()
+  const { data: items } = useInventoryItems()
+  const item = items?.find((i) => i.id === id)
+  const { data: files } = useItemFiles(id)
+  const upload = useUploadFile()
+  const { data: graph } = useItemGraph(id, 2)
+  const [selected, setSelected] = useState<FileMeta | null>(null)
+  const isChrom = selected ? /\.ab1$/i.test(selected.filename) : false
+  const isSeq = selected ? /\.(fa|fasta|fastq|fq)$/i.test(selected.filename) : false
+  const { data: chromData } = useFileChromatogram(isChrom ? selected.id : null)
+  const { data: seqData } = useFileSequence(isSeq ? selected.id : null)
+
+  useEffect(() => {
+    if (items && !item) router.push('/inventory')
+  }, [items, item, router])
+
+  if (!item) return <div>Loading...</div>
+
+  const handleUpload = (e: React.FormEvent<HTMLFormElement>) => {
+    e.preventDefault()
+    const formEl = e.currentTarget
+    const fileInput = formEl.elements.namedItem('file') as HTMLInputElement
+    if (fileInput.files && fileInput.files[0]) {
+      upload.mutate({ itemId: id, file: fileInput.files[0] })
+      formEl.reset()
+    }
+  }
+
+  return (
+    <div>
+      <Link href="/inventory" className="text-blue-600">&larr; Back</Link>
+      <h1 className="text-xl my-4">{item.name}</h1>
+      <pre className="bg-gray-100 p-2 mb-4 text-sm">
+        {JSON.stringify(item.custom_data, null, 2)}
+      </pre>
+      <form onSubmit={handleUpload} className="mb-4 space-x-2">
+        <input type="file" name="file" />
+        <button type="submit" className="bg-blue-500 text-white px-2 py-1">
+          Upload
+        </button>
+      </form>
+      <h2 className="font-semibold mb-2">Files</h2>
+      <ul className="mb-4 space-y-1">
+        {files?.map((f) => (
+          <li key={f.id} className="flex items-center space-x-2">
+            <button
+              onClick={() => setSelected(f)}
+              className="text-blue-600 underline"
+            >
+              {f.filename}
+            </button>
+          </li>
+        ))}
+      </ul>
+      {chromData && (
+        <div className="mb-4">
+          <h3 className="font-semibold">Chromatogram Preview</h3>
+          <pre className="whitespace-pre-wrap text-sm break-all mb-2">
+            {chromData.sequence.slice(0, 200)}
+          </pre>
+          <ChromatogramPlot data={chromData} height={150} />
+        </div>
+      )}
+      {seqData && (
+        <div className="mb-4">
+          <h3 className="font-semibold">Sequence Preview</h3>
+          <pre className="whitespace-pre-wrap text-sm break-all">
+            {seqData.map((r) => `>${r.id}\n${r.seq}`).join('\n').slice(0, 200)}
+          </pre>
+        </div>
+      )}
+      {graph && (
+        <div>
+          <h2 className="font-semibold mb-2">Relationship Graph</h2>
+          <Graph data={graph} />
+        </div>
+      )}
+    </div>
+  )
+}
diff --git a/frontend/app/inventory/page.tsx b/frontend/app/inventory/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..68c751faae91ec846139bdc47e470d04f96f1408
--- /dev/null
+++ b/frontend/app/inventory/page.tsx
@@ -0,0 +1,130 @@
+'use client'
+import { useState, useEffect } from 'react'
+import DynamicForm from '../components/DynamicForm'
+import Spinner from '../components/Spinner'
+import {
+  useInventoryItems,
+  useCreateItem,
+  useUpdateItem,
+  useDeleteItem,
+} from '../hooks/useInventory'
+import api from '../api/client'
+import type { FieldDefinition, InventoryItem } from '../types'
+
+export default function InventoryPage() {
+  const {
+    data: items,
+    isLoading,
+    error,
+  } = useInventoryItems()
+  const createItem = useCreateItem()
+  const updateItem = useUpdateItem()
+  const deleteItem = useDeleteItem()
+
+  const [itemType, setItemType] = useState('sample')
+  const [fields, setFields] = useState<FieldDefinition[]>([])
+  const [editing, setEditing] = useState<InventoryItem | null>(null)
+
+  useEffect(() => {
+    api
+      .get(`/api/fields/definitions/${itemType}`)
+      .then((r) =>
+        setFields([
+          {
+            field_key: 'name',
+            field_label: 'Name',
+            field_type: 'text',
+            is_required: true,
+            id: 'name',
+            entity_type: itemType,
+          } as FieldDefinition,
+          ...r.data,
+        ])
+      )
+      .catch(() =>
+        setFields([
+          {
+            field_key: 'name',
+            field_label: 'Name',
+            field_type: 'text',
+            is_required: true,
+            id: 'name',
+            entity_type: itemType,
+          } as FieldDefinition,
+        ])
+      )
+  }, [itemType])
+
+  const submit = (data: any) => {
+    const { name, ...custom } = data
+    if (editing) {
+      updateItem.mutate({ id: editing.id, data: { name, custom_data: custom } })
+      setEditing(null)
+    } else {
+      createItem.mutate({ item_type: itemType, name, custom_data: custom })
+    }
+  }
+
+  return (
+    <div>
+      <h1 className="text-xl mb-4">Inventory</h1>
+      <div className="mb-4 flex gap-2 items-center">
+        <label>Item Type</label>
+        <input
+          className="border p-1"
+          value={itemType}
+          onChange={(e) => setItemType(e.target.value)}
+        />
+      </div>
+      <DynamicForm
+        fields={fields}
+        onSubmit={submit}
+        defaultValues={
+          editing ? { name: editing.name, ...editing.custom_data } : {}
+        }
+      />
+      {editing && (
+        <button
+          className="text-sm text-gray-600 mt-2"
+          onClick={() => setEditing(null)}
+        >
+          Cancel Edit
+        </button>
+      )}
+      <h2 className="text-lg mt-6 mb-2">Items</h2>
+      {isLoading && <Spinner />}
+      {error && (
+        <p className="text-red-600" role="alert">Failed to load items</p>
+      )}
+      <ul className="space-y-2">
+        {items?.map((item) => (
+          <li key={item.id} className="border p-2 flex justify-between items-center">
+            <span>
+              <a href={`/inventory/${item.id}`} className="text-blue-600 underline mr-2">
+                {item.name}
+              </a>
+              ({item.item_type})
+            </span>
+            <span className="space-x-2">
+              <button
+                className="text-blue-600"
+                onClick={() => {
+                  setEditing(item)
+                  setItemType(item.item_type)
+                }}
+              >
+                Edit
+              </button>
+              <button
+                className="text-red-600"
+                onClick={() => deleteItem.mutate(item.id)}
+              >
+                Delete
+              </button>
+            </span>
+          </li>
+        ))}
+      </ul>
+    </div>
+  )
+}
diff --git a/frontend/app/knowledge/page.tsx b/frontend/app/knowledge/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..cede3f19986b495872c497db10fbfe19558a4a23
--- /dev/null
+++ b/frontend/app/knowledge/page.tsx
@@ -0,0 +1,64 @@
+'use client'
+import { useState } from 'react'
+import DynamicForm from '../components/DynamicForm'
+import {
+  useKnowledge,
+  useCreateArticle,
+  useUpdateArticle,
+  useDeleteArticle,
+} from '../hooks/useKnowledge'
+import type { KnowledgeArticle } from '../types'
+
+export default function KnowledgePage() {
+  const { data: articles } = useKnowledge()
+  const create = useCreateArticle()
+  const update = useUpdateArticle()
+  const remove = useDeleteArticle()
+  const [editing, setEditing] = useState<KnowledgeArticle | null>(null)
+
+  const fields = [
+    { id: 'title', entity_type: 'ka', field_key: 'title', field_label: 'Title', field_type: 'text', is_required: true },
+    { id: 'content', entity_type: 'ka', field_key: 'content', field_label: 'Content', field_type: 'text', is_required: true },
+    { id: 'tags', entity_type: 'ka', field_key: 'tags', field_label: 'Tags (comma separated)', field_type: 'text' },
+  ] as any
+
+  const handleSubmit = (data: any) => {
+    if (data.tags) {
+      data.tags = data.tags.split(',').map((t: string) => t.trim())
+    }
+    if (editing) {
+      update.mutate({ id: editing.id, data })
+      setEditing(null)
+    } else {
+      create.mutate(data)
+    }
+  }
+
+  return (
+    <div>
+      <h1 className="text-xl mb-4">Knowledge Base</h1>
+      <DynamicForm fields={fields} onSubmit={handleSubmit} defaultValues={editing ? editing : {}} />
+      {editing && (
+        <button className="text-sm text-gray-600 mt-2" onClick={() => setEditing(null)}>
+          Cancel Edit
+        </button>
+      )}
+      <h2 className="text-lg mt-6 mb-2">Articles</h2>
+      <ul className="space-y-2">
+        {articles?.map((a) => (
+          <li key={a.id} className="border p-2 space-y-1">
+            <div className="flex justify-between items-center">
+              <span className="font-semibold">{a.title}</span>
+              <div className="space-x-2 text-sm">
+                <button className="text-blue-600" onClick={() => setEditing(a)}>Edit</button>
+                <button className="text-red-600" onClick={() => remove.mutate(a.id)}>Delete</button>
+              </div>
+            </div>
+            <p className="text-sm text-gray-700">{a.content}</p>
+            {a.tags && <p className="text-xs text-gray-500">Tags: {a.tags.join(', ')}</p>}
+          </li>
+        ))}
+      </ul>
+    </div>
+  )
+}
diff --git a/frontend/app/labs/page.tsx b/frontend/app/labs/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..3695415cefe14b835e3bc233cc532ffb5b712af1
--- /dev/null
+++ b/frontend/app/labs/page.tsx
@@ -0,0 +1,58 @@
+'use client'
+import { useState } from 'react'
+import {
+  useLabs,
+  useCreateLab,
+  useConnections,
+  useRequestConnection,
+  useAcceptConnection,
+} from '../hooks/useLabs'
+
+export default function LabsPage() {
+  const { data: labs } = useLabs()
+  const createLab = useCreateLab()
+  const { data: connections } = useConnections()
+  const accept = useAcceptConnection()
+  const [name, setName] = useState('')
+  const [target, setTarget] = useState('')
+  const [selected, setSelected] = useState<string | null>(null)
+
+  const request = useRequestConnection(selected ?? '')
+
+  return (
+    <div>
+      <h1 className="text-xl mb-4">Labs</h1>
+      <div className="mb-4">
+        <input className="border p-1 mr-2" value={name} onChange={(e) => setName(e.target.value)} />
+        <button onClick={() => { createLab.mutate({ name }); setName('') }}>Create Lab</button>
+      </div>
+      <ul className="space-y-2 mb-6">
+        {labs?.map((l) => (
+          <li key={l.id} className="border p-2 cursor-pointer" onClick={() => setSelected(l.id)}>
+            {l.name}
+          </li>
+        ))}
+      </ul>
+      {selected && (
+        <div className="mb-6">
+          <h2 className="text-lg mb-2">Request Connection</h2>
+          <input className="border p-1 mr-2" value={target} onChange={(e) => setTarget(e.target.value)} placeholder="Target Lab ID" />
+          <button onClick={() => { request.mutate(target); setTarget('') }}>Send</button>
+        </div>
+      )}
+      <h2 className="text-lg mb-2">Connections</h2>
+      <ul className="space-y-2">
+        {connections?.map((c) => (
+          <li key={c.id} className="border p-2 flex justify-between">
+            <span>
+              {c.from_lab} ➜ {c.to_lab} - {c.status}
+            </span>
+            {c.status === 'pending' && (
+              <button onClick={() => accept.mutate(c.id)}>Accept</button>
+            )}
+          </li>
+        ))}
+      </ul>
+    </div>
+  )
+}
diff --git a/frontend/app/layout.tsx b/frontend/app/layout.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..054c6f7cae98f57c69539cc35dbeca50040260b7
--- /dev/null
+++ b/frontend/app/layout.tsx
@@ -0,0 +1,75 @@
+'use client'
+import './styles/globals.css'
+import { ReactNode, useState } from 'react'
+import Link from 'next/link'
+import { useAuth } from './store/useAuth'
+import { useRouter } from 'next/navigation'
+
+export default function RootLayout({ children }: { children: ReactNode }) {
+  const token = useAuth((s) => s.token)
+  const setToken = useAuth((s) => s.setToken)
+  const router = useRouter()
+  const [menuOpen, setMenuOpen] = useState(false)
+
+  const logout = () => {
+    localStorage.removeItem('token')
+    setToken(null)
+    router.push('/login')
+  }
+
+  return (
+    <html lang="en">
+      <body>
+        <a href="#main" className="sr-only focus:not-sr-only">
+          Skip to content
+        </a>
+        <nav className="p-4 border-b md:flex md:items-center md:gap-4">
+          <div className="flex justify-between items-center">
+            <Link href="/">Home</Link>
+            <button
+              className="md:hidden p-2"
+              aria-label="Toggle menu"
+              onClick={() => setMenuOpen((v) => !v)}
+            >
+              ☰
+            </button>
+          </div>
+          <div className={`${menuOpen ? 'block' : 'hidden'} md:flex md:gap-4`}>
+            {token && (
+              <>
+                <Link href="/inventory">Inventory</Link>
+                <Link href="/fields">Fields</Link>
+                <Link href="/search">Search</Link>
+                <Link href="/protocols">Protocols</Link>
+                <Link href="/notebook">Notebook</Link>
+                <Link href="/comments">Comments</Link>
+                <Link href="/projects">Projects</Link>
+                <Link href="/troubleshooting">Troubleshooting</Link>
+                <Link href="/knowledge">Knowledge Base</Link>
+                <Link href="/community">Community</Link>
+                <Link href="/labs">Labs</Link>
+                <Link href="/calendar">Calendar</Link>
+                <Link href="/sequence">Sequence</Link>
+                <Link href="/assistant">Assistant</Link>
+                <Link href="/marketplace">Marketplace</Link>
+                <Link href="/compliance">Compliance</Link>
+                <Link href="/analytics">Analytics</Link>
+              </>
+            )}
+            {token ? (
+              <button onClick={logout}>Logout</button>
+            ) : (
+              <>
+                <Link href="/login">Login</Link>
+                <Link href="/register">Register</Link>
+              </>
+            )}
+          </div>
+        </nav>
+        <main id="main" className="p-4">
+          {children}
+        </main>
+      </body>
+    </html>
+  )
+}
diff --git a/frontend/app/login/page.tsx b/frontend/app/login/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..1be95188ab051d14aec81ad5fe1927dab5a2001f
--- /dev/null
+++ b/frontend/app/login/page.tsx
@@ -0,0 +1,50 @@
+'use client'
+import { useState } from 'react'
+import { useRouter } from 'next/navigation'
+import api from '../api/client'
+import { useAuth } from '../store/useAuth'
+
+export default function LoginPage() {
+  const [email, setEmail] = useState('')
+  const [password, setPassword] = useState('')
+  const router = useRouter()
+  const setToken = useAuth((s) => s.setToken)
+
+  const submit = async (e: React.FormEvent) => {
+    e.preventDefault()
+    try {
+      const resp = await api.post('/api/auth/login', { email, password })
+      const token = resp.data.access_token
+      localStorage.setItem('token', token)
+      setToken(token)
+      router.push('/')
+    } catch (err) {
+      console.error(err)
+      alert('Login failed')
+    }
+  }
+
+  return (
+    <div className="p-4 max-w-sm mx-auto">
+      <h1 className="text-xl mb-4">Login</h1>
+      <form onSubmit={submit} className="space-y-2">
+        <input
+          className="border p-2 w-full"
+          placeholder="Email"
+          value={email}
+          onChange={(e) => setEmail(e.target.value)}
+        />
+        <input
+          className="border p-2 w-full"
+          type="password"
+          placeholder="Password"
+          value={password}
+          onChange={(e) => setPassword(e.target.value)}
+        />
+        <button className="bg-blue-500 text-white px-4 py-2" type="submit">
+          Login
+        </button>
+      </form>
+    </div>
+  )
+}
diff --git a/frontend/app/marketplace/page.tsx b/frontend/app/marketplace/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..158c4664e87d1a6cdecdf8979d14a0088734acb8
--- /dev/null
+++ b/frontend/app/marketplace/page.tsx
@@ -0,0 +1,89 @@
+'use client'
+import { useState } from 'react'
+import {
+  useMarketplaceListings,
+  useCreateListing,
+  useMarketplaceRequests,
+  useCreateRequest,
+  useAcceptRequest,
+  useRejectRequest,
+} from '../hooks/useMarketplace'
+
+export default function MarketplacePage() {
+  const { data: listings } = useMarketplaceListings()
+  const create = useCreateListing()
+  const [itemId, setItemId] = useState('')
+  const [price, setPrice] = useState('')
+  const [selected, setSelected] = useState<string | null>(null)
+  const { data: requests } = useMarketplaceRequests(selected ?? '')
+  const makeRequest = useCreateRequest(selected ?? '')
+  const accept = useAcceptRequest()
+  const reject = useRejectRequest()
+
+  const handleCreate = () => {
+    create.mutate({ item_id: itemId, price: price ? Number(price) : null })
+    setItemId('')
+    setPrice('')
+  }
+
+  const handleRequest = (listingId: string) => {
+    makeRequest.mutate({ message: 'Interested' })
+  }
+
+  return (
+    <div>
+      <h1 className="text-xl mb-4">Marketplace</h1>
+      <div className="mb-4 space-x-2">
+        <input
+          className="border p-1"
+          placeholder="Item ID"
+          value={itemId}
+          onChange={(e) => setItemId(e.target.value)}
+        />
+        <input
+          className="border p-1"
+          placeholder="Price"
+          type="number"
+          value={price}
+          onChange={(e) => setPrice(e.target.value)}
+        />
+        <button onClick={handleCreate}>List Item</button>
+      </div>
+      <h2 className="text-lg mb-2">Open Listings</h2>
+      <ul className="space-y-2 mb-6">
+        {listings?.map((l) => (
+          <li
+            key={l.id}
+            className="border p-2 flex justify-between"
+            onClick={() => setSelected(l.id)}
+          >
+            <span>
+              {l.item_id} - {l.price ?? 'N/A'} - {l.status}
+            </span>
+            <button onClick={() => handleRequest(l.id)}>Request</button>
+          </li>
+        ))}
+      </ul>
+      {selected && (
+        <div>
+          <h2 className="text-lg mb-2">Requests for {selected}</h2>
+          <ul className="space-y-2">
+            {requests?.map((r) => (
+              <li key={r.id} className="border p-2 flex justify-between">
+                <span>
+                  {r.buyer_id} - {r.status}
+                </span>
+                {r.status === 'pending' && (
+                  <span className="space-x-2 text-sm">
+                    <button onClick={() => accept.mutate(r.id)}>Accept</button>
+                    <button onClick={() => reject.mutate(r.id)}>Reject</button>
+                  </span>
+                )}
+              </li>
+            ))}
+          </ul>
+        </div>
+      )}
+    </div>
+  )
+}
diff --git a/frontend/app/notebook/page.tsx b/frontend/app/notebook/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..0e7d3d6b1af8a586dc3dd433b256ce06abd629ca
--- /dev/null
+++ b/frontend/app/notebook/page.tsx
@@ -0,0 +1,81 @@
+'use client'
+import { useState } from 'react'
+import DynamicForm from '../components/DynamicForm'
+import {
+  useNotebookEntries,
+  useCreateEntry,
+  useUpdateEntry,
+  useDeleteEntry,
+} from '../hooks/useNotebook'
+import type { NotebookEntry } from '../types'
+
+export default function NotebookPage() {
+  const { data: entries } = useNotebookEntries()
+  const create = useCreateEntry()
+  const update = useUpdateEntry()
+  const remove = useDeleteEntry()
+  const [editing, setEditing] = useState<NotebookEntry | null>(null)
+
+  const fields = [
+    {
+      id: 'title',
+      entity_type: 'notebook',
+      field_key: 'title',
+      field_label: 'Title',
+      field_type: 'text',
+      is_required: true,
+    },
+    {
+      id: 'content',
+      entity_type: 'notebook',
+      field_key: 'content',
+      field_label: 'Content',
+      field_type: 'text',
+      is_required: true,
+    },
+  ] as any
+
+  const handleSubmit = (data: any) => {
+    if (editing) {
+      update.mutate({ id: editing.id, data })
+      setEditing(null)
+    } else {
+      create.mutate(data)
+    }
+  }
+
+  return (
+    <div>
+      <h1 className="text-xl mb-4">Lab Notebook</h1>
+      <DynamicForm
+        fields={fields}
+        onSubmit={handleSubmit}
+        defaultValues={editing ? { title: editing.title, content: editing.content } : {}}
+      />
+      {editing && (
+        <button className="text-sm text-gray-600 mt-2" onClick={() => setEditing(null)}>
+          Cancel Edit
+        </button>
+      )}
+      <h2 className="text-lg mt-6 mb-2">Entries</h2>
+      <ul className="space-y-2">
+        {entries?.map((e) => (
+          <li key={e.id} className="border p-2 space-y-1">
+            <div className="flex justify-between items-center">
+              <span className="font-semibold">{e.title}</span>
+              <div className="space-x-2 text-sm">
+                <button className="text-blue-600" onClick={() => setEditing(e)}>
+                  Edit
+                </button>
+                <button className="text-red-600" onClick={() => remove.mutate(e.id)}>
+                  Delete
+                </button>
+              </div>
+            </div>
+            <p className="text-sm whitespace-pre-wrap">{e.content}</p>
+          </li>
+        ))}
+      </ul>
+    </div>
+  )
+}
diff --git a/frontend/app/page.tsx b/frontend/app/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..4d69a39ef2630aab73a0da4eee3d2d52f9b57da3
--- /dev/null
+++ b/frontend/app/page.tsx
@@ -0,0 +1,14 @@
+'use client'
+import { useAuth } from './store/useAuth'
+import Tour from './components/Tour'
+
+export default function Home() {
+  const token = useAuth((s) => s.token)
+  return (
+    <div>
+      <h1 className="text-xl mb-2">BioLabs Frontend</h1>
+      {token ? <p>Logged in!</p> : <p>Please login or register.</p>}
+      <Tour />
+    </div>
+  )
+}
diff --git a/frontend/app/projects/page.tsx b/frontend/app/projects/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..959be6fe783a752fa92e3830b8406042669e582e
--- /dev/null
+++ b/frontend/app/projects/page.tsx
@@ -0,0 +1,66 @@
+'use client'
+import { useState } from 'react'
+import { useProjects, useCreateProject, useProjectTasks, useCreateTask, useUpdateTask, useDeleteTask } from '../hooks/useProjects'
+
+export default function ProjectsPage() {
+  const { data: projects } = useProjects()
+  const createProject = useCreateProject()
+  const [selected, setSelected] = useState<string | null>(null)
+  const { data: tasks } = useProjectTasks(selected ?? '')
+  const createTask = useCreateTask(selected ?? '')
+  const updateTask = useUpdateTask(selected ?? '')
+  const deleteTask = useDeleteTask(selected ?? '')
+
+  const [name, setName] = useState('')
+  const [taskName, setTaskName] = useState('')
+
+  const addProject = () => {
+    createProject.mutate({ name })
+    setName('')
+  }
+
+  const addTask = () => {
+    if (!selected) return
+    createTask.mutate({ name: taskName })
+    setTaskName('')
+  }
+
+  return (
+    <div>
+      <h1 className="text-xl mb-4">Projects</h1>
+      <div className="mb-4">
+        <input className="border p-1 mr-2" value={name} onChange={(e) => setName(e.target.value)} />
+        <button onClick={addProject}>Add Project</button>
+      </div>
+      <ul className="space-y-2 mb-6">
+        {projects?.map((p) => (
+          <li key={p.id} className="border p-2 cursor-pointer" onClick={() => setSelected(p.id)}>
+            {p.name}
+          </li>
+        ))}
+      </ul>
+      {selected && (
+        <div>
+          <h2 className="text-lg mb-2">Tasks</h2>
+          <div className="mb-2">
+            <input className="border p-1 mr-2" value={taskName} onChange={(e) => setTaskName(e.target.value)} />
+            <button onClick={addTask}>Add Task</button>
+          </div>
+          <ul className="space-y-2">
+            {tasks?.map((t) => (
+              <li key={t.id} className="border p-2 flex justify-between">
+                <span>
+                  {t.name} - {t.status}
+                </span>
+                <span className="space-x-2">
+                  <button onClick={() => updateTask.mutate({ id: t.id, data: { status: 'done' } })}>Done</button>
+                  <button onClick={() => deleteTask.mutate(t.id)}>Delete</button>
+                </span>
+              </li>
+            ))}
+          </ul>
+        </div>
+      )}
+    </div>
+  )
+}
diff --git a/frontend/app/protocols/diff/page.tsx b/frontend/app/protocols/diff/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..bd10d6174aab0e5929ae1e9f28d53fcf0b3569f0
--- /dev/null
+++ b/frontend/app/protocols/diff/page.tsx
@@ -0,0 +1,39 @@
+'use client'
+import { useState } from 'react'
+import Link from 'next/link'
+import { useProtocolTemplates, useProtocolDiff } from '../../hooks/useProtocols'
+
+export default function ProtocolDiffPage() {
+  const { data: templates } = useProtocolTemplates()
+  const [oldId, setOldId] = useState('')
+  const [newId, setNewId] = useState('')
+  const { data: diff } = useProtocolDiff(oldId || null, newId || null)
+
+  return (
+    <div>
+      <h1 className="text-xl mb-4">Protocol Diff</h1>
+      <div className="space-x-2">
+        <select value={oldId} onChange={(e) => setOldId(e.target.value)}>
+          <option value="">Old template</option>
+          {templates?.map((t) => (
+            <option key={t.id} value={t.id}>
+              {t.name} v{t.version}
+            </option>
+          ))}
+        </select>
+        <select value={newId} onChange={(e) => setNewId(e.target.value)}>
+          <option value="">New template</option>
+          {templates?.map((t) => (
+            <option key={t.id} value={t.id}>
+              {t.name} v{t.version}
+            </option>
+          ))}
+        </select>
+      </div>
+      {diff && <pre className="whitespace-pre mt-4 bg-gray-100 p-2">{diff}</pre>}
+      <Link href="/protocols" className="text-blue-600 block mt-4">
+        Back to protocols
+      </Link>
+    </div>
+  )
+}
diff --git a/frontend/app/protocols/page.tsx b/frontend/app/protocols/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..8b49a6f54f790a50c153a69beb5ad08eb9e840e1
--- /dev/null
+++ b/frontend/app/protocols/page.tsx
@@ -0,0 +1,143 @@
+'use client'
+import { useState } from 'react'
+import Link from 'next/link'
+import DynamicForm from '../components/DynamicForm'
+import {
+  useProtocolTemplates,
+  useCreateTemplate,
+  useUpdateTemplate,
+  useDeleteTemplate,
+  useProtocolExecutions,
+  useCreateExecution,
+  useUpdateExecution,
+} from '../hooks/useProtocols'
+
+export default function ProtocolsPage() {
+  const { data: templates } = useProtocolTemplates()
+  const { data: executions } = useProtocolExecutions()
+  const createTemplate = useCreateTemplate()
+  const updateTemplate = useUpdateTemplate()
+  const deleteTemplate = useDeleteTemplate()
+  const createExecution = useCreateExecution()
+  const updateExecution = useUpdateExecution()
+  const [showForm, setShowForm] = useState(false)
+  const [editing, setEditing] = useState<string | null>(null)
+
+  const fields = [
+    {
+      id: 'name',
+      entity_type: 'protocol',
+      field_key: 'name',
+      field_label: 'Name',
+      field_type: 'text',
+      is_required: true,
+    },
+    {
+      id: 'content',
+      entity_type: 'protocol',
+      field_key: 'content',
+      field_label: 'Content',
+      field_type: 'text',
+      is_required: true,
+    },
+  ] as any
+
+  const submit = (data: any) => {
+    if (editing) {
+      updateTemplate.mutate({ id: editing, data })
+      setEditing(null)
+    } else {
+      createTemplate.mutate(data)
+    }
+    setShowForm(false)
+  }
+
+  return (
+    <div>
+      <h1 className="text-xl mb-4">Protocols</h1>
+      <Link href="/protocols/diff" className="text-blue-600 underline">
+        Diff Viewer
+      </Link>
+      {showForm ? (
+        <div className="mb-4">
+          <DynamicForm fields={fields} onSubmit={submit} />
+          <button
+            className="text-sm text-gray-600 mt-2"
+            onClick={() => setShowForm(false)}
+          >
+            Cancel
+          </button>
+        </div>
+      ) : (
+        <button className="mb-4 text-blue-600" onClick={() => setShowForm(true)}>
+          New Template
+        </button>
+      )}
+
+      <h2 className="text-lg mb-2">Templates</h2>
+      <ul className="space-y-2">
+        {templates?.map((t) => (
+          <li key={t.id} className="border p-2 space-y-1">
+            <div className="flex justify-between items-center">
+              <span className="font-semibold">
+                {t.name} <span className="text-xs text-gray-600">v{t.version}</span>
+              </span>
+              <div className="space-x-2">
+                <button
+                  className="text-blue-600 text-sm"
+                  onClick={() => createExecution.mutate({ template_id: t.id })}
+                >
+                  Run
+                </button>
+                <button
+                  className="text-sm text-gray-600"
+                  onClick={() => setEditing(t.id)}
+                >
+                  Edit
+                </button>
+                <button
+                  className="text-sm text-red-600"
+                  onClick={() => deleteTemplate.mutate(t.id)}
+                >
+                  Delete
+                </button>
+              </div>
+            </div>
+            <pre className="text-sm whitespace-pre-wrap">{t.content}</pre>
+            {editing === t.id && (
+              <DynamicForm
+                fields={fields}
+                onSubmit={submit}
+                defaultValues={{ name: t.name, content: t.content }}
+              />
+            )}
+          </li>
+        ))}
+      </ul>
+
+      <h2 className="text-lg mt-6 mb-2">Executions</h2>
+      <ul className="space-y-2">
+        {executions?.map((e) => (
+          <li key={e.id} className="border p-2 flex justify-between items-center">
+            <span>
+              {e.template_id.slice(0, 8)}... - {e.status}
+            </span>
+            {e.status !== 'completed' && (
+              <button
+                className="text-blue-600 text-sm"
+                onClick={() =>
+                  updateExecution.mutate({
+                    id: e.id,
+                    data: { status: 'completed', result: { ok: true } },
+                  })
+                }
+              >
+                Mark Complete
+              </button>
+            )}
+          </li>
+        ))}
+      </ul>
+    </div>
+  )
+}
diff --git a/frontend/app/register/page.tsx b/frontend/app/register/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..ea651511fb9175e2b7317fc41e401f375d51ec35
--- /dev/null
+++ b/frontend/app/register/page.tsx
@@ -0,0 +1,50 @@
+'use client'
+import { useState } from 'react'
+import { useRouter } from 'next/navigation'
+import api from '../api/client'
+import { useAuth } from '../store/useAuth'
+
+export default function RegisterPage() {
+  const [email, setEmail] = useState('')
+  const [password, setPassword] = useState('')
+  const router = useRouter()
+  const setToken = useAuth((s) => s.setToken)
+
+  const submit = async (e: React.FormEvent) => {
+    e.preventDefault()
+    try {
+      const resp = await api.post('/api/auth/register', { email, password })
+      const token = resp.data.access_token
+      localStorage.setItem('token', token)
+      setToken(token)
+      router.push('/')
+    } catch (err) {
+      console.error(err)
+      alert('Registration failed')
+    }
+  }
+
+  return (
+    <div className="p-4 max-w-sm mx-auto">
+      <h1 className="text-xl mb-4">Register</h1>
+      <form onSubmit={submit} className="space-y-2">
+        <input
+          className="border p-2 w-full"
+          placeholder="Email"
+          value={email}
+          onChange={(e) => setEmail(e.target.value)}
+        />
+        <input
+          className="border p-2 w-full"
+          type="password"
+          placeholder="Password"
+          value={password}
+          onChange={(e) => setPassword(e.target.value)}
+        />
+        <button className="bg-blue-500 text-white px-4 py-2" type="submit">
+          Register
+        </button>
+      </form>
+    </div>
+  )
+}
diff --git a/frontend/app/search/page.tsx b/frontend/app/search/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..b7005712309b115595779e788562a7a114b1a9c4
--- /dev/null
+++ b/frontend/app/search/page.tsx
@@ -0,0 +1,29 @@
+'use client'
+import { useState } from 'react'
+import { useSearchItems } from '../hooks/useSearch'
+import Link from 'next/link'
+
+export default function SearchPage() {
+  const [query, setQuery] = useState('')
+  const { data } = useSearchItems(query)
+
+  return (
+    <div>
+      <h1 className="text-xl font-bold mb-2">Search Inventory</h1>
+      <input
+        className="border p-2 mr-2"
+        value={query}
+        onChange={(e) => setQuery(e.target.value)}
+        placeholder="Search by name"
+      />
+      <ul className="mt-4 space-y-2">
+        {data?.map((item) => (
+          <li key={item.id} className="border p-2">
+            <Link href={`/inventory/${item.id}`}>{item.name}</Link>
+          </li>
+        ))}
+      </ul>
+    </div>
+  )
+}
+
diff --git a/frontend/app/sequence/blast/page.tsx b/frontend/app/sequence/blast/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..dea8c39c846cb1113058a933448f3bb4e5740264
--- /dev/null
+++ b/frontend/app/sequence/blast/page.tsx
@@ -0,0 +1,56 @@
+'use client'
+import { useState } from 'react'
+import { useBlastSearch } from '../../hooks/useSequence'
+import type { BlastResult } from '../../types'
+
+export default function BlastPage() {
+  const blast = useBlastSearch()
+  const [query, setQuery] = useState('')
+  const [subject, setSubject] = useState('')
+  const [result, setResult] = useState<BlastResult | null>(null)
+
+  const handleSubmit = (e: React.FormEvent<HTMLFormElement>) => {
+    e.preventDefault()
+    blast.mutate({ query, subject }, { onSuccess: setResult })
+  }
+
+  return (
+    <div>
+      <h1 className="text-xl mb-4">BLAST Search</h1>
+      <form onSubmit={handleSubmit} className="space-y-2 mb-4">
+        <div>
+          <label className="block font-semibold mb-1">Query Sequence</label>
+          <textarea
+            value={query}
+            onChange={(e) => setQuery(e.target.value)}
+            className="border p-1 w-full"
+            rows={4}
+          />
+        </div>
+        <div>
+          <label className="block font-semibold mb-1">Subject Sequence</label>
+          <textarea
+            value={subject}
+            onChange={(e) => setSubject(e.target.value)}
+            className="border p-1 w-full"
+            rows={4}
+          />
+        </div>
+        <button type="submit" className="bg-blue-500 text-white px-2 py-1">
+          Search
+        </button>
+      </form>
+      {result && (
+        <div className="text-sm mt-4">
+          <p>Score: {result.score.toFixed(2)}</p>
+          <p>Identity: {result.identity.toFixed(2)}%</p>
+          <pre className="whitespace-pre-wrap break-all mt-2">
+            {result.query_aligned}
+            {'\n'}
+            {result.subject_aligned}
+          </pre>
+        </div>
+      )}
+    </div>
+  )
+}
diff --git a/frontend/app/sequence/chromatogram/page.tsx b/frontend/app/sequence/chromatogram/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..1a435945b3de11ef2c4dee38410a4351db2c68e2
--- /dev/null
+++ b/frontend/app/sequence/chromatogram/page.tsx
@@ -0,0 +1,30 @@
+'use client'
+import { useState } from 'react'
+import { useChromatogram } from '../../hooks/useSequence'
+import ChromatogramPlot from '../../components/ChromatogramPlot'
+import type { ChromatogramData } from '../../types'
+
+export default function ChromatogramPage() {
+  const parse = useChromatogram()
+  const [data, setData] = useState<ChromatogramData | null>(null)
+
+  const handleFile = (e: React.ChangeEvent<HTMLInputElement>) => {
+    const file = e.target.files?.[0]
+    if (!file) return
+    parse.mutate(file, { onSuccess: setData })
+  }
+
+  return (
+    <div>
+      <h1 className="text-xl mb-4">Sanger Chromatogram</h1>
+      <input type="file" onChange={handleFile} accept=".ab1" />
+      {data && (
+        <div className="mt-4 space-y-4">
+          <p>Sequence length: {data.sequence.length}</p>
+          <pre className="whitespace-pre-wrap break-all">{data.sequence.slice(0,200)}</pre>
+          <ChromatogramPlot data={data} height={150} />
+        </div>
+      )}
+    </div>
+  )
+}
diff --git a/frontend/app/sequence/jobs/page.tsx b/frontend/app/sequence/jobs/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..0951511b85b6fc1dffb96917a9bbb6116cd51b23
--- /dev/null
+++ b/frontend/app/sequence/jobs/page.tsx
@@ -0,0 +1,57 @@
+'use client'
+import { useState } from 'react'
+import { useCreateSequenceJob, useSequenceJobs } from '../../hooks/useSequence'
+import type { SequenceJob } from '../../types'
+
+export default function SequenceJobsPage() {
+  const [file, setFile] = useState<File | null>(null)
+  const [format, setFormat] = useState('fasta')
+  const create = useCreateSequenceJob()
+  const { data: jobs } = useSequenceJobs()
+
+  const handleSubmit = (e: React.FormEvent<HTMLFormElement>) => {
+    e.preventDefault()
+    if (!file) return
+    create.mutate({ file, format })
+  }
+
+  return (
+    <div>
+      <h1 className="text-xl mb-4">Sequence Analysis Jobs</h1>
+      <form onSubmit={handleSubmit} className="space-y-2 mb-4">
+        <input
+          type="file"
+          accept=".fasta,.fastq"
+          onChange={(e) => setFile(e.target.files?.[0] || null)}
+        />
+        <select value={format} onChange={(e) => setFormat(e.target.value)} className="border p-1">
+          <option value="fasta">FASTA</option>
+          <option value="fastq">FASTQ</option>
+        </select>
+        <button type="submit" className="bg-blue-500 text-white px-2 py-1">Submit</button>
+      </form>
+      {jobs && jobs.length > 0 && (
+        <table className="table-auto border-collapse text-sm">
+          <thead>
+            <tr>
+              <th className="border px-2">ID</th>
+              <th className="border px-2">Status</th>
+              <th className="border px-2">Format</th>
+              <th className="border px-2">Created</th>
+            </tr>
+          </thead>
+          <tbody>
+            {jobs.map((j: SequenceJob) => (
+              <tr key={j.id}>
+                <td className="border px-2">{j.id.slice(0, 8)}</td>
+                <td className="border px-2">{j.status}</td>
+                <td className="border px-2">{j.format}</td>
+                <td className="border px-2">{new Date(j.created_at).toLocaleString()}</td>
+              </tr>
+            ))}
+          </tbody>
+        </table>
+      )}
+    </div>
+  )
+}
diff --git a/frontend/app/sequence/page.tsx b/frontend/app/sequence/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..572407335d39c8862af8cf8ac1bbdc8a34fe6579
--- /dev/null
+++ b/frontend/app/sequence/page.tsx
@@ -0,0 +1,49 @@
+'use client'
+import { useState } from 'react'
+import { useAnnotateSequence } from '../hooks/useSequence'
+import type { SequenceFeature } from '../types'
+
+export default function SequencePage() {
+  const annotate = useAnnotateSequence()
+  const [features, setFeatures] = useState<SequenceFeature[] | null>(null)
+
+  const handleFile = (e: React.ChangeEvent<HTMLInputElement>) => {
+    const file = e.target.files?.[0]
+    if (!file) return
+    annotate.mutate(file, {
+      onSuccess: (data) => setFeatures(data),
+    })
+  }
+
+  return (
+    <div>
+      <h1 className="text-xl mb-4">Sequence Annotation</h1>
+      <p className="mb-2 space-x-4">
+        <a href="/sequence/chromatogram" className="underline text-blue-600">Sanger chromatogram tool</a>
+        <a href="/sequence/blast" className="underline text-blue-600">BLAST search tool</a>
+        <a href="/sequence/jobs" className="underline text-blue-600">Analysis jobs</a>
+      </p>
+      <input type="file" onChange={handleFile} accept=".gb,.gbk" />
+      {features && (
+        <table className="mt-4 table-auto border-collapse">
+          <thead>
+            <tr>
+              <th className="border px-2">Type</th>
+              <th className="border px-2">Start</th>
+              <th className="border px-2">End</th>
+            </tr>
+          </thead>
+          <tbody>
+            {features.map((f, idx) => (
+              <tr key={idx}>
+                <td className="border px-2">{f.type}</td>
+                <td className="border px-2 text-right">{f.start}</td>
+                <td className="border px-2 text-right">{f.end}</td>
+              </tr>
+            ))}
+          </tbody>
+        </table>
+      )}
+    </div>
+  )
+}
diff --git a/frontend/app/store/useAuth.ts b/frontend/app/store/useAuth.ts
new file mode 100644
index 0000000000000000000000000000000000000000..bf280d44cdddcb675bc2965c7e57b16a71d97612
--- /dev/null
+++ b/frontend/app/store/useAuth.ts
@@ -0,0 +1,12 @@
+'use client'
+import { create } from 'zustand'
+
+interface AuthState {
+  token: string | null
+  setToken: (token: string | null) => void
+}
+
+export const useAuth = create<AuthState>((set) => ({
+  token: null,
+  setToken: (token) => set({ token })
+}))
diff --git a/frontend/app/styles/globals.css b/frontend/app/styles/globals.css
new file mode 100644
index 0000000000000000000000000000000000000000..b5c61c956711f981a41e95f7fcf0038436cfbb22
--- /dev/null
+++ b/frontend/app/styles/globals.css
@@ -0,0 +1,3 @@
+@tailwind base;
+@tailwind components;
+@tailwind utilities;
diff --git a/frontend/app/troubleshooting/page.tsx b/frontend/app/troubleshooting/page.tsx
new file mode 100644
index 0000000000000000000000000000000000000000..ff4bcdd86f8b556c9d3e5929d83c008d8106f7a1
--- /dev/null
+++ b/frontend/app/troubleshooting/page.tsx
@@ -0,0 +1,104 @@
+'use client'
+import { useState } from 'react'
+import {
+  useArticles,
+  useCreateArticle,
+  useUpdateArticle,
+  useMarkSuccess,
+} from '../hooks/useTroubleshooting'
+import DynamicForm from '../components/DynamicForm'
+import type { TroubleshootingArticle } from '../types'
+
+export default function TroubleshootingPage() {
+  const [category, setCategory] = useState('')
+  const { data: articles } = useArticles(category || undefined)
+  const create = useCreateArticle()
+  const update = useUpdateArticle()
+  const mark = useMarkSuccess()
+  const [editing, setEditing] = useState<TroubleshootingArticle | null>(null)
+
+  const fields = [
+    {
+      id: 'title',
+      entity_type: 'troubleshooting',
+      field_key: 'title',
+      field_label: 'Title',
+      field_type: 'text',
+      is_required: true,
+    },
+    {
+      id: 'category',
+      entity_type: 'troubleshooting',
+      field_key: 'category',
+      field_label: 'Category',
+      field_type: 'text',
+      is_required: true,
+    },
+    {
+      id: 'content',
+      entity_type: 'troubleshooting',
+      field_key: 'content',
+      field_label: 'Content',
+      field_type: 'text',
+      is_required: true,
+    },
+  ] as any
+
+  const handleSubmit = (data: any) => {
+    if (editing) {
+      update.mutate({ id: editing.id, data })
+      setEditing(null)
+    } else {
+      create.mutate(data)
+    }
+  }
+
+  return (
+    <div>
+      <h1 className="text-xl mb-4">Troubleshooting</h1>
+      <div className="mb-4 flex gap-2 items-center">
+        <label>Category</label>
+        <input
+          className="border p-1"
+          value={category}
+          onChange={(e) => setCategory(e.target.value)}
+        />
+      </div>
+      <DynamicForm
+        fields={fields}
+        onSubmit={handleSubmit}
+        defaultValues={
+          editing
+            ? { title: editing.title, category: editing.category, content: editing.content }
+            : {}
+        }
+      />
+      {editing && (
+        <button className="text-sm text-gray-600 mt-2" onClick={() => setEditing(null)}>
+          Cancel Edit
+        </button>
+      )}
+      <h2 className="text-lg mt-6 mb-2">Articles</h2>
+      <ul className="space-y-2">
+        {articles?.map((a) => (
+          <li key={a.id} className="border p-2 space-y-1">
+            <div className="flex justify-between items-center">
+              <span className="font-semibold">
+                {a.title} <span className="text-xs text-gray-600">({a.category})</span>
+              </span>
+              <div className="space-x-2 text-sm">
+                <button className="text-blue-600" onClick={() => setEditing(a)}>
+                  Edit
+                </button>
+                <button className="text-green-600" onClick={() => mark.mutate(a.id)}>
+                  Mark Success ({a.success_count})
+                </button>
+              </div>
+            </div>
+            <p className="text-sm">{a.content}</p>
+          </li>
+        ))}
+      </ul>
+    </div>
+  )
+}
diff --git a/frontend/app/types.ts b/frontend/app/types.ts
new file mode 100644
index 0000000000000000000000000000000000000000..f18bcac7890fca2558bc9fb1ab7d3ccafc1e01e0
--- /dev/null
+++ b/frontend/app/types.ts
@@ -0,0 +1,292 @@
+export interface InventoryItem {
+  id: string
+  item_type: string
+  name: string
+  barcode?: string
+  team_id?: string
+  owner_id?: string
+  location: Record<string, any>
+  custom_data: Record<string, any>
+  created_at: string
+  updated_at: string
+}
+
+export interface FieldOption {
+  value: string
+  label: string
+}
+
+export interface FieldDefinition {
+  id: string
+  entity_type: string
+  field_key: string
+  field_label: string
+  field_type: 'text' | 'number' | 'date' | 'select'
+  is_required: boolean
+  options?: FieldOption[]
+  validation?: Record<string, any>
+}
+
+export interface FileMeta {
+  id: string
+  filename: string
+  file_type: string
+  file_size: number
+  storage_path: string
+  item_id: string
+  uploaded_by: string
+  created_at: string
+}
+
+export interface GraphEdge {
+  id: string
+  from_item: string
+  to_item: string
+  relationship_type: string
+  meta: Record<string, any>
+}
+
+export interface GraphData {
+  nodes: InventoryItem[]
+  edges: GraphEdge[]
+}
+
+export interface TroubleshootingArticle {
+  id: string
+  title: string
+  category: string
+  content: string
+  created_by?: string
+  success_count: number
+  created_at: string
+  updated_at: string
+}
+
+export interface KnowledgeArticle {
+  id: string
+  title: string
+  content: string
+  tags?: string[]
+  created_by?: string
+  created_at: string
+  updated_at: string
+}
+
+export interface ProtocolTemplate {
+  id: string
+  name: string
+  content: string
+  version: string
+  team_id?: string
+  created_by?: string
+  created_at: string
+  updated_at: string
+}
+
+export interface ProtocolExecution {
+  id: string
+  template_id: string
+  run_by?: string
+  status: string
+  params: Record<string, any>
+  result: Record<string, any>
+  created_at: string
+  updated_at: string
+}
+
+export interface NotebookEntry {
+  id: string
+  title: string
+  content: string
+  item_id?: string | null
+  execution_id?: string | null
+  created_by?: string
+  created_at: string
+  updated_at: string
+}
+
+export interface Comment {
+  id: string
+  content: string
+  item_id?: string | null
+  entry_id?: string | null
+  created_by?: string
+  created_at: string
+  updated_at: string
+}
+
+export interface SequenceFeature {
+  record_id: string
+  type: string
+  start: number
+  end: number
+  strand: number | null
+  qualifiers: Record<string, string[]>
+}
+
+export interface ChromatogramData {
+  sequence: string
+  traces: Record<string, number[]>
+}
+
+export interface SequenceRead {
+  id: string
+  seq: string
+  length: number
+  gc_content: number
+}
+
+export interface BlastResult {
+  query_aligned: string
+  subject_aligned: string
+  score: number
+  identity: number
+}
+
+export interface SequenceJob {
+  id: string
+  status: string
+  format: string
+  result: SequenceRead[] | null
+  created_at: string
+  updated_at: string
+}
+
+export interface AssistantMessage {
+  id: string
+  is_user: boolean
+  message: string
+  created_at: string
+}
+
+export interface Project {
+  id: string
+  name: string
+  description?: string
+  start_date?: string
+  end_date?: string
+  team_id?: string
+  created_by?: string
+  created_at: string
+  updated_at: string
+}
+
+export interface ProjectTask {
+  id: string
+  project_id: string
+  name: string
+  description?: string
+  due_date?: string
+  status: string
+  created_by?: string
+  created_at: string
+  updated_at: string
+}
+
+export interface ItemTypeCount {
+  item_type: string
+  count: number
+}
+
+export interface ComplianceRecord {
+  id: string
+  item_id?: string | null
+  user_id?: string | null
+  record_type: string
+  status: string
+  notes?: string | null
+  created_at: string
+}
+
+export interface StatusCount {
+  status: string
+  count: number
+}
+
+export interface CalendarEvent {
+  id: string
+  title: string
+  start_time: string
+  end_time: string
+  description?: string | null
+  team_id?: string | null
+  user_id?: string | null
+  created_by?: string | null
+  created_at: string
+}
+
+export interface Lab {
+  id: string
+  name: string
+  description?: string | null
+  owner_id?: string | null
+  created_at: string
+}
+
+export interface LabConnection {
+  id: string
+  from_lab: string
+  to_lab: string
+  status: string
+  created_at: string
+}
+
+export interface MarketplaceListing {
+  id: string
+  item_id: string
+  seller_id: string
+  price?: number | null
+  description?: string | null
+  status: string
+  created_at: string
+}
+
+export interface MarketplaceRequest {
+  id: string
+  listing_id: string
+  buyer_id: string
+  message?: string | null
+  status: string
+  created_at: string
+}
+
+export interface Post {
+  id: string
+  user_id: string
+  content: string
+  created_at: string
+}
+
+export interface Follow {
+  follower_id: string
+  followed_id: string
+  created_at: string
+}
+export interface TrendingProtocol {
+  template_id: string
+  template_name: string
+  count: number
+}
+
+export interface TrendingArticle {
+  article_id: string
+  title: string
+  count: number
+}
+
+export interface TrendingItem {
+  item_id: string
+  name: string
+  count: number
+}
+
+export interface TrendingThread {
+  thread_id: string
+  title: string
+  count: number
+}
+
+
+export interface ProtocolDiff {
+  diff: string
+}
diff --git a/frontend/e2e/basic.spec.ts b/frontend/e2e/basic.spec.ts
new file mode 100644
index 0000000000000000000000000000000000000000..38b02b0adbbafe382a1b4d20b1445630dc71603d
--- /dev/null
+++ b/frontend/e2e/basic.spec.ts
@@ -0,0 +1,21 @@
+import { test, expect } from '@playwright/test';
+
+const user = {
+  email: 'testuser@example.com',
+  password: 'password123'
+};
+
+test('register and login', async ({ page }) => {
+  await page.goto('/register');
+  await page.getByPlaceholder('Email').fill(user.email);
+  await page.getByPlaceholder('Password').fill(user.password);
+  await page.click('button[type="submit"]');
+  await page.waitForURL('/');
+  await page.click('text=Logout');
+
+  await page.goto('/login');
+  await page.getByPlaceholder('Email').fill(user.email);
+  await page.getByPlaceholder('Password').fill(user.password);
+  await page.click('button[type="submit"]');
+  await expect(page).toHaveURL('/');
+});
diff --git a/frontend/next-env.d.ts b/frontend/next-env.d.ts
new file mode 100644
index 0000000000000000000000000000000000000000..4f11a03dc6cc37f2b5105c08f2e7b24c603ab2f4
--- /dev/null
+++ b/frontend/next-env.d.ts
@@ -0,0 +1,5 @@
+/// <reference types="next" />
+/// <reference types="next/image-types/global" />
+
+// NOTE: This file should not be edited
+// see https://nextjs.org/docs/basic-features/typescript for more information.
diff --git a/frontend/next.config.js b/frontend/next.config.js
new file mode 100644
index 0000000000000000000000000000000000000000..2113e18aff8132656838219b0259e1d908b1a1ea
--- /dev/null
+++ b/frontend/next.config.js
@@ -0,0 +1,8 @@
+/** @type {import('next').NextConfig} */
+const nextConfig = {
+  experimental: {
+    appDir: true
+  }
+}
+
+module.exports = nextConfig
diff --git a/frontend/package.json b/frontend/package.json
new file mode 100644
index 0000000000000000000000000000000000000000..8a5bf5c3390ff0f5ac7821377b57cf12afc2d2b7
--- /dev/null
+++ b/frontend/package.json
@@ -0,0 +1,29 @@
+{
+  "name": "biolabs-frontend",
+  "private": true,
+  "version": "0.1.0",
+  "scripts": {
+    "dev": "next dev",
+    "build": "next build",
+    "start": "next start",
+    "test:e2e": "playwright test"
+  },
+  "dependencies": {
+    "next": "14.1.0",
+    "react": "18.2.0",
+    "react-dom": "18.2.0",
+    "axios": "^1.6.7",
+    "zustand": "^4.3.9",
+    "@tanstack/react-query": "^5.22.0",
+    "react-hook-form": "^7.50.0",
+    "zod": "^3.22.4",
+    "@hookform/resolvers": "^3.3.4",
+    "d3": "^7.8.5"
+  },
+  "devDependencies": {
+    "autoprefixer": "^10.4.15",
+    "postcss": "^8.4.24",
+    "tailwindcss": "^3.4.1",
+    "@playwright/test": "^1.41.2"
+  }
+}
diff --git a/frontend/playwright.config.ts b/frontend/playwright.config.ts
new file mode 100644
index 0000000000000000000000000000000000000000..762b60d0c27be1a1bb1391fccde5d56d5a4d2499
--- /dev/null
+++ b/frontend/playwright.config.ts
@@ -0,0 +1,17 @@
+import type { PlaywrightTestConfig } from '@playwright/test';
+
+const config: PlaywrightTestConfig = {
+  testDir: './e2e',
+  webServer: {
+    command: 'npm run dev',
+    port: 3000,
+    reuseExistingServer: !process.env.CI,
+    timeout: 120 * 1000,
+  },
+  use: {
+    baseURL: 'http://localhost:3000',
+    headless: true,
+  },
+};
+
+export default config;
diff --git a/frontend/postcss.config.js b/frontend/postcss.config.js
new file mode 100644
index 0000000000000000000000000000000000000000..33ad091d26d8a9dc95ebdf616e217d985ec215b8
--- /dev/null
+++ b/frontend/postcss.config.js
@@ -0,0 +1,6 @@
+module.exports = {
+  plugins: {
+    tailwindcss: {},
+    autoprefixer: {},
+  },
+}
diff --git a/frontend/tailwind.config.js b/frontend/tailwind.config.js
new file mode 100644
index 0000000000000000000000000000000000000000..eb9f31a082108d62526b712ccd5718cfe51b37a7
--- /dev/null
+++ b/frontend/tailwind.config.js
@@ -0,0 +1,11 @@
+/** @type {import('tailwindcss').Config} */
+module.exports = {
+  content: [
+    './app/**/*.{ts,tsx}',
+    './components/**/*.{ts,tsx}'
+  ],
+  theme: {
+    extend: {}
+  },
+  plugins: []
+}
diff --git a/frontend/tsconfig.json b/frontend/tsconfig.json
new file mode 100644
index 0000000000000000000000000000000000000000..b4c238b5813bb10c638cf523a5ec4719ce1fb329
--- /dev/null
+++ b/frontend/tsconfig.json
@@ -0,0 +1,36 @@
+{
+  "compilerOptions": {
+    "target": "esnext",
+    "lib": [
+      "dom",
+      "dom.iterable",
+      "esnext"
+    ],
+    "allowJs": true,
+    "skipLibCheck": true,
+    "strict": true,
+    "forceConsistentCasingInFileNames": true,
+    "noEmit": true,
+    "esModuleInterop": true,
+    "module": "esnext",
+    "moduleResolution": "bundler",
+    "resolveJsonModule": true,
+    "isolatedModules": true,
+    "jsx": "preserve",
+    "incremental": true,
+    "plugins": [
+      {
+        "name": "next"
+      }
+    ]
+  },
+  "include": [
+    "next-env.d.ts",
+    "**/*.ts",
+    "**/*.tsx",
+    ".next/types/**/*.ts"
+  ],
+  "exclude": [
+    "node_modules"
+  ]
+}
diff --git a/progress.md b/progress.md
new file mode 100644
index 0000000000000000000000000000000000000000..35bf3a0996a0ddd051173f08bc7525c236422fcd
--- /dev/null
+++ b/progress.md
@@ -0,0 +1,530 @@
+# Progress Log
+
+## 2025-07-02
+- Initialized progress log.
+
+## 2025-07-02
+- Added progress tracking file
+- Implemented improved validation logic in DynamicForm
+- Added update and delete hooks for inventory items
+- Inventory page now supports editing and deleting items
+
+## 2025-07-02
+- Started integrating file uploads and relationship graphs in the frontend
+- Created hooks for fetching files and graphs
+- Added D3-based Graph component and item detail page with upload form
+- Linked inventory list to item detail pages
+
+## 2025-07-02
+- Implemented websocket endpoint and Redis pubsub for real-time item updates
+- Added item event publishing on create, update, and delete
+- Created websocket test using fakeredis
+
+## 2025-07-02
+- Implemented protocol template model and CRUD routes
+- Added tests for protocol template creation and versioning
+- Updated API main router to include protocols
+
+## 2025-07-02
+- Added protocol execution tracking model and CRUD endpoints
+- Created tests covering execution creation, listing, and updates
+- Updated project plan to focus on troubleshooting system next
+
+## 2025-07-02
+- Implemented troubleshooting article model and API endpoints
+- Added tests for creating, updating, and marking troubleshooting articles
+
+## 2025-07-02
+- Added troubleshooting page with article list and form
+- Created hooks for managing articles
+- Navigation updated to link to troubleshooting section
+
+## 2025-07-02
+- Implemented protocol templates and executions UI
+- Added React hooks for protocols
+- Navigation includes a link to the new Protocols page
+- Updated plan marking troubleshooting UI complete
+
+## 2025-07-02
+- Added update and delete endpoints for protocol templates
+- Extended tests to cover template updates and removal
+- Protocols page now supports editing and deleting templates inline
+- Updated plan to mark protocol UI as finished
+
+## 2025-07-02
+- Implemented lab notebook backend module
+- Added NotebookEntry model and CRUD API routes
+- Created schemas and integrated router into main app
+- Wrote tests covering create, update, and delete of notebook entries
+- Updated project plan to start frontend work next
+## 2025-07-02
+- Implemented lab notebook frontend with CRUD UI and hooks
+- Added Notebook page link to navigation
+- Updated frontend README with Notebook notes
+- Updated plan to start collaboration features
+
+## 2025-07-02
+- Added comment system for collaboration
+- Implemented CRUD API and frontend hooks
+- Added comments page and navigation link
+
+## 2025-07-02
+- Started resource scheduling system
+- Added Resource and Booking models with conflict detection
+- Implemented schedule API routes for resources and bookings
+- Registered new router in FastAPI app
+- Created tests for booking conflicts
+- Updated project plan to reflect scheduling work
+## 2025-07-02
+- Integrated scheduling with basic notification system
+- Added Notification model and API for listing and marking notifications
+- Booking creation now sends notifications to resource owners
+- Created tests for notification workflow and updated router imports
+
+## 2025-07-02
+- Implemented notification preferences model and API
+- Booking notifications respect user preferences
+- Added tests for preference workflow
+- Updated project plan with completed preference center
+## 2025-07-02
+- Expanded notifications to support email and SMS channels
+- Added channel field to notification preferences and updated API
+- Booking creation now sends email and SMS alerts based on preferences
+- Implemented simple email/SMS sender with in-memory outbox for tests
+- Updated plan marking channel expansion complete
+
+## 2025-07-02
+- Implemented daily digest function aggregating unread notifications
+- Added `last_digest` field to users
+- Added test covering digest email content
+- Updated project plan marking digest complete
+
+## 2025-07-02
+- Added user profile API with ORCID field
+- Created /api/users/me endpoints for retrieving and updating profile
+- Added tests covering profile workflow
+- Updated project plan with new user profile feature
+
+## 2025-07-02
+- Implemented sequence analysis endpoint using BioPython
+- Added SequenceRead schema and tests for FASTA parsing
+- Updated main app and router imports to include sequence module
+- Project plan updated marking sequence utilities complete
+
+## 2025-07-02
+- Added Celery task queue for asynchronous sequence analysis
+- Created SequenceAnalysisJob model and API endpoints
+- Tests ensure jobs execute and results are stored
+- Updated project plan with new async analysis feature
+
+## 2025-07-02
+- Added sequence alignment endpoint using Biopython pairwise2
+- Created schemas for alignment input and output
+- Added tests covering alignment API
+- Updated project plan with alignment feature and primer design as next step
+
+## 2025-07-02
+- Implemented primer design endpoint using simple algorithm
+- Added PrimerDesign schemas and route
+- Updated tests to cover primer design
+- Updated project plan marking primer design complete
+
+## 2025-07-02
+- Implemented restriction mapping endpoint using Biopython Restriction module
+- Added sequence annotation endpoint parsing GenBank features
+- Created Sequence page in frontend with upload and feature table
+- Project plan updated marking annotation tools complete
+
+## 2025-07-02
+- Added chromatogram parsing helper using Biopython AbiIO
+- Exposed `/api/sequence/chromatogram` endpoint returning sequence and trace data
+- Added React hook and page for uploading AB1 files
+- Created gzip-compressed test fixture for AB1 parsing
+- Updated project plan with chromatogram work in progress
+
+## 2025-07-02
+- Built D3-based `ChromatogramPlot` component for visualizing trace data
+- Updated chromatogram page to display sequence and plot
+- Added types and hooks for chromatogram results
+- Project plan moved viewer task to completed
+
+## 2025-07-02
+- Added endpoint to download files and parse chromatograms from stored files
+- Item detail page lists files with preview using `ChromatogramPlot`
+- New React hook fetches chromatogram data for a file
+- Project plan updated marking viewer integration complete
+
+## 2025-07-02
+- Added sequence preview endpoint for FASTA/FASTQ files
+- Implemented hook and UI to display sequence previews on item page
+- Updated project plan marking FASTA/FASTQ previews complete
+
+## 2025-07-02
+- Implemented BLAST search endpoint using local alignment
+- Added schemas and tests for BLAST search API
+- Updated plan with BLAST completion and frontend integration as next step
+
+## 2025-07-02
+- Created `useBlastSearch` React hook and BLAST page
+- Linked BLAST page from Sequence tools
+- Updated plan marking BLAST frontend complete and queued job status UI next
+## 2025-07-02
+- Added job listing endpoint and tests for sequence analysis jobs
+- Created React hooks for submitting and listing jobs
+- Added Sequence Jobs page and link from sequence tools
+- Updated project plan marking job status UI complete
+
+## 2025-07-02
+- Implemented project management module with CRUD API and item linking
+- Added calendar events API for teams and users
+- Created pluggable analysis tool system with simple Python scripts
+- Added corresponding tests for projects, calendar, and tools
+- Updated main router and plan to track new features
+
+
+## 2025-07-02
+- Finalized calendar events and analysis tools features
+- Introduced lab buddy assistant with simple AI responses
+- Assistant stores conversation history per user
+- Added `/api/assistant` endpoints and tests
+- Updated project plan and router imports accordingly
+
+## 2025-07-02
+- Added assistant hooks and chat page in the frontend
+- Navigation now links to the Assistant page
+- Updated plan marking assistant integration complete
+
+## 2025-07-02
+- Implemented search module with optional Elasticsearch integration
+- Added /api/search/items endpoint and router
+- Indexed items on creation via fallback DB search
+- Added tests for search functionality
+
+## 2025-07-02
+- Added `/api/inventory/export` endpoint returning CSV
+- Added test covering CSV export
+- Updated plan with CSV export completion and barcode generation next
+
+## 2025-07-02
+- Added barcode utilities using python-barcode
+- New `/api/inventory/items/{id}/barcode` route returns PNG and stores unique code
+- Added test for barcode generation
+- Updated requirements and project plan
+
+## 2025-07-02
+- Added CSV import endpoint allowing bulk item creation via uploaded files
+- Updated tests to cover import functionality
+- Project plan records import completion and starts 2FA work
+
+## 2025-07-02
+- Implemented two-factor authentication with TOTP
+- Added `/api/auth/enable-2fa` and `/api/auth/verify-2fa` endpoints
+- Login now requires OTP code when 2FA is enabled
+- Added pyotp dependency and tests covering the 2FA flow
+- Updated project plan to mark 2FA done and start password reset feature
+
+## 2025-07-02
+- Implemented password reset flow with email tokens
+- Added `/api/auth/request-password-reset` and `/api/auth/reset-password` endpoints
+- Created `PasswordResetToken` model and schemas
+- Tests verify requesting and completing a reset updates the password
+- Updated PLAN.md moving password reset to completed and starting audit logging
+
+## 2025-07-02
+- Added `AuditLog` model and API for listing logs
+- Created `log_action` helper and recorded events for registration, login, and inventory modifications
+- Updated inventory and auth routes to log actions
+- Added tests covering audit log creation during item creation
+- Updated PLAN.md marking audit logging complete
+
+## 2025-07-02
+- Implemented analytics summary endpoint returning counts by item type
+- Added analytics router and test suite
+- Created React hook, bar chart component, and analytics page
+- Updated PLAN.md with analytics completion and equipment integration next
+
+## 2025-07-02
+- Added Equipment and EquipmentReading models
+- Implemented equipment API for creating devices, updating status, and logging readings
+- Created tests covering equipment workflow
+- Registered new router and updated PLAN.md with next step
+
+## 2025-07-03
+- Implemented external service connector for PubMed search
+- Added `/api/external/pubmed` endpoint and schemas
+- Created tests mocking the PubMed API
+- Updated PLAN.md marking external connectors done and planning compliance dashboard next
+
+## 2025-07-03
+- Added ComplianceRecord model and API endpoints for creating, updating, and listing records
+- Implemented compliance summary endpoint returning counts by status
+- Created React hooks and Compliance page displaying records and summary
+- Updated PLAN.md moving compliance dashboard to completed and starting audit report generator
+
+## 2025-07-03
+- Implemented audit report generator returning action counts over a date range
+- Added `/api/audit/report` endpoint and tests
+- Updated PLAN.md marking audit report generator complete
+
+## 2025-07-03
+- Added notebook export endpoint returning PDF files
+- Implemented FPDF-based helper and route `/api/notebook/entries/{id}/export`
+- Created tests verifying PDF export works
+- Updated requirements with fpdf2 and documented progress in PLAN.md
+## 2025-07-03
+- Added Dockerfile for backend and frontend with production builds
+- Created docker-compose.yml to run Postgres, Redis, MinIO, backend, and frontend
+- Updated README with Docker usage instructions
+- Added GitHub Actions workflow for running backend tests
+- Documented containerization progress in PLAN.md
+
+## 2025-07-03
+- Added Playwright configuration and basic register/login test
+- Updated frontend package.json with Playwright dependency and npm script
+- Documented E2E testing workflow in README
+- Updated PLAN.md marking Playwright tests complete
+## 2025-07-03
+- Added locust-based benchmarking script under `backend/benchmarks`
+- Declared `locust` dependency in backend requirements
+- Documented performance benchmarking in README
+- Updated PLAN.md marking benchmarking complete and starting UI/UX refinements
+## 2025-07-03
+- Started UI/UX refinement sprint focusing on accessibility and onboarding
+- Added responsive navigation menu with mobile toggle and skip link
+- Implemented loading and error states on the inventory page using a new Spinner component
+- Created a simple onboarding tour that appears on first visit to the home page
+## 2025-07-03
+- Implemented Prometheus metrics middleware and /metrics endpoint
+- Integrated Sentry error tracking via environment variable
+- Added daily backup task with Celery beat and tests for metrics and backups
+- Extended docker-compose with Prometheus and Grafana services
+- Documented monitoring setup in README and updated PLAN.md
+## 2025-07-04
+- Created `tools.md` summarizing recommended Python data and ML libraries
+- Added Pandas-based CSV summary endpoint under `/api/data/summary`
+- Registered the new router and wrote tests covering CSV summaries
+- Listed data analysis toolkit completion in PLAN.md
+
+## 2025-07-04
+- Implemented knowledge base article model and API
+- Added CRUD routes under /api/knowledge and tests
+- Registered the knowledge router in the app
+## 2025-07-04
+- Added workflow engine with run endpoint combining tools and protocols
+- Extended notebook entries to link projects, multiple items, protocols and images
+- Documented new features in README and updated PLAN.md
+## 2025-07-04
+- Added CalendarEvent update API and tests
+- Created calendar hooks and page on the frontend with basic form
+- Navigation includes a Calendar link
+- Documented calendar feature in README and PLAN
+
+## 2025-07-05
+- Implemented project task model and CRUD API
+- Added React hooks and Projects page to manage tasks
+- Updated navigation and README with project management section
+- Logged project task tracking completion in PLAN.md
+
+## 2025-07-06
+- Added lab network models and API endpoints for creating labs and managing connection requests
+- Created React hooks and basic labs page for viewing and connecting labs
+- Documented lab network feature in README and marked completion in PLAN
+
+## 2025-07-07
+- Implemented resource sharing models and API routes
+- Created tests covering the share request workflow
+- Documented resource sharing usage in README
+- Updated PLAN with marketplace milestone
+
+## 2025-07-08
+- Added marketplace listing and request models with CRUD API
+- Created tests verifying listing creation and request acceptance
+- Documented marketplace endpoints in README
+- Marked marketplace infrastructure complete and started marketplace interface in PLAN
+
+## 2025-07-09
+- Implemented marketplace hooks and page in the frontend
+- Added navigation link and types for listings and requests
+- Updated README with interface usage
+- Marked marketplace interface complete in PLAN
+
+## 2025-07-10
+- Added social feed models and API routes for posts and follows
+- Implemented community feed endpoints and tests
+- Documented the new feature in README and PLAN
+
+## 2025-07-11
+- Added post reporting model and API endpoints
+- Implemented moderation queue with resolve endpoint
+- Added tests covering report workflow
+- Documented moderation endpoints in README
+- Updated PLAN with community moderation milestone
+
+## 2025-07-12
+- Added `ensure_item_access` helper enforcing item ownership or team role
+- Secured relationship and barcode endpoints with new checks
+- Implemented startup audit verifying all routes require authentication
+- Added tests for unauthorized access and route audit
+- Documented security improvements in README and PLAN
+## 2025-07-03
+- Integrated Alembic migrations and created baseline
+- Added permission checks for updating and deleting inventory items
+- Rate-limited auth endpoints using SlowAPI
+\n## 2025-07-03\n- Introduced RBAC helpers enforcing team and project roles\n- Added `is_admin` column and project member roles\n- Updated team member and project endpoints to check permissions\n- Documented role system in README\n
+- Enforced SECRET_KEY presence at startup and updated tests
+
+## 2025-07-13
+- Added unique constraint on field definitions with migration
+- Implemented hierarchical location model and CRUD API
+- Inventory items reference locations via location_id
+- Documented location management in README and updated project plan
+
+
+## 2025-07-14
+- Added notebook entry signing and witnessing workflow
+- Created NotebookEntryVersion model with migration
+- Entries now create a version on each save and lock after signing
+- Implemented endpoints to sign, witness, and list versions
+- Updated README and PLAN with new feature and started refinement tracker
+
+## 2025-07-15
+- Implemented equipment maintenance, SOP, and training models
+- Added API routes for managing maintenance tasks, SOPs and training records
+- Created Alembic migration for new tables
+- Documented endpoints in README and updated project plan
+
+## 2025-07-16
+- Added inventory faceted search backend with new filters and /facets endpoint
+- Extended schemas to include status field
+- Updated tests for filtering and facets
+- Documented progress in PLAN and refinement tracker
+
+## 2025-07-17
+- Added variables field to ProtocolTemplate model and API
+- Protocol executions now validate required parameters
+- Workflow steps support optional condition expressions
+- Created migration for protocol variables
+- Documented new functionality in README and PLAN
+
+## 2025-07-18
+- Introduced structured notebook blocks stored as JSON
+- Updated schemas and endpoints to handle a `blocks` array
+- Created Alembic migration for the new columns
+- Documented block usage in README and marked task complete in PLAN
+
+## 2025-07-19
+- Added service marketplace tables and API endpoints
+- Created Alembic migration for new tables
+- Implemented tests covering service listing and request flow
+- Documented service marketplace in README and updated project plan
+
+## 2025-07-20
+- Added `is_public` and `forked_from` fields to protocol templates
+- Implemented listing of public protocols and a forking endpoint
+- Documented protocol sharing in README and added Alembic migration
+- Logged new work in refinement tracker
+
+## 2025-07-21
+- Implemented protocol merge request workflow
+- Added endpoints to create, list, accept and reject merge requests
+- Created Alembic migration and updated docs and plan
+
+## 2025-07-22
+- Added inventory forecasting endpoint to lab buddy assistant
+- New schema and tests compute projected days remaining from notebook usage
+- Documented assistant features and marked plan item complete
+
+## 2025-07-23
+- Assistant can suggest protocols and materials
+- Added /api/assistant/suggest endpoint and tests
+- Updated documentation and plan
+
+## 2025-07-24
+- Assistant can design experiments using existing protocols and knowledge articles
+- Added /api/assistant/design endpoint and tests
+- Documented new helper and updated plan
+
+## 2025-07-25
+- Added scheduled inventory alerts using daily Celery task
+- Notifications are created and emails sent when forecasted stock falls below threshold
+- Documented INVENTORY_WARNING_DAYS setting and updated plan
+
+## 2025-07-26
+- Extended service marketplace with result delivery and payment confirmation
+- Added file upload endpoint `/api/services/requests/{id}/deliver`
+- Requesters mark payment via `/api/services/requests/{id}/confirm-payment`
+- Updated models, schemas, and tests with new fields
+
+## 2025-07-27
+- Added trending protocols analytics endpoint `/api/analytics/trending-protocols`
+- Counts protocol executions from the last 30 days
+- Documented new analytics section and updated plan
+
+## 2025-07-28
+- Added article view tracking with `knowledge_article_views` table
+- `/api/knowledge/articles/{id}` now records a view
+- Added `/api/analytics/trending-articles` endpoint listing most viewed articles
+- Updated documentation and plan
+
+## 2025-07-29
+- Implemented `/api/analytics/trending-items` to report frequently referenced
+  inventory items in the last 30 days
+- Added tests and documentation for the new analytics endpoint
+- Updated roadmap to include "Trending item analytics"
+
+## 2025-07-30
+- Added frontend hooks for trending analytics endpoints
+- Analytics page now lists trending protocols, articles, and inventory items
+- Documented the new visuals in the README and project plan
+
+## 2025-07-31
+- Trending analytics endpoints now accept a `days` query parameter
+- Updated tests to cover custom date ranges
+- README documents the new parameter
+- Project plan notes the analytics timeframe feature
+
+## 2025-08-01
+- Added `is_public` flag to knowledge articles and comment support on articles
+- Introduced forum threads and posts for community discussions
+- Implemented protocol diff endpoint to compare template versions
+- Created tests for new features and documented them in the README and plan
+
+## 2025-08-02
+- Added `trending-threads` analytics endpoint counting forum posts
+- Documented the new endpoint and updated tests and schemas
+
+## 2025-08-03
+- Integrated trending forum threads into the analytics page
+- Added React hook and types for trending thread data
+- Updated README to mention threads in analytics visuals
+
+
+## 2025-08-04
+- Implemented protocol diff viewer page and hook
+- Added navigation link from protocol list
+- Documented diff viewer in README
+
+## 2025-08-05
+- Added post like endpoints and counts
+- Implemented `/api/analytics/trending-posts` ranking posts by likes
+- Updated README and plan
+
+## 2025-08-06
+- Improved trending algorithms to weight recency
+- Updated threads and posts analytics and tests
+- Documented ranking changes in README and plan
+## 2025-08-07
+- Weighted protocols, articles and item trending by recency
+- Updated README analytics documentation
+
+## 2025-08-08
+- Added protocol star endpoints and star-based trending analytics
+- Updated README and plan with new functionality
+
+\n## 2025-08-09
+- Added article star endpoints and star-based trending analytics
+- Updated README and plan
+## 2025-08-10
+- Added analytics endpoint for trending article comments
+- Updated documentation and plan
+
diff --git a/refinement.md b/refinement.md
new file mode 100644
index 0000000000000000000000000000000000000000..c71ce904350633c565a3c75c1e1f3b800e65e07e
--- /dev/null
+++ b/refinement.md
@@ -0,0 +1,83 @@
+# Refinement Roadmap
+
+This tracker outlines advanced enhancements planned after the MVP. Each section lists concrete tasks that build on the existing infrastructure to deliver a polished, production-ready experience.
+
+## Completed
+- **Notebook signing & versioning** (2025-07-14)
+  - Entries can be signed and locked by the author
+  - Witnesses may countersign locked entries
+  - Every save creates a `NotebookEntryVersion` record
+  - API endpoints support signing, witnessing and version retrieval
+- **Hierarchical locations** (2025-07-13)
+  - Added `Location` model and CRUD endpoints
+  - Inventory items reference `location_id`
+- **Equipment operations module** (2025-07-15)
+  - Schedule calibration and maintenance tasks for devices
+  - Maintain an SOP repository with version history
+  - Record user training linked to SOPs and equipment
+- **Inventory faceted search** (2025-07-16)
+  - Added sidebar filters and facets endpoint for inventory listing
+- **Protocol variables & conditional workflows** (2025-07-17)
+  - Templates define variables filled at execution time
+  - Workflow steps can be conditionally skipped
+- **Structured notebook blocks** (2025-07-18)
+  - Notebook entries store an array of rich content blocks
+  - API and schemas accept a `blocks` array
+- **Service marketplace for CRO offerings** (2025-07-19)
+  - Added service listing and request APIs
+  - Providers can accept or reject service requests
+- **Public protocol sharing** (2025-07-20)
+  - Templates include `is_public` flag and optional `forked_from` reference
+  - `/api/protocols/public` lists shared templates
+  - `/api/protocols/templates/{id}/fork` creates a copy for your team
+
+- **Protocol merge requests** (2025-07-21)
+  - Users can propose changes to public templates
+  - Authors review requests and accept or reject them
+- **Assistant protocol suggestions** (2025-07-23)
+  - `/api/assistant/suggest` recommends protocols matching a goal
+  - Returns suggested inventory items for required variables
+- **Predictive inventory alerts** (2025-07-25)
+  - Daily task checks forecasted stock levels
+  - Sends notifications or emails when items may run low
+- **Service result delivery & payment tracking** (2025-07-26)
+  - CRO providers upload results for service requests
+  - Requesters confirm payment once results are received
+- **Trending protocol analytics** (2025-07-27)
+  - `/api/analytics/trending-protocols` lists most-run templates in the last 30 days
+- **Trending article analytics** (2025-07-28)
+  - `/api/analytics/trending-articles` shows the most viewed knowledge articles in the last 30 days
+- **Trending item analytics** (2025-07-29)
+  - `/api/analytics/trending-items` lists inventory items appearing most often in notebook entries
+- **Trending thread analytics** (2025-08-02)
+  - `/api/analytics/trending-threads` lists forum threads with the most posts
+- **Protocol diff viewer** (2025-08-04)
+  - View unified diffs between protocol templates
+- **Post like analytics** (2025-08-05)
+  - Users can like posts and `/api/analytics/trending-posts` ranks them
+- **Advanced trending ranking** (2025-08-06)
+  - Trending posts and threads weighted by recency
+- **Weighted protocol, article and item analytics** (2025-08-07)
+  - Trending protocols, articles and items now factor in how recent the
+    executions, views and notebook entries occurred
+- **Protocol stars and trending by stars** (2025-08-08)
+  - Users can star templates and `/api/analytics/trending-protocol-stars`
+    lists the most starred templates weighted by recency
+- **Article stars and trending by stars** (2025-08-09)
+  - Knowledge articles can be starred and `/api/analytics/trending-article-stars`
+    lists the most starred articles weighted by recency
+- **Article comment analytics** (2025-08-10)
+  - `/api/analytics/trending-article-comments` ranks articles by recent comment activity
+
+## Next Steps
+
+## Future Opportunities
+- **Service marketplace for CRO offerings**
+  - Support service listings and request workflows
+  - Handle file delivery and payment tracking
+- **Forkable public protocols**
+  - Users may publish protocols and accept merge requests
+  - Version history shows provenance of community contributions
+- **Intelligent assistant**
+  - Analyze inventory usage to forecast shortages
+  - Suggest protocols and assemble materials lists automatically
diff --git a/tools.md b/tools.md
new file mode 100644
index 0000000000000000000000000000000000000000..e850d4f0de070293ec5fa761328b2b22e6600b26
--- /dev/null
+++ b/tools.md
@@ -0,0 +1,27 @@
+# Data Analysis & ML Tools
+
+This document outlines Python libraries that are most relevant to the BioLabs architecture. These packages can be used in custom analysis tools and notebook workflows.
+
+## Core Data Libraries
+- **NumPy** – base n-dimensional array library used for numerical computation.
+- **Pandas** – data manipulation with DataFrames, great for tabular lab data.
+- **SciPy** – scientific algorithms built on NumPy (optimization, statistics, etc.).
+
+## Visualization
+- **Matplotlib** – publication quality static plots.
+- **Seaborn** – statistical plotting built on Matplotlib.
+
+## Machine Learning
+- **scikit-learn** – classic ML algorithms and model utilities.
+- **XGBoost / LightGBM** – high performance gradient boosting.
+- **TensorFlow / PyTorch** – deep learning frameworks for complex models.
+
+## Interactive Computing
+- **JupyterLab** – notebook environment for exploratory analysis.
+
+These libraries complement existing packages like BioPython and can be installed in the backend environment to power custom scripts and analysis endpoints.
+
+## Integration Plan
+1. Add the core libraries (`numpy`, `pandas`, `scipy`, `scikit-learn`, `matplotlib`, `seaborn`) to backend requirements.
+2. Provide a simple data analysis endpoint that summarizes uploaded CSV files using Pandas.
+3. Allow analysis tools to leverage these libraries for advanced workflows.

EOF
)